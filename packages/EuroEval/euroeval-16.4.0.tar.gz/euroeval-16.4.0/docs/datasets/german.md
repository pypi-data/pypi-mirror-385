# üá©üá™ German

This is an overview of all the datasets used in the German part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.

## Sentiment Classification

### SB10k

This dataset was published in [this paper](https://aclanthology.org/W17-1106/) and is
based on German tweets, which were manually annotated by three annotators.

The original full dataset consists of 1,840 / 324 / 870 samples, and we use a 1,024 /
256 / 1,024 split for training, validation and testing, respectively. The splits are new
and there can thus be some overlap between the original validation and test sets and our
validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "ALEMANHA (4-5-1): Neuer; Schmelzer, Hummels, Mertesacker, Lahm; G√ºndogan, Khedira, √ñzil, M√ºller, Reus; Klose",
  "label": "positive"
}
```

```json
{
  "text": "@user ok. Bin jetzt dann hernach gleich nochmal weg, aber schreib ruhig.",
  "label": "neutral"
}
```

```json
{
  "text": "@user Schw√ºle 34¬∞, Tendenz steigend. #schrecklich",
  "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Im Folgenden sind Tweets und ihre Stimmung aufgef√ºhrt, die 'positiv', 'neutral' oder 'negativ' sein kann.
  ```

- Base prompt template:

  ```text
  Tweet: {text}
  Stimmungslage: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Tweet: {text}

  Klassifizieren Sie die Stimmung im Tweet. Antworten Sie mit 'positiv', 'neutral' oder 'negativ'.
  ```

- Label mapping:
  - `positive` ‚û°Ô∏è `positiv`
  - `neutral` ‚û°Ô∏è `neutral`
  - `negative` ‚û°Ô∏è `negativ`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset sb10k
```

## Named Entity Recognition

### GermEval

This dataset was published in [this paper](https://aclanthology.org/L14-1251/) and is
based on German Wikipedia as well as news articles, and was manually annotated. It
roughly follows the CoNLL-2003 format, but also allows overlapping entities and derived
entities (such as "English" for "England"). We remove the derived entities and convert
the partially overlapping entities to non-overlapping entities (e.g., `B-ORGpart` to
`B-ORG`).

The original full dataset consists of 24,000 / 2,200 / 5,100 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training,

Here are a few examples from the training split:

```json
{
  'tokens': array(['Am', 'Ende', 'der', 'Saison', '2006/07', 'soll', 'es', 'f√ºr', 'die', 'L√∂wen', 'wieder', 'zu', 'einem', 'Europapokal-Platz', 'reichen', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-LOC', 'O', 'O'], dtype=object)
}
```

```json
{
  'tokens': array(['In', 'einer', 'Stichwahl', 'gegen', 'seinen', 'Vorg√§nger', 'Georg', 'Kronawitter', 'wurde', 'Erich', 'Kiesl', 'am', '1.', 'April', '1984', 'abgew√§hlt', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```

```json
{
  'tokens': array(['Noch', 'im', '13.', 'Jahrhundert', 'wurde', 'sie', 'in', 'manchen', 'Handschriften', 'mit', 'der', 'Christherre-Chronik', 'verschmolzen', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:

  ```text
  Es folgen S√§tze und JSON-W√∂rterb√ºcher mit den benannten Entit√§ten, die in der angegebenen Phrase vorkommen.
  ```

- Base prompt template:

  ```text
  Satz: {text}
  Benannte Entit√§ten: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Satz: {text}

  Identifizieren Sie die benannten Entit√§ten im Satz. Sie sollten dies als JSON-W√∂rterbuch mit den Schl√ºsseln 'person', 'ort', 'organisation' und 'verschiedenes' ausgeben. Die Werte sollten Listen der benannten Entit√§ten dieses Typs sein, genau wie sie im Satz erscheinen.
  ```

- Label mapping:
  - `B-PER` ‚û°Ô∏è `person`
  - `I-PER` ‚û°Ô∏è `person`
  - `B-LOC` ‚û°Ô∏è `ort`
  - `I-LOC` ‚û°Ô∏è `ort`
  - `B-ORG` ‚û°Ô∏è `organisation`
  - `I-ORG` ‚û°Ô∏è `organisation`
  - `B-MISC` ‚û°Ô∏è `verschiedenes`
  - `I-MISC` ‚û°Ô∏è `verschiedenes`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset germeval
```

## Linguistic Acceptability

### ScaLA-de

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [German Universal Dependencies
treebank](https://raw.githubusercontent.com/UniversalDependencies/UD_German-GSD) by
assuming that the documents in the treebank are correct, and corrupting the samples to
create grammatically incorrect samples. The corruptions were done by either removing a
word from a sentence, or by swapping two neighbouring words in a sentence. To ensure
that this does indeed break the grammaticality of the sentence, a set of rules were used
on the part-of-speech tags of the words in the sentence.

The original dataset consists of 15,590 samples, from which we use 1,024 / 256 / 2,048
samples for training, validation and testing, respectively (so 3,328 samples used in
total). These splits are used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "Im In dem Sommer drau√üen zu sitzen ist immer wieder eine \"Wonne\", so man noch einen Platz bekommt",
  "label": "correct"
}
```

```json
{
  "text": "Eine 65 m lange Betonmauer tr√§gt nachts einen Leucht - Schriftzug \"HOSTAL HOSTILE HOTEL HOSTAGE GOSTIN OSTILE HOSTEL HOSTIL HOST\", was in seinem etymologischen Wortspiel so viel bedeutet, dass aus einem feindlichen ein gastfreundlicher Ort geworden ist, in Anspielung auf das auf dem Gel√§nde des ehemaligen Frauenlagers genau gegen√ºber liegende Novotel Goldene Bremm (heute Mercure Saarbr√ºcken - S√ºd), das konzeptionell insoweit in die Idee einbezogen ist.",
  "label": "incorrect"
}
```

```json
{
  "text": "Allerdings wurde nachgewiesen, dass sich der ebenfalls in Extremlebensr√§umen vorkommende Nematode Halicephalobus mephisto im in dem Labor bevorzugt Desulforudis audaxviator ern√§hrt, wenn er eine Wahl hat (Alternative: E. coli).",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:

  ```text
  Die folgenden S√§tze und ob sie grammatikalisch korrekt sind.
  ```

- Base prompt template:

  ```text
  Satz: {text}
  Grammatikalisch richtig: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Satz: {text}

  Bestimmen Sie, ob der Satz grammatikalisch korrekt ist oder nicht. Antworten Sie mit 'ja', wenn der Satz korrekt ist und 'nein', wenn er es nicht ist.
  ```

- Label mapping:
  - `correct` ‚û°Ô∏è `ja`
  - `incorrect` ‚û°Ô∏è `nein`

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset scala-de
```

## Reading Comprehension

### GermanQuAD

This dataset was published in [this paper](https://aclanthology.org/2021.mrqa-1.4/) and
is based on German Wikipedia articles, and was manually annotated.

The original full dataset consists of 11,518 / 2,204 samples for training and testing,
respectively. We use a 1,024 / 256 / 2,048 split for training, validation and testing,
respectively (so 3,328 samples used in total). These splits are new and there can thus
be some overlap between the original validation and test sets and our validation and
test sets.

Here are a few examples from the training split:

```json
{
  "context": "Mali\n\n=== Verwaltungsgliederung ===\nDer Staat gliedert sich in zehn Regionen und den Hauptstadtdistrikt. Diese teilen sich in 49 Kreise ''(cercles)'' und 703 Gemeinden ''(communes)''. Die Regionen sind nach ihren Hauptst√§dten benannt. Zwei dieser zehn Regionen, M√©naka und Taoud√©nit, wurden 2012 per Gesetzesbeschluss gebildet. Die Einrichtung ist seit 2016 im Gange.\nDie Angaben der Regionen Gao und Timbuktu, aus denen die Regionen M√©naka und Taoud√©nit ausgegliedert wurden, spiegeln noch den Stand vor der Aufspaltung wider.\nUm auch Fl√ºchtlinge und vor allem Nomaden in das Verwaltungssystem eingliedern zu k√∂nnen, entstanden sogenannte ''Fractions'' (''Fractions Nomades'', ein Begriff, den schon die Kolonialregierung nutzte), die es dementsprechend vor allem im Norden in der N√§he von D√∂rfern gibt. Seit den gro√üen Trockenphasen entstanden durch Wanderungsbewegungen solche Verwaltungseinheiten allerdings auch verst√§rkt im S√ºden.",
  "question": 'Wie viele verschiedene Regionen hat Mali? ',
  "answers": {
    "answer_start": array([63], dtype=int32),
    "text": array(['zehn Regionen und den Hauptstadtdistrikt'], dtype=object)
  }
}
```

```json
{
  "context": 'Iran\n\n=== Automobilindustrie ===\nIn der Automobilindustrie waren 2010 rund 500.000 Menschen besch√§ftigt, damit ist die Branche der zweitgr√∂√üte Arbeitgeber nach der √ñlindustrie und der Iran der gr√∂√üte Automobilproduzent im Mittleren Osten. 2012 ist die Automobilproduktion des Iran jedoch scharf eingebrochen; es wurden nur noch 989.110 Fahrzeuge produziert ‚Äì 40 Prozent weniger als 2011. Darunter fallen 848.000 PKW und 141.110 Nutzfahrzeuge.\nDie beiden gr√∂√üten Automobilhersteller sind die staatliche SAIPA ‚Äì derzeit im Privatisierungsprozess ‚Äì und Iran Khodro (IKCO). Die IKCO produziert neben einheimischen Modellen wie Dena und Runna in Lizenz Modelle u.\xa0a. von Peugeot. SAIPA hat die IKCO im Jahr 2010 das erste Mal in der Rangfolge √ºberholt. Nach Ansicht des Business Monitor International‚Äôs Iran Autos Report wird sich die Belastbarkeit der iranischen Automobilindustrie erst in den n√§chsten Jahren zeigen, wenn der einheimische Markt ges√§ttigt ist und der Iran zunehmend auf dem internationalen Markt agiert, denn bisher ist der Produktionsanstieg noch √ºberwiegend auf die Unterst√ºtzung der Regierung zur√ºckzuf√ºhren. 12,64 % der zugelassenen Kraftfahrzeuge werden mit Gas betrieben. Der Iran liegt damit weltweit an f√ºnfter Stelle der Nutzung von gasbetriebenen Kraftfahrzeugen.\nDer schwedische LKW-Produzent Scania er√∂ffnete 2011 eine neue Produktionslinie in Qazvin und l√∂st damit Daimler-Chrysler ab, das seine Gesch√§ftskontakte mit dem Iran abgebrochen hat.',
  "question": 'Wie hei√üen die Automodelle von Iran Khodro?',
  "answers": {
    "answer_start": array([622], dtype=int32),
    "text": array([' Dena und Runna'], dtype=object)
  }
}
```

```json
{
  "context": 'Griechenland\n\n=== Klima ===\nGriechenland hat √ºberwiegend ein mediterranes Klima mit feucht-milden Wintern und trocken-hei√üen Sommern. An der K√ºste ist es im Winter sehr mild und es regnet h√§ufig; Schnee f√§llt nur selten. Die Sommer sind relativ hei√ü und es gibt nur gelegentlich Sommergewitter. Mit 48¬∞ wurde 1977 in Griechenland der kontinentaleurop√§ische Hitzerekord gemessen.\nIm Landesinneren ist es vor allem im Winter deutlich k√ºhler und es gibt h√§ufig Nachtfrost, manchmal auch starke Schneef√§lle. Der Fr√ºhling ist kurz, verw√∂hnt aber ‚Äûmit einem Feuerwerk aus Lavendel und Anemonen, Klatschmohn und Kamille‚Äú. Im Sommer ist es √§hnlich wie an der K√ºste hei√ü und trocken. Die j√§hrlichen Niederschl√§ge schwanken zwischen 400 und 1000\xa0mm. Da Griechenland sehr gebirgig ist, ist Wintersport durchaus m√∂glich, es existieren 19 Wintersportgebiete unterschiedlicher Gr√∂√üe. Ein kleiner Teil im Nordwesten des Festlandes liegt in der gem√§√üigten Klimazone.',
  "question": 'Wie oft schneit es in Griechenland?',
  "answers": {
    "answer_start": array([209], dtype=int32),
    "text": array(['nur selten'], dtype=object)
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  Im Folgenden finden Sie Texte mit den dazugeh√∂rigen Fragen und Antworten.
  ```

- Base prompt template:

  ```text
  Text: {text}
  Fragen: {question}
  Fragen Antwort in maximal 3 W√∂rtern: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Text: {text}

  Beantworten Sie die folgende Frage zum obigen Text in h√∂chstens 3 W√∂rtern.

  Frage: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset germanquad
```

### Unofficial: XQuAD-de

This dataset was published in [this paper](https://aclanthology.org/2020.acl-main.421/)
and contains 1190 question-answer pairs from [SQuAD
v1.1](https://rajpurkar.github.io/SQuAD-explorer/) translated into ten languages by
professional translators.

The dataset is split intro 550 / 128 / 512 question-answer pairs for training,
validation, and testing, respectively.

Here are a few examples from the training split:

```json
{
    "context": "Irgendwann vor etwa einer Milliarde Jahren drang ein freilebendes Cyanobakterium in eine fr√ºhe eukaryotische Zelle ein, entweder als Nahrung oder als interner Parasit, schaffte es aber, aus der phagozytischen Vakuole zu entkommen, in der es enthalten war. Die innersten Lipiddoppelschicht-Membranen, die alle Chloroplasten umgeben, entsprechen der √§u√üeren und inneren Membran der gramnegativen Zellwand des anzestralen Cyanobakteriums und nicht der phagosomalen Membran des Wirts, die wahrscheinlich verloren ging. Der neue Zellenbewohner wurde schnell zu einem Vorteil, indem er dem eukaryotischen Wirt, welcher ihm erlaubte, in ihm zu leben, Nahrung zur Verf√ºgung stellte. Mit der Zeit wurde das Cyanobakterium assimiliert und viele seiner Gene gingen verloren oder in den Nukleus des Wirts √ºbertragen. Einige seiner Proteine wurden dann im Zellplasma der Wirtzelle synthetisiert und zur√ºck in den Chloroplasten (das ehemalige Cyanobakterium) importiert.",
    "question": "In welche Art von Zell drangen vor langer Zeit Cynaobakterien ein?",
    "answers": {
        "answer_start": array([95], dtype=int32),
        "text": array(["eukaryotische"], dtype=object)
    }
}
```

```json
{
    "context": "Im tibetischen Buddhismus werden die Dharma-Lehrer/innen gew√∂hnlich als Lama bezeichnet. Ein Lama, der sich durch Phowa und Siddhi bewusst zur Wiedergeburt, h√§ufig mehrere Male, entschlossen hat, um sein Bodhisattva-Gel√ºbte fortsetzen zu k√∂nnen, wird Tulku genannt.",
    "question": "Zu wie vielen Wiedergeburten hat sich ein Lama bereiterkl√§rt?",
    "answers": {
        "answer_start": array([164], dtype=int32),
        "text": array(["mehrere Male"], dtype=object)
    }
}
```

```json
{
    "context": "Trotz ihrer weichen, gallertartigen K√∂rper wurden Fossilien in Lagerst√§tten gefunden, die bis ins fr√ºhe Kambrium vor etwa 515 Millionen Jahren zur√ºckreichen und von denen man annimmt, dass sie Rippenquallen darstellen. Die Fossilien verf√ºgen nicht √ºber Tentakel, haben aber viel mehr Kammreihen als moderne Formen. Die Position der Rippenquallen im evolution√§ren Stammbaum der Tiere ist seit langem umstritten. Die heutigen Mehrheitsmeinung, die auf der molekularen Phylogenese basiert, geht davon aus, dass Nesseltiere und Bilateria enger miteinander verwandt sind als die Rippenquallen selbst. Eine k√ºrzlich durchgef√ºhrte Analyse der molekularen Phylogenese kam zu dem Schluss, dass der gemeinsame Vorfahre aller modernen Rippenquallen cydippida-√§hnlich war und alle modernen Gruppen erst relativ sp√§t auftauchten, wahrscheinlich nach der Kreide-Pal√§ogen-Grenze vor 66 Millionen Jahren. Die seit den 1980er Jahren ansammelnden Beweise deuten darauf hin, dass ‚ÄûCydippida‚Äú nicht monophyletisch sind. Mit anderen Worten, sie beinhalten nicht alle Nachkommen, sondern nur die Nachkommen eines einzigen gemeinsamen Vorfahren. Dies wird angenommen, da alle anderen traditionellen Gruppen von Rippenquallen Nachkommen verschiedener Cydippida sind.",
    "question": "Was fehlte den Rippenquallen-Fossilien, √ºber das heutige Rippenquallen verf√ºgen?",
    "answers": {
        "answer_start": array([253], dtype=int32),
        "text": array(["Tentakel"], dtype=object)
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  Im Folgenden finden Sie Texte mit den dazugeh√∂rigen Fragen und Antworten.
  ```

- Base prompt template:

  ```text
  Text: {text}
  Fragen: {question}
  Fragen Antwort in maximal 3 W√∂rtern: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Text: {text}

  Beantworten Sie die folgende Frage zum obigen Text in h√∂chstens 3 W√∂rtern.

  Frage: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset xquad-de
```

### Unofficial: BeleBele-de

This dataset was published in [this paper](https://aclanthology.org/2024.acl-long.44/)
and features multiple-choice reading comprehension questions across 122 languages.

The original dataset contains 900 unique multiple-choice reading comprehension passages
and questions. From these, we use a 256 / 64 / 580 split for training, validation and
testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Text: Es gibt viele Dinge, die Sie vor und w√§hrend einer Reise ber√ºcksichtigen m√ºssen. Erwarten Sie nicht, dass die Dinge beim Reisen genau so sind wie ‚Äûzuhause‚Äú. Umgangsformen, Gesetze, Essen, Verkehr, Unterk√ºnfte, Standards, Spache und so weiter werden zu einem gewissen Grad anders sein als dort, wo Sie leben. Dies ist etwas, was man immer im Hinterkopf behalten sollte, um Entt√§uschung oder gar Abneigung √ºber lokale Vorgehensweisen zu vermeiden.\nFragen: Was kann Reisenden dem Abschnitt nach helfen, Entt√§uschung beim Besuch neuer Orte zu vermeiden?\nAntwortm√∂glichkeiten:\na. √Ñhnliche Standards wie zuhause erwarten\nb. Essen probieren, das ungewohnt ist\nc. Die gleichen Gesetze wie zuhause einhalten\nd. Nicht vorher nach Unterk√ºnften recherchieren",
  "label": "b"
}
```

```json
{
  "text": "Text: Genehmigungen m√ºssen im Voraus bestellt werden. Sie ben√∂tigen eine Genehmigung, um in La Sirena zu √ºbernachten. Sirena ist die einzige Rangerstation, die neben Zelten auch √úbernachtung im Schlafsaal und warme Mahlzeiten anbietet. La Leona, San Pedrillo und Los Patos bieten nur Camping ohne Verpflegung an. Es ist m√∂glich, eine Parklizenz direkt bei der Rangerstation in Puerto Jim√©nez zu bekommen, aber sie akzeptieren keine Kreditkarten Die Parkverwaltung (MINAE) stellt Genehmigungen  f√ºr den Park nicht fr√ºher als einen Monat vor der geplanten Ankunft aus. CafeNet El Sol bietet einen Reservierungsservice gegen eine Geb√ºhr von 30 US-Dollar bzw. 10 US-Dollar f√ºr Tageskarten an. Einzelheiten dazu findet man auf deren Corcovado-Seite.\nFragen: Welche der folgenden Rangerstationen bietet zwei √úbernachtungsm√∂glichkeiten an?\nAntwortm√∂glichkeiten:\na. Sirena\nb. Los Patos\nc. La Leona\nd. San Pedrillo",
  "label": "a"
}
```

```json
{
  "text": "Text: Naturnaher Tourismus zieht Leute an, die daran interessiert sind, Naturgebiete zu besuchen, um die Landschaft zu genie√üen, einschlie√ülich der wilden Pflanzen und Tiere. Beispiele f√ºr Aktivit√§ten vor Ort sind Jagen, Angeln, Fotografie, Vogelbeobachtung, der Besuch von Parks und das Lernen von Informationen √ºber das √ñkosystem. Ein Beispiel daf√ºr ist der Besuch, das Fotografieren und das Studieren von Orangutangs in Borneo.\nFragen: Welche der folgenden Aktivit√§ten ist kein Beispiel f√ºr naturnahen Tourismus?\nAntwortm√∂glichkeiten:\na. Wandern zu einem Wasserfall\nb. Fotografieren von Wildblumen\nc. Besuch eines Wissenschaftsmuseum\nd. Fliegenfischen",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).
  ```

- Base prompt template:

  ```text
  Frage: {text}
  Antwort: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Frage: {text}
  Antwortm√∂glichkeiten:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Beantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset belebele-de
```

### Unofficial: MultiWikiQA-de

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2509.04111)
and contains Wikipedia articles with LLM-generated questions and answers in 300+
languages.

The original full dataset consists of 5,000 samples in a single split. We use a 1,024 /
256 / 2,048 split for training, validation and testing, respectively, sampled randomly.

Here are a few examples from the training split:

```json
{
    "context": "Claire Patricia Grogan (* 17. M√§rz 1962 in Glasgow, Schottland) ist eine britische Schauspielerin, Pops√§ngerin sowie Kinder- und Jugendbuchautorin.\n\nTrotz abweichender Schreibweise ist sie seit Beginn ihrer Karriere unter dem Namen Clare Grogan bekannt. Im Fernsehen trat sie sp√§ter als C.P. Grogan auf, da es in der britischen K√ºnstlergewerkschaft Equity eine andere Person gleichen Namens gab.\n\nLeben \nClare Grogan wurde vom schottischen Filmregisseur Bill Forsyth in Glasgow entdeckt, wo sie in einem Restaurant als Kellnerin arbeitete. Im Alter von 19 Jahren spielte sie die Rolle der Susan im Spielfilm Gregory‚Äôs Girl. Zu diesem Zeitpunkt feierte sie bereits als S√§ngerin der New-Wave-Band Altered Images erste Erfolge. Mit Titeln wie Happy Birthday und I Could Be Happy wurde die Band Anfang der 1980er-Jahre auch au√üerhalb Gro√übritanniens bekannt. Sie l√∂ste sich 1984 nach der Produktion des dritten Albums aufgrund nachlassenden Publikumszuspruchs auf.\n\n1987 startete Grogan den Versuch einer Solokarriere, hatte mit ihrer Single Love Bomb jedoch keinen Erfolg. Auch ihr Album Trash Mad wurde nie ver√∂ffentlicht. Musikalisch trat sie danach nur noch selten in Erscheinung. 1993 war sie an der Produktion des Musikvideos Young at Heart der Gruppe Bluebells beteiligt. Der Titel stand vier Wochen lang auf dem ersten Platz der britischen Singlecharts. 2000 steuerte sie den Gesang im Song Night Falls Like A Grand Piano aus dem Album Hyacinths and Thistles der Band The 6ths bei. Im zwei Jahre sp√§ter ver√∂ffentlichten The Ultimate Celtic Album ist sie mit dem St√ºck Her Hooped Dream vertreten. F√ºr das 2003 erschienene Album A Tribute to Frankie Miller nahm sie eine neue Version von Angels With Dirty Faces auf. Nach einer 18-j√§hrigen Pause trat sie in den 2000er-Jahren mit wechselnden Musikern mehrmals bei der Here and Now Tour, beim Rewind Festival sowie √§hnlichen Revival-Veranstaltungen in Gro√übritannien und Irland unter dem Namen Altered Images auf.\n\nIm Jahr 1985 setzte sie ihre zweite Karriere als Schauspielerin mit einer kleinen Rolle als Empfangsdame in der sechsteiligen BBC-Produktion Blott on the Landscape fort. In der Science-Fiction-Fernsehserie Red Dwarf spielte sie die Kristine Kochanski, wurde sp√§ter aber durch die Schauspielerin Chlo√´ Annett ersetzt. Weitere Auftritte in den Serien Father Ted und EastEnders sowie in den britischen Spielfilmen Bury It und The Penalty King folgten. Grogan war auch Moderatorin im Musiksender VH1 und Gastgeberin einer Talkshow. Zuweilen half sie als Sprecherin beim Radiosender BBC Radio 6 Music aus.\n\nAls Autorin deb√ºtierte Grogan im Oktober 2008 mit dem Kinderbuch Tallulah and the Teenstars. Es erz√§hlt die Geschichte einer Sch√ºlerin, die eine Popband gr√ºndet und den aufkommenden Erfolg bew√§ltigen muss. Ende 2011 erschien eine Fortsetzung mit dem Titel Tallulah on Tour.\n\n1994 heiratete Grogan den Produzenten Steve Lironi, fr√ºher selbst Gitarrist und Schlagzeuger der Altered Images. Das Paar adoptierte 2005 ein M√§dchen und lebt im Londoner Stadtbezirk London Borough of Haringey.\n\nWerke\n\nKinofilme und Fernsehproduktionen \n 1980: Gregory‚Äôs Girl\n 1984: Comfort and Joy\n 1985: Blott on the Landscape (britische Fernsehserie)\n 1988: Red Dwarf (britische Fernsehserie), Episoden The End, Balance of Power und Stasis Leak\n 1993: Red Dwarf, Episode Psirens\n 1996: Father Ted (britische Fernsehserie), Episode Rock-a-Hula Ted\n 1997: Jilting Joe\n 1997: EastEnders (britische Fernsehserie), zwei Episoden\n 2002: Bury It\n 2006: The Penalty King\n 2007: Legit (britische Fernsehserie), Episoden Birthday, Manitoba und Night of the Lobster\n 2011: Skins ‚Äì Hautnah, Episode Mini\n 2012: Waterloo Road (britische Fernsehserie), Episode Future Proof\n\nB√ºcher \n 2008: Tallulah and the Teenstars\n 2011: Tallulah on Tour\n\nWeblinks\n\nEinzelnachweise \n\nFilmschauspieler\nAutor\nPops√§nger\nLiteratur (21. Jahrhundert)\nLiteratur (Englisch)\nKinder- und Jugendliteratur\nMusiker (Vereinigtes K√∂nigreich)\nPerson (Glasgow)\nSchotte\nBrite\nGeboren 1962\nFrau",
    "question": "Was war Clare Grogans T√§tigkeit, bevor sie von Bill Forsyth entdeckt wurde?",
    "answers": {
        "answer_start": array([519]),
        "text": array(["Kellnerin"], dtype=object)
    }
}
```

```json
{
    "context": "Claris International Inc. (bis August 2019 FileMaker, Inc.) ist eine hundertprozentige US-amerikanische Tochtergesellschaft des kalifornischen Computerherstellers Apple, die die Datenbanksoftware FileMaker entwickelt. Die Firma FileMaker entstand 1998 als Nachfolgerin von Claris, die ihrerseits 1987 als Ableger von Apple gegr√ºndet worden war.\n\nGeschichte \nClaris wurde Anfang 1998 aufgel√∂st. Das Programm FileMaker Pro wurde Grundlage des neu gegr√ºndeten Unternehmens FileMaker, Inc.\n\nProdukte von Claris waren:\n ClarisCAD, ein CAD-Programm\n Claris MacDraw, ein Zeichenprogramm\n Claris Em@iler, ein E-Mail-Programm\n FileMaker, sp√§ter FileMaker Pro, das dominierende Datenbankprogramm auf der Macintosh-Plattform\n Claris Home Page, ein HTML-Editor\n Claris Impact, ein Pr√§sentationsprogramm\n Claris MacWrite Pro, eine Textverarbeitung\n Claris Organizer, ein Personal Information Manager\n Claris Resolve, eine Tabellenkalkulation\n ClarisWorks, ein B√ºropaket, das sp√§ter von Apple als AppleWorks weitergef√ºhrt wurde\n Claris MacPaint, ein Bildbearbeitungsprogramm\n\nVon 2008 bis 2013 wurde die pers√∂nliche Datenbankanwendung Bento verkauft.\n\nIm August 2019 gab das Unternehmen bekannt, zum alten Unternehmensnamen Claris zur√ºckzukehren.\n\nEinzelnachweise \n\nApple\nSoftwarehersteller (Vereinigte Staaten)\nUnternehmen (Santa Clara, Kalifornien)\nGegr√ºndet 1998",
    "question": "Unter welchem Namen war FileMaker, Inc. fr√ºher bekannt, bevor es in Claris International Inc. umbenannt wurde?",
    "answers": {
        "answer_start": array([31]),
        "text": array(["August 2019"], dtype=object)
    }
}
```

```json
{
    "context": "Augusta Marie Gertrude von Hanau (* 21. September 1829 in Niederdorfelden; ‚Ä† 18. September 1887 in Halle) war die unehelich geborene √§lteste Tochter des Kurf√ºrsten Friedrich Wilhelm I. von Hessen-Kassel (1802‚Äì1875) und seiner erst sp√§teren Ehefrau Gertrude, sp√§tere F√ºrstin von Hanau und zu Ho≈ôowitz (1803‚Äì1882).\n\nKurprinz Friedrich Wilhelm lernte seine Frau kennen, als diese noch mit dem Leutnant Karl Michael Lehmann (1787‚Äì1882) verheiratet war, beging mit ihr Ehebruch, erreichte schlie√ülich die Scheidung und heiratete sie 1831. Augusta Marie Gertrude wurde so zu einer Zeit geboren, als ihre Mutter noch eine verheiratete Lehmann war. Sie wurde deshalb zun√§chst vom damaligen Mann ihrer Mutter als ehelich anerkannt. Erst nach der Scheidung und der Heirat von Gertrude Lehmann mit dem Kurprinzen verzichtete Karl Michael Lehmann auf die Vaterschaftsrechte. Augusta Marie Gertrude Lehmann wurde nun von ihrem leiblichen Vater zur Gr√§fin Schaumburg und sp√§ter zur Prinzessin von Hanau erhoben.\n\nAm 17. Juli 1849 heiratete sie den Grafen Ferdinand Maximilian zu Ysenburg-B√ºdingen (* 24. Oktober 1823; ‚Ä† 5. Mai 1903). Dieser war mental wohl etwas gest√∂rt. Nachdem eine Kasseler Zeitung 1853 seine Frau ‚ÄûErlaucht‚Äú statt ‚ÄûDurchlaucht‚Äú betitelt hatte, griff er den Ersten Minister seines Schwiegervaters, Ludwig Hassenpflug, t√§tlich an und verletzte ihn mit Stockschl√§gen. Er kam darauf vor√ºbergehend in eine Klinik. 1865 wurde er durch den Kurf√ºrsten in den F√ºrstenstand erhoben und nannte sich nun Ferdinand-Maximillian I.\n\nF√ºrstin Augusta Marie Gertrude hatte ein sehr enges Verh√§ltnis zu ihrem Vater. Als er 1866 nach dem gegen Preu√üen verlorenen Krieg in Stettin als Kriegsgefangener einsa√ü, besuchte sie ihn.\n\nSie starb in Halle, wohin sie ihren Mann begleitet hatte, der sich dort einer Operation unterziehen musste.\n\nLiteratur \n R√ºdiger Ham: Ludwig Hassenpflug: Staatsmann und Jurist zwischen Revolution und Reaktion. Eine politische Biographie = Studien zur Geschichtsforschung der Neuzeit 50. Hamburg 2007. ISBN 978-3-8300-2764-5\nMichel Huberty: L' Allemagne dynastique: Les 15 familles qui ont fait l'empire. Bd. 1: Hesse - Reuss - Saxe. Le Perreux-sur-Marne 1976. ISBN 2-901138-01-2\n Philipp Losch: Die F√ºrstin von Hanau und ihre Kinder. In: Hanauer Geschichtsbl√§tter 13 (1939), S. 33.\n\nWeblinks\n\nEinzelnachweise \n\nFriedrich Wilhelm I. (Hessen-Kassel)\nTitularf√ºrst (Isenburg)\nFamilienmitglied des Hauses Hanau-Ho≈ôovice\n‚ö≠Augusta Marie Gertrude #Hanau\nDeutscher\nGeboren 1829\nGestorben 1887\nFrau",
    "question": "Wann wurde Ferdinand Maximilian von Ysenburg-B√ºdingen F√ºrst?",
    "answers": {
        "answer_start": array([1416]),
        "text": array(["1865"], dtype=object)
    }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:

  ```text
  Im Folgenden finden Sie Texte mit den dazugeh√∂rigen Fragen und Antworten.
  ```

- Base prompt template:

  ```text
  Text: {text}
  Fragen: {question}
  Fragen Antwort in maximal 3 W√∂rtern: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Text: {text}

  Beantworten Sie die folgende Frage zum obigen Text in h√∂chstens 3 W√∂rtern.

  Frage: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset multi-wiki-qa-de
```

## Knowledge

### MMLU-de

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
German was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "Teotihuac√°n wurde im Becken von Mexiko bekannt, nachdem sein Rivale Cuicuilco,\nAntwortm√∂glichkeiten:\na. von einem Vulkanausbruch gel√§hmt wurde.\nb. einem B√ºrgerkrieg unter seinen herrschenden Familien erlag.\nc. unter einer Ernteplage litt.\nd. von einem Hurrikan an der Golfk√ºste √ºberschwemmt wurde.",
  "label": "a"
}
```

```json
{
  "text": "Wer von den folgenden ist der industrielle Philanthrop?\nAntwortm√∂glichkeiten:\na. Frederick Taylor\nb. Seebohm Rowntree\nc. Henry Ford\nd. Max Weber",
  "label": "b"
}
```

```json
{
  "text": "Verglichen mit der Varianz der Maximum-Likelihood-Sch√§tzung (MLE) ist die Varianz der Maximum-A-Posteriori (MAP)-Sch√§tzung ________\nAntwortm√∂glichkeiten:\na. h√∂her\nb. gleich\nc. niedriger\nd. es kann jede der obigen Optionen sein",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).
  ```

- Base prompt template:

  ```text
  Frage: {text}
  Antwort: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Frage: {text}
  Antwortm√∂glichkeiten:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Beantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mmlu-de
```

### Unofficial: ARC-de

This dataset is a machine translated version of the English [ARC
dataset](https://doi.org/10.48550/arXiv.1803.05457) and features US grade-school science
questions. The translation to German was done by the University of Oregon as part of
[this paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 1,110 / 297 / 1,170 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training,
validation and testing, respectively (so 2,304 samples used in total). All new splits
are subsets of the original splits.

Here are a few examples from the training split:

```json
{
  "text": "Callahan zitiert die Ergebnisse des Oregon Death with Dignity Legal Defense and Education Center, wonach es \"nach vier vollen Jahren keine Missteps, Missbr√§uche oder Zwangstendenzen\" bez√ºglich der Gesetze zur Euthanasie gab. Er argumentiert dagegen, dass\nAntwortm√∂glichkeiten:\na. sie dies ohne eine anonyme Umfrage nicht sicher wissen k√∂nnen.\nb. andere Studien haben widerspr√ºchliche Ergebnisse gefunden.\nc. selbst wenn das Ergebnis wahr ist, ist es irrelevant f√ºr den moralischen Status der Euthanasie.\nd. die Ergebnisse sind verd√§chtig, weil die Studie von Bef√ºrwortern der Euthanasie durchgef√ºhrt wurde.",
  "label": "a"
}
```

```json
  "text": "Eine Frau besa√ü ein Land im absoluten Besitz. Die Frau √ºbertrug das Land an einen Freund ‚Äúauf Lebenszeit‚Äù und als der Freund starb, sollte das Land an den Nachbarn der Frau \"und ihre Erben\" weitergegeben werden. Der Nachbar starb und in ihrem ordnungsgem√§√ü beglaubigten Testament vermachte sie ihre gesamte Hinterlassenschaft an eine √∂rtliche Wohlt√§tigkeitsorganisation. Wenn sie intestat gestorben w√§re, w√§re ihre Tochter ihre einzige Erbin gewesen. Ein Jahr nach dem Tod des Nachbarn √ºbertrug dessen Tochter durch eine Quitclaims-Erkl√§rung jegliches Interesse, das sie an dem Land haben k√∂nnte, an die Freundin der Frau. Das Common Law Rule Against Perpetuities ist in der Gerichtsbarkeit unver√§ndert. Es gibt keine weiteren anwendbaren Gesetze. Wer hat welches Interesse an dem Land?\nAntwortm√∂glichkeiten:\na. Der Freund hat einen absoluten Besitz, weil sein Lebensbesitz mit dem verbleibenden Teil verschmolzen ist, den ihm die Tochter √ºbertragen hat.\nb. Der Freund hat einen Lebensbesitz und die Wohlt√§tigkeitsorganisation hat einen unverfallbaren Rest, weil das Interesse des Nachbarn √ºbertragbar war.\nc. Der Freund hat einen Lebensbesitz und die Tochter hat einen unverfallbaren Rest, weil die Erkl√§rung der Frau ein Interesse an den Erben des Nachbarn schuf.\nd. Der Freund hat einen Lebensbesitz und die Frau hat einen R√ºckfall, weil das Restinteresse des Nachbarn gem√§√ü dem Rule Against Perpetuities ung√ºltig war.",
  "label": "b"
}
```

```json
{
  "text": "F√ºr welches dieser beiden Szenarien tut der Hauptcharakter (der ich/mich/mein verwendet) etwas, das nach den gew√∂hnlichen moralischen Standards in den USA im Jahr 2020 eindeutig moralisch falsch ist? Szenario 1 | Ich gehe gerne in die Kirche, weil es mich in h√∂chstem Ma√üe Gott nahe f√ºhlen l√§sst. Szenario 2 | Ich habe den Test meines Nachbarn angesehen, um eine gute Note zu bekommen.\nAntwortm√∂glichkeiten:\na. Falsch, Falsch\nb. Falsch, Nicht falsch\nc. Nicht falsch, Falsch\nd. Nicht falsch, Nicht falsch",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).
  ```

- Base prompt template:

  ```text
  Frage: {text}
  Antwort: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Frage: {text}
  Antwortm√∂glichkeiten:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Beantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset arc-de
```

## Common-sense Reasoning

### HellaSwag-de

This dataset is a machine translated version of the English [HellaSwag
dataset](https://aclanthology.org/P19-1472/). The original dataset was based on both
video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset
was translated by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split
for training, validation and testing, respectively (so 3,328 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "[header] Wie man sich trennt, wenn Kinder involviert sind [title] Erstellen Sie einen Trennungsplan mit Ihrem Partner. [step] Sie sollten sich auch auf das Gespr√§ch mit Ihren Kindern vorbereiten, indem Sie vorher mit Ihrem Partner einen Plan f√ºr die Zukunft erstellen. Sie sollten gemeinsam besprechen, wer wo leben wird, wer f√ºr bestimmte t√§gliche Bed√ºrfnisse und Aktivit√§ten der Kinder verantwortlich sein wird und wann der offizielle Scheidungsprozess beginnen wird.\nAntwortm√∂glichkeiten:\na. Indem Sie hier√ºber klare Vorstellungen haben, k√∂nnen Sie Ihre Kinder besser beruhigen und einheitlich auftreten. [substeps] Zum Beispiel, k√∂nnten Sie vereinbaren, dass Ihr Partner auszieht und in einer nahegelegenen Wohnung oder einem anderen Haus lebt.\nb. Sie beide sollten Ihre Aktionen in den Monaten bis zur Eheschlie√üung sowie dar√ºber, wie Sie alles tun werden, planen, sobald das Kind wieder mit seinem Vater vereint ist. [title] Entscheiden Sie, was Sie mit dem Kind machen werden.\nc. Stellen Sie sicher, dass Ihr Partner einverstanden ist und zustimmt, immer Pausen zu machen. [substeps] Sie sollten sich nun auf die Urlaubsdaten und Reisepl√§ne einigen, zu denen Ihre Kinder gehen werden.\nd. Der erste Schritt zu diesem Plan ist, ein Telefongespr√§ch zu vereinbaren, damit Sie mit Ihrem Partner pers√∂nlich sprechen k√∂nnen. Sprechen Sie ruhig und deutlich, um den Ton f√ºr dieses Gespr√§ch zu setzen.",
  "label": "a"
}
```

```json
{
  "text": "[header] Wie man Festival-Make-up macht [title] Bereiten Sie Ihr Gesicht vor. [step] Bevor Sie Ihr Augen-Make-up auftragen, m√ºssen Sie eine Basis schaffen. Dies hilft sicherzustellen, dass Ihr Augen-Make-up den ganzen Tag h√§lt.\nAntwortm√∂glichkeiten:\na. [substeps] Zeichnen Sie eine runde, quadratische oder diagonale Linie um Ihr Auge. Verfolgen Sie den Kreis um Ihr Auge und ziehen Sie dann einen rechteckigen Streifen in der Mitte.\nb. [substeps] Beginnen Sie mit einem sauberen, mit Feuchtigkeit versorgten Gesicht. Reinigen Sie Ihr Gesicht zun√§chst mit einem sanften Reinigungsmittel und tragen Sie dann einen leichten Feuchtigkeitsspender auf Ihr Gesicht und Ihren Hals auf, um das Erscheinungsbild feiner Linien zu reduzieren.\nc. Bevor Sie Lidschatten auftragen, w√§hlen Sie einen einzelnen Lidschatten aus und messen Sie ihn so aus, dass er etwas gr√∂√üer ist als das Auge, das Sie verblenden m√∂chten. Tragen Sie den Lidschatten auf die Spitze jedes Auges auf und streichen Sie mit einem Verblendpinsel dar√ºber.\nd. Make-up am fr√ºhen Morgen zu tragen ist nicht immer eine Option, aber Sie k√∂nnen es am Abend tun. [substeps] Duschen Sie, um Ihre Haut sauber und mit Feuchtigkeit versorgt zu halten.",
  "label": "b"
}
```

```json
{
  "text": "Wir sehen einen Mann in einem Orchester Grimassen schneiden. Der Mann steht dann auf und spielt die Violine. Wir sehen Menschen an Spinden. wir\nAntwortm√∂glichkeiten:\na. sehen Menschen in einem Bus.\nb. sehen Menschen beim √úben von Kampfsport und Musik spielen.\nc. kehren zum Mann zur√ºck, der die Violine spielt.\nd. sehen den Mann am Keyboard wieder.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).
  ```

- Base prompt template:

  ```text
  Frage: {text}
  Antwort: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Frage: {text}
  Antwortm√∂glichkeiten:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Beantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset hellaswag-de
```

### Unofficial: GoldenSwag-de

This dataset is a filtered and machine translated version of the English [HellaSwag
dataset](https://aclanthology.org/P19-1472/), featuring both video descriptions from
ActivityNet as well as how-to articles from WikiHow. The machine translated version was
published in [this paper](https://doi.org/10.48550/arXiv.2410.08928) and was done using
DeepL, and the filtering was published in [this
paper](https://doi.org/10.48550/arXiv.2504.07825), which resulted in higher quality
samples.

The original full dataset consists of 1530 / 1530 samples for training and validation,
respectively. However, they are exactly equal. We use a split of 660 / 256 / 2,048
samples for training, validation, and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Wie man Rouge auftr√§gt. Verwenden Sie die richtige Art von Pinsel. Die Art des Pinsels h√§ngt davon ab, wo Sie das Rouge auftragen wollen. Da Sie das Rouge nicht nur auf die Wangen√§pfel auftragen werden, sollten Sie f√ºr kleinere Bereiche einen kleineren Pinsel verwenden.\nAntwortm√∂glichkeiten:\na. F√ºr die Wangen k√∂nnen Sie einen normalen Rougepinsel verwenden. Manche empfehlen, f√ºr die kleineren Gesichtspartien einen Abdeckpinsel zu verwenden.\nb. Je kleiner der Pinsel ist, desto mehr Rouge m√ºssen Sie auf Ihre Wangen auftragen. √úberpr√ºfen Sie auf der Verpackung die richtige Pinselgr√∂√üe f√ºr diesen Bereich.\nc. W√§hlen Sie den Pinsel, der am besten zu Ihrem Haartyp passt. Bei lockigem Haar verwenden Sie einen gr√∂√üeren Pinsel f√ºr d√ºnneres Haar und einen kleineren Pinsel f√ºr d√ºnnes Haar.\nd. F√ºr gr√∂√üere Fl√§chen k√∂nnen Sie einen Tubenpinsel oder einen Pinsel in einer anderen Farbe verwenden, um ein Zusammenfallen zu vermeiden. Verwenden Sie einen Pinsel mit Borsten in der Farbe Ihrer Grundierung, damit die abgerundeten Borsten weniger auffallen.",
  "label": "a"
}
```

```json
{
  "text": "Wie Sie einen Redakteur auf sich aufmerksam machen k√∂nnen. Lesen und befolgen Sie die Einreichungsrichtlinien der Publikation. Publikationen erstellen Einreichungsrichtlinien, um es sowohl den Autoren als auch den Redakteuren leichter zu machen. Wenn Sie die Richtlinien lesen und befolgen, erstellen Sie einen Beitrag, der den Anforderungen der Publikation entspricht, was es f√ºr Sie als Autor einfacher macht, und zwar in einem Format, das die Redakteure leichter auf Eignung und Qualit√§t pr√ºfen k√∂nnen.\nAntwortm√∂glichkeiten:\na. Vermeiden Sie es, den Namen und die Ver√∂ffentlichungsseite der Publikation vollst√§ndig zu blockieren. Wenn die Publikation nicht sehr k√ºnstlerisch ist, wird sie vielleicht gar nicht ver√∂ffentlicht.\nb. Vergewissern Sie sich, dass Ihr Artikel diesen Richtlinien entspricht, wenn Sie sich um eine Stelle als Redakteur bewerben. Bei einigen Stellen m√ºssen Sie eine bestimmte Menge an Arbeit leisten, um eine Redakteursstelle zu erhalten, w√§hrend bei anderen ein Minimum von 30 Arbeitsstunden erforderlich ist.\nc. Die meisten Publikationen mit Internetpr√§senz bieten ihre Richtlinien f√ºr die Einreichung von Beitr√§gen auf ihren Websites an. Wenn dies nicht der Fall ist, k√∂nnen Sie die Richtlinien erhalten, indem Sie an die angegebene Adresse der Publikation schreiben.\nd. Bitten Sie die Autoren am Ende der Ver√∂ffentlichung, Ihre Arbeit regelm√§√üig zu ver√∂ffentlichen. Heben Sie in Ihrem Beitrag wichtige Aspekte hervor, damit Sie nicht von der Publikation ausgeschlossen werden.",
  "label": "c"
}
```

```json
{
  "text": "Wie Sie Hundegeruch aus Ihrem Auto entfernen. Waschen Sie alle abnehmbaren Teile Ihres Autos. Alle Teile Ihres Autos, die Sie abnehmen k√∂nnen, sollten Sie in der Waschmaschine waschen. Dadurch wird der Hundegeruch entfernt und Ihr Auto riecht wieder frischer.\nAntwortm√∂glichkeiten:\na. Wenn Sie feststellen, dass Ihr Auto nach Ihnen riecht, wenn Sie es ausstecken, sollten Sie die Teile 5 Minuten in warmem Wasser und 20 Minuten in kaltem Wasser einweichen. Wenn Sie ein Stra√üenfest veranstalten, verwenden Sie einen Trichter, um Plastikteile in die Waschmaschine zu bef√∂rdern, w√§hrend die √§u√üeren Teile weggeworfen werden.\nb. Gummimatten, Autositzbez√ºge und alle Decken, die Sie f√ºr Ihren Hund aufbewahren, k√∂nnen entfernt und gewaschen werden. Waschen Sie die Teile Ihres Autos sicherheitshalber bei einer k√ºhlen Temperatur.\nc. Eine Schicht Antitranspirant hingegen entfernt nur das Produkt, und Ihr Auto riecht wahrscheinlich schon nach Urin. Wenn Ihr Auto mit Ledersitzen ausgestattet ist, wischen Sie das Produkt, das sich dort angesammelt hat, ab.\nd. Am sichersten ist es, alle abnehmbaren Teile Ihres Autos zu entfernen, einschlie√ülich der "Fifflers". Diese Teile k√∂nnen bei hei√üem Wetter leicht stinken, aber sie k√∂nnen auch schwitzen und den Eigengeruch Ihres Hundes produzieren.",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).
  ```

- Base prompt template:

  ```text
  Frage: {text}
  Antwort: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Frage: {text}
  Antwortm√∂glichkeiten:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Beantworten Sie die obige Frage mit 'a', 'b', 'c' oder 'd', und nichts anderes.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset goldenswag-de
```

### Unofficial: Winogrande-de

This dataset was published in [this paper](https://doi.org/10.48550/arXiv.2506.19468)
and is a translated and filtered version of the English [Winogrande
dataset](https://doi.org/10.1145/3474381).

The original full dataset consists of 47 / 1,210 samples for training and testing, and
we use 128 of the test samples for validation, resulting in a 47 / 128 / 1,085 split for
training, validation and testing, respectively.

Here are a few examples from the training split:

```json
{
  "text": "Einmal in Polen genoss Dennis die Reise mehr als Jason, weil _ ein tieferes Verst√§ndnis der polnischen Sprache hatte. Worauf bezieht sich der leere _?\nAntwortm√∂glichkeiten:\na. Dennis\nb. Jason",
  "label": "a"
}
```

```json
{
  "text": "Johns Zertifizierung war weniger wichtig als Jims Abschluss, weil die _ von einer unbedeutenden Universit√§t war. Worauf bezieht sich der leere _?\nAntwortm√∂glichkeiten:\na. Zertifizierung\nb. Abschluss",
  "label": "a"
}
```

```json
{
  "text": "Um Verhaltensverzerrungen zu √ºberwinden, m√ºssen wir uns mehr darauf konzentrieren, die bewussten Handlungen zu √§ndern, anstatt die unbewussten Handlungen, weil die _ Handlungen freiwillig sind. Worauf bezieht sich der leere _?\nAntwortm√∂glichkeiten:\na. unbewusst\nb. bewusst",
  "label": "b"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:

  ```text
  Die folgenden Fragen sind Multiple-Choice-Fragen (mit Antworten).
  ```

- Base prompt template:

  ```text
  Frage: {text}
  Antwort: {label}
  ```

- Instruction-tuned prompt template:

  ```text
  Frage: {text}
  Antwortm√∂glichkeiten:
  a. {option_a}
  b. {option_b}

  Beantworten Sie die obige Frage mit 'a' oder 'b', und nichts anderes.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset winogrande-de
```

## Summarisation

### MLSum-de

This dataset was published in [this
paper](https://aclanthology.org/2020.emnlp-main.647/) and features news articles and
their summaries in five languages, including German. The German part of the dataset is
based on news articles from S√ºddeutsche Zeitung, with human-written summaries.

The original full dataset consists of 221,000 / 11,400 / 10,700 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). All new splits
are subsets of the original splits.

Here are a few examples from the training split:

```json
{
  "text": "Jede neue Schlagzeile ein Stich ins Herz: F√ºhrende Muslime beklagen in einem offenen Brief die wachsende \"Feindseligkeit\" gegen Migranten in Deutschland. Sie fordern Bundespr√§sident Wulff auf, Stellung zu beziehen. In einem offenen Brief haben 15 namhafte deutsche Muslime Bundespr√§sident Christian Wulff aufgefordert, in der schwelenden Debatte um Integrationsprobleme Stellung zu beziehen. Ausl√∂ser der Kontroverse war das Buch Deutschland schafft sich ab des SPD-Politikers und scheidenden Bundesbankvorstandes Thilo Sarrazin. Detailansicht √∂ffnen In der von SPD-Politiker und Noch-Bundesbanker Thilo Sarrazin ausgel√∂sten Integrationsdebatte fordern namhafte deutsche Muslime nun von Bundespr√§sident Christian Wulff, Stellung zu beziehen. (Foto: dpa) Intellektuelle wie der Regisseur Fatih Akin und der Schriftsteller Feridun Zaimoglu beklagten in dem in der taz ver√∂ffentlichten Brief wachsende \"Feindseligkeit\" gegen Muslime in Deutschland. W√∂rtlich hei√üt es: \"F√ºr Musliminnen und Muslime ist derzeit nicht einmal der Gang zum Zeitungsh√§ndler leicht, weil sie nie wissen, welche Schlagzeile, welches stereotype Bild sie dort erwartet.\" Die Unterzeichner erinnerten Wulff an seine Antrittsrede, in der er die Chancen der Integration betont hatte. \"Wir bitten Sie, gerade in der derzeitigen angespannten Stimmung f√ºr die Leits√§tze einer offenen, von gegenseitigem Respekt gepr√§gten demokratischen Kultur einzustehen und √∂ffentlich f√ºr sie zu werben\", hei√üt es in dem Appell an Wulff. Ausl√∂ser f√ºr den offenen Brief sei der Aufruf der Bild-Zeitung gewesen, an Pr√§sident Wulff zu schreiben, sagte Shermin Langhoff, Intendantin des Berliner Theaters Ballhaus Naunynstra√üe. \"Wir dachten uns, das k√∂nnen wir nicht so stehen lassen\", sagte die Mitunterzeichnerin zur SZ. Sie sprach von \"biologistischen Wahnthesen\" Sarrazins und hofft auf ein \"Wort der Vernunft\" aus Bellevue. Auch andere Unterzeichnerinnen setzen darauf, dass sich das Staatsoberhaupt in die Debatte einschaltet. Aylin Selcuk, Initiatorin des Vereins Deukische Generation, w√ºnscht sich ein starkes Zeichen Wulffs. Der Pr√§sident m√∂ge zeigen, dass die Muslime in Deutschland dazugeh√∂ren. \"Wir bitten Sie: Bekennen Sie sich zu uns.\" Lamya Kaddor vom Liberal-Islamischen Bund sprach von einem \"√∂ffentlichen Bekenntnis\" des Pr√§sidenten. In der laufenden Debatte gehe es nicht nur um Muslime, sondern um den \"Zusammenhalt in der Gesellschaft\", warnte Selcuk. Die Studentin hatte Sarrazin nach seinen √Ñu√üerungen zur vererbten Intelligenz wegen Volksverhetzung angezeigt. Seitdem erreichten sie unz√§hlige E-Mails, in denen sie geschm√§ht und bedroht werde, sagte Selcuk. Nun hofft sie auf Wulff. \"Wir werden dieses Land nicht aufgeben\", hei√üt es in dem Brief an Christian Wulff. \"Dieses Land ist unsere Heimat und Sie sind unser Pr√§sident.\"",
  "target_text": "Jede neue Schlagzeile ein Stich ins Herz: F√ºhrende Muslime beklagen in einem offenen Brief die wachsende \"Feindseligkeit\" gegen Migranten in Deutschland. Sie fordern Bundespr√§sident Wulff auf, Stellung zu beziehen."
}
```

```json
{
  "text": "Hoch flog der erste Schl√§ger in die Luft, und viele andere Gegenst√§nde folgten ihm. √úberall auf dem Eis lag die Ausr√ºstung der deutschen Mannschaft zerstreut, Handschuhe, Helme, Schl√§ger, weg damit, wer braucht so etwas schon, wenn er hemmungslos jubeln kann? In einer Ecke des Eises versammelten sich die Spieler der deutschen Eishockey-Mannschaft. Sie h√ºpften und tanzten und schrien, und wenn es nicht zu den Gepflogenheiten des Sports z√§hlen w√ºrde, irgendwann zum H√§ndesch√ºtteln mit dem Gegner in der Mitte des Feldes zu erscheinen, dann h√§tten sie wahrscheinlich noch eine ganze Weile so weitergemacht. Es war nun wirklich ein sporthistorischer Moment, den das Team des Deutschen Eishockey-Bundes (DEB) dort zelebrierte. Mit 4:3 (1:0, 3:1, 0:2) hatte es in einem ph√§nomenalen Spiel den Rekord-Olympiasieger Kanada bezwungen und sich damit f√ºr das Finale des Turniers gegen die Olympischen Athleten aus Russland (5.10 Uhr MEZ) qualifiziert. Zum ersten Mal √ºberhaupt kann eine deutsche Mannschaft Olympiasieger werden, es ist der gr√∂√üte Erfolg in der Geschichte des deutschen Eishockeys. \"Verr√ºckt, ne, verr√ºckt, verr√ºckte Welt\", sagte Bundestrainer Marco Sturm: \"Das ist einmalig.\" Ein ohnehin schon irres Turnier kulminiert in diesem 4:3 im Halbfinale Ja, einmalig war es in der Tat, was seine Mannschaft da geleistete hatte. Und es war interessant mitzuerleben, wie nach dem Spiel ein Akteur nach dem anderen in die Kabine trottete und sich unterwegs kurz den Journalisten stellte. Da war etwa der Torwart Danny aus den Birken, der v√∂llig ausgelaugt war. Oder Defensivspieler Moritz M√ºller, der seine Tr√§nen kaum halten konnte. Oder die NHL-gest√§hlten Routiniers Christian Erhoff und Marcel Goc, die schon so viel erlebt haben, aber so etwas wie an diesem Abend dann doch noch nicht. Keiner hatte schon so recht begriffen, was da geschehen war, und keiner wollte zu gro√üen sportfachlichen Analysen ansetzen, als es um die Gr√ºnde f√ºr den Erfolg ging. Ein jeder sagte nur: Team. Mannschaft. Teamgeist. Mannschaftsgeist. Diese W√∂rter fallen oft im Sport, aber soweit sich das von au√üen beurteilen l√§sst, trifft das bei den Eishockey-Spielern tats√§chlich zu. Sturm hat in den drei Jahren eine bemerkenswerte Mannschaft geformt, die ohnehin ein irres Turnier spielt. Das knappe 0:1 gegen Schweden in der Vorrunde, der Penalty-Sieg √ºber Norwegen, der Erfolg nach Verl√§ngerung gegen die Schweiz, das denkw√ºrdige 4:3 gegen Schweden im Viertelfinale. Aber all das kulminierte jetzt in diesem 4:3 gegen Kanada im Halbfinale. In einem \"Jahrhundertspiel\", wie Alfons H√∂rmann, Pr√§sident des Deutschen Olympischen Sportbundes, nicht ganz zu Unrecht schw√§rmte.",
  "target_text": "Nach dem sensationellen 4:3-Sieg gegen Kanada kann das deutsche Eishockey-Team erstmals Olympiasieger werden. Im Finale ist der Gegner der Favorit - doch die Mannschaft von Marco Sturm glaubt an sich."
}
```

```json
{
  "text": "Monatelang haben Sicherheitsbeh√∂rden nach Salah Abdeslam gefahndet. Jetzt ist der 26-j√§hrige Terrorverd√§chtige festgenommen worden. Er soll an den Anschl√§gen von Paris beteiligt gewesen sein, bei denen am 13. November drei Killerkommandos 130 Menschen get√∂tet hatten. Was man bisher √ºber den Mann wei√ü Salah Abdeslam ist in Br√ºssel geboren, aber franz√∂sischer Staatsb√ºrger. Er ist der Bruder des Selbstmordattent√§ters Brahim, der ebenfalls bei den Anschl√§gen dabei war. Die verst√ºmmelte Leiche des 31-j√§hrigen Brahim Abdeslam hatte die Polizei am Tag des Anschlags am Boulevard Voltaire in der N√§he des Konzertsaals Bataclan gefunden, wo er sich in die Luft gesprengt hatte. Salah wohnte im Br√ºsseler Vorort Molenbeek, der als eine Hochburg von gewaltbereiten Islamisten in Belgien gilt. Abdeslam soll in Deutschland gewesen sein Laut Recherchen des SWR soll sich Abdeslam Anfang Oktober 2015 kurzzeitig in Baden-W√ºrttemberg aufgehalten und dort wom√∂glich Komplizen abgeholt haben. Demnach fuhr er in der Nacht vom 2. auf den 3. Oktober 2015 mit einem auf seinen Namen angemieteten Wagen nach Ulm und offenbar nach etwa einer Stunde wieder zur√ºck. Er k√∂nnte in Ulm laut SWR drei M√§nner, die sich als Syrer ausgegeben hatten, aus einer Fl√ºchtlingsunterkunft abgeholt haben. Bei einer Anwesenheitskontrolle am 3. Oktober wurde festgestellt, dass die drei M√§nner in der Unterkunft fehlten. Ihre Identit√§t werde vom Bundeskriminalamt gemeinsam mit franz√∂sischen und belgischen Sicherheitsbeh√∂rden gepr√ºft, hie√ü es. Die deutschen Beh√∂rden wollten sich nicht zu dem Vorgang √§u√üern. Familie bat ihn, sich zu stellen Wie andere Islamisten auch ist Abdeslam im Br√ºsseler Stadtteil Molenbeek aufgewachsen. Er war der Polizei wegen Drogendelikten bekannt. Seinen Job als Mechaniker verlor er 2011 wegen h√§ufiger Abwesenheit. Ab 2013 betrieb er eine Bar in Molenbeek, die schlie√ülich von den Beh√∂rden geschlossen wurde, weil G√§ste dort Drogen genommen haben sollen. Mit Abdelhamid Abaaoud, der die Anschl√§ge von Paris vermutlich geplant hat, war Salah Abdeslam seit seiner Kindheit befreundet. Nach den Anschl√§gen in Frankreich wurde er per internationalem Haftbefehl gesucht. Fahnder beschrieben ihn als \"gef√§hrlich\" und m√∂glicherweise \"schwer bewaffnet\". Zwischenzeitlich war auch √ºber einen Aufenthalt in Syrien spekuliert worden. Salahs Bruder Mohamed hatte in Fernsehinterviews an den Gesuchten appelliert, sich zu stellen. Er selbst war nach den Anschl√§gen kurzzeitig festgenommen, aber bald wieder freigelassen worden. Seine Anw√§ltin sagte, er habe \"nicht das gleiche Leben gew√§hlt\" wie seine Br√ºder. Mohamed berichtete, dass Brahim und Salah in den Monaten vor den Anschl√§gen im November in Paris ges√ºnder gelebt, gebetet, keinen Alkohol mehr getrunken h√§tten und hin und wieder in die Moschee gegangen seien. Er wollte darin aber \"nicht direkt ein Zeichen f√ºr Radikalisierung\" sehen. Zur Rolle seines Bruders bei den Anschl√§gen in Paris sagte Mohamed: \"Salah ist sehr intelligent. Er hat in letzter Minute kehrtgemacht\". Salah sollte angeblich in Paris auch ein Selbstmordattentat ver√ºben. Er z√ºndete die Bombe aber nicht, sondern warf seinen Sprengstoffg√ºrtel in einem Pariser Vorort in einen M√ºlleimer.",
  "target_text": "Dort soll der Terrorist drei Komplizen aus einer Fl√ºchtlingsunterkunft abgeholt haben. Die belgischen Beh√∂rden haben den 26-J√§hrigen jetzt wegen Mordes angeklagt."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:

  ```text
  Im Folgenden finden Sie Nachrichtenartikel mit den dazugeh√∂rigen Zusammenfassungen.
  ```

- Base prompt template:

  ```text
  Nachrichtenartikel: {text}
  Zusammenfassung: {target_text}
  ```

- Instruction-tuned prompt template:

  ```text
  Nachrichtenartikel: {text}

  Schreiben Sie eine Zusammenfassung des obigen Artikels.
  ```

You can evaluate this dataset directly as follows:

```bash
euroeval --model <model-id> --dataset mlsum-de
```
