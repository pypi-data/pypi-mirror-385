{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Representation and Chunk Mapping\n",
    "\n",
    "This tutorial shows how to work with the IntermediateRepresentation (IR) to understand the relationship between structured prompts and their rendered text.\n",
    "\n",
    "The IR is the bridge between structure and output:\n",
    "- **Structure**: StructuredPrompt with elements and hierarchy\n",
    "- **IR**: Chunks that map back to elements\n",
    "- **Output**: Final text or multi-modal content\n",
    "\n",
    "This enables structured optimization, debugging, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from t_prompts import dedent, prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an IntermediateRepresentation\n",
    "\n",
    "Call `.ir()` on a StructuredPrompt to get its IntermediateRepresentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Alice\"\n",
    "age = \"30\"\n",
    "p = prompt(t\"Name: {name:n}, Age: {age:a}\")\n",
    "\n",
    "# Get the IntermediateRepresentation\n",
    "ir = p.ir()\n",
    "\n",
    "print(f\"IR type: {type(ir).__name__}\")\n",
    "print(f\"Text: {ir.text}\")\n",
    "print(f\"Number of chunks: {len(ir.chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Chunks\n",
    "\n",
    "The IR contains chunks - each chunk maps to exactly one source element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine each chunk\n",
    "print(\"Chunks in the IR:\\n\")\n",
    "for i, chunk in enumerate(ir.chunks):\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(f\"  Type: {type(chunk).__name__}\")\n",
    "    print(f\"  Text: {chunk.text!r}\")\n",
    "    print(f\"  Element ID: {chunk.element_id}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Chunks to Elements\n",
    "\n",
    "Each chunk's `element_id` maps back to a specific element in the structured prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from t_prompts import Static, TextInterpolation\n",
    "\n",
    "# Show the correspondence between chunks and elements\n",
    "print(\"Chunk → Element mapping:\\n\")\n",
    "\n",
    "for i, chunk in enumerate(ir.chunks):\n",
    "    # Find the element with this ID\n",
    "    matching_elem = None\n",
    "    for elem in p.children:\n",
    "        if elem.id == chunk.element_id:\n",
    "            matching_elem = elem\n",
    "            break\n",
    "\n",
    "    if matching_elem:\n",
    "        elem_type = type(matching_elem).__name__\n",
    "        if isinstance(matching_elem, Static):\n",
    "            elem_desc = f\"Static(key={matching_elem.key})\"\n",
    "        elif isinstance(matching_elem, TextInterpolation):\n",
    "            elem_desc = f\"TextInterpolation(key='{matching_elem.key}')\"\n",
    "        else:\n",
    "            elem_desc = elem_type\n",
    "\n",
    "        print(f\"Chunk {i} ({chunk.text!r}) → {elem_desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Prompts and Chunks\n",
    "\n",
    "When prompts are nested, each element still produces its own chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting = \"Hello\"\n",
    "inner = prompt(t\"{greeting:g}, world!\")\n",
    "outer = prompt(t\"Message: {inner:msg}\")\n",
    "\n",
    "# Get IR for the outer prompt\n",
    "ir_nested = outer.ir()\n",
    "\n",
    "print(f\"Text: {ir_nested.text}\")\n",
    "print(f\"\\nNumber of chunks: {len(ir_nested.chunks)}\")\n",
    "print(\"\\nChunks:\")\n",
    "for i, chunk in enumerate(ir_nested.chunks):\n",
    "    print(f\"  {i}. {chunk.text!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CompiledIR for Efficient Queries\n",
    "\n",
    "Call `.compile()` on an IR to build indexes for efficient element-to-chunks queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the IR\n",
    "compiled = ir_nested.compile()\n",
    "\n",
    "print(f\"Compiled IR type: {type(compiled).__name__}\")\n",
    "print(f\"Number of chunks: {len(compiled.ir.chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Chunks for a Subtree\n",
    "\n",
    "Use `get_chunks_for_subtree(element_id)` to get all chunks from an element and its descendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chunks for the entire outer prompt\n",
    "all_chunks = compiled.get_chunks_for_subtree(outer.id)\n",
    "print(\"All chunks for outer prompt:\")\n",
    "for chunk in all_chunks:\n",
    "    print(f\"  {chunk.text!r}\")\n",
    "\n",
    "# Get chunks for just the nested inner prompt\n",
    "nested_chunks = compiled.get_chunks_for_subtree(outer[\"msg\"].id)\n",
    "print(\"\\nChunks for nested 'msg' prompt:\")\n",
    "for chunk in nested_chunks:\n",
    "    print(f\"  {chunk.text!r}\")\n",
    "\n",
    "# Reconstruct text from chunks\n",
    "nested_text = \"\".join(chunk.text for chunk in nested_chunks)\n",
    "print(f\"\\nReconstructed text from nested chunks: {nested_text!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Analyzing Chunk Sizes\n",
    "\n",
    "Understanding chunk sizes helps with optimization and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = \"You are a helpful assistant.\"\n",
    "user_query = \"What is Python?\"\n",
    "examples = \"Example 1: Hello -> Bonjour\\nExample 2: Goodbye -> Au revoir\"\n",
    "\n",
    "p = dedent(t\"\"\"\n",
    "    System: {system_msg:sys}\n",
    "\n",
    "    Examples:\n",
    "    {examples:ex}\n",
    "\n",
    "    User: {user_query:user}\n",
    "    \"\"\")\n",
    "\n",
    "ir_analysis = p.ir()\n",
    "\n",
    "print(\"Chunk size analysis:\\n\")\n",
    "total_size = 0\n",
    "for i, chunk in enumerate(ir_analysis.chunks):\n",
    "    size = len(chunk.text)\n",
    "    total_size += size\n",
    "    print(\n",
    "        f\"Chunk {i}: {size:3d} chars - {chunk.text[:30]!r}...\"\n",
    "        if size > 30\n",
    "        else f\"Chunk {i}: {size:3d} chars - {chunk.text!r}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nTotal size: {total_size} characters\")\n",
    "print(f\"Text length: {len(ir_analysis.text)} characters\")\n",
    "print(f\"Match: {total_size == len(ir_analysis.text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Finding Elements by ID\n",
    "\n",
    "Given a chunk's element_id, you can navigate back to the element in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_element_by_id(prompt, element_id):\n",
    "    \"\"\"Recursively search for an element by its ID.\"\"\"\n",
    "    from t_prompts import StructuredPrompt\n",
    "\n",
    "    # Check each child\n",
    "    for elem in prompt.children:\n",
    "        if elem.id == element_id:\n",
    "            return elem\n",
    "\n",
    "        # If element is a nested StructuredPrompt, recurse\n",
    "        if isinstance(elem, StructuredPrompt):\n",
    "            result = find_element_by_id(elem, element_id)\n",
    "            if result:\n",
    "                return result\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Pick a chunk and find its element\n",
    "first_chunk = ir_analysis.chunks[1]  # Get a non-static chunk\n",
    "element = find_element_by_id(p, first_chunk.element_id)\n",
    "\n",
    "if element:\n",
    "    print(f\"Chunk text: {first_chunk.text!r}\")\n",
    "    print(f\"Element type: {type(element).__name__}\")\n",
    "    print(f\"Element key: {element.key}\")\n",
    "    if hasattr(element, \"expression\"):\n",
    "        print(f\"Element expression: {element.expression}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Selective Text Extraction\n",
    "\n",
    "Extract text from specific parts of the prompt by querying chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt with identifiable sections\n",
    "header = \"Task Overview\"\n",
    "body = \"Please analyze the following data and provide insights.\"\n",
    "footer = \"Thank you for your help!\"\n",
    "\n",
    "section_prompt = dedent(t\"\"\"\n",
    "    === {header:header} ===\n",
    "\n",
    "    {body:body}\n",
    "\n",
    "    ---\n",
    "    {footer:footer}\n",
    "    \"\"\")\n",
    "\n",
    "section_ir = section_prompt.ir()\n",
    "section_compiled = section_ir.compile()\n",
    "\n",
    "# Extract text from just the body section\n",
    "body_chunks = section_compiled.get_chunks_for_subtree(section_prompt[\"body\"].id)\n",
    "body_text = \"\".join(chunk.text for chunk in body_chunks)\n",
    "\n",
    "print(\"Full text:\")\n",
    "print(section_ir.text)\n",
    "print(\"\\nExtracted body text:\")\n",
    "print(body_text)\n",
    "print(f\"\\nBody is {len(body_text)} of {len(section_ir.text)} total characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Token Budget Analysis\n",
    "\n",
    "Analyze which parts of a prompt consume the most tokens (simulated with character counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complex prompt\n",
    "instruction = \"You are an expert translator.\"\n",
    "context = \"The user wants formal business translations.\"\n",
    "examples_text = \"\\n\".join([f\"EN: Example {i} -> FR: Exemple {i}\" for i in range(10)])\n",
    "\n",
    "budget_prompt = dedent(t\"\"\"\n",
    "    {instruction:inst}\n",
    "\n",
    "    Context: {context:ctx}\n",
    "\n",
    "    Examples:\n",
    "    {examples_text:examples}\n",
    "\n",
    "    Now translate the following:\n",
    "    \"\"\")\n",
    "\n",
    "budget_ir = budget_prompt.ir()\n",
    "budget_compiled = budget_ir.compile()\n",
    "\n",
    "# Analyze size by interpolation key\n",
    "print(\"Token budget analysis (character counts as proxy):\\n\")\n",
    "\n",
    "for key in budget_prompt.keys():\n",
    "    elem = budget_prompt[key]\n",
    "    chunks = budget_compiled.get_chunks_for_subtree(elem.id)\n",
    "    size = sum(len(chunk.text) for chunk in chunks)\n",
    "    percentage = (size / len(budget_ir.text)) * 100\n",
    "\n",
    "    print(f\"{key:12s}: {size:4d} chars ({percentage:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotal: {len(budget_ir.text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-modal Chunks with Images\n",
    "\n",
    "IntermediateRepresentation supports both TextChunk and ImageChunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Create a simple image\n",
    "img = Image.new(\"RGB\", (100, 100), color=\"blue\")\n",
    "\n",
    "description = \"Here is a blue square\"\n",
    "img_prompt = dedent(t\"\"\"\n",
    "    {description:desc}\n",
    "\n",
    "    Image: {img:image}\n",
    "    \"\"\")\n",
    "\n",
    "img_ir = img_prompt.ir()\n",
    "\n",
    "print(\"Chunks in multi-modal IR:\\n\")\n",
    "for i, chunk in enumerate(img_ir.chunks):\n",
    "    chunk_type = type(chunk).__name__\n",
    "    if chunk_type == \"TextChunk\":\n",
    "        print(f\"  {i}. {chunk_type}: {chunk.text!r}\")\n",
    "    else:\n",
    "        print(f\"  {i}. {chunk_type}: {chunk.text}\")\n",
    "\n",
    "# Text representation includes image placeholders\n",
    "print(f\"\\nText representation:\\n{img_ir.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "IntermediateRepresentation provides the bridge between structured prompts and rendered output:\n",
    "\n",
    "✅ **Chunks** - Each chunk maps to exactly one source element  \n",
    "✅ **Element IDs** - Track provenance from output back to structure  \n",
    "✅ **CompiledIR** - Efficient queries for element subtrees  \n",
    "✅ **Multi-modal** - Supports both text and image chunks  \n",
    "✅ **Analysis** - Enable size analysis, optimization, and debugging  \n",
    "\n",
    "This makes it possible to:\n",
    "- Trace rendered text back to source variables\n",
    "- Extract specific sections of complex prompts\n",
    "- Analyze token budgets by component\n",
    "- Implement structured optimization strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
