<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Code architecture &mdash; BONSAI dataio Python package 1.1.3.post1.dev3+gf14f81b documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=45e03889"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            BONSAI dataio Python package
          </a>
              <div class="version">
                1.1.3.post1.dev3+gf14f81b
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="readme.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="datapackage_tutorial.html">Datapackage tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="database_tutorial.html">Database tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_concepts.html">Basic concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributions &amp; Help</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">Module Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BONSAI dataio Python package</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Code architecture</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/code.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="code-architecture">
<h1>Code architecture<a class="headerlink" href="#code-architecture" title="Link to this heading"></a></h1>
<p>The code base of the project is a collection of Python packages stored as repositories in subgroups of the <a class="reference external" href="https://source.coderefinery.org/bonsai/">BONSAI coderefinery group</a>. This chapter describes how it is organized, and it contains the folowing sections:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#code-overview"><span class="std std-ref">Overview</span></a> describes the organization of th BONSAI coderefinery group and introduces the concepts of utility, task and data transformation stage.</p></li>
<li><p><a class="reference internal" href="#code-workflow"><span class="std std-ref">Workflow management</span></a> describes the management of the data transformation workflow.</p></li>
<li><p><a class="reference internal" href="#code-task"><span class="std std-ref">Task template</span></a> describes the main features of the code architecture of a task package.</p></li>
<li><p><a class="reference internal" href="#code-io"><span class="std std-ref">Data package utiliity</span></a> describes the main features of the utility to read and write data packages.</p></li>
<li><p><a class="reference internal" href="#data-admin"><span class="std std-ref">Administration database</span></a></p></li>
</ol>
<p>Code concerning calculations and the web application is not currently discussed here.</p>
<section id="overview">
<span id="code-overview"></span><h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>The BONSAI coderefinery group is organized as described in figure 1, with names in uppercase being placeholders.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>bonsai/
  ├── documentation
  ├── personal/
  ├── web/
  ├── admin/
  ├── util/
  ├── collect/
  ├── clean/
  ├── load/
  ├── build/
  └── calc/
</pre></div>
</div>
<p>Figure 1. Tree structure of the coderefinery BONSAI group.</p>
<p>In the group root there is only one repository, <code class="docutils literal notranslate"><span class="pre">documentation</span></code>, hosting the current material. Subgroup <code class="docutils literal notranslate"><span class="pre">personal</span></code> may in turn hold one subgroup for each project member, to contain ad-hoc repositories, for example exploratory scripts. Subgroup <code class="docutils literal notranslate"><span class="pre">web</span></code> contains website-related repositories, such as <code class="docutils literal notranslate"><span class="pre">frontend</span></code> or <code class="docutils literal notranslate"><span class="pre">backend</span></code>. Subgroup <code class="docutils literal notranslate"><span class="pre">admin</span></code> hosts repositories used for managing the database server, <code class="docutils literal notranslate"><span class="pre">database</span></code> and the computation cluster, <code class="docutils literal notranslate"><span class="pre">workflow</span></code>. Subgroup <code class="docutils literal notranslate"><span class="pre">calc</span></code> hosts repositories used for calculations, e.g., footprints, various decompositions and uncertainty or sensitivity analyses. Subgroup <code class="docutils literal notranslate"><span class="pre">util</span></code> hosts <em>utilities</em>: these are Python packages which are do not receive or deliver data, but are called by other Python packages. Repositories in other subgroups hold Python packages that are used in the data transformation <em>workflow</em>: each folder corresponds to a different <em>stage</em> in that workflow; and each repository holds a Python package that is executed in a <em>task</em> in that stage.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p><a class="reference internal" href="#../../assets/architecture/code/full_workflow.gv.png"><span class="xref myst"><img alt="" src="../../assets/architecture/code/full_workflow.gv.png" /></span></a></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>Figure 2. Illustrative DAG of the BONSAI data transformation workflow.</p></td>
</tr>
</tbody>
</table>
<p>The complete data transformation workflow, from raw data to the BONSAI input-output system, is illustrated in figure 2. Collect tasks for which there is a repository in <code class="docutils literal notranslate"><span class="pre">bonsai/collect</span></code> fetch data from the web and store raw data, here interpreted as a collection of files. Some raw data (bulk contribution) is manually provided and so has no corresponding code repository. Each task in the workflow delivers either one data folder (in the collect stage), or (in all other stages) one <em>data package</em>, which is a collection of csv files (each representing a <em>table</em>) and a metadata yaml file compliant with frictionless syntax. <code class="docutils literal notranslate"><span class="pre">bonsai/clean</span></code> tasks deliver stand-alone data packages, i.e., without foreign key relations to tables in other data packages. Clean data packages generated by clean tasks define either major or minor versions of the database. Element contributions define patches and are stored for now as separate data packages that follow the same entity-relation model as the major or minor clean data package, but which store either new or different records.</p>
<p>While working with files, the ‘merge’ stage tasks then combine the newer information from patches (element contribution) with older data to generate ‘merge’ data. All merge tasks execute the same merge algorithm, whose repository is stoed as <code class="docutils literal notranslate"><span class="pre">bonsai/util/merge</span></code> so there is no <code class="docutils literal notranslate"><span class="pre">bonsai/merge</span></code> folder. The last two stages are ‘load’ and ‘build’: they both deliver data packages in the main database, but they differ because ‘load’ tasks receive as input at least one ‘merge’ data package, and ‘build’ only receive data packages already present in the main database. In the main database data packages have foreign keys to other data packages. In the main database data packages are either <em>dimension data packages</em> or <em>data cubes</em>: data cubes reference dimension data packages (and some dimension data packages reference each other).</p>
<p>In the collect, clean and merge stages each data package stream is independent, but in the load and build stages they are combined. In the load stage, tasks that deliver dimension data packages are executed before those that deliver data packages. And within dimension data packages there is strict sequence: the <em>source dimension data package</em> is the first and does not have any input data from the current stage, instead queries (nonsensitive) data from the admin database. Then the <em>function</em>, <em>flag</em>, <em>unit</em> and <em>miscellaneous</em> dimension data packages are imported, followed by <em>classification data packages</em> and, finally, by data cubes.</p>
<p>In the build stage, there are three initial steps of <em>harmonization</em>, <em>gap-filling</em> and <em>balancing</em>. In these three steps a new version of each data cube is generated: in harmonization the native classifications is replaced by a main classification; in gap-filling missing values are estimated; and in balancing values are adjusted so that constraints are satisfied. The following steps then lead to the compilation of a core input-output model, which is then expanded with transformations to its flow version, and finally to its coefficient version.</p>
<p>Table 1 shows the data underlying figure 2. For each task its input tasks (i.e., those generating its input data packages) are indicated in column ‘Inputs’ while column ‘Repository’ indicates where the code they execute is stored in CodeRefinery. Several notes follow. In this example the source data package B is a manual contribution, since it’s collect task is not associated with a repository. All merge tasks execute code from the same repository.</p>
</section>
<section id="workflow-management">
<span id="code-workflow"></span><h2>Workflow management<a class="headerlink" href="#workflow-management" title="Link to this heading"></a></h2>
<p>The data transformation workflow is managed by Airflow, which executes DAGs specified in python scripts:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dag_main</span><span class="o">.</span><span class="n">py</span>
<span class="n">dag_major_</span><span class="o">&lt;</span><span class="n">major</span><span class="o">&gt;.</span><span class="n">py</span>
</pre></div>
</div>
<p>where <major> = 0, 1, …, i.e., there is one such file per major version of the Bonsai database.</p>
<p>File <code class="docutils literal notranslate"><span class="pre">dag_main.py</span></code> queries the admin_db on a regular schedule and when performs the following steps:</p>
<ol class="arabic simple">
<li><p>Open the workflow log file</p></li>
<li><p>Query the admin database for new requests</p></li>
<li><p>If there is no new request, write to log file and stop. If there is a new request, write to log file and continue.</p></li>
<li><p>From admin_db collect information: new release number, new release type and major db version.</p></li>
<li><p>Check if input data is valid. Write to log file. If valid proceed.</p></li>
<li><p>Update information in admin_db concerning coderefinery repositories and check consistency of admin_db. Write to log file. If valid proceed.</p></li>
<li><p>Launch the <code class="docutils literal notranslate"><span class="pre">dag_major_&lt;major&gt;.py</span></code> corresponding to the requested <major> release, passing as information: pointer to admin_db, new release number, new release type and major_db version.</p></li>
</ol>
<p>Following the usual Airflow syntax, file <code class="docutils literal notranslate"><span class="pre">dag_major_&lt;major&gt;.py</span></code> contains the list of tasks of the corresponding DAG, followed by the hardcoded edge dependencies. There are different ways in which the following can be achieved (e.g., in the dag operator, or in the manifest of the underlying docker) but each task should call a generic object, for now referred to as <code class="docutils literal notranslate"><span class="pre">bonsai_task</span></code> to which it passes the common information received from <code class="docutils literal notranslate"><span class="pre">dag_main.py</span></code> and an additional <code class="docutils literal notranslate"><span class="pre">task_id</span></code> parameter that identifies the task in the <code class="docutils literal notranslate"><span class="pre">task</span></code> table of the admin_db. The generic <code class="docutils literal notranslate"><span class="pre">bonsai_task</span></code> then performs the following steps:</p>
<ol class="arabic simple">
<li><p>Write to the workflow log file (id, time and status).</p></li>
<li><p>Query the admin database for status of dependencies. If dependencies have been initialized but not changed since last execution and write to table <code class="docutils literal notranslate"><span class="pre">db_task_version</span></code> and <code class="docutils literal notranslate"><span class="pre">db_edge_version</span></code> of admin_db and write to workflow log.</p></li>
<li><p>If answer to query 2 is positive, stop. Otherwise, write to tables <code class="docutils literal notranslate"><span class="pre">task_version</span></code> and <code class="docutils literal notranslate"><span class="pre">edge_version</span></code> and continue.</p></li>
<li><p>From admin_db collect information on input and output data package versions and paths and create config.yaml file in location accessible to task.</p></li>
<li><p>Create instance of task, e.g., Docker container and install the Python package from the Coderefinery repository as <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">git+ssh</span> <span class="pre">git&#64;source.bonsai.coderefinery.org/&lt;url_to_repo&gt;:&lt;version&gt;</span></code>.</p></li>
<li><p>Execute the task as <code class="docutils literal notranslate"><span class="pre">&lt;repo_name&gt;.main</span> <span class="pre">--run</span> <span class="pre">&lt;path_to_config.yaml&gt;</span></code>.</p></li>
<li><p>Close the instance.</p></li>
<li><p>Update admin_db and log with information about the success of task execution.</p></li>
</ol>
<p>Currently API info is being handled by environment variables, for production maybe it is easier to write it explicitly in the config file? Otherwise the values in config.yaml under api_info may be the name of environment variables, with are created by the Bonsai task operator in the instance that will execute the task.</p>
<p>The first load task loads the source dimension data package, which needs to query the admin database. How to handle this? Should the necessary data for the sqlalchemy pointer be passed in config the same way as api_info in the ‘collect’ stage?</p>
</section>
<section id="task-and-utility-template">
<span id="code-task"></span><h2>Task and utility template<a class="headerlink" href="#task-and-utility-template" title="Link to this heading"></a></h2>
<p>The code architecture of each repository that executes a task must comply with the architecture described in figure 4. To start with, notice that a Python package has two different names: <code class="docutils literal notranslate"><span class="pre">&lt;python_distribution&gt;</span></code> is the name used to manage an installation, e.g., <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">show</span> <span class="pre">&lt;python_distribution&gt;</span></code> in command line, and <code class="docutils literal notranslate"><span class="pre">&lt;python_package&gt;</span></code> is the name used to load the package within the Python interpreter, e.g., <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">&lt;python_package&gt;</span></code>. Additionally, each task is expected to generate one data package, called <code class="docutils literal notranslate"><span class="pre">&lt;data_package&gt;</span></code>. In the following paragraphs describe now in some detail four files (<code class="docutils literal notranslate"><span class="pre">tox.ini</span></code>, <code class="docutils literal notranslate"><span class="pre">docs/index.md</span></code>, <code class="docutils literal notranslate"><span class="pre">tests/test_main.py</span></code>  and <code class="docutils literal notranslate"><span class="pre">src/&lt;python_package&gt;/main.py</span></code>) and the folder <code class="docutils literal notranslate"><span class="pre">tests/data/</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;python_distribution&gt;/
  ├── tox.ini
  ├── ...
  ├── docs/
  │     ├── index.md
  │     └── ...
  ├── tests/
  │     ├── test_main.py
  │     ├── ...
  │     └── data/
  │           ├── config.yaml
  │           ├── input/
  │           │     ├── &lt;data_package_0&gt;/
  │           │     │     ├── &lt;data_package_0&gt;.metadata.yaml
  │           │     │     ├── &lt;data_package_0&gt;.gv.svg
  │           │     │     ├── &lt;file_0&gt;.csv
  │           │     │     └── ...
  │           │     └── ...
  │           └── output/
  │                 └── &lt;data_package&gt;/
  │                       ├── &lt;data_package&gt;.log
  │                       └── ...
  └── src/
        └── &lt;python_package&gt;/
              ├── main.py
              └── ...
</pre></div>
</div>
<p>Figure 4. Tree structure of a task repository.</p>
<p>Foder <code class="docutils literal notranslate"><span class="pre">tests/data/</span></code> contains a template <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> with the structure of the arguments required to execute the task, and when the data in <code class="docutils literal notranslate"><span class="pre">tests/data/input/</span></code> is correct, the task should return output matching <code class="docutils literal notranslate"><span class="pre">tests/data/output/</span></code>. Input data, if any, and usually output data are expected to be data packages, which consist of csv files and a metadata.yaml file.</p>
<p>File <code class="docutils literal notranslate"><span class="pre">tox.ini</span></code> contains instructions on automated testing and generation of documentation. In particular, it will launch <code class="docutils literal notranslate"><span class="pre">tests/test_main.py</span></code> which, among other things generates the entity-relation diagrams of input and output data inside <code class="docutils literal notranslate"><span class="pre">tests/data/</span></code>. <code class="docutils literal notranslate"><span class="pre">index.md</span></code> should either contain instructions for installation and the description of the entity-relation models of input and output data, including the diagrams. <code class="docutils literal notranslate"><span class="pre">tests/test_main.py</span></code> should contain tests for the three main behaviours expected of the task:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;python_package&gt;.main</span> <span class="pre">--run</span> <span class="pre">&lt;path_to_config.yaml&gt;</span></code>, where the <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> used is <code class="docutils literal notranslate"><span class="pre">tests/data/config.yaml</span></code>, and the task is executed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;python_package&gt;.main</span> <span class="pre">--plot</span> <span class="pre">&lt;path_to_metadata.yaml&gt;</span></code>, where the <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code> files used are all those under <code class="docutils literal notranslate"><span class="pre">tests/data/</span></code>, and entity-relation diagrams are created in the relevant folder.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;python_package&gt;.main</span> <span class="pre">--export</span> <span class="pre">&lt;export_path&gt;</span></code>, where all files under <code class="docutils literal notranslate"><span class="pre">tests/data/</span></code> is exported to <code class="docutils literal notranslate"><span class="pre">&lt;export_path&gt;</span></code>.</p></li>
</ol>
<p>The content of file <code class="docutils literal notranslate"><span class="pre">src/&lt;python_package&gt;/main.py</span></code> should be:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">task_wrapper</span> <span class="kn">import</span> <span class="n">task_wrapper</span>
<span class="kn">from</span> <span class="o">&lt;</span><span class="n">my_module</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="o">&lt;</span><span class="n">my_function</span><span class="o">&gt;</span>

<span class="nd">@task_wrapper</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">argv</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; useful information &quot;&quot;&quot;</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">argv</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># start edit</span>
    <span class="n">output_data</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">my_function</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
    <span class="c1"># stop edit</span>

    <span class="k">return</span> <span class="n">output_data</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; useful information &quot;&quot;&quot;</span>
    <span class="n">main</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice that the input of main,  argv, is not the one which is passed, since the task_wrapper will append it with the dictionary read from config.yaml (if argv[1] == –run), and with the input data packages (in a list). Need to check if this is possible.</p>
<p>The parts that should be edited by the task developer are those within the <code class="docutils literal notranslate"><span class="pre">#start</span> <span class="pre">edit</span></code> and <code class="docutils literal notranslate"><span class="pre">#end</span> <span class="pre">edit</span></code> comments, the <code class="docutils literal notranslate"><span class="pre">&quot;&quot;&quot;</span> <span class="pre">useful</span> <span class="pre">information&quot;&quot;&quot;</span></code> blocks and the import line <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">&lt;my_module&gt;</span> <span class="pre">import</span> <span class="pre">&lt;my_function&gt;</span></code>. The task_wrapper is a decorator that is imported from a utility (which should be declared in <code class="docutils literal notranslate"><span class="pre">setup.cfg</span></code>), and which performs the following actions:</p>
<ol class="arabic simple">
<li><p>Parse and validate the list of arguments. The firt element should be <code class="docutils literal notranslate"><span class="pre">--run</span></code> (or alias <code class="docutils literal notranslate"><span class="pre">-r</span></code>), <code class="docutils literal notranslate"><span class="pre">--export</span></code> (or <code class="docutils literal notranslate"><span class="pre">-e</span></code>) or <code class="docutils literal notranslate"><span class="pre">--plot</span></code> (or <code class="docutils literal notranslate"><span class="pre">-p</span></code>), each receiving a path as argument, described above when describing the test behaviour. If something is invalid provide useful feedback and stop, otherwise continue.</p></li>
<li><p>Create any output folder if needed, open a log file to it, describe initial steps, then pass logger to task, and close after completion.</p></li>
<li><p>In the case of the ‘run’ functionality, use the data_io package to load any input data, and append them to the list of arguments passed to the task.</p></li>
<li><p>After the task is finished write the output data package to the output folder (if it is valid).</p></li>
</ol>
<p>The ‘plot’ functionality also uses the data_io package. A ‘logger_setup’ standalone function should be available from the task_wrapper utility to be imported for development of tasks and utilities.</p>
<p><strong>Collect stage</strong>:</p>
<p>Fields in config.yaml of the collect stage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stage</span><span class="p">:</span> <span class="s1">&#39;collect&#39;</span>
<span class="n">output</span><span class="p">:</span>
    <span class="n">name</span><span class="p">:</span>
    <span class="n">path</span><span class="p">:</span>
    <span class="n">version</span><span class="p">:</span>
    <span class="n">create_path</span><span class="p">:</span> <span class="kc">False</span>
    <span class="n">overwrite</span><span class="p">:</span> <span class="kc">False</span>
<span class="n">api_info</span><span class="p">:</span>
    <span class="n">username</span><span class="p">:</span>
    <span class="n">password</span><span class="p">:</span>
    <span class="n">key</span><span class="p">:</span>
    <span class="n">token</span><span class="p">:</span>
</pre></div>
</div>
<p>The task_wrapper will output a metadata.yaml file to the raw data folder with additional fields obtained from introspection or checking with the template metadata:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    files: &lt;list with names of expected files&gt;
    data_name: CONFIG
    data_path: CONFIG
    data_version: CONFIG
    datetime: RUNTIME
    repo: RUNTIME
    repo_version: RUNTIME ()
    contact_person:
    source:
    document:
    license:
    ...?
</pre></div>
</div>
<p>As a rule, the values in tests/data/&lt;data_folder&gt;/metadata.yaml can be standard string, meaning they will be copied to the output metadata, or be RUNTIME, meaning they are determined at runtime, or CONFIG, meaning they are to be read from config. The same logic can apply to tests/data/config.yaml.</p>
<p>In the case of manually provided data, repo and repo_version can be None or MANUAL?</p>
<p>task_wrapper will not actually write the files. That must be managed by the actual content of the main function. In other stages the main function only needs to pass the objects. task_wrapper will also not generate entity-relation diagrams, for example the function plot may have a condition if stage == ‘collect’ do nothing.</p>
<p>The choice of values for the create_path and overwrite options assume that the Bonsai task operator previously created the folder. Alternatively, it could be task_wrapper doing that, in which case the options are different. There is also the issue of the root path. should in config also a root path be provided, from which the output path is relative?</p>
<p>The utility template does not need to have any particular structure, for as long as it contains clear instructions on how to use. The export of any test data and a test script that illustrates its application should be included. The task_wrapper utility may include a standalone ‘export’ functionality to be used for this purpose.</p>
<p><strong>Clean stage</strong>:</p>
<p>Fields in config.yaml:</p>
<p>stage: ‘clean’
input:
name:
path:
version:
output:
name:
path:
version:
create_path: False
overwrite: False</p>
<p>task_wrapper constraints: inputs are expected to be files, output is expected to have no upstream dependencies. Output is a datapackage, so diagram should be created, maybe add a ‘datapackage: True’ field to metadata? As in ‘collect’ metadata has non-standard fields with admin data (contact-person, source, document, license).</p>
<p><strong>Merge stage</strong>:</p>
<p>Merge tasks all call the same ‘merge’ repository, which is expected to receive two inputs, new_contrib and previous_merge, and delivers a new_merge. The distinction can be done assuming that new_contrib comes from database ‘clean’ and previous_current from ‘merge’ (if any).</p>
<p>In other stages, task_wrapper checks that the output template metadata and the generated metadata have the same entity-relation model. However, this check must be skipped for the merge “task”. The check instead is that both input data packages have the same entity-relation model. Admin metadata needs to be concatenated, so it is better to have a special sub-dictionary with lists. That is, in metadata there is:</p>
<p>admin:
contact_person: […]
source: […]
document: […]
license: […]</p>
<p>The output data pacakge should be ‘merge’, no upstream dependencies allowed.</p>
<p>Merge should add to each table a reference to the contribution from which that record originates. This means this info needs to be passed on by workflow management.</p>
<p><strong>Load stage</strong>:</p>
<p>Admin metadata is discarded from now on, as it is explicitly stored in tables.</p>
<p>Inputs can be from database ‘merge’ or from ‘main’. Output is ‘main’.</p>
<p><strong>Build stage</strong>:</p>
<p>Inputs and output are ‘main’.</p>
</section>
<section id="data-package-utility">
<span id="code-io"></span><h2>Data package utility<a class="headerlink" href="#data-package-utility" title="Link to this heading"></a></h2>
<p>While the task_wrapper utility handles specific paths that comply with the architecture of task repositories, the functionalities to handle data packages are in the ‘data_io’ package. This Python package should have a <code class="docutils literal notranslate"><span class="pre">DataPackage</span></code> class with the main methods and attributes described below.</p>
<p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">data_io</span> <span class="pre">import</span> <span class="pre">DataPackage</span></code> and <code class="docutils literal notranslate"><span class="pre">dp</span> <span class="pre">=</span> <span class="pre">DataPackage()</span></code> initialize an empty data package.</p>
<p><code class="docutils literal notranslate"><span class="pre">dp.load(path,</span> <span class="pre">depth=0)</span></code>: given path to a folder with a Frictionless-compliant <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code> file, populates the data package. The <code class="docutils literal notranslate"><span class="pre">depth</span></code> argument indicates whether upstream dependencies of a certain depth are loaded too (0 means not, -1 means all, i &gt; 0 indicates the highest level of dependency imported). Alternative syntax is <code class="docutils literal notranslate"><span class="pre">dp</span> <span class="pre">=</span> <span class="pre">data_io.load(path,</span> <span class="pre">depth=0)</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">dp.build(metadata:</span> <span class="pre">dict,</span> <span class="pre">tables:</span> <span class="pre">list</span> <span class="pre">of</span> <span class="pre">pd.DataFrames)</span></code>: assembles a data package from Python objects. It can be done is steps, first building the metadata and then the tables.</p>
<p><code class="docutils literal notranslate"><span class="pre">dp.dump(path)</span></code>: Dumps to path (only depth zero is allowed for dumping).</p>
<p><code class="docutils literal notranslate"><span class="pre">dp.check()</span></code>: Check internal consistency of data package.</p>
<p><code class="docutils literal notranslate"><span class="pre">dp.plot(path)</span></code>: Generate entity-relation diagram.</p>
<p>The first attribute is <code class="docutils literal notranslate"><span class="pre">dp.metadata:</span> <span class="pre">dict</span></code>: dictionary with a syntax based on the Frictionless framework with some additional fields:</p>
<ol class="arabic simple">
<li><p>Root fields: <code class="docutils literal notranslate"><span class="pre">datapackage_name</span></code>, <code class="docutils literal notranslate"><span class="pre">datapackage_version</span></code>, <code class="docutils literal notranslate"><span class="pre">root_path</span></code>, <code class="docutils literal notranslate"><span class="pre">task_name</span></code>, <code class="docutils literal notranslate"><span class="pre">task_version</span></code>, <code class="docutils literal notranslate"><span class="pre">repo_full_url</span></code>, <code class="docutils literal notranslate"><span class="pre">database</span></code>, <code class="docutils literal notranslate"><span class="pre">depth</span></code>, <code class="docutils literal notranslate"><span class="pre">dependencies</span></code>. All except the last two are strings. <code class="docutils literal notranslate"><span class="pre">depth</span></code> is an int and the last one is a dict as: <code class="docutils literal notranslate"><span class="pre">{&lt;datapackage_0&gt;:</span> <span class="pre">{version:</span> <span class="pre">str,</span> <span class="pre">path:</span> <span class="pre">str,</span> <span class="pre">depth:</span> <span class="pre">int},</span> <span class="pre">...}</span></code>. Each dependency is an upstream data package, that is found by combining the <code class="docutils literal notranslate"><span class="pre">root_path</span></code> with <code class="docutils literal notranslate"><span class="pre">dependencies[&lt;datapackage_0&gt;]['path']</span></code>.</p></li>
<li><p>Within each <code class="docutils literal notranslate"><span class="pre">['resources'][&lt;table_0&gt;]</span></code> there is an additional field <code class="docutils literal notranslate"><span class="pre">datapackage</span></code> indicating either <code class="docutils literal notranslate"><span class="pre">&lt;datapackage_name&gt;</span></code> (optional) or a eky of <code class="docutils literal notranslate"><span class="pre">dependencies</span></code> (mandatory).</p></li>
<li><p>Within each <code class="docutils literal notranslate"><span class="pre">['resources'][&lt;table_0&gt;]['schema']['foreignKeys'][...]['reference']</span></code> there is an additional field <code class="docutils literal notranslate"><span class="pre">datapackage</span></code> indicating either <code class="docutils literal notranslate"><span class="pre">&lt;datapackage_name&gt;</span></code> (optional) or a key of <code class="docutils literal notranslate"><span class="pre">dependencies</span></code> (mandatory).</p></li>
</ol>
<p>This architecture is not ideal since it does not preclude clashes of tables with the same name in different data packages. Maybe the name of the table should be a composite <code class="docutils literal notranslate"><span class="pre">&lt;datapackage_0.table_0&gt;</span></code>.</p>
<p>Additional fields are required for the entity-relation diagrams.  Within each <code class="docutils literal notranslate"><span class="pre">['resources'][&lt;table_0&gt;]['schema']['foreignKeys'][...]['reference']</span></code>, <code class="docutils literal notranslate"><span class="pre">direction</span></code> in <code class="docutils literal notranslate"><span class="pre">['forward',</span> <span class="pre">'back']</span></code> and <code class="docutils literal notranslate"><span class="pre">distance:</span> <span class="pre">int</span></code>.</p>
<p>Other attributes are the data packages and tables proper: <code class="docutils literal notranslate"><span class="pre">dp.&lt;data_package_0&gt;.&lt;table_0&gt;:</span> <span class="pre">pd.DataFrame</span></code>: pandas dataframe with table &lt;table_0&gt; in data package &lt;data_package_0&gt;. If depth is zero, then there is only one data package, and otherwise upstream dependencies are stored in their own attributes. The index should be the primary key of the table (field name ‘id’). The constraints defined in the metadata resources should be valid.</p>
<p>The class has an inner join method <code class="docutils literal notranslate"><span class="pre">dp.join(&lt;child_table&gt;,</span> <span class="pre">&lt;parent_table&gt;,</span> <span class="pre">[&lt;fields&gt;])</span></code> or similar.</p>
<p>Ideally we would like to have table and data package archetypes. Table archetypes are fact, dimension, classification and concordance, data package archetypes are data cube, dimension and classification. However, these cannot be subclasses because these archetypes are defined only in relation with other objects and subclassing the pandas dataframe class is officially discouraged. Thus, we use <code class="docutils literal notranslate"><span class="pre">archetype</span></code> as keys in the metadata of both the datapackage as a whole (in the root and the dependencies field), and in each resource (=table). Method <code class="docutils literal notranslate"><span class="pre">DataPackage.check()</span></code> checks for archetype consistency.</p>
</section>
<section id="admin-database">
<span id="data-admin"></span><h2>Admin database<a class="headerlink" href="#admin-database" title="Link to this heading"></a></h2>
<p>Administrative data is kept separately for security reasons. This include sensitive information concerning: users (contact, affiliation, passwords); API keys and tokens; data sources and licenses; and workflow management (tasks, repositories, versions and their interaction). The part concerning users, APIs and data sources is discussed in the user experience chapter. The part concerning workflow management is discussed in the workflow tutorial. The full entity-relation model of the admin database is presented in figure 12.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p><a class="reference internal" href="#../../assets/architecture/data/admin_db.gv.png"><span class="xref myst"><img alt="" src="../../assets/architecture/data/admin_db.gv.png" /></span></a></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>Figure 12. Entity-relation diagram of the full admin database.</p></td>
</tr>
</tbody>
</table>
<p>The <a class="reference internal" href="#../guidelines/workflow.md"><span class="xref myst">workflow management minimal working example</span></a> describes the lower and right part of the full admin database. The top left corner roughly overlaps with the source <a class="reference internal" href="#data-dimension"><span class="xref myst">dimension data package</span></a>, but contains additional sensitive information. It is not shown explicitly in order not to overwhelm the diagram, but all tables expect ‘user_group’ have an additional field ‘created_by’ with a foreign key to ‘user’, and all tables have an additional field ‘create_time’. Table ‘user_group’ has lists user groups with different permissions.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Getting The Data Right project.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>