{
  "LLM Providers": "LLM Providers",
  "TTS Providers": "TTS Providers",
  "Neuro": "Neuro",
  "Chatbot": "Chatbot",
  "Stream": "Stream",
  "Server": "Server",
  "Provider ID": "Provider ID",
  "Display Name": "Display Name",
  "Provider Type": "Provider Type",
  "API Key": "API Key",
  "Base URL": "Base URL",
  "Model Name": "Model Name",
  "Region": "Region",
  "LLM Provider ID": "LLM Provider ID",
  "TTS Provider ID": "TTS Provider ID",
  "Input Chat Sample Size": "Input Chat Sample Size",
  "Post-Speech Cooldown (sec)": "Post-Speech Cooldown (sec)",
  "Initial Greeting": "Initial Greeting",
  "Neuro Input Queue Max Size": "Neuro Input Queue Max Size",
  "Enable Dynamic Pool": "Enable Dynamic Pool",
  "Dynamic Pool Size": "Dynamic Pool Size",
  "Generation Interval (sec)": "Generation Interval (sec)",
  "Chats per Batch": "Chats per Batch",
  "Streamer Nickname": "Streamer Nickname",
  "Stream Title": "Stream Title",
  "Stream Category": "Stream Category",
  "Stream Tags": "Stream Tags",
  "Host": "Host",
  "Port": "Port",
  "Panel Password": "Panel Password",
  "Client Origins": "Client Origins",
  "Audience Chat Buffer Max Size": "Audience Chat Buffer Max Size",
  "Initial Chat Backlog Limit": "Initial Chat Backlog Limit",
  "Add Item": "Add Item",
  "Edit Item": "Edit Item",
  "Item": "Item",
  "Save": "Save",
  "Cancel": "Cancel",
  "Add": "Add",
  "Edit": "Edit",
  "Loading configuration...": "Loading configuration...",
  "Save Configuration": "Save Configuration",
  "Connection": "Connection",
  "Control": "Control",
  "Configuration": "Configuration",
  "Logs": "Logs",
  "Agent": "Agent",
  "Connection Lost": "Connection Lost",
  "The connection to the backend was unexpectedly lost. Please reconnect.": "The connection to the backend was unexpectedly lost. Please reconnect.",
  "Go to Connection Page": "Go to Connection Page",
  "ChatBot": "ChatBot",
  "Confirm": "Confirm",
  "Please confirm": "Please confirm",
  "Context Mode": "Context Mode",
  "Failed to get prompt": "Failed to get prompt",
  "Failed to get context": "Failed to get context",
  "Init Memory": "Init Memory",
  "Refresh": "Refresh",
  "No init memory.": "No init memory.",
  "Temp Memory": "Temp Memory",
  "Clear": "Clear",
  "No temp memory.": "No temp memory.",
  "Core Memory": "Core Memory",
  "Add Memory Block": "Add Memory Block",
  "No core memory.": "No core memory.",
  "Add Temp Memory": "Add Temp Memory",
  "Role": "Role",
  "Content": "Content",
  "Add/Edit Core Memory Block": "Add/Edit Core Memory Block",
  "Editing": "Editing",
  "Adding": "Adding",
  "Title": "Title",
  "Description": "Description",
  "Content (one per line)": "Content (one per line)",
  "Add/Edit Init Memory Item": "Add/Edit Init Memory Item",
  "Key": "Key",
  "Value (String, JSON, or newline-separated array)": "Value (String, JSON, or newline-separated array)",
  "Are you sure you want to delete this memory block?": "Are you sure you want to delete this memory block?",
  "Are you sure you want to delete the key": "Are you sure you want to delete the key",
  "Are you sure you want to clear all temp memory?": "Are you sure you want to clear all temp memory?",
  "Reload Tools": "Reload Tools",
  "Save Allocations": "Save Allocations",
  "Here you can assign available tool tags to Agents. The Neuro Agent is responsible for interacting with the audience, while the Memory Agent is responsible for organizing memories in the background.": "Here you can assign available tool tags to Agents. The Neuro Agent is responsible for interacting with the audience, while the Memory Agent is responsible for organizing memories in the background.",
  "All Available Tools": "All Available Tools",
  "Tool Name": "Tool Name",
  "Neuro Agent": "Neuro Agent",
  "Memory Agent": "Memory Agent",
  "Neuro Agent Toolset": "Neuro Agent Toolset",
  "Memory Agent Toolset": "Memory Agent Toolset",
  "Conversation": "Conversation",
  "Memory": "Memory",
  "Tools": "Tools",
  "Currently using an external Agent": "Currently using an external Agent",
  "Please go to the corresponding platform for control": "Please go to the corresponding platform for control",
  "Chatbot control is under development": "Chatbot control is under development",
  "Backend API is not yet implemented": "Backend API is not yet implemented",
  "Stream Control": "Stream Control",
  "Current Status": "Current Status",
  "Running": "Running",
  "Stopped": "Stopped",
  "Start Stream": "Start Stream",
  "Stop Stream": "Stop Stream",
  "Restart Stream": "Restart Stream",
  "Automatically connected to the server": "Automatically connected to the server",
  "No manual connection required for the built-in panel, please refresh if accidentally disconnected": "No manual connection required for the built-in panel, please refresh if accidentally disconnected",
  "Connection Settings": "Connection Settings",
  "Backend URL": "Backend URL",
  "Access Password (optional)": "Access Password (optional)",
  "Connect": "Connect",
  "Disconnect": "Disconnect",
  "Server Logs": "Server Logs",
  "Evil sold out": "*Evil sold out",
  "Neuro LLM Provider ID": "Neuro LLM Provider ID",
  "Neuro Memory LLM Provider ID": "Neuro Memory LLM Provider ID",
  "Reflection Threshold": "Reflection Threshold",
  "Chatbot LLM Provider ID": "Chatbot LLM Provider ID",
  "Chatbot Memory LLM Provider ID": "Chatbot Memory LLM Provider ID",
  "Automatic generated unique identifier for this provider instance.": "Automatic generated unique identifier for this provider instance.",
  "User-friendly name for this provider.": "User-friendly name for this provider.",
  "The type of the provider service.": "The type of the provider service.",
  "API key for authentication.": "API key for authentication.",
  "Optional custom base URL for the API endpoint.": "Optional custom base URL for the API endpoint.",
  "The specific model to be used (e.g., gpt-4, gemini-pro).": "The specific model to be used (e.g., gpt-4, gemini-pro).",
  "The service region for the provider (e.g., eastus).": "The service region for the provider (e.g., eastus).",
  "The ID of the LLM provider for Neuro's main responses.": "The ID of the LLM provider for Neuro's main responses.",
  "The ID of the LLM provider for Neuro's memory operations.": "The ID of the LLM provider for Neuro's memory operations.",
  "The ID of the TTS provider for speech synthesis.": "The ID of the TTS provider for speech synthesis.",
  "Number of recent chat messages to use as context in one turn.": "Number of recent chat messages to use as context in one turn.",
  "Time to wait after Neuro speaks before she can speak again.": "Time to wait after Neuro speaks before she can speak again.",
  "The message Neuro will see when the stream first starts.": "The message Neuro will see when the stream first starts.",
  "Max number of incoming events (chats, etc.) to hold in the queue.": "Max number of incoming events (chats, etc.) to hold in the queue.",
  "Number of turns before triggering memory consolidation. Set to 0 to disable.": "Number of turns before triggering memory consolidation. Set to 0 to disable.",
  "Whether to dynamically generate nicknames for viewers.": "Whether to dynamically generate nicknames for viewers.",
  "The number of dynamically generated nicknames to maintain.": "The number of dynamically generated nicknames to maintain.",
  "The ID of the LLM provider for the audience-facing chatbot.": "The ID of the LLM provider for the audience-facing chatbot.",
  "The ID of the LLM provider for the chatbot's memory operations.": "The ID of the LLM provider for the chatbot's memory operations.",
  "How often (in seconds) the chatbot should try to generate a message.": "How often (in seconds) the chatbot should try to generate a message.",
    "How many chat messages the chatbot should generate at once.": "How many chat messages the chatbot should generate at once.",
    "Settings for generating viewer nicknames.": "Settings for generating viewer nicknames.",
  "The nickname of the streamer.": "The nickname of the streamer.",
  "The title of the stream.": "The title of the stream.",
  "The category or game being streamed.": "The category or game being streamed.",
  "Tags to associate with the stream.": "Tags to associate with the stream.",
  "The IP address the server will bind to.": "The IP address the server will bind to.",
  "The port the server will listen on.": "The port the server will listen on.",
  "Password to protect access to the admin dashboard.": "Password to protect access to the admin dashboard.",
  "Allowed origins for CORS (whitelist for remote dashboard).": "Allowed origins for CORS (whitelist for remote dashboard).",
  "How many recent chat messages to keep in buffer for new clients.": "How many recent chat messages to keep in buffer for new clients.",
  "How many messages from buffer to send to a new client.": "How many messages from buffer to send to a new client.",
  "Configuration for Large Language Model providers.": "Configuration for Large Language Model providers.",
  "Configuration for Text-to-Speech providers.": "Configuration for Text-to-Speech providers.",
  "Settings for Neuro Agent.": "Settings for Neuro Agent.",
  "Settings for Chatbot Agent.": "Settings for Chatbot Agent.",
  "Settings related to the stream's appearance.": "Settings related to the stream's appearance.",
  "Settings for the server and performance.": "Settings for the server and performance.",
  "Force JSON Output": "Force JSON Output",
  "Ensures the model's output is always a valid JSON object, improving reliability for tool calls.": "Ensures the model's output is always a valid JSON object, improving reliability for tool calls.",
  "Temperature": "Temperature",
  "Controls randomness. Higher values (e.g., 1.2) make output more random, lower values (e.g., 0.7) make it more deterministic.": "Controls randomness. Higher values (e.g., 1.2) make output more random, lower values (e.g., 0.7) make it more deterministic.",
  "Top P": "Top P",
  "Nucleus sampling: model considers results of tokens with this probability mass. (e.g., 0.1 means only tokens comprising the top 10% probability mass are considered).": "Nucleus sampling: model considers results of tokens with this probability mass. (e.g., 0.1 means only tokens comprising the top 10% probability mass are considered).",
  "Top K": "Top K",
  "Model considers the top K most likely tokens at each step.": "Model considers the top K most likely tokens at each step.",
  "Frequency Penalty": "Frequency Penalty",
  "Positive values penalize new tokens based on their existing frequency, decreasing repetition. (OpenAI/Gemini)": "Positive values penalize new tokens based on their existing frequency, decreasing repetition. (OpenAI/Gemini)",
  "Presence Penalty": "Presence Penalty",
  "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. (OpenAI/Gemini)": "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. (OpenAI/Gemini)",
  "Max Output Tokens": "Max Output Tokens",
  "The maximum number of tokens to generate in the response.": "The maximum number of tokens to generate in the response.",
  "Stop Sequences": "Stop Sequences",
  "A list of strings that will cause the model to stop generating text if they are produced.": "A list of strings that will cause the model to stop generating text if they are produced.",
  "Seed": "Seed",
  "A seed for sampling to create reproducible results. (Useful for testing).": "A seed for sampling to create reproducible results. (Useful for testing).",
  "TTS Timeout (sec)": "TTS Timeout (sec)",
  "Timeout in seconds for the TTS synthesis request.": "Timeout in seconds for the TTS synthesis request.",
  "Ambient Chat Ratio": "Ambient Chat Ratio",
  "The proportion of chat messages in a batch that should be ambient/random instead of reacting to Neuro.": "The proportion of chat messages in a batch that should be ambient/random instead of reacting to Neuro.",
  "Enable Dynamic Nickname Pool": "Enable Dynamic Nickname Pool",
  "Whether to dynamically generate nicknames for viewers.": "Whether to dynamically generate nicknames for viewers.",
  "Dynamic Nickname Pool Size": "Dynamic Nickname Pool Size",
  "The number of dynamically generated nicknames to maintain.": "The number of dynamically generated nicknames to maintain.",
  "Initial Prompt": "Initial Prompt",
  "The message the chatbot will use as context before Neuro has spoken.": "The message the chatbot will use as context before Neuro has spoken.",
  "Recent History Lines": "Recent History Lines",
  "Number of recent spoken lines to include in the prompt context.": "Number of recent spoken lines to include in the prompt context.",
  "Post-Speech Cooldown Range (sec)": "Post-Speech Cooldown Range (sec)",
  "The min and max time to wait after a speech segment. A random value in this range is chosen. Set both to the same value for a fixed delay.": "The min and max time to wait after a speech segment. A random value in this range is chosen. Set both to the same value for a fixed delay.",
  "Neuro Filter LLM Provider ID": "Neuro Filter LLM Provider ID",
  "The ID of the LLM provider for Neuro's filter module. If not set, it will fallback to neuro_llm_provider_id.": "The ID of the LLM provider for Neuro's filter module. If not set, it will fallback to neuro_llm_provider_id.",
  "Enable Filter": "Enable Filter",
  "If true, a second LLM call is made via the Filter module to review and potentially revise Neuro's response.": "If true, a second LLM call is made via the Filter module to review and potentially revise Neuro's response.",
  "Log Level": "Log Level",
  "The minimum level of logs to display.": "The minimum level of logs to display.",
  "Danger Zone": "Danger Zone",
  "These actions are destructive and cannot be undone.": "These actions are destructive and cannot be undone.",
  "Reset Settings to Default": "Reset Settings to Default",
  "Reset Data to Initial State": "Reset Data to Initial State",
  "Are you sure you want to reset all settings to their default values? This cannot be undone.": "Are you sure you want to reset all settings to their default values? This cannot be undone.",
  "Configuration has been reset. The new settings are now active.": "Configuration has been reset. The new settings are now active.",
  "Failed to reset configuration.": "Failed to reset configuration.",
  "Are you sure you want to reset all data (prompts, memory, etc.) to the initial state? This cannot be undone.": "Are you sure you want to reset all data (prompts, memory, etc.) to the initial state? This cannot be undone.",
  "Data has been reset. The application is re-initializing with the new data.": "Data has been reset. The application is re-initializing with the new data.",
  "Failed to reset data.": "Failed to reset data."
}