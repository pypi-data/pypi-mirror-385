# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: envoy/service/metrics/v2/metrics_service.proto
# plugin: python-betterproto2
# This file has been @generated

__all__ = (
    "MetricsServiceStub",
    "StreamMetricsMessage",
    "StreamMetricsMessageIdentifier",
    "StreamMetricsResponse",
)

from collections.abc import Iterable
from dataclasses import dataclass

import betterproto2
import grpc

from .....message_pool import default_message_pool

_COMPILER_VERSION = "0.9.0"
betterproto2.check_compiler_version(_COMPILER_VERSION)


@dataclass(eq=False, repr=False)
class StreamMetricsMessage(betterproto2.Message):
    identifier: "StreamMetricsMessageIdentifier | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Identifier data effectively is a structured metadata. As a performance optimization this will
    only be sent in the first message on the stream.
    """

    envoy_metrics: "list[____io__prometheus__client__.MetricFamily]" = (
        betterproto2.field(2, betterproto2.TYPE_MESSAGE, repeated=True)
    )
    """
    A list of metric entries
    """


default_message_pool.register_message(
    "envoy.service.metrics.v2", "StreamMetricsMessage", StreamMetricsMessage
)


@dataclass(eq=False, repr=False)
class StreamMetricsMessageIdentifier(betterproto2.Message):
    node: "___api__v2__core__.Node | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The node sending metrics over the stream.
    """


default_message_pool.register_message(
    "envoy.service.metrics.v2",
    "StreamMetricsMessage.Identifier",
    StreamMetricsMessageIdentifier,
)


@dataclass(eq=False, repr=False)
class StreamMetricsResponse(betterproto2.Message):
    pass


default_message_pool.register_message(
    "envoy.service.metrics.v2", "StreamMetricsResponse", StreamMetricsResponse
)


class MetricsServiceStub:
    """
    [#protodoc-title: Metrics service]

    Service for streaming metrics to server that consumes the metrics data. It uses Prometheus metric
    data model as a standard to represent metrics information.
    """

    def __init__(self, channel: grpc.Channel):
        self._channel = channel

    def stream_metrics(
        self, messages: "Iterable[StreamMetricsMessage]"
    ) -> "StreamMetricsResponse":
        """
        Envoy will connect and send StreamMetricsMessage messages forever. It does not expect any
        response to be sent as nothing would be done in the case of failure.
        """

        return self._channel.stream_unary(
            "/envoy.service.metrics.v2.MetricsService/StreamMetrics",
            StreamMetricsMessage.SerializeToString,
            StreamMetricsResponse.FromString,
        )(iter(messages))


from .....io.prometheus import client as ____io__prometheus__client__
from ....api.v2 import core as ___api__v2__core__
