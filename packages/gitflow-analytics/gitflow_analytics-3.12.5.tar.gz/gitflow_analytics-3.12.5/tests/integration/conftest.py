"""Shared fixtures for integration tests.

This module provides fixtures for creating realistic test repositories,
configurations, and helper functions for verifying end-to-end workflows.
"""

import shutil
import tempfile
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any

import pytest
from git import Actor, Repo
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from gitflow_analytics.config import Config
from gitflow_analytics.core.cache import GitAnalysisCache
from gitflow_analytics.models.database import Base


@pytest.fixture
def temp_workspace():
    """Create a temporary workspace directory for test files and repositories.

    Yields:
        Path: Temporary workspace directory path

    Cleanup:
        Removes the entire workspace after test completes
    """
    workspace = Path(tempfile.mkdtemp(prefix="gitflow_test_"))
    yield workspace
    shutil.rmtree(workspace, ignore_errors=True)


@pytest.fixture
def test_author():
    """Create a consistent git author for test commits.

    Returns:
        Actor: GitPython Actor object with test author details
    """
    return Actor("Test Developer", "test@example.com")


@pytest.fixture
def test_repo_with_merges(temp_workspace, test_author):
    """Create a test Git repository with regular commits and merge commits.

    This fixture creates a realistic repository structure:
    - Main branch with 5 regular commits (10 lines each)
    - Feature branch with 5 commits (10 lines each)
    - Merge commit from feature â†’ main (creates large diff)
    - Another feature branch with 3 commits
    - Second merge commit

    Args:
        temp_workspace: Temporary directory for repository
        test_author: Git author for commits

    Returns:
        dict: Repository information containing:
            - repo: GitPython Repo object
            - repo_path: Path to repository
            - regular_commits: List of regular commit hashes
            - merge_commits: List of merge commit hashes
            - expected_lines_regular: Expected line count from regular commits
            - expected_lines_with_merges: Expected line count including merges
    """
    repo_path = temp_workspace / "test_repo"
    repo_path.mkdir()

    # Initialize repository
    repo = Repo.init(repo_path)

    # Configure git user
    with repo.config_writer() as config:
        config.set_value("user", "name", test_author.name)
        config.set_value("user", "email", test_author.email)

    file_path = repo_path / "test.txt"
    regular_commits = []
    merge_commits = []

    # Track expected line counts
    expected_lines_regular = 0
    expected_lines_with_merges = 0

    # Create 5 regular commits on main
    for i in range(5):
        content = f"Main content {i}\n" * 10  # 10 lines per commit
        file_path.write_text(content)
        # Use relative path to avoid macOS /var vs /private/var symlink issues
        repo.index.add(["test.txt"])
        commit = repo.index.commit(f"Main commit {i}", author=test_author, committer=test_author)
        regular_commits.append(commit.hexsha)
        expected_lines_regular += 10
        expected_lines_with_merges += 10

    # Capture default branch name before creating feature branch
    default_branch = repo.active_branch

    # Create feature branch
    feature_branch = repo.create_head("feature")
    feature_branch.checkout()

    # Create 5 commits on feature branch
    for i in range(5):
        content = f"Feature content {i}\n" * 10  # 10 lines per commit
        file_path.write_text(content)
        repo.index.add(["test.txt"])
        commit = repo.index.commit(f"Feature commit {i}", author=test_author, committer=test_author)
        regular_commits.append(commit.hexsha)
        expected_lines_regular += 10
        expected_lines_with_merges += 10

    # Switch back to default branch (main or master) and create merge commit
    default_branch.checkout()

    # Merge feature branch (no-ff to ensure merge commit is created)
    repo.git.merge("feature", no_ff=True, m="Merge feature branch")
    merge_commit = repo.head.commit
    merge_commits.append(merge_commit.hexsha)

    # Merge commits typically have large diffs (all feature changes)
    # In this case: 5 commits * 10 lines = 50 lines from merge
    expected_lines_with_merges += 50  # Approximate merge diff

    # Create second feature branch with more commits
    feature2_branch = repo.create_head("feature2")
    feature2_branch.checkout()

    for i in range(3):
        content = f"Feature2 content {i}\n" * 10  # 10 lines per commit
        file_path.write_text(content)
        repo.index.add(["test.txt"])
        commit = repo.index.commit(f"Feature2 commit {i}", author=test_author, committer=test_author)
        regular_commits.append(commit.hexsha)
        expected_lines_regular += 10
        expected_lines_with_merges += 10

    # Merge second feature branch
    default_branch.checkout()
    repo.git.merge("feature2", no_ff=True, m="Merge feature2 branch")
    merge_commit2 = repo.head.commit
    merge_commits.append(merge_commit2.hexsha)

    # Second merge adds ~30 lines from feature2
    expected_lines_with_merges += 30

    return {
        "repo": repo,
        "repo_path": repo_path,
        "regular_commits": regular_commits,
        "merge_commits": merge_commits,
        "expected_lines_regular": expected_lines_regular,
        "expected_lines_with_merges": expected_lines_with_merges,
        "total_commits": len(regular_commits) + len(merge_commits),
        "regular_commit_count": len(regular_commits),
        "merge_commit_count": len(merge_commits),
    }


@pytest.fixture
def test_config_dict(temp_workspace, test_repo_with_merges):
    """Create a test configuration dictionary for GitFlow Analytics.

    This fixture provides a configuration dictionary that can be used
    to configure the system for testing without requiring a full Config object.

    Args:
        temp_workspace: Temporary workspace directory
        test_repo_with_merges: Test repository with merge commits

    Returns:
        dict: Configuration dictionary
    """
    cache_dir = temp_workspace / ".gitflow-cache"
    cache_dir.mkdir(exist_ok=True)

    reports_dir = temp_workspace / "reports"
    reports_dir.mkdir(exist_ok=True)

    config_data = {
        "repositories": [
            {
                "name": "test-repo",
                "path": str(test_repo_with_merges["repo_path"]),
                "project_key": "TEST",
            }
        ],
        "cache_dir": str(cache_dir),
        "reports_dir": str(reports_dir),
        "analysis": {
            "exclude_merge_commits": True,  # Enable merge exclusion by default
        },
        "developers": {
            "identity_threshold": 0.85,
            "manual_mappings": [],
        },
        "tickets": {
            "default_platform": "github",
        },
    }

    return config_data


@pytest.fixture
def test_cache(temp_workspace):
    """Create a test cache instance.

    Args:
        temp_workspace: Temporary workspace directory

    Returns:
        GitAnalysisCache: Cache instance for testing
    """
    cache_dir = temp_workspace / ".gitflow-cache"
    cache_dir.mkdir(exist_ok=True)

    cache = GitAnalysisCache(
        cache_dir=cache_dir,
        ttl_hours=168,  # 1 week default
    )

    return cache


@pytest.fixture
def integration_db_session(test_cache):
    """Create a database session for integration tests.

    Args:
        test_cache: Test cache instance

    Returns:
        Session: SQLAlchemy database session

    Cleanup:
        Closes the session after test completes
    """
    session = test_cache.db.get_session()
    yield session
    session.close()


def verify_commit_in_database(session, commit_hash: str, repo_path: Path) -> dict[str, Any]:
    """Verify that a commit exists in the database and return its data.

    Args:
        session: Database session
        commit_hash: Commit hash to verify
        repo_path: Repository path for filtering

    Returns:
        dict: Commit data including filtered stats

    Raises:
        AssertionError: If commit is not found
    """
    from gitflow_analytics.models.database import CachedCommit

    commit = (
        session.query(CachedCommit)
        .filter(
            CachedCommit.commit_hash == commit_hash,
            CachedCommit.repo_path == str(repo_path),
        )
        .first()
    )

    assert commit is not None, f"Commit {commit_hash[:8]} not found in database"

    return {
        "hash": commit.commit_hash,
        "is_merge": commit.is_merge,
        "insertions": commit.insertions,
        "deletions": commit.deletions,
        "filtered_insertions": commit.filtered_insertions,
        "filtered_deletions": commit.filtered_deletions,
    }


def calculate_total_lines_from_commits(session, repo_path: Path, use_filtered: bool = True) -> dict[str, int]:
    """Calculate total line counts from commits in the database.

    Args:
        session: Database session
        repo_path: Repository path for filtering
        use_filtered: If True, use filtered stats; otherwise use raw stats

    Returns:
        dict: Total line counts with keys:
            - total_insertions: Total lines added
            - total_deletions: Total lines deleted
            - total_lines: Total lines changed
            - commit_count: Number of commits
    """
    from sqlalchemy import func
    from gitflow_analytics.models.database import CachedCommit

    if use_filtered:
        result = (
            session.query(
                func.sum(CachedCommit.filtered_insertions).label("insertions"),
                func.sum(CachedCommit.filtered_deletions).label("deletions"),
                func.count(CachedCommit.id).label("count"),
            )
            .filter(CachedCommit.repo_path == str(repo_path))
            .first()
        )
    else:
        result = (
            session.query(
                func.sum(CachedCommit.insertions).label("insertions"),
                func.sum(CachedCommit.deletions).label("deletions"),
                func.count(CachedCommit.id).label("count"),
            )
            .filter(CachedCommit.repo_path == str(repo_path))
            .first()
        )

    insertions = result.insertions or 0
    deletions = result.deletions or 0

    return {
        "total_insertions": insertions,
        "total_deletions": deletions,
        "total_lines": insertions + deletions,
        "commit_count": result.count or 0,
    }
