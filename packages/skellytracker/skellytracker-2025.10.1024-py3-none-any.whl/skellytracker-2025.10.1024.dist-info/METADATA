Metadata-Version: 2.4
Name: skellytracker
Version: 2025.10.1024
Summary: Top-level package for skellytracker
Keywords: camera,stream,video,image,opencv,skelly,freemocap,motion capture,synchronization,computer vision
Author-email: Skelly FreeMoCap <info@freemocap.org>
Requires-Python: >=3.9,<3.13
Description-Content-Type: text/markdown
Classifier: License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Healthcare Industry
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: End Users/Desktop
Classifier: Intended Audience :: Other Audience
Classifier: Natural Language :: English
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Utilities
Classifier: Topic :: Multimedia :: Video
Classifier: Topic :: Multimedia :: Video :: Capture
Classifier: Topic :: Multimedia :: Video :: Display
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Image Processing
Classifier: Topic :: Scientific/Engineering :: Visualization
Classifier: Topic :: Scientific/Engineering :: Human Machine Interfaces
Classifier: Topic :: System :: Hardware
Classifier: Topic :: System :: Hardware :: Universal Serial Bus (USB)
Classifier: Topic :: System :: Hardware :: Universal Serial Bus (USB) :: Video (UVC)
License-File: LICENSE
Requires-Dist: opencv-contrib-python==4.8.*
Requires-Dist: pydantic==2.*
Requires-Dist: numpy<2
Requires-Dist: tqdm==4.*
Requires-Dist: ultralytics~=8.3.132 ; extra == "all"
Requires-Dist: torch==2.8.* ; extra == "all"
Requires-Dist: torchvision==0.23.* ; extra == "all"
Requires-Dist: mediapipe==0.10.14 ; extra == "all"
Requires-Dist: black ; extra == "dev"
Requires-Dist: bumpver ; extra == "dev"
Requires-Dist: isort ; extra == "dev"
Requires-Dist: pip-tools ; extra == "dev"
Requires-Dist: pytest ; extra == "dev"
Requires-Dist: ruff ; extra == "dev"
Requires-Dist: mediapipe==0.10.14 ; extra == "mediapipe"
Requires-Dist: ultralytics~=8.3.132 ; extra == "yolo"
Requires-Dist: torch==2.8.* ; extra == "yolo"
Requires-Dist: torchvision==0.23.* ; extra == "yolo"
Project-URL: Homepage, https://github.com/freemocap/skellytracker
Provides-Extra: all
Provides-Extra: dev
Provides-Extra: mediapipe
Provides-Extra: yolo

# skellytracker

The tracking backend for freemocap. Collects different pose estimation tools and aggregates them using a consistent API. Can run pose estimation on images, webcams, and videos.

## Run skelly_tracker

Installation: `pip install skellytracker`
Then it can be run with `skellytracker`.

Running the basic `skellytracker` will open the first webcam port on your computer and run pose estimaiton in realtime with mediapipe holistic as a tracker. You can specify the tracker with `skellytracker TRACKER_NAME`, where `TRACKER_NAME` is the name of an available tracker. To view the names of all available trackers, see `RUN_ME.py`.

It will take some time to initialize the tracker the first time you run it, as it will likely need to download the model.

## Using skellytracker in your project

To use skellytracker in your project, import a tracker like `from skellytracker import YOLOPoseTracker`, then instantiate it with your desired parameters like `tracker = YOLOPoseTracker(model_size="medium")`, and then use `tracker.process_image(frame)` or `tracker.process_video(video_filepath)`. Processing image by image will let you access each individual annotated frame with `tracker.annotated_image`, and you can optionally record the data with `tracker.recorder.record()`. Access recorded data with `tracker.recorder.process_tracked_objects()`. The running, recording, and processing are done separately to give control over the amount of processing done at each step in the pipeline. Processing an entire video allows you to save the annotated frames as a video, and optionally saves and returns the data as a numpy array. Each tracker has an associated `ModelInfo` class to access model attributes.

Skellytracker is still under development, so version updates may make breaking changes to the API. Please report any issues and pull requests to the [skellytracker repo](https://github.com/freemocap/skellytracker).

### Extending the API
To extend the API, import the `BaseTracker` and `BaseRecorder` abstract base classes from skellytracker. Then create a new tracker and recorder inheriting from the base classes and implement all of the abstract methods.

## Contributing

We love your input! We want to make contributing to this project as easy and transparent as possible, whether it's:

- Reporting a bug
- Discussing the current state of the code
- Submitting a fix
- Proposing new features
- Becoming a maintainer

Pull requests are the best way to propose changes to the codebase (we
use [Github Flow](https://docs.github.com/en/get-started/quickstart/github-flow)). We actively welcome your pull
requests:

1. Fork the repo and create your branch from `main`.
2. Download the development dependencies with `pip install -e '.[dev]'`.
2. If you've added code that should be tested (including any tracker), add tests.
3. If you've changed APIs, update the documentation.
4. Ensure the test suite passes by running `pytest skellytracker/tests`.
5. Make sure your code lints.
6. Make that pull request!

