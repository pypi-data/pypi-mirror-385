{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Pytorch Models for Sequential Data\n",
    "output-file: hpopt.html\n",
    "title: Hyperparameter Optimization Module\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tune\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tsfast.data import *\n",
    "from tsfast.models import *\n",
    "from tsfast.learner import *\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.callback.core import Callback\n",
    "# from fastai.callback.schedule import *\n",
    "# from fastai.callback.rnn import *\n",
    "# from fastai.callback.tracker import *\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import *\n",
    "from ray.tune.experiment.trial import ExportFormat\n",
    "from ray.tune import Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = get_config().config_file.parent\n",
    "f_path = project_root / 'test_data/WienerHammerstein'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_files = L([f for f in get_hdf_files(f_path) if '_test.hdf5' not in str(f)])\n",
    "tfm_src = CreateDict([DfHDFCreateWindows(win_sz=400,stp_sz=100,clm='u')])\n",
    "dls = DataBlock(blocks=(SequenceBlock.from_hdf(['u'],TensorSequencesInput),\n",
    "                        SequenceBlock.from_hdf(['y'],TensorSequencesOutput)),\n",
    "                get_items=tfm_src,\n",
    "                splitter=ApplyToDict(FuncSplitter(lambda o: 'valid' in str(o)))).dataloaders(hdf_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need a log uniform distibution for variables with vast value ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def log_uniform(min_bound, max_bound, base=10):\n",
    "    '''uniform sampling in an exponential range'''\n",
    "    logmin = np.log(min_bound) / np.log(base)\n",
    "    logmax = np.log(max_bound) / np.log(base)\n",
    "    def _sample():\n",
    "        return base**(np.random.uniform(logmin, logmax))\n",
    "    return _sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.591524992137234e-08,\n",
       " 0.003755410605938488,\n",
       " 2.920688605923387e-07,\n",
       " 3.4750213799838236e-06,\n",
       " 2.1312097874133118e-08]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[log_uniform(1e-8, 1e-2)() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LearnerTrainable(tune.Trainable):\n",
    "\n",
    "    def setup(self, config):\n",
    "        self.create_lrn = ray.get(config['create_lrn'])\n",
    "        self.dls = ray.get(config['dls'])\n",
    "\n",
    "        self.lrn = self.create_lrn(self.dls,config)\n",
    "\n",
    "    def step(self):\n",
    "        with self.lrn.no_bar(): self.lrn.fit(1)\n",
    "        train_loss,valid_loss,rmse = self.lrn.recorder.values[-1]\n",
    "        result = {'train_loss': train_loss,\n",
    "                'valid_loss': valid_loss,\n",
    "                'mean_loss': rmse}\n",
    "        return result\n",
    "\n",
    "    def save_checkpoint(self, tmp_checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(tmp_checkpoint_dir, \"model.pth\")\n",
    "        torch.save(self.lrn.model.state_dict(), checkpoint_path)\n",
    "        return tmp_checkpoint_dir\n",
    "\n",
    "    def load_checkpoint(self, tmp_checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(tmp_checkpoint_dir, \"model.pth\")\n",
    "        self.lrn.model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    def _export_model(self, export_formats, export_dir):\n",
    "        if export_formats == [ExportFormat.MODEL]:\n",
    "            path = os.path.join(export_dir, \"exported_model\")\n",
    "            torch.save(self.lrn.model.state_dict(), path)\n",
    "            return {ExportFormat.MODEL: path}\n",
    "        else:\n",
    "            raise ValueError(\"unexpected formats: \" + str(export_formats))\n",
    "\n",
    "    # the learner class will be recreated with every perturbation, saving the model\n",
    "    # that way the new hyperparameter will be applied\n",
    "    def reset_config(self, new_config):\n",
    "        self.lrn = self.create_lrn(self.dls,new_config)\n",
    "        self.config = new_config\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from multiprocessing.managers import SharedMemoryManager\n",
    "def stop_shared_memory_managers(obj):\n",
    "    \"\"\"\n",
    "    Iteratively finds and stops all SharedMemoryManager instances contained within the provided object.\n",
    "    \"\"\"\n",
    "    visited = set()  # Track visited objects to avoid infinite loops\n",
    "    stack = [obj]  # Use a stack to manage objects to inspect\n",
    "\n",
    "    while stack:\n",
    "        current_obj = stack.pop()\n",
    "        obj_id = id(current_obj)\n",
    "\n",
    "        if obj_id in visited:\n",
    "            continue  # Skip already visited objects\n",
    "        visited.add(obj_id)\n",
    "\n",
    "        # Check if the current object is a SharedMemoryManager and stop it\n",
    "        if isinstance(current_obj, SharedMemoryManager):\n",
    "            current_obj.shutdown()\n",
    "            continue\n",
    "\n",
    "        # If it's a collection, add its items to the stack. Otherwise, add its attributes.\n",
    "        if isinstance(current_obj, dict):\n",
    "            stack.extend(current_obj.keys())\n",
    "            stack.extend(current_obj.values())\n",
    "        elif isinstance(current_obj, (list, set, tuple)):\n",
    "            stack.extend(current_obj)\n",
    "        elif hasattr(current_obj, '__dict__'):  # Check for custom objects with attributes\n",
    "            stack.extend(vars(current_obj).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import gc\n",
    "def learner_optimize(config):\n",
    "    try:\n",
    "        create_lrn = ray.get(config['create_lrn'])\n",
    "        dls = ray.get(config['dls'])\n",
    "        \n",
    "        #Scheduling Parameters for training the Model\n",
    "        lrn_kwargs = {'n_epoch':100,'pct_start':0.5}\n",
    "        for attr in ['n_epoch','pct_start']:\n",
    "            if attr in config: lrn_kwargs[attr] = config[attr]\n",
    "    \n",
    "        lrn = create_lrn(dls,config)\n",
    "        \n",
    "        # load checkpoint data if provided\n",
    "        checkpoint: tune.Checkpoint = tune.get_checkpoint()\n",
    "        if checkpoint:\n",
    "            with checkpoint.as_directory() as checkpoint_dir:\n",
    "                lrn.model.load_state_dict(torch.load(checkpoint_dir + 'model.pth'))\n",
    "        \n",
    "        lrn.lr = config['lr'] if 'lr' in config else 3e-3\n",
    "        lrn.add_cb(CBRayReporter() if 'reporter' not in config else ray.get(config['reporter'])())\n",
    "        with lrn.no_bar(): \n",
    "            ray.get(config['fit_method'])(lrn,**lrn_kwargs)\n",
    "    finally:\n",
    "        #cleanup shared memory even when earlystopping occurs\n",
    "        if 'lrn' in locals():\n",
    "            stop_shared_memory_managers(lrn)\n",
    "            del lrn\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainSpecificEpoch(Callback):\n",
    "    \"Skip training up to `epoch`\"\n",
    "    order = 70\n",
    "    \n",
    "    def __init__(self, epoch:int):\n",
    "        self._skip_to = epoch\n",
    "\n",
    "    def before_epoch(self):\n",
    "        print(self.epoch)\n",
    "        # if self.epoch < self._skip_to:\n",
    "        #     raise CancelEpochException\n",
    "        # if self.epoch > self._skip_to:\n",
    "        # raise CancelFitException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableModel(tune.Trainable):\n",
    "    def setup(self, config):\n",
    "        # Assuming create_lrn and dls are accessible here or passed in config\n",
    "        self.create_lrn = ray.get(config['create_lrn'])\n",
    "        self.dls = ray.get(config['dls'])\n",
    "        self.config = config\n",
    "\n",
    "        self.lrn = self.create_lrn(self.dls, config)\n",
    "\n",
    "        self.lrn.lr = config['lr'] if 'lr' in config else 3e-3\n",
    "        if 'wd' in config: self.lrn.wd = config['wd']\n",
    "        self._setup_callbacks()\n",
    "\n",
    "        if 'reporter' not in self.config:\n",
    "            self.lrn.add_cb(CBRayReporter())\n",
    "        else:\n",
    "            self.lrn.add_cb(ray.get(self.config['reporter'])())\n",
    "\n",
    "        if self.lrn.opt is None: self.lrn.create_opt()\n",
    "        self.lrn.opt.set_hyper('lr', self.lrn.lr)\n",
    "        lr = np.array([h['lr'] for h in self.lrn.opt.hypers])\n",
    "        pct_start = config['pct_start'] if 'pct_start' in config else 0.3\n",
    "        self.n_epoch = config['n_epoch'] if 'n_epoch' in config else 10\n",
    "        lr_scheds = {'lr': combined_cos(pct_start, lr, lr, lr/div_final)}\n",
    "        self.steps=0\n",
    "\n",
    "    def step(self):\n",
    "\n",
    "        self.fit(self.n_epoch, cbs=TrainSpecificEpoch(self.steps)+ParamScheduler(scheds)+L(cbs), wd=wd)\n",
    "        self.steps += 1\n",
    "\n",
    "        \n",
    "        scores = self.lrn.recorder.values[-1]\n",
    "        metrics = {\n",
    "            'train_loss': scores[0],\n",
    "            'valid_loss': scores[1]\n",
    "        }        \n",
    "        for metric,value in zip(self.learn.metrics,scores[2:]):\n",
    "            m_name = metric.name if hasattr(metric,'name') else str(metric)\n",
    "            metrics[m_name] = value\n",
    "        return metrics\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        file = os.path.join(temp_checkpoint_dir,'model.pth')\n",
    "        save_model(file, self.learn.model,opt=None) \n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        self.lrn.model.load_state_dict(torch.load(checkpoint_dir + 'model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableModel(tune.Trainable):\n",
    "    def setup(self, config):\n",
    "        # Assuming create_lrn and dls are accessible here or passed in config\n",
    "        self.create_lrn = ray.get(config['create_lrn'])\n",
    "        self.dls = ray.get(config['dls'])\n",
    "        self.config = config\n",
    "        self.lrn_kwargs = {'n_epoch': 100, 'pct_start': 0.5}\n",
    "\n",
    "        for attr in ['n_epoch', 'pct_start']:\n",
    "            if attr in config:\n",
    "                self.lrn_kwargs[attr] = config[attr]\n",
    "\n",
    "        self.lrn = self.create_lrn(self.dls, config)\n",
    "        self.lrn.lr = config['lr'] if 'lr' in config else 3e-3\n",
    "\n",
    "\n",
    "    def step(self):\n",
    "        print(self.iteration)\n",
    "        # fit_kwargs = {**self.lrn_kwargs,**{'cbs':TrainSpecificEpoch(self.iteration)}}\n",
    "        # fit_kwargs = {**self.lrn_kwargs,**{'cbs':SkipToEpoch(self.iteration)}}\n",
    "        # fit_kwargs = self.lrn_kwargs\n",
    "        with self.lrn.no_bar(): \n",
    "            # ray.get(self.config['fit_method'])(self.lrn,**fit_kwargs)\n",
    "            # self.lrn.fit_flat_cos(**fit_kwargs)\n",
    "            self.lrn.fit_flat_cos(self.lrn_kwargs['n_epoch'],cbs=TrainSpecificEpoch(self.iteration))\n",
    "\n",
    "        \n",
    "        metrics = {\n",
    "            'train_loss': 1,#scores[0],\n",
    "            'valid_loss': 1,#scores[1],\n",
    "             tune.result.DONE: self.iteration >= self.lrn_kwargs['n_epoch']-1\n",
    "        }  \n",
    "        \n",
    "        # scores = self.lrn.recorder.values[-1]\n",
    "        # metrics = {\n",
    "        #     'train_loss': scores[0],\n",
    "        #     'valid_loss': scores[1],\n",
    "        #      tune.result.DONE: self.epoch_iter >= self.lrn_kwargs['n_epoch']\n",
    "        # }        \n",
    "        # for metric,value in zip(self.lrn.metrics,scores[2:]):\n",
    "        #     m_name = metric.name if hasattr(metric,'name') else str(metric)\n",
    "        #     metrics[m_name] = value\n",
    "        return metrics\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        file = os.path.join(temp_checkpoint_dir,'model.pth')\n",
    "        save_model(file, self.learn.model,opt=None) \n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        self.lrn.model.load_state_dict(torch.load(checkpoint_dir + 'model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataBlock(blocks=(SequenceBlock.from_hdf(['u'],TensorSequencesInput),\n",
    "                    SequenceBlock.from_hdf(['y'],TensorSequencesOutput)),\n",
    "            get_items=tfm_src,\n",
    "            splitter=ApplyToDict(FuncSplitter(lambda o: 'valid' in str(o)))).dataloaders(hdf_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutation config dictionary consists of functions that sample from a distribution. In order to retrieve a dictionary with one realisation we need the function sample_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sample_config(config):\n",
    "    ret_conf = config.copy()\n",
    "    for k in ret_conf:\n",
    "        ret_conf[k]=ret_conf[k]()\n",
    "    return ret_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CBRayReporter(Callback):\n",
    "    \"`Callback` reports progress after every epoch to the ray tune logger\"\n",
    "    \n",
    "    order=70 #order has to be >50, to be executed after the recorder callback\n",
    "\n",
    "    def after_epoch(self):\n",
    "        # train_loss,valid_loss,rmse = self.learn.recorder.values[-1]\n",
    "        # metrics = {\n",
    "        #     'train_loss': train_loss,\n",
    "        #     'valid_loss': valid_loss,\n",
    "        #     'mean_loss': rmse,\n",
    "        # }\n",
    "        scores = self.learn.recorder.values[-1]\n",
    "        metrics = {\n",
    "            'train_loss': scores[0],\n",
    "            'valid_loss': scores[1]\n",
    "        }\n",
    "        for metric,value in zip(self.learn.metrics,scores[2:]):\n",
    "            m_name = metric.name if hasattr(metric,'name') else str(metric)\n",
    "            metrics[m_name] = value\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            file = os.path.join(temp_checkpoint_dir,'model.pth')\n",
    "            #the model has to be saved to the checkpoint directory on creation\n",
    "            #that is why a seperate callback for model saving is not trivial\n",
    "            save_model(file, self.learn.model,opt=None) \n",
    "            ray.tune.report(metrics, checkpoint=Checkpoint.from_directory(temp_checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HPOptimizer():\n",
    "    def __init__(self,create_lrn,dls):\n",
    "        self.create_lrn = create_lrn\n",
    "        self.dls = dls\n",
    "        self.analysis = None\n",
    "    \n",
    "    @delegates(ray.init)\n",
    "    def start_ray(self,**kwargs):\n",
    "        ray.shutdown()\n",
    "        ray.init(**kwargs)\n",
    "        \n",
    "    def stop_ray(self):\n",
    "        ray.shutdown()\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    @delegates(tune.run, keep=True)\n",
    "    def optimize(self,config,optimize_func=learner_optimize,resources_per_trial={\"gpu\": 1.0},verbose=1,**kwargs):\n",
    "        config['create_lrn'] = ray.put(self.create_lrn)\n",
    "        #dls are large objects, letting ray handle the copying process makes it much faster\n",
    "        config['dls'] = ray.put(self.dls) \n",
    "        if 'fit_method' not in config: config['fit_method'] = ray.put(Learner.fit_flat_cos)\n",
    "\n",
    "        self.analysis = tune.run(\n",
    "            optimize_func,\n",
    "            config=config,\n",
    "            resources_per_trial=resources_per_trial,\n",
    "            verbose=verbose,\n",
    "            **kwargs)\n",
    "        return self.analysis\n",
    "        \n",
    "    @delegates(tune.run, keep=True)\n",
    "    def optimize_pbt(self,opt_name,num_samples,config,mut_conf,perturbation_interval=2,\n",
    "                 stop={\"training_iteration\": 40 },\n",
    "                 resources_per_trial={\"gpu\": 1 },\n",
    "                 resample_probability=0.25,\n",
    "                 quantile_fraction=0.25,\n",
    "                 **kwargs):\n",
    "        self.mut_conf = mut_conf\n",
    "        \n",
    "        config['create_lrn'] = ray.put(self.create_lrn)\n",
    "        #dls are large objects, letting ray handle the copying process makes it much faster\n",
    "        config['dls'] = ray.put(self.dls) \n",
    "        \n",
    "\n",
    "        \n",
    "        scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        metric=\"mean_loss\",\n",
    "        mode=\"min\",\n",
    "        perturbation_interval=perturbation_interval,\n",
    "        resample_probability=resample_probability,\n",
    "        quantile_fraction=quantile_fraction,\n",
    "        hyperparam_mutations=mut_conf)\n",
    "        \n",
    "        self.analysis = tune.run(\n",
    "            LearnerTrainable,\n",
    "            name=opt_name,\n",
    "            scheduler=scheduler,\n",
    "            reuse_actors=True,\n",
    "            verbose=1,\n",
    "            stop=stop,\n",
    "            checkpoint_score_attr=\"mean_loss\",\n",
    "            num_samples=num_samples,\n",
    "            resources_per_trial=resources_per_trial,\n",
    "            config=config,\n",
    "            **kwargs)\n",
    "        return self.analysis\n",
    "    \n",
    "    def best_model(self):\n",
    "        if self.analysis is None: raise Exception\n",
    "        model = self.create_lrn(self.dls,sample_config(self.mut_conf)).model\n",
    "        f_path = ray.get(self.analysis.get_best_trial('mean_loss',mode='min').checkpoint.value)\n",
    "        model.load_state_dict(torch.load(f_path))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Population Based Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lrn(dls,config):\n",
    "    lr = config['lr']\n",
    "    alpha = config['alpha']\n",
    "    beta = config['beta']\n",
    "    weight_p = config['weight_p']\n",
    "    \n",
    "    lrn = RNNLearner(dls)\n",
    "    lrn.lr = lr\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "            \"lr\": tune.loguniform(1e-2, 1e-4),\n",
    "            \"alpha\": tune.loguniform(1e-5, 10),\n",
    "            \"beta\": tune.loguniform(1e-5, 10),\n",
    "            \"weight_p\": tune.uniform(0, 0.5)}\n",
    "mut_conf = {# distribution for resampling\n",
    "            \"lr\": log_uniform(1e-8, 1e-2),\n",
    "            \"alpha\": log_uniform(1e-5, 10),\n",
    "            \"beta\": log_uniform(1e-5, 10),\n",
    "            \"weight_p\": lambda: np.random.uniform(0, 0.5)}\n",
    "\n",
    "hp_opt = HPOptimizer(create_lrn,dls)\n",
    "# hp_opt.start_ray()\n",
    "# hp_opt.optimize_pbt('pbt_test',4,config,mut_conf,perturbation_interval=1,\n",
    "#                  stop={\"training_iteration\": 1 },\n",
    "#                  resources_per_trial={\"gpu\": 0.5},\n",
    "#                  storage_path=str(Path.home() / 'ray_results'))#no cpu count is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hp_opt.best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lrn(dls,config):\n",
    "    dls = DataBlock(blocks=(SequenceBlock.from_hdf(['u'],TensorSequencesInput),\n",
    "                        SequenceBlock.from_hdf(['y'],TensorSequencesOutput)),\n",
    "                get_items=tfm_src,\n",
    "                splitter=ApplyToDict(FuncSplitter(lambda o: 'valid' in str(o)))).dataloaders(hdf_files)\n",
    "    lrn = RNNLearner(dls,hidden_size=config['hidden_size'],metrics=[fun_rmse,mse])\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_opt = HPOptimizer(create_lrn,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"hidden_size\": tune.grid_search([10,20,50,100]),\n",
    "    'n_epoch':10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_opt.optimize(optimize_func=TrainableModel,\n",
    "#                 resources_per_trial={\"cpu\": 4},\n",
    "#                 config=search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_opt.analysis.get_best_config('mean_loss',mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
