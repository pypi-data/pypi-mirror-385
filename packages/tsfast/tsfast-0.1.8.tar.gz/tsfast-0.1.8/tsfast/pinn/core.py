# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/06_pinn/00_core.ipynb.

# %% auto 0
__all__ = ['DEFAULT_SIGNAL_TYPES', 'DEFAULT_SIGNAL_PARAMS', 'generate_excitation_signals', 'diff1_forward', 'diff1_central',
           'diff2_forward', 'diff2_central', 'diff3_forward', 'diff3_central', 'PhysicsLossCallback',
           'CollocationPointsCB']

# %% ../../nbs/06_pinn/00_core.ipynb 2
import torch
from fastai.learner import Callback
import numpy as np

# %% ../../nbs/06_pinn/00_core.ipynb 4
DEFAULT_SIGNAL_TYPES = ['sine', 'multisine', 'step', 'ramp', 'chirp', 'noise', 'prbs', 'square', 'doublet']

DEFAULT_SIGNAL_PARAMS = {
    'sine': {'phase_range': (0, 2*np.pi)},
    'multisine': {'n_components': 3},
    'step': {'time_range': (0.2, 0.8)},
    'ramp': {'slope_range': (-0.5, 0.5), 'start_time_range': (0.1, 0.6)},
    'chirp': {'f0_range': (0.1, 1.0), 'f1_range': (1.0, 5.0)},
    'prbs': {'switch_probability': 0.02},
    'square': {'duty_cycle_range': (0.3, 0.7)},
    'doublet': {'duration_range': (0.05, 0.2), 'start_time_range': (0.2, 0.5)}
}

def _generate_sine(
    seq_length:int, # Length of sequence
    dt:float, # Time step
    amplitudes:np.ndarray, # Signal amplitudes [num_signals]
    frequencies:np.ndarray, # Frequencies in Hz [num_signals]
    phases:np.ndarray # Phase offsets in radians [num_signals]
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple sine waves vectorized'''
    t = np.arange(seq_length) * dt
    return amplitudes[:, np.newaxis] * np.sin(2 * np.pi * frequencies[:, np.newaxis] * t + phases[:, np.newaxis])

def _generate_multisine(
    seq_length:int, # Length of sequence
    dt:float, # Time step
    amplitudes:np.ndarray, # Total signal amplitudes [num_signals]
    all_frequencies:list # List of frequency arrays, one per signal
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple multisine signals vectorized'''
    num_signals = len(amplitudes)
    t = np.arange(seq_length) * dt
    signals = np.zeros((num_signals, seq_length))
    for i in range(num_signals):
        freqs = all_frequencies[i]
        amp_per_component = amplitudes[i] / len(freqs)
        for freq in freqs:
            signals[i] += amp_per_component * np.sin(2 * np.pi * freq * t)
    return signals

def _generate_step(
    seq_length:int, # Length of sequence
    amplitudes:np.ndarray, # Step amplitudes [num_signals]
    step_indices:np.ndarray # Indices where step occurs [num_signals]
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple step signals vectorized'''
    num_signals = len(amplitudes)
    signals = np.zeros((num_signals, seq_length))
    for i in range(num_signals):
        signals[i, step_indices[i]:] = amplitudes[i]
    return signals

def _generate_ramp(
    seq_length:int, # Length of sequence
    amplitudes:np.ndarray, # Final amplitudes [num_signals]
    slopes:np.ndarray, # Slopes of ramps [num_signals]
    start_indices:np.ndarray # Start indices of ramps [num_signals]
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple ramp signals vectorized'''
    num_signals = len(amplitudes)
    signals = np.zeros((num_signals, seq_length))
    for i in range(num_signals):
        start_idx = start_indices[i]
        ramp_length = seq_length - start_idx
        signals[i, start_idx:] = slopes[i] * np.arange(ramp_length)
        signals[i] = np.clip(signals[i], -abs(amplitudes[i]), abs(amplitudes[i]))
    return signals

def _generate_chirp(
    seq_length:int, # Length of sequence
    dt:float, # Time step
    amplitudes:np.ndarray, # Signal amplitudes [num_signals]
    f0s:np.ndarray, # Start frequencies [num_signals]
    f1s:np.ndarray # End frequencies [num_signals]
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple chirp signals vectorized'''
    t = np.arange(seq_length) * dt
    duration = seq_length * dt
    k = (f1s - f0s) / duration
    phases = 2 * np.pi * (f0s[:, np.newaxis] * t + 0.5 * k[:, np.newaxis] * t * t)
    return amplitudes[:, np.newaxis] * np.sin(phases)

def _generate_noise(
    seq_length:int, # Length of sequence
    amplitudes:np.ndarray # Noise amplitudes (std) [num_signals]
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple Gaussian white noise signals vectorized'''
    num_signals = len(amplitudes)
    return amplitudes[:, np.newaxis] * np.random.randn(num_signals, seq_length)

def _generate_prbs(
    seq_length:int, # Length of sequence
    amplitudes:np.ndarray, # Signal amplitudes [num_signals]
    switch_probs:np.ndarray # Probabilities of switching per time step [num_signals]
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple PRBS signals'''
    num_signals = len(amplitudes)
    signals = np.zeros((num_signals, seq_length))
    for i in range(num_signals):
        current_level = amplitudes[i] if np.random.rand() < 0.5 else -amplitudes[i]
        signals[i, 0] = current_level
        for j in range(1, seq_length):
            if np.random.rand() < switch_probs[i]:
                current_level = -current_level
            signals[i, j] = current_level
    return signals

def _generate_square(
    seq_length:int, # Length of sequence
    dt:float, # Time step
    amplitudes:np.ndarray, # Signal amplitudes [num_signals]
    frequencies:np.ndarray, # Frequencies in Hz [num_signals]
    duty_cycles:np.ndarray # Duty cycles (0-1) [num_signals]
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple square wave signals vectorized'''
    t = np.arange(seq_length) * dt
    periods = 1.0 / frequencies
    phases = (t[np.newaxis, :] % periods[:, np.newaxis]) / periods[:, np.newaxis]
    return amplitudes[:, np.newaxis] * ((phases < duty_cycles[:, np.newaxis]).astype(float) * 2 - 1)

def _generate_doublet(
    seq_length:int, # Length of sequence
    amplitudes:np.ndarray, # Pulse amplitudes [num_signals]
    duration_indices:np.ndarray, # Duration of pulse in samples [num_signals]
    start_indices:np.ndarray # Start indices of pulses [num_signals]
) -> np.ndarray: # Signals [num_signals, seq_length]
    '''Generate multiple doublet signals'''
    num_signals = len(amplitudes)
    signals = np.zeros((num_signals, seq_length))
    for i in range(num_signals):
        end_idx = min(start_indices[i] + duration_indices[i], seq_length)
        signals[i, start_indices[i]:end_idx] = amplitudes[i]
    return signals


# %% ../../nbs/06_pinn/00_core.ipynb 5
def generate_excitation_signals(
    batch_size:int, # Number of sequences in batch
    seq_length:int, # Length of each sequence
    n_inputs:int = 1, # Number of input dimensions
    dt:float = 0.01, # Time step
    device:str = 'cpu', # Device for tensors
    signal_types:list = None, # Signal types to use (None = all core types)
    amplitude_range:tuple = (0.5, 2.0), # Global amplitude range
    frequency_range:tuple = (0.1, 3.0), # Global frequency range
    input_configs:list = None, # Per-input configuration (list of dicts)
    noise_probability:float = 0.0, # Probability of adding noise per sequence
    noise_std_range:tuple = (0.05, 0.15), # Noise std as fraction of amplitude
    bias_probability:float = 0.0, # Probability of adding DC bias per sequence
    bias_range:tuple = (-0.5, 0.5), # DC bias range
    synchronized_inputs:bool = False, # If True, all inputs get same signal type
    seed:int = None # Random seed
) -> torch.Tensor: # Returns [batch_size, seq_length, n_inputs]
    '''Generate standard excitation signals for PINN collocation points (vectorized)'''
    if seed is not None:
        np.random.seed(seed)
    
    signal_types = signal_types or DEFAULT_SIGNAL_TYPES
    total_signals = batch_size * n_inputs
    
    # Build configuration for each signal
    configs = []
    for batch_idx in range(batch_size):
        for input_idx in range(n_inputs):
            if input_configs and input_idx < len(input_configs):
                input_cfg = input_configs[input_idx]
                configs.append({
                    'amplitude_range': input_cfg.get('amplitude_range', amplitude_range),
                    'frequency_range': input_cfg.get('frequency_range', frequency_range),
                    'signal_types': input_cfg.get('signal_types', signal_types),
                    'signal_params': input_cfg.get('signal_params', {})
                })
            else:
                configs.append({
                    'amplitude_range': amplitude_range,
                    'frequency_range': frequency_range,
                    'signal_types': signal_types,
                    'signal_params': {}
                })
    
    # Pre-sample signal types (handling synchronized_inputs)
    signal_type_choices = np.empty(total_signals, dtype=object)
    if synchronized_inputs:
        for batch_idx in range(batch_size):
            sig_type = np.random.choice(signal_types)
            for input_idx in range(n_inputs):
                idx = batch_idx * n_inputs + input_idx
                signal_type_choices[idx] = sig_type
    else:
        for idx, cfg in enumerate(configs):
            signal_type_choices[idx] = np.random.choice(cfg['signal_types'])
    
    # Pre-sample amplitudes
    amplitudes = np.array([np.random.uniform(*cfg['amplitude_range']) for cfg in configs])
    
    # Group signals by type
    result = np.zeros((total_signals, seq_length))
    for sig_type in set(signal_type_choices):
        indices = np.where(signal_type_choices == sig_type)[0]
        if len(indices) == 0:
            continue
        
        type_amps = amplitudes[indices]
        type_configs = [configs[i] for i in indices]
        
        # Generate based on signal type
        if sig_type == 'sine':
            freqs = np.array([np.random.uniform(*cfg['signal_params'].get('sine', {}).get('frequency_range', cfg['frequency_range'])) 
                             for cfg in type_configs])
            phases = np.array([np.random.uniform(*cfg['signal_params'].get('sine', {}).get('phase_range', DEFAULT_SIGNAL_PARAMS['sine']['phase_range'])) 
                              for cfg in type_configs])
            result[indices] = _generate_sine(seq_length, dt, type_amps, freqs, phases)
        
        elif sig_type == 'multisine':
            all_freqs = []
            for cfg in type_configs:
                n_comp = cfg['signal_params'].get('multisine', {}).get('n_components', DEFAULT_SIGNAL_PARAMS['multisine']['n_components'])
                freq_range = cfg['signal_params'].get('multisine', {}).get('frequency_range', cfg['frequency_range'])
                all_freqs.append(np.random.uniform(*freq_range, size=n_comp))
            result[indices] = _generate_multisine(seq_length, dt, type_amps, all_freqs)
        
        elif sig_type == 'step':
            time_ranges = np.array([[*cfg['signal_params'].get('step', {}).get('time_range', DEFAULT_SIGNAL_PARAMS['step']['time_range'])] 
                                   for cfg in type_configs])
            step_times = np.random.uniform(time_ranges[:, 0], time_ranges[:, 1])
            step_indices = (step_times * seq_length).astype(int)
            result[indices] = _generate_step(seq_length, type_amps, step_indices)
        
        elif sig_type == 'ramp':
            slope_ranges = np.array([[*cfg['signal_params'].get('ramp', {}).get('slope_range', DEFAULT_SIGNAL_PARAMS['ramp']['slope_range'])] 
                                    for cfg in type_configs])
            start_time_ranges = np.array([[*cfg['signal_params'].get('ramp', {}).get('start_time_range', DEFAULT_SIGNAL_PARAMS['ramp']['start_time_range'])] 
                                         for cfg in type_configs])
            slopes = np.random.uniform(slope_ranges[:, 0], slope_ranges[:, 1])
            start_times = np.random.uniform(start_time_ranges[:, 0], start_time_ranges[:, 1])
            start_indices = (start_times * seq_length).astype(int)
            result[indices] = _generate_ramp(seq_length, type_amps, slopes, start_indices)
        
        elif sig_type == 'chirp':
            f0_ranges = np.array([[*cfg['signal_params'].get('chirp', {}).get('f0_range', DEFAULT_SIGNAL_PARAMS['chirp']['f0_range'])] 
                                 for cfg in type_configs])
            f1_ranges = np.array([[*cfg['signal_params'].get('chirp', {}).get('f1_range', DEFAULT_SIGNAL_PARAMS['chirp']['f1_range'])] 
                                 for cfg in type_configs])
            f0s = np.random.uniform(f0_ranges[:, 0], f0_ranges[:, 1])
            f1s = np.random.uniform(f1_ranges[:, 0], f1_ranges[:, 1])
            result[indices] = _generate_chirp(seq_length, dt, type_amps, f0s, f1s)
        
        elif sig_type == 'noise':
            result[indices] = _generate_noise(seq_length, type_amps)
        
        elif sig_type == 'prbs':
            switch_probs = np.array([cfg['signal_params'].get('prbs', {}).get('switch_probability', DEFAULT_SIGNAL_PARAMS['prbs']['switch_probability']) 
                                    for cfg in type_configs])
            result[indices] = _generate_prbs(seq_length, type_amps, switch_probs)
        
        elif sig_type == 'square':
            freqs = np.array([np.random.uniform(*cfg['signal_params'].get('square', {}).get('frequency_range', cfg['frequency_range'])) 
                             for cfg in type_configs])
            duty_cycle_ranges = np.array([[*cfg['signal_params'].get('square', {}).get('duty_cycle_range', DEFAULT_SIGNAL_PARAMS['square']['duty_cycle_range'])] 
                                         for cfg in type_configs])
            duty_cycles = np.random.uniform(duty_cycle_ranges[:, 0], duty_cycle_ranges[:, 1])
            result[indices] = _generate_square(seq_length, dt, type_amps, freqs, duty_cycles)
        
        elif sig_type == 'doublet':
            duration_ranges = np.array([[*cfg['signal_params'].get('doublet', {}).get('duration_range', DEFAULT_SIGNAL_PARAMS['doublet']['duration_range'])] 
                                       for cfg in type_configs])
            start_time_ranges = np.array([[*cfg['signal_params'].get('doublet', {}).get('start_time_range', DEFAULT_SIGNAL_PARAMS['doublet']['start_time_range'])] 
                                         for cfg in type_configs])
            durations = np.random.uniform(duration_ranges[:, 0], duration_ranges[:, 1])
            start_times = np.random.uniform(start_time_ranges[:, 0], start_time_ranges[:, 1])
            duration_indices = np.maximum(1, (durations * seq_length).astype(int))
            start_indices = (start_times * seq_length).astype(int)
            result[indices] = _generate_doublet(seq_length, type_amps, duration_indices, start_indices)
    
    # Vectorized composition: noise and bias
    if noise_probability > 0:
        noise_flags = np.random.rand(total_signals) < noise_probability
        if noise_flags.any():
            noise_stds = np.random.uniform(*noise_std_range, size=total_signals) * np.abs(amplitudes)
            noise_signals = _generate_noise(seq_length, noise_stds[noise_flags])
            result[noise_flags] += noise_signals
    
    if bias_probability > 0:
        bias_flags = np.random.rand(total_signals) < bias_probability
        if bias_flags.any():
            biases = np.random.uniform(*bias_range, size=bias_flags.sum())
            result[bias_flags] += biases[:, np.newaxis]
    
    # Reshape and convert to torch
    result = result.reshape(batch_size, n_inputs, seq_length).transpose(0, 2, 1)
    return torch.from_numpy(result).to(device).float()


# %% ../../nbs/06_pinn/00_core.ipynb 10
@torch.jit.script
def diff1_forward(signal: torch.Tensor, dt: float) -> torch.Tensor:
    """
    First-order forward difference (JIT-compiled).
    f'(x) ≈ (f(x+h) - f(x)) / h
    Accuracy: O(dt)
    """
    interior = (signal[:, 1:] - signal[:, :-1]) / dt
    last = interior[:, -1:]
    return torch.cat([interior, last], dim=1)


@torch.jit.script
def diff1_central(signal: torch.Tensor, dt: float) -> torch.Tensor:
    """
    First-order central difference (JIT-compiled).
    f'(x) ≈ (f(x+h) - f(x-h)) / (2h)
    Accuracy: O(dt²)
    """
    dt2 = 2.0 * dt
    interior = (signal[:, 2:] - signal[:, :-2]) / dt2
    first = (signal[:, 1:2] - signal[:, 0:1]) / dt
    last = (signal[:, -1:] - signal[:, -2:-1]) / dt
    return torch.cat([first, interior, last], dim=1)
    
@torch.jit.script
def diff2_forward(signal: torch.Tensor, dt: float) -> torch.Tensor:
    """
    Second-order forward difference (JIT-compiled).
    f''(x) ≈ (f(x+2h) - 2f(x+h) + f(x)) / h²
    Accuracy: O(dt)
    """
    dt_sq = dt * dt
    interior = (signal[:, 2:] - 2.0 * signal[:, 1:-1] + signal[:, :-2]) / dt_sq
    first = (signal[:, 2:3] - 2.0 * signal[:, 1:2] + signal[:, 0:1]) / dt_sq
    last = (signal[:, -1:] - 2.0 * signal[:, -2:-1] + signal[:, -3:-2]) / dt_sq
    return torch.cat([first, interior, last], dim=1)


@torch.jit.script
def diff2_central(signal: torch.Tensor, dt: float) -> torch.Tensor:
    """
    Second-order central difference (JIT-compiled).
    f''(x) ≈ (f(x+h) - 2f(x) + f(x-h)) / h²
    Accuracy: O(dt²)
    """
    dt_sq = dt * dt
    interior = (signal[:, 2:] - 2.0 * signal[:, 1:-1] + signal[:, :-2]) / dt_sq
    first = (signal[:, 2:3] - 2.0 * signal[:, 1:2] + signal[:, 0:1]) / dt_sq
    last = (signal[:, -1:] - 2.0 * signal[:, -2:-1] + signal[:, -3:-2]) / dt_sq
    return torch.cat([first, interior, last], dim=1)

@torch.jit.script
def diff3_forward(signal: torch.Tensor, dt: float) -> torch.Tensor:
    """
    Third-order forward difference (JIT-compiled).
    f'''(x) ≈ (f(x+3h) - 3f(x+2h) + 3f(x+h) - f(x)) / h³
    Accuracy: O(dt)
    """
    dt_cb = dt * dt * dt
    interior = (signal[:, 3:] - 3.0 * signal[:, 2:-1] + 3.0 * signal[:, 1:-2] - signal[:, :-3]) / dt_cb
    first = (signal[:, 3:4] - 3.0 * signal[:, 2:3] + 3.0 * signal[:, 1:2] - signal[:, 0:1]) / dt_cb
    second = first
    last = (signal[:, -1:] - 3.0 * signal[:, -2:-1] + 3.0 * signal[:, -3:-2] - signal[:, -4:-3]) / dt_cb
    return torch.cat([first, second, interior, last], dim=1)


@torch.jit.script
def diff3_central(signal: torch.Tensor, dt: float) -> torch.Tensor:
    """
    Third-order central difference (JIT-compiled).
    f'''(x) ≈ (f(x+2h) - 2f(x+h) + 2f(x-h) - f(x-2h)) / (2h³)
    Accuracy: O(dt²)
    """
    dt_cb = 2.0 * dt * dt * dt
    interior = (signal[:, 4:] - 2.0 * signal[:, 3:-1] + 2.0 * signal[:, 1:-3] - signal[:, :-4]) / dt_cb
    
    # Boundary using forward formula
    dt_cb_fwd = dt * dt * dt
    d1 = (signal[:, 3:4] - 3.0 * signal[:, 2:3] + 3.0 * signal[:, 1:2] - signal[:, 0:1]) / dt_cb_fwd
    d2 = (signal[:, 4:5] - 2.0 * signal[:, 3:4] + 2.0 * signal[:, 1:2] - signal[:, 0:1]) / dt_cb
    d_n1 = (signal[:, -1:] - 2.0 * signal[:, -2:-1] + 2.0 * signal[:, -4:-3] - signal[:, -5:-4]) / dt_cb
    d_n = (signal[:, -1:] - 3.0 * signal[:, -2:-1] + 3.0 * signal[:, -3:-2] - signal[:, -4:-3]) / dt_cb_fwd
    
    return torch.cat([d1, d2, interior, d_n1, d_n], dim=1)

# %% ../../nbs/06_pinn/00_core.ipynb 12
class PhysicsLossCallback(Callback):
    "`Callback` that adds physics-informed loss using actual training data"
    def __init__(self, 
                 norm_input, # Normalizer with `.mean` and `.std` for denormalization
                 physics_loss_func, # Function(y_pred, u_phys, learn) -> dict of losses or single loss tensor
                 weight: float = 1.0, # Global scaling factor for physics loss contribution
                 loss_weights: dict = None # Per-component weights like {'physics': 1.0, 'derivative': 0.1}
                ):
        '''Apply physics-informed loss to training batches after denormalizing inputs'''
        self.mean = norm_input.mean
        self.std = norm_input.std
        self.weight = weight
        self.loss_weights = loss_weights or {}
        self.physics_loss_func = physics_loss_func

    def after_loss(self):
        '''Compute physics-informed loss on training data and add to total loss'''
        if not self.training: return
        
        u_norm = self.xb[0]
        device = u_norm.device
        
        # Denormalize input to physical space
        mean, std = self.mean.to(device), self.std.to(device)
        u_phys = u_norm * std + mean
        
        # Get predictions (already computed in forward pass)
        y_pred = self.pred
        
        # Compute physics losses (system-specific)
        loss_dict = self.physics_loss_func(y_pred, u_phys, self.learn)
        
        # Handle both dict and single tensor returns
        if isinstance(loss_dict, dict):
            physics_total = sum(
                self.loss_weights.get(k, 1.0) * v 
                for k, v in loss_dict.items()
            )
        else:
            physics_total = loss_dict
        
        # Add weighted physics loss to main loss
        self.learn.loss = self.learn.loss + self.weight * physics_total
        self.learn.loss_grad = self.learn.loss_grad + self.weight * physics_total


# %% ../../nbs/06_pinn/00_core.ipynb 19
class CollocationPointsCB(Callback):
    "`Callback` that adds physics-informed loss using collocation points with user-defined physics"
    def __init__(self, 
                 norm_input, # Normalizer with `.mean` and `.std` attributes for input scaling
                 generate_pinn_input, # Function(batch_size, seq_len, device) -> tensor of collocation points
                 physics_loss_func, # Function(y_pred, u_coloc, learn) -> dict of losses or single loss tensor
                 weight: float = 1.0, # Global scaling factor for physics loss contribution
                 loss_weights: dict = None, # Per-component weights like {'physics': 1.0, 'derivative': 0.1}
                 num_workers: int = 2 # Number of parallel workers for collocation point generation
                ):
        """
        Initialize callback with normalization stats, collocation generator, and physics equations.
        """
        self.mean = norm_input.mean
        self.std = norm_input.std
        self.weight = weight
        self.loss_weights = loss_weights or {}
        self.generate_pinn_input = generate_pinn_input
        self.physics_loss_func = physics_loss_func
        self.num_workers = num_workers
        self.loader_iter = None

    def _prepare_loader(self, 
                       u_real # Sample tensor to infer batch_size and seq_length
                       ): # DataLoader with parallel workers
        "Create DataLoader with worker processes that continuously generate collocation points"
        class _Dataset(torch.utils.data.IterableDataset):
            def __init__(self, gen_fn, bs, seq_len):
                self.gen_fn = gen_fn
                self.bs = bs
                self.seq_len = seq_len
            
            def __iter__(self):
                while True:
                    yield self.gen_fn(self.bs, self.seq_len, 'cpu')
        
        loader = torch.utils.data.DataLoader(
            _Dataset(self.generate_pinn_input, u_real.shape[0], u_real.shape[1]),
            batch_size=None,
            num_workers=self.num_workers,
            prefetch_factor=2
        )
        return loader

    def after_loss(self):
        """
        Compute physics-informed loss on collocation points and add to training loss.
        Calls user-provided physics_loss_func to compute system-specific residuals.
        """
        if not self.training: return
        
        u_real = self.xb[0]
        device = u_real.device
        
        # Lazy initialization: create loader on first batch
        if self.loader_iter is None:
            self.loader_iter = iter(self._prepare_loader(u_real))
        
        # Get pre-generated collocation points from worker
        u_coloc_phys = next(self.loader_iter).to(device)
        mean, std = self.mean.to(device), self.std.to(device)
        u_norm = (u_coloc_phys - mean) / std
        
        # Forward pass with gradients enabled for physics loss
        with torch.enable_grad():
            y_pred = self.learn.model(u_norm)
        
        # Compute physics losses (system-specific)
        loss_dict = self.physics_loss_func(y_pred, u_coloc_phys, self.learn)
        
        # Handle both dict and single tensor returns
        if isinstance(loss_dict, dict):
            physics_total = sum(
                self.loss_weights.get(k, 1.0) * v 
                for k, v in loss_dict.items()
            )
        else:
            physics_total = loss_dict
        
        # Add weighted physics loss to main loss
        self.learn.loss = self.learn.loss + self.weight * physics_total
        self.learn.loss_grad = self.learn.loss_grad + self.weight * physics_total
