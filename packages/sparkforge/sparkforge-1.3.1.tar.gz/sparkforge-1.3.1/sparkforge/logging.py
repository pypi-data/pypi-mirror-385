"""
Simplified logging system for the framework.

This module provides a clean, focused logging system for pipeline operations
without the complexity of the previous over-engineered system.
"""

import logging
import sys
from contextlib import contextmanager
from datetime import datetime
from typing import Dict, Generator, List, Optional, Union


class PipelineLogger:
    """
    Simple, focused logging for pipeline operations.

    Features:
    - Basic logging levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)
    - Console and file output
    - Simple context management
    - Performance timing
    """

    def __init__(
        self,
        name: str = "PipelineRunner",
        level: int = logging.INFO,
        log_file: Optional[str] = None,
        verbose: bool = True,
    ):
        self.name = name
        self.level = level
        self.log_file = log_file
        self.verbose = verbose

        # Create logger
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)

        # Clear existing handlers
        self.logger.handlers.clear()

        # Setup handlers
        self._setup_handlers()

        # Performance tracking
        self._timers: Dict[str, datetime] = {}

    def _setup_handlers(self) -> None:
        """Setup logging handlers."""
        # Console handler
        if self.verbose:
            console_handler = logging.StreamHandler(sys.stdout)
            console_formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                datefmt="%H:%M:%S",
            )
            console_handler.setFormatter(console_formatter)
            console_handler.setLevel(self.level)
            self.logger.addHandler(console_handler)

        # File handler
        if self.log_file:
            file_handler = logging.FileHandler(self.log_file)
            file_formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                datefmt="%Y-%m-%d %H:%M:%S",
            )
            file_handler.setFormatter(file_formatter)
            file_handler.setLevel(self.level)
            self.logger.addHandler(file_handler)

    # Basic logging methods
    def debug(self, message: str, **kwargs: Union[str, int, float, bool, None]) -> None:
        """Log debug message."""
        self.logger.debug(self._format_message(message, kwargs))

    def info(self, message: str, **kwargs: Union[str, int, float, bool, None]) -> None:
        """Log info message."""
        self.logger.info(self._format_message(message, kwargs))

    def warning(self, message: str, **kwargs: Union[str, int, float, bool, None]) -> None:
        """Log warning message."""
        self.logger.warning(self._format_message(message, kwargs))

    def error(self, message: str, **kwargs: Union[str, int, float, bool, None]) -> None:
        """Log error message."""
        self.logger.error(self._format_message(message, kwargs))

    def critical(self, message: str, **kwargs: Union[str, int, float, bool, None]) -> None:
        """Log critical message."""
        self.logger.critical(self._format_message(message, kwargs))

    def _format_message(self, message: str, kwargs: Dict[str, Union[str, int, float, bool, None]]) -> str:
        """Format message with context."""
        if not kwargs:
            return message

        context = ", ".join(f"{k}={v}" for k, v in kwargs.items())
        return f"{message} | {context}"

    # Pipeline-specific logging methods
    def pipeline_start(self, pipeline_name: str, mode: str = "initial") -> None:
        """Log pipeline start."""
        self.info(f"üöÄ Starting pipeline: {pipeline_name} (mode: {mode})")

    def pipeline_end(
        self, pipeline_name: str, duration: float, success: bool = True
    ) -> None:
        """Log pipeline end."""
        status = "‚úÖ Success" if success else "‚ùå Failed"
        self.info(f"{status} pipeline: {pipeline_name} ({duration:.2f}s)")

    def step_start(self, stage: str, step: str) -> None:
        """Log step start."""
        self.info(f"üöÄ Starting {stage.upper()} step: {step}")

    def step_complete(
        self,
        stage: str,
        step: str,
        duration: float,
        rows_processed: int = 0,
        rows_written: Optional[int] = None,
        invalid_rows: Optional[int] = None,
        validation_rate: Optional[float] = None
    ) -> None:
        """Log step completion."""
        # Build the info string
        info_parts = [f"{duration:.2f}s"]

        # Add rows processed
        info_parts.append(f"{rows_processed:,} rows processed")

        # Add rows written if different from processed or if specified
        if rows_written is not None and rows_written != rows_processed:
            info_parts.append(f"{rows_written:,} written")

        # Add invalid rows if any (safely handle non-int types for mocking compatibility)
        try:
            if invalid_rows is not None and isinstance(invalid_rows, (int, float)) and invalid_rows > 0:
                info_parts.append(f"{invalid_rows:,} invalid")
        except (TypeError, AttributeError):
            # Handle Mock objects or other edge cases gracefully
            pass

        # Add validation rate
        if validation_rate is not None:
            info_parts.append(f"validation: {validation_rate:.1f}%")

        self.info(
            f"‚úÖ Completed {stage.upper()} step: {step} ({', '.join(info_parts)})"
        )

    def step_failed(
        self, stage: str, step: str, error: str, duration: float = 0
    ) -> None:
        """Log step failure."""
        self.error(
            f"‚ùå Failed {stage.upper()} step: {step} ({duration:.2f}s) - {error}"
        )

    def validation_passed(
        self, stage: str, step: str, rate: float, threshold: float
    ) -> None:
        """Log validation success."""
        self.info(
            f"‚úÖ Validation passed for {stage}:{step} - {rate:.2f}% >= {threshold:.2f}%"
        )

    def validation_failed(
        self, stage: str, step: str, rate: float, threshold: float
    ) -> None:
        """Log validation failure."""
        self.warning(
            f"‚ùå Validation failed for {stage}:{step} - {rate:.2f}% < {threshold:.2f}%"
        )

    def performance_metric(
        self, metric_name: str, value: float, unit: str = "s"
    ) -> None:
        """Log performance metric."""
        self.info(f"üìä {metric_name}: {value:.2f}{unit}")

    # Context management
    @contextmanager
    def context(
        self,
        **context_data: Union[str, int, float, bool, List[str], Dict[str, str], None],
    ) -> Generator[None, None, None]:
        """Add context to all log messages within this block."""
        # Store context in logger's extra data
        old_extra = getattr(self.logger, "extra", {})
        self.logger.extra = {**old_extra, **context_data}  # type: ignore[attr-defined]
        try:
            yield
        finally:
            self.logger.extra = old_extra  # type: ignore[attr-defined]

    # Performance timing
    def start_timer(self, operation: str) -> None:
        """Start timing an operation."""
        self._timers[operation] = datetime.utcnow()

    def end_timer(self, operation: str) -> float:
        """End timing an operation and return duration."""
        if operation not in self._timers:
            return 0.0

        start_time = self._timers.pop(operation)
        duration = (datetime.utcnow() - start_time).total_seconds()
        self.performance_metric(operation, duration)
        return duration

    @contextmanager
    def timer(self, operation: str) -> Generator[None, None, None]:
        """Context manager for timing operations."""
        self.start_timer(operation)
        try:
            yield
        finally:
            self.end_timer(operation)

    # Utility methods
    def set_level(self, level: int) -> None:
        """Set logging level."""
        self.level = level
        self.logger.setLevel(level)
        for handler in self.logger.handlers:
            handler.setLevel(level)

    def close(self) -> None:
        """Close all handlers."""
        for handler in self.logger.handlers:
            handler.close()
        self.logger.handlers.clear()


# Global logger instance
_global_logger: Optional[PipelineLogger] = None


def get_logger() -> PipelineLogger:
    """Get the global logger instance."""
    global _global_logger
    if _global_logger is None:
        _global_logger = PipelineLogger()
    return _global_logger


def set_logger(logger: PipelineLogger) -> None:
    """Set the global logger instance."""
    global _global_logger
    _global_logger = logger


def create_logger(
    name: str = "PipelineRunner",
    level: int = logging.INFO,
    log_file: Optional[str] = None,
    verbose: bool = True,
) -> PipelineLogger:
    """Create a new logger instance."""
    return PipelineLogger(name=name, level=level, log_file=log_file, verbose=verbose)


def get_global_logger() -> PipelineLogger:
    """Get the global logger instance (alias for get_logger)."""
    return get_logger()


def set_global_logger(logger: PipelineLogger) -> None:
    """Set the global logger instance (alias for set_logger)."""
    set_logger(logger)


def reset_global_logger() -> None:
    """Reset the global logger instance."""
    global _global_logger
    if _global_logger is not None:
        _global_logger.close()
    _global_logger = None
