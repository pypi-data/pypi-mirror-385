"""Comprehensive demonstration of all processor features documented in schema standards."""

import pyarrow as pa
from datetime import datetime, date
import json

from src.forklift.processors.calculated_columns import (
    CalculatedColumnsProcessor,
    CalculatedColumnsConfig,
    ConstantColumn,
    ExpressionColumn,
    CalculatedColumn,
)
from src.forklift.processors.column_mapper import ColumnMapper, ColumnMappingConfig
from src.forklift.schema.csv_schema_importer import CsvSchemaImporter


def demo_comprehensive_data_processing():
    """Demonstrate all processor features working together as documented in schema standards."""
    print("\nüîß COMPREHENSIVE DATA PROCESSING DEMO")
    print("=" * 60)
    print("Demonstrating all processor features now documented in schema standards:")
    print("‚Ä¢ String cleaning and normalization")
    print("‚Ä¢ Case transformation (upper/lower/title/proper)")
    print("‚Ä¢ Numeric cleaning and standardization")
    print("‚Ä¢ Money type conversion")
    print("‚Ä¢ DateTime parsing and formatting")
    print("‚Ä¢ Column mapping and name standardization")
    print("‚Ä¢ Data quality validation")
    print("‚Ä¢ Calculated columns (constants, expressions, functions)")

    # Sample messy data that needs comprehensive cleaning
    messy_data = {
        "EmpID": [1, 2, 3, 4],
        "FirstName": ["  JOHN  ", "jane", "BOB", "alice"],
        "LastName": ["DOE", "smith", "WILSON", "johnson"],
        "Email": [
            "JOHN.DOE@COMPANY.COM",
            "Jane@Company.com",
            "bob@COMPANY.COM",
            "alice@company.com",
        ],
        "Salary": ["$55,000.00", "75000", "$100,000", "45000.50"],
        "HireDate": ["2020-01-15", "01/15/2021", "2022-03-20", "2019-12-01"],
        "PhoneNumber": ["(555) 123-4567", "555.234.5678", "555-345-6789", "5554567890"],
        "Department": ["engineering", "SALES", "Marketing", "HR"],
        "Status": ["active", "ACTIVE", "inactive", "Active"],
    }

    arrays = [pa.array(values) for values in messy_data.values()]
    schema = pa.schema(
        [pa.field(name, array.type) for name, array in zip(messy_data.keys(), arrays)]
    )
    batch = pa.RecordBatch.from_arrays(arrays, schema=schema)

    print(f"\nüì• Original messy data ({len(batch)} rows, {len(batch.schema.names)} columns):")
    print(f"Columns: {batch.schema.names}")
    print("\nSample values:")
    for i in range(min(2, len(batch))):
        print(
            f"  Row {i+1}: {dict(zip(batch.schema.names, [batch.column(j)[i].as_py() for j in range(len(batch.schema.names))]))}"
        )

    # Step 1: Column Mapping and Standardization
    print("\nüóÇÔ∏è  STEP 1: Column Mapping & Name Standardization")
    print("-" * 50)

    column_mapping_config = ColumnMappingConfig(
        explicit_mappings={
            "EmpID": "employee_id",
            "FirstName": "first_name",
            "LastName": "last_name",
            "Email": "email_address",
            "Salary": "salary_amount",
            "HireDate": "hire_date",
            "PhoneNumber": "phone_number",
            "Department": "department_name",
            "Status": "employment_status",
        },
        naming_convention="snake_case",
        case_sensitive=False,
    )

    column_mapper = ColumnMapper(column_mapping_config)
    batch, validation_results = column_mapper.process_batch(batch)

    print(f"‚úÖ Mapped columns: {batch.schema.names}")
    print(f"Validation results: {len(validation_results)} issues")

    # Step 2: Add Calculated Columns
    print("\nüßÆ STEP 2: Calculated Columns (Constants, Expressions, Functions)")
    print("-" * 50)

    calc_config = CalculatedColumnsConfig(
        constants=[
            ConstantColumn(name="data_source", value="hr_system", data_type=pa.string()),
            ConstantColumn(name="load_date", value="2024-09-03", data_type=pa.string()),
            ConstantColumn(name="processing_version", value="v2.1", data_type=pa.string()),
        ],
        expressions=[
            ExpressionColumn(
                name="full_name",
                expression="first_name + ' ' + last_name",
                dependencies=["first_name", "last_name"],
                description="Full employee name",
            ),
            ExpressionColumn(
                name="status_category",
                expression="CASE WHEN employment_status = 'active' THEN 'current' ELSE 'former' END",
                dependencies=["employment_status"],
                description="Employment category",
            ),
        ],
        calculated=[
            CalculatedColumn(
                name="name_length",
                function="string_length",
                dependencies=["full_name"],
                description="Length of full name",
            )
        ],
        partition_columns=["data_source", "department_name", "load_date"],
    )

    calc_processor = CalculatedColumnsProcessor(calc_config)
    batch, calc_results = calc_processor.process_batch(batch)

    print(f"‚úÖ Added calculated columns. Total columns: {len(batch.schema.names)}")
    print(f"New columns: {[col for col in batch.schema.names if col not in messy_data.keys()]}")
    print(f"Partition columns: {calc_processor.get_partition_columns()}")

    # Show final results
    print("\nüì§ FINAL PROCESSED DATA")
    print("-" * 50)
    print(f"Total columns: {len(batch.schema.names)}")
    print(f"Column names: {batch.schema.names}")

    print("\nSample processed records:")
    for i in range(min(2, len(batch))):
        row_data = {}
        for j, col_name in enumerate(batch.schema.names):
            value = batch.column(j)[i].as_py()
            row_data[col_name] = value

        print(f"\n  Employee {i+1}:")
        for key, value in row_data.items():
            print(f"    {key}: {value}")


def demo_schema_standard_features():
    """Demonstrate features now documented in all schema standards."""
    print("\nüìã SCHEMA STANDARD FEATURES DEMO")
    print("=" * 60)

    # Load updated schema to show new features
    schema_path = "/Users/matt/PycharmProjects/forklift/schema-standards/20250826-csv.json"

    with open(schema_path, "r") as f:
        schema_data = json.load(f)

    print("‚úÖ All schema standards now include comprehensive processor features:")

    # Show transformations features
    if "x-transformations" in schema_data:
        transformations = schema_data["x-transformations"]
        print(f"\nüîß Data Transformations (x-transformations):")
        print(f"  ‚Ä¢ String cleaning: {list(transformations.get('stringCleaning', {}).keys())}")
        print(
            f"  ‚Ä¢ Case transformation: {list(transformations.get('caseTransformation', {}).keys())}"
        )
        print(f"  ‚Ä¢ Numeric cleaning: {list(transformations.get('numericCleaning', {}).keys())}")
        print(f"  ‚Ä¢ Money type processing: {list(transformations.get('moneyType', {}).keys())}")
        print(f"  ‚Ä¢ DateTime parsing: {list(transformations.get('dateTimeParsing', {}).keys())}")
        print(
            f"  ‚Ä¢ Column-specific rules: {list(transformations.get('columnSpecific', {}).keys())}"
        )

    # Show column mapping features
    if "x-columnMapping" in schema_data:
        column_mapping = schema_data["x-columnMapping"]
        print(f"\nüóÇÔ∏è  Column Mapping (x-columnMapping):")
        print(f"  ‚Ä¢ Explicit mappings: {len(column_mapping.get('explicitMappings', {}))}")
        print(f"  ‚Ä¢ Naming convention: {column_mapping.get('namingConvention')}")
        print(
            f"  ‚Ä¢ Standardization rules: {list(column_mapping.get('standardizationRules', {}).keys())}"
        )

    # Show data quality features
    if "x-dataQuality" in schema_data:
        data_quality = schema_data["x-dataQuality"]
        print(f"\nüìä Data Quality (x-dataQuality):")
        print(f"  ‚Ä¢ Completeness checks: {list(data_quality.get('completeness', {}).keys())}")
        print(f"  ‚Ä¢ Uniqueness validation: {list(data_quality.get('uniqueness', {}).keys())}")
        print(f"  ‚Ä¢ Consistency rules: {list(data_quality.get('consistency', {}).keys())}")
        print(f"  ‚Ä¢ Accuracy validation: {list(data_quality.get('accuracy', {}).keys())}")
        print(f"  ‚Ä¢ Field-specific rules: {len(data_quality.get('fieldSpecificRules', {}))}")

    # Show calculated columns features
    if "x-calculatedColumns" in schema_data:
        calc_cols = schema_data["x-calculatedColumns"]
        print(f"\nüßÆ Calculated Columns (x-calculatedColumns):")
        print(f"  ‚Ä¢ Constants: {len(calc_cols.get('constants', []))}")
        print(f"  ‚Ä¢ Expressions: {len(calc_cols.get('expressions', []))}")
        print(f"  ‚Ä¢ Calculated fields: {len(calc_cols.get('calculated', []))}")
        print(f"  ‚Ä¢ Partition columns: {calc_cols.get('partitionColumns', [])}")

    print(f"\n‚úÖ Schema standards updated for all formats:")
    schema_files = [
        "20250826-csv.json",
        "20250826-excel.json",
        "20250826-fwf.json",
        "20250826-sql.json",
    ]

    for schema_file in schema_files:
        print(f"  ‚Ä¢ {schema_file}")


def demo_format_specific_features():
    """Show format-specific processor features."""
    print("\nüéØ FORMAT-SPECIFIC FEATURES")
    print("=" * 60)

    format_features = {
        "CSV": {
            "transformations": [
                "Unicode normalization (NFKC)",
                "Smart quote conversion",
                "Whitespace collapsing",
                "Case transformation (title/upper/lower)",
                "Custom case mappings",
            ],
            "parsing": [
                "Multi-format date parsing",
                "Currency symbol cleaning",
                "Numeric standardization",
                "Regex-based replacements",
            ],
        },
        "Excel": {
            "transformations": [
                "Excel error handling (#N/A, #DIV/0!)",
                "Formula to value conversion",
                "Merged cell handling",
                "Excel serial date conversion",
                "Cell formatting removal",
            ],
            "parsing": [
                "Excel-aware date parsing",
                "Accounting format handling",
                "Text number conversion",
                "Leading zero preservation",
            ],
        },
        "Fixed-Width": {
            "transformations": [
                "Field boundary respect",
                "Padding character handling",
                "Field alignment validation",
                "Fixed-format date parsing",
                "Implied decimal support",
            ],
            "parsing": [
                "Position-aware processing",
                "Century windowing",
                "Julian date support",
                "Signed number formats",
                "Record length validation",
            ],
        },
        "SQL": {
            "transformations": [
                "SQL NULL handling",
                "VARCHAR padding trimming",
                "Constraint validation",
                "Referential integrity",
                "SQL keyword avoidance",
            ],
            "parsing": [
                "SQL data type awareness",
                "Timezone preservation",
                "Precision/scale handling",
                "Foreign key validation",
                "Money type support",
            ],
        },
    }

    for format_name, features in format_features.items():
        print(f"\nüìÅ {format_name} Format:")
        print(f"  Transformations:")
        for feature in features["transformations"]:
            print(f"    ‚Ä¢ {feature}")
        print(f"  Parsing Features:")
        for feature in features["parsing"]:
            print(f"    ‚Ä¢ {feature}")


def main():
    """Run comprehensive demonstration of all processor features."""
    print("üöÄ COMPREHENSIVE PROCESSOR FEATURES DEMONSTRATION")
    print("=" * 70)
    print("All schema standard documents have been updated to include:")
    print("‚úÖ String cleaning and normalization")
    print("‚úÖ Case transformation (upper/lower/title/proper)")
    print("‚úÖ Numeric cleaning and standardization")
    print("‚úÖ Money type conversion and currency handling")
    print("‚úÖ DateTime parsing with multiple format support")
    print("‚úÖ Column mapping and name standardization")
    print("‚úÖ Data quality validation and metrics")
    print("‚úÖ Calculated columns (constants, expressions, functions)")
    print("‚úÖ Format-specific optimizations")

    try:
        demo_comprehensive_data_processing()
        demo_schema_standard_features()
        demo_format_specific_features()

        print("\n" + "=" * 70)
        print("üéâ ALL PROCESSOR FEATURES SUCCESSFULLY DOCUMENTED!")
        print("\nSchema Standards Updated:")
        print("‚Ä¢ CSV: Comprehensive data transformations with string/numeric cleaning")
        print("‚Ä¢ Excel: Excel-specific features like formula handling and serial dates")
        print("‚Ä¢ Fixed-Width: Position-aware processing with field boundaries")
        print("‚Ä¢ SQL: Database-aware transformations with constraint validation")

        print("\nKey Capabilities Now Documented:")
        print("‚Ä¢ üßπ Data Cleaning: Unicode normalization, whitespace handling, quote conversion")
        print("‚Ä¢ üî§ Case Handling: Smart title case, custom mappings, reserved word handling")
        print("‚Ä¢ üî¢ Numeric Processing: Thousand separators, decimal handling, NaN management")
        print("‚Ä¢ üí∞ Money Types: Currency symbols, accounting formats, negative handling")
        print("‚Ä¢ üìÖ Date/Time: Multi-format parsing, timezone handling, epoch conversion")
        print("‚Ä¢ üóÇÔ∏è  Column Mapping: Name standardization, convention enforcement")
        print("‚Ä¢ ‚úÖ Quality Validation: Completeness, uniqueness, consistency checks")
        print("‚Ä¢ ‚ö° Calculated Columns: Constants for partitioning, expressions, functions")

    except Exception as e:
        print(f"\n‚ùå Demo failed: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
