"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
Copyright 2025 Phonexia s.r.o.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

Phonexia Time Analysis gRPC API.
"""

import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.message
import phonexia.grpc.common.core_pb2
import typing

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

@typing.final
class AnalyzeRequest(google.protobuf.message.Message):
    """The top-level message sent by the client for the <code>Analyze</code>
    method.
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    AUDIO_FIELD_NUMBER: builtins.int
    @property
    def audio(self) -> phonexia.grpc.common.core_pb2.Audio:
        """Audio data for which Time Analysis should be performed.
        Audio can be either mono or stereo. In case of mono, only the ChannelAnalysis
        message is returned. At least 900 milliseconds of audio is required, otherwise
        the result will not contain any analyses.
        """

    def __init__(
        self,
        *,
        audio: phonexia.grpc.common.core_pb2.Audio | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["audio", b"audio"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["audio", b"audio"]) -> None: ...

global___AnalyzeRequest = AnalyzeRequest

@typing.final
class ReactionAnalysis(google.protobuf.message.Message):
    """Time Analysis of how an individual channel reacts to the other channel."""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    REACTING_CHANNEL_FIELD_NUMBER: builtins.int
    REACTIONS_COUNT_FIELD_NUMBER: builtins.int
    AVERAGE_REACTION_TIME_FIELD_NUMBER: builtins.int
    FASTEST_REACTION_POSITION_FIELD_NUMBER: builtins.int
    SLOWEST_REACTION_POSITION_FIELD_NUMBER: builtins.int
    CROSSTALKS_FIELD_NUMBER: builtins.int
    reacting_channel: builtins.int
    """Index of the channel whose reactions are analyzed."""
    reactions_count: builtins.int
    """Number of reactions of this channel to the other channel. A "reaction" is defined
    as the act when the speaker in the reacting channel starts speaking AFTER the
    speaker in the other channel has stopped speaking.
    """
    @property
    def average_reaction_time(self) -> google.protobuf.duration_pb2.Duration:
        """Average time that elapsed between the speaker in the other channel stopped speaking
        and the speaker in the reacting channel started speaking.
        When no reaction to the other channel was detected, this field is set to 0.
        """

    @property
    def fastest_reaction_position(self) -> phonexia.grpc.common.core_pb2.TimeRange:
        """Position of this channel's fastest reaction (shortest reaction time).
        When no reaction to the other channel was detected, this field is set to 0.
        """

    @property
    def slowest_reaction_position(self) -> phonexia.grpc.common.core_pb2.TimeRange:
        """Position of this channel's slowest reaction (longest reaction time).
        When no reaction to the other channel was detected, this field is set to 0.
        """

    @property
    def crosstalks(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[phonexia.grpc.common.core_pb2.TimeRange]:
        """List of positions of this channel's crosstalks. A "crosstalk" is defined as the act
        when the speaker in the reacting channel starts speaking WHILE the speaker in the
        other channel is still speaking. The crosstalk lasts as long as both speakers are
        speaking.
        """

    def __init__(
        self,
        *,
        reacting_channel: builtins.int = ...,
        reactions_count: builtins.int = ...,
        average_reaction_time: google.protobuf.duration_pb2.Duration | None = ...,
        fastest_reaction_position: phonexia.grpc.common.core_pb2.TimeRange | None = ...,
        slowest_reaction_position: phonexia.grpc.common.core_pb2.TimeRange | None = ...,
        crosstalks: collections.abc.Iterable[phonexia.grpc.common.core_pb2.TimeRange] | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["average_reaction_time", b"average_reaction_time", "fastest_reaction_position", b"fastest_reaction_position", "slowest_reaction_position", b"slowest_reaction_position"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["average_reaction_time", b"average_reaction_time", "crosstalks", b"crosstalks", "fastest_reaction_position", b"fastest_reaction_position", "reacting_channel", b"reacting_channel", "reactions_count", b"reactions_count", "slowest_reaction_position", b"slowest_reaction_position"]) -> None: ...

global___ReactionAnalysis = ReactionAnalysis

@typing.final
class ChannelAnalysis(google.protobuf.message.Message):
    """Time Analysis for an individual channel."""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    CHANNEL_NUMBER_FIELD_NUMBER: builtins.int
    SPEECH_LENGTH_FIELD_NUMBER: builtins.int
    SPEECH_RATE_FIELD_NUMBER: builtins.int
    TOTAL_LENGTH_FIELD_NUMBER: builtins.int
    channel_number: builtins.int
    """Index of the channel."""
    speech_rate: builtins.float
    """Speech rate as the number of phonemes per second."""
    @property
    def speech_length(self) -> google.protobuf.duration_pb2.Duration:
        """Length of speech in this channel."""

    @property
    def total_length(self) -> google.protobuf.duration_pb2.Duration:
        """Length of audio in this channel."""

    def __init__(
        self,
        *,
        channel_number: builtins.int = ...,
        speech_length: google.protobuf.duration_pb2.Duration | None = ...,
        speech_rate: builtins.float | None = ...,
        total_length: google.protobuf.duration_pb2.Duration | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_speech_rate", b"_speech_rate", "speech_length", b"speech_length", "speech_rate", b"speech_rate", "total_length", b"total_length"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_speech_rate", b"_speech_rate", "channel_number", b"channel_number", "speech_length", b"speech_length", "speech_rate", b"speech_rate", "total_length", b"total_length"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["_speech_rate", b"_speech_rate"]) -> typing.Literal["speech_rate"] | None: ...

global___ChannelAnalysis = ChannelAnalysis

@typing.final
class AnalyzeResult(google.protobuf.message.Message):
    """The collection of all Time Analysis result types."""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    CHANNEL_ANALYSES_FIELD_NUMBER: builtins.int
    REACTION_ANALYSES_FIELD_NUMBER: builtins.int
    @property
    def channel_analyses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ChannelAnalysis]:
        """List of Time Analyses for individual channels."""

    @property
    def reaction_analyses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ReactionAnalysis]:
        """List of Time Analyses for channel combinations."""

    def __init__(
        self,
        *,
        channel_analyses: collections.abc.Iterable[global___ChannelAnalysis] | None = ...,
        reaction_analyses: collections.abc.Iterable[global___ReactionAnalysis] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["channel_analyses", b"channel_analyses", "reaction_analyses", b"reaction_analyses"]) -> None: ...

global___AnalyzeResult = AnalyzeResult

@typing.final
class AnalyzeResponse(google.protobuf.message.Message):
    """The top-level message returned to the client by the <code>Analyze</code>
    method.
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    RESULT_FIELD_NUMBER: builtins.int
    PROCESSED_AUDIO_LENGTH_FIELD_NUMBER: builtins.int
    @property
    def result(self) -> global___AnalyzeResult:
        """Time Analysis result."""

    @property
    def processed_audio_length(self) -> google.protobuf.duration_pb2.Duration:
        """Total length of the processed audio.
        Set only if this is the last response in the stream.
        """

    def __init__(
        self,
        *,
        result: global___AnalyzeResult | None = ...,
        processed_audio_length: google.protobuf.duration_pb2.Duration | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["processed_audio_length", b"processed_audio_length", "result", b"result"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["processed_audio_length", b"processed_audio_length", "result", b"result"]) -> None: ...

global___AnalyzeResponse = AnalyzeResponse
