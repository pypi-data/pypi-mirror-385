Metadata-Version: 2.4
Name: acet
Version: 1.0.7
Summary: Agentic Context Toolkit: context delta learning for adaptive LLM agents
Author-email: Lionel <lioarce1@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/lioarce01/agentic-context-toolkit
Project-URL: Documentation, https://github.com/lioarce01/agentic-context-toolkit
Project-URL: Repository, https://github.com/lioarce01/agentic-context-toolkit
Project-URL: CHANGELOG, https://github.com/lioarce01/agentic-context-toolkit/blob/main/CHANGELOG.md
Project-URL: Issues, https://github.com/lioarce01/agentic-context-toolkit/issues
Keywords: llm,agents,context,rag,ai,machine-learning,context-engineering,self-improving
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Typing :: Typed
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pydantic>=2.9
Requires-Dist: httpx>=0.27
Requires-Dist: tiktoken>=0.8
Requires-Dist: numpy>=2.1
Requires-Dist: aiosqlite>=0.20
Requires-Dist: sentence-transformers>=3.2
Requires-Dist: sqlalchemy>=2.0
Requires-Dist: structlog>=24.0
Requires-Dist: python-dotenv>=1.0
Provides-Extra: openai
Requires-Dist: openai>=1.54; extra == "openai"
Provides-Extra: anthropic
Requires-Dist: anthropic>=0.39; extra == "anthropic"
Provides-Extra: litellm
Requires-Dist: litellm>=1.52; extra == "litellm"
Provides-Extra: ollama
Requires-Dist: ollama>=0.4; extra == "ollama"
Provides-Extra: faiss
Requires-Dist: faiss-cpu>=1.9; extra == "faiss"
Provides-Extra: chroma
Requires-Dist: chromadb>=0.5; extra == "chroma"
Provides-Extra: postgres
Requires-Dist: psycopg2-binary>=2.9; extra == "postgres"
Requires-Dist: pgvector>=0.3; extra == "postgres"
Provides-Extra: langchain
Requires-Dist: langchain>=0.3; extra == "langchain"
Requires-Dist: langchain-community>=0.3; extra == "langchain"
Provides-Extra: llamaindex
Requires-Dist: llama-index>=0.11; extra == "llamaindex"
Provides-Extra: dev
Requires-Dist: pytest>=8.3; extra == "dev"
Requires-Dist: pytest-cov>=6.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.24; extra == "dev"
Requires-Dist: pytest-benchmark>=4.0; extra == "dev"
Requires-Dist: mypy>=1.13; extra == "dev"
Requires-Dist: ruff>=0.7; extra == "dev"
Requires-Dist: black>=24.10; extra == "dev"
Requires-Dist: sphinx>=8.0; extra == "dev"
Requires-Dist: sphinx-rtd-theme>=3.0; extra == "dev"
Requires-Dist: matplotlib>=3.9; extra == "dev"
Provides-Extra: all
Requires-Dist: openai>=1.54; extra == "all"
Requires-Dist: anthropic>=0.39; extra == "all"
Requires-Dist: litellm>=1.52; extra == "all"
Requires-Dist: ollama>=0.4; extra == "all"
Requires-Dist: faiss-cpu>=1.9; extra == "all"
Requires-Dist: chromadb>=0.5; extra == "all"
Requires-Dist: psycopg2-binary>=2.9; extra == "all"
Requires-Dist: pgvector>=0.3; extra == "all"
Requires-Dist: langchain>=0.3; extra == "all"
Requires-Dist: langchain-community>=0.3; extra == "all"
Requires-Dist: llama-index>=0.11; extra == "all"
Dynamic: license-file

[![CI](https://github.com/lioarce01/agentic-context-toolkit/actions/workflows/ci.yml/badge.svg)](https://github.com/lioarce01/agentic-context-toolkit/actions/workflows/ci.yml) [![Docs](https://github.com/lioarce01/agentic-context-toolkit/actions/workflows/docs.yml/badge.svg)](https://github.com/lioarce01/agentic-context-toolkit/actions/workflows/docs.yml) [![Publish](https://github.com/lioarce01/agentic-context-toolkit/actions/workflows/publish.yml/badge.svg)](https://github.com/lioarce01/agentic-context-toolkit/actions/workflows/publish.yml) [![Coverage](https://img.shields.io/badge/coverage-90%25-brightgreen.svg)](https://github.com/lioarce01/agentic-context-toolkit/actions/workflows/ci.yml)
# Agentic Context Engineering Toolkit

Research-oriented framework for Agentic Context Engineering. It captures, ranks, and reuses "context deltas" from LLM interactions so agents adapt without retraining, following the methodology described in [Agentic Context Engineering Framework](https://www.arxiv.org/abs/2510.04618).

## Features
- LLM provider agnostic (OpenAI, Anthropic, LiteLLM, Ollama, custom wrappers)
- Storage backend agnostic (memory, SQLite, Postgres/pgvector, extensible interfaces)
- Token budget management, retrieval & ranking, reflection, and curation pipelines
- Ready for Python 3.12 with strict typing, async workflows, and modern tooling

## Getting Started
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

## Project Layout
```
.
  acet/               # Library source (packages added per phase)
  benchmarks/         # Performance and benchmark suites
  docs/               # Documentation site sources
  examples/           # Usage examples and sample apps
  tests/              # Unit, integration, and benchmark tests
```

## Development Workflow
1. Create/activate the local virtual environment.
2. Install dependencies with `pip install -r requirements.txt`.
3. Run format and lint checks: `black .` and `ruff check`.
4. Run type checks: `mypy --strict .`.
5. Run tests: `pytest --cov=acet`.

## Performance Snapshot
- **Delta retrieval (250 active deltas)**: ~2 ms mean latency (`tests/benchmarks/test_delta_retrieval.py`)
- **SQLite save/query (300 staged deltas)**: ~23 ms mean latency (`tests/benchmarks/test_storage_throughput.py`)
- **Curator dedup (300 proposed insights, 30% duplicates)**: ~140 ms mean latency (`tests/benchmarks/test_curator_throughput.py`)

All benchmarks are reproducible via the CLI harnesses under `benchmarks/`. For example:
```bash
python benchmarks/delta_retrieval.py --iterations 30 --plot benchmarks/artifacts/delta_latency.png
python benchmarks/storage_throughput.py --backend all --iterations 30 --plot benchmarks/artifacts/storage_latency.png
python benchmarks/curator_throughput.py --proposals 300 --duplicate-ratio 0.3 --iterations 20 --plot benchmarks/artifacts/curator_latency.png
```
Adjust the parameters or swap in your production embeddings/backends to profile your deployment.





