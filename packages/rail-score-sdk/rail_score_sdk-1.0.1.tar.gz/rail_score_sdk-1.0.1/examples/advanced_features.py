"""
Advanced features example for RAIL Score Python SDK.

This example demonstrates advanced features like custom weights,
model preferences, and combining multiple API calls.
"""

from rail_score_sdk import RailScoreClient
import json

# Initialize the client
client = RailScoreClient(
    api_key='your-api-key-here',
    timeout=60
)

print("=" * 70)
print("RAIL Score SDK - Advanced Features")
print("=" * 70)

# Example 1: Custom Dimension Weights
print("\nExample 1: Custom Dimension Weights")
print("-" * 70)

content = """
Our AI-powered financial advisor helps you make investment decisions
based on your risk profile and financial goals. The system analyzes
market trends and provides personalized recommendations.
"""

# Standard weights (all equal)
print("Evaluating with standard weights...")
standard_result = client.calculate(
    content=content,
    domain='finance',
    explain_scores=False
)

print(f"Standard RAIL Score: {standard_result.rail_score}/10")

# Custom weights prioritizing safety and reliability for finance
print("\nEvaluating with custom weights (prioritize safety & reliability)...")
custom_result = client.calculate(
    content=content,
    domain='finance',
    explain_scores=False,
    custom_weights={
        'fairness': 0.10,
        'safety': 0.25,          # Higher weight
        'reliability': 0.25,     # Higher weight
        'transparency': 0.15,
        'privacy': 0.10,
        'accountability': 0.10,
        'inclusivity': 0.03,
        'user_impact': 0.02
    }  # Must sum to 1.0
)

print(f"Custom RAIL Score: {custom_result.rail_score}/10")
print(f"\nScore difference: {abs(custom_result.rail_score - standard_result.rail_score):.2f} points")

# Example 2: Model Preference
print("\n\nExample 2: Model Preference")
print("-" * 70)

content = "AI systems should be designed with user privacy as the top priority."

# Try with OpenAI model
print("Evaluating with OpenAI model preference...")
openai_result = client.calculate(
    content=content,
    domain='general',
    explain_scores=True,
    model_preference='openai'
)

print(f"OpenAI Result: {openai_result.rail_score}/10")
print(f"Model Used: {openai_result.evaluation_metadata.model_used}")
print(f"Eval Time: {openai_result.evaluation_metadata.evaluation_time_ms}ms")

# Try with Gemini model
print("\nEvaluating with Gemini model preference...")
gemini_result = client.calculate(
    content=content,
    domain='general',
    explain_scores=True,
    model_preference='gemini'
)

print(f"Gemini Result: {gemini_result.rail_score}/10")
print(f"Model Used: {gemini_result.evaluation_metadata.model_used}")
print(f"Eval Time: {gemini_result.evaluation_metadata.evaluation_time_ms}ms")

# Try with both models (highest quality, slower)
print("\nEvaluating with both models...")
both_result = client.calculate(
    content=content,
    domain='general',
    explain_scores=True,
    model_preference='both'
)

print(f"Both Models Result: {both_result.rail_score}/10")
print(f"Model Used: {both_result.evaluation_metadata.model_used}")
print(f"Eval Time: {both_result.evaluation_metadata.evaluation_time_ms}ms")

# Example 3: Source Tracking
print("\n\nExample 3: Source Tracking")
print("-" * 70)

# Track different content sources
sources = ['chatgpt', 'gemini', 'claude', 'custom', 'pasted']

for source in sources[:3]:  # Demo with first 3
    result = client.calculate(
        content=f"Content generated by {source}",
        domain='general',
        explain_scores=False,
        source=source
    )
    print(f"{source.capitalize()}: {result.rail_score}/10 (Source: {result.evaluation_metadata.source})")

# Example 4: Domain-Specific Evaluation
print("\n\nExample 4: Domain-Specific Evaluation")
print("-" * 70)

healthcare_content = """
Our telemedicine platform connects patients with licensed doctors
for virtual consultations. Patient data is encrypted and stored
securely in HIPAA-compliant servers.
"""

domains = ['general', 'healthcare', 'law']

print("Evaluating same content across different domains:")
for domain in domains:
    result = client.calculate(
        content=healthcare_content,
        domain=domain,
        explain_scores=False
    )
    print(f"  {domain.capitalize()}: {result.rail_score}/10")

# Example 5: Combining Multiple API Calls
print("\n\nExample 5: Complete Content Workflow")
print("-" * 70)

# Step 1: Generate content
print("Step 1: Generating content...")
gen_result = client.generate(
    prompt="Write about ethical considerations in AI hiring tools",
    length='medium',
    context={
        'purpose': 'blog_post',
        'industry': 'hr',
        'target_audience': 'hr_professionals',
        'tone': 'professional'
    },
    rail_requirements={
        'minimum_scores': {
            'fairness': 8.0,
            'transparency': 7.5
        },
        'auto_regenerate': True,
        'max_attempts': 2
    }
)

generated_content = gen_result.content
print(f"✓ Content generated (RAIL Score: {gen_result.rail_scores.rail_score}/10)")

# Step 2: Calculate detailed RAIL score
print("\nStep 2: Calculating detailed RAIL score...")
calc_result = client.calculate(
    content=generated_content,
    domain='hr',
    explain_scores=True,
    custom_weights={
        'fairness': 0.30,        # Critical for HR
        'safety': 0.15,
        'reliability': 0.15,
        'transparency': 0.20,     # Important for HR
        'privacy': 0.10,
        'accountability': 0.05,
        'inclusivity': 0.03,
        'user_impact': 0.02
    }
)

print(f"Detailed Score: {calc_result.rail_score}/10 ({calc_result.grade})")

# Step 3: If score is low in any dimension, regenerate
low_dimensions = [
    dim for dim, details in calc_result.dimension_scores.items()
    if details.score < 7.0
]

if low_dimensions:
    print(f"\nStep 3: Improving low-scoring dimensions: {', '.join(low_dimensions)}")
    regen_result = client.regenerate(
        original_content=generated_content,
        improve_dimensions=low_dimensions,
        user_notes="Improve the weak dimensions while maintaining professional tone",
        keep_structure=True,
        keep_tone=True
    )
    final_content = regen_result.content
    print(f"✓ Content improved")
else:
    final_content = generated_content
    print(f"\nStep 3: All dimensions meet requirements, no regeneration needed")

# Step 4: Final validation
print("\nStep 4: Final validation...")
final_result = client.calculate(
    content=final_content,
    domain='hr',
    explain_scores=False
)

print(f"✓ Final RAIL Score: {final_result.rail_score}/10 ({final_result.grade})")

# Example 6: Health Check and API Status
print("\n\nExample 6: API Health and Version Check")
print("-" * 70)

# Check API health
health = client.health()
print(f"API Status: {health['status']}")
if 'timestamp' in health:
    print(f"Timestamp: {health['timestamp']}")

# Check API version
version = client.version()
print(f"API Version: {version['version']}")
if 'build' in version:
    print(f"Build: {version['build']}")

# Example 7: Working with Metadata
print("\n\nExample 7: Extracting and Using Metadata")
print("-" * 70)

result = client.calculate(
    content="AI should be developed with ethical guidelines and oversight.",
    domain='general',
    explain_scores=True
)

# Extract evaluation metadata
eval_meta = result.evaluation_metadata
print(f"Evaluation Metadata:")
print(f"  Model: {eval_meta.model_used}")
print(f"  Time: {eval_meta.evaluation_time_ms}ms")
print(f"  Cached: {eval_meta.cached}")
print(f"  Trace ID: {eval_meta.trace_id}")
print(f"  Domain: {eval_meta.domain}")

# Extract response metadata (if available)
if result.metadata:
    resp_meta = result.metadata
    print(f"\nResponse Metadata:")
    print(f"  Credits Used: {resp_meta.credits_used}")
    print(f"  Credits Remaining: {resp_meta.credits_remaining}")
    print(f"  Tier: {resp_meta.tier}")
    print(f"  Trace ID: {resp_meta.trace_id}")

# Example 8: Exporting Results
print("\n\nExample 8: Exporting Results to JSON")
print("-" * 70)

result = client.calculate(
    content="Sample content for export demonstration.",
    domain='general',
    explain_scores=True
)

# Convert result to dictionary format
result_dict = {
    'rail_score': result.rail_score,
    'grade': result.grade,
    'dimension_scores': {
        dim: {
            'score': details.score,
            'grade': details.grade,
            'explanation': details.explanation,
            'suggestions': details.suggestions
        }
        for dim, details in result.dimension_scores.items()
    },
    'overall_analysis': {
        'strengths': result.overall_analysis.strengths,
        'weaknesses': result.overall_analysis.weaknesses,
        'top_priority': result.overall_analysis.top_priority
    },
    'metadata': {
        'model_used': result.evaluation_metadata.model_used,
        'evaluation_time_ms': result.evaluation_metadata.evaluation_time_ms,
        'domain': result.evaluation_metadata.domain
    }
}

# Export to JSON
json_output = json.dumps(result_dict, indent=2)
print("Exported to JSON:")
print(json_output[:500] + "...")  # Show first 500 chars

# Save to file (uncomment to use)
# with open('rail_score_result.json', 'w') as f:
#     f.write(json_output)
# print("\n✓ Saved to rail_score_result.json")

# Best Practices
print("\n" + "=" * 70)
print("Advanced Features - Best Practices")
print("=" * 70)
print("""
1. Custom Weights:
   - Use for domain-specific priorities (e.g., safety in healthcare)
   - Must sum to exactly 1.0
   - Test with standard weights first for baseline

2. Model Preference:
   - 'openai': Fast, good quality
   - 'gemini': Fast, good quality
   - 'both': Highest quality, slower (consensus)
   - Default: Automatically selected

3. Domain Selection:
   - Choose domain matching your content type
   - Affects scoring criteria and thresholds
   - Options: general, healthcare, law, hr, politics, news, finance

4. Source Tracking:
   - Track content origin for analytics
   - Useful for comparing AI model outputs
   - Options: chatgpt, gemini, claude, grok, custom, pasted

5. Workflow Combinations:
   - Generate → Calculate → Regenerate (if needed) → Validate
   - Use metadata for monitoring and optimization
   - Export results for record-keeping and analysis

6. Performance Tips:
   - Set explain_scores=False when you don't need details
   - Use appropriate timeout for generation/regeneration
   - Cache results when evaluating same content multiple times
   - Monitor credits_remaining in metadata
""")

print("=" * 70)
print("Advanced Features Examples Complete!")
print("=" * 70)
