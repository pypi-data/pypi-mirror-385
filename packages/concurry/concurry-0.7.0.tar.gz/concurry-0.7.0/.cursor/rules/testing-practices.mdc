---
globs: tests/**/*.py
description: Comprehensive testing practices for Concurry, including pytest fixtures and execution mode testing
---

# Concurry Testing Practices

## Test Timeout Configuration

**ALL tests have a 60-second timeout by default** to prevent hanging tests.

- **Configured in**: `tests/conftest.py` via `pytest_configure` hook
- **Default**: 60 seconds per test
- **Method**: Thread-based timeout (compatible with Ray and multiprocessing)
- **Override**: Use `pytest --timeout=120` to change timeout
- **Disable**: Use `pytest --timeout=0` to disable timeout
- **On Timeout**: Full stack trace is displayed for debugging
- **Behavior**: Timeout marks test as **FAILED** but **continues to next test** (non-fatal)

**Why 60 seconds?**: Most tests should complete in < 10 seconds. The 60-second timeout catches hanging tests (deadlocks, infinite loops, semaphore issues) while allowing slower integration tests to complete.

**Important**: Timeouts do NOT stop the entire test suite! When a test times out:
1. The test is marked as **FAILED** with timeout information
2. Full stack traces are displayed showing where the hang occurred
3. The test runner **continues to the next test**
4. All remaining tests will still run

This allows you to identify multiple hanging tests in a single test run.

**Example timeout error output**:
```
++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++
~~~~ Stack of MainThread (140735268369408) ~~~~
File "/path/to/test.py", line 123, in test_something
    result = future.result()
File "/path/to/future.py", line 456, in result
    self._wait()
```

## Running Tests

**NEVER use `-q` (quiet mode) or `--tb=line` when debugging issues**, as these suppress important output.

**Recommended pytest commands**:
- `pytest tests/file.py -vs` - Verbose, no capture (best for debugging multiple tests)
- `pytest tests/file.py -xvs` - Stop on first failure, verbose, no capture (best for debugging single issue)
- `pytest tests/file.py -v` - Verbose output showing all test names
- `pytest tests/file.py --tb=short` - Short traceback format (good for CI)

**Important about `-x` flag**:
- **WITH `-x`**: Stops on **first failure** (including timeouts) - use when debugging one specific issue
- **WITHOUT `-x`**: Continues after failures/timeouts - use to identify **all** failing tests in one run

**AVOID**:
- `pytest -q` - Suppresses output, makes debugging impossible
- `pytest --tb=line` - Only shows one line per failure, hides context
- `pytest -qq` - Ultra-quiet mode, completely useless for debugging

**For timeout issues**: Run without `-x` to see all timeouts in one run:
```bash
pytest tests/file.py -v  # Will show ALL tests that timeout
```

## Pytest Fixtures from conftest.py

The [tests/conftest.py](mdc:tests/conftest.py) file provides essential fixtures for testing across all execution modes. **Always use these fixtures** when writing tests.

### Available Fixtures

#### 1. `worker_mode` Fixture

**Purpose**: Parametrize tests across ALL execution modes (sync, thread, process, asyncio, ray)

**Usage**:
```python
def test_my_feature(self, worker_mode):
    """Test feature across all execution modes."""
    w = MyWorker.options(mode=worker_mode).init(param=value)
    
    # Your test logic
    result = w.method().result()
    assert result == expected
    
    w.stop()
```

**Important**: This fixture automatically runs your test 5 times (once per mode). If Ray is not installed, it runs 4 times.

#### 2. `pool_mode` Fixture

**Purpose**: Parametrize tests across pool-supporting modes (thread, process, ray)

**Usage**:
```python
def test_pool_feature(self, pool_mode):
    """Test feature that requires multiple workers."""
    w = MyWorker.options(mode=pool_mode, max_workers=3).init()
    
    # Your test logic for pools
    futures = [w.task(i) for i in range(10)]
    results = [f.result() for f in futures]
    
    w.stop()
```

**Why separate from worker_mode?**: Sync and asyncio modes only support `max_workers=1`, so pool-specific features cannot be tested with them.

#### 3. `initialize_ray` Fixture

**Purpose**: Session-level fixture that initializes Ray once before all tests

**Usage**: Automatic - no need to explicitly use this fixture. Ray is initialized at session start if available.

**Important**: Always include the runtime_env when manually initializing Ray in tests:
```python
import ray
import morphic
import concurry

ray.init(
    ignore_reinit_error=True,
    num_cpus=4,
    runtime_env={"py_modules": [concurry, morphic]},
)
```

### WORKER_MODES and POOL_MODES Constants

Available for direct use when needed:
```python
from tests.conftest import WORKER_MODES, POOL_MODES

# WORKER_MODES = ["sync", "thread", "process", "asyncio", "ray"]  # if Ray installed
# POOL_MODES = ["thread", "process", "ray"]  # if Ray installed
```

---

## Comprehensive Execution Mode Testing

### Golden Rule: Test ALL Execution Modes

**Every test must run across all applicable execution modes using the `worker_mode` or `pool_mode` fixture.**

❌ **NEVER write tests like this:**
```python
def test_feature(self):
    """Bad: Only tests sync mode."""
    worker = MyWorker.options(mode="sync").init()
    # ...
```

✅ **ALWAYS write tests like this:**
```python
def test_feature(self, worker_mode):
    """Good: Tests all execution modes."""
    worker = MyWorker.options(mode=worker_mode).init()
    # ...
```

### Example: Basic Test Structure

```python
import pytest
from concurry import Worker

class ComputeWorker(Worker):
    def __init__(self, multiplier: int = 1):
        self.multiplier = multiplier
    
    def compute(self, x: int) -> int:
        return x * self.multiplier

class TestComputeWorker:
    """Test ComputeWorker across all modes."""
    
    def test_basic_computation(self, worker_mode):
        """Test basic computation across all execution modes."""
        w = ComputeWorker.options(mode=worker_mode).init(multiplier=2)
        
        future = w.compute(5)
        result = future.result(timeout=5.0)
        
        assert result == 10
        
        w.stop()
    
    def test_multiple_calls(self, worker_mode):
        """Test multiple method calls across all execution modes."""
        w = ComputeWorker.options(mode=worker_mode).init(multiplier=3)
        
        futures = [w.compute(i) for i in range(5)]
        results = [f.result(timeout=5.0) for f in futures]
        
        assert results == [0, 3, 6, 9, 12]
        
        w.stop()
```

### Example: Pool-Specific Tests

```python
class TestWorkerPool:
    """Test worker pool features."""
    
    def test_round_robin_dispatch(self, pool_mode):
        """Test round-robin load balancing across pool modes."""
        w = ComputeWorker.options(
            mode=pool_mode,
            max_workers=3,
            load_balancing="round_robin"
        ).init(multiplier=2)
        
        # Submit 9 tasks
        futures = [w.compute(i) for i in range(9)]
        results = [f.result(timeout=5.0) for f in futures]
        
        assert results == [i * 2 for i in range(9)]
        
        # Check pool stats
        stats = w.get_pool_stats()
        assert stats["total_workers"] == 3
        
        w.stop()
```

---

## Handling Mode-Specific Behavior

### NEVER Skip Tests Due to Failures

**Critical Rule**: If a test fails for certain execution modes, **DO NOT skip it**. These are important edge cases that must be handled.

❌ **WRONG Approach:**
```python
def test_feature(self, worker_mode):
    if worker_mode == "ray":
        pytest.skip("Fails on Ray, skipping")  # ❌ NEVER DO THIS
    
    # test logic
```

✅ **CORRECT Approach - Handle the Edge Case:**
```python
def test_feature(self, worker_mode):
    """Test feature with mode-specific behavior."""
    w = MyWorker.options(mode=worker_mode).init()
    
    if worker_mode == "ray":
        # Ray has different behavior - test it explicitly
        with pytest.raises(SpecificException, match="expected message"):
            w.problematic_method()
    else:
        # Other modes work normally
        result = w.problematic_method().result()
        assert result == expected
    
    w.stop()
```

### Valid Reasons to Skip Tests

**Only skip tests when a feature is fundamentally not supported by a mode:**

#### Example 1: Pool Features (Not Supported by Sync/Asyncio)

```python
def test_multiple_workers(self, worker_mode):
    """Test feature requiring multiple workers."""
    if worker_mode in ("sync", "asyncio"):
        pytest.skip("Sync and asyncio modes only support max_workers=1")
    
    # This feature genuinely requires multiple workers
    w = MyWorker.options(mode=worker_mode, max_workers=4).init()
    # ... test logic requiring parallelism
    w.stop()
```

#### Example 2: Timeout Behavior in Sync Mode

```python
def test_timeout_behavior(self, worker_mode):
    """Test timeout handling across modes."""
    if worker_mode == "sync":
        pytest.skip("Sync mode completes immediately, cannot timeout")
    
    w = MyWorker.options(mode=worker_mode).init()
    
    # Test that long-running task times out
    future = w.slow_task(duration=10.0)
    with pytest.raises(TimeoutError):
        future.result(timeout=0.1)
    
    w.stop()
```

#### Example 3: Mode-Specific Features

```python
def test_ray_specific_feature(self, worker_mode):
    """Test Ray-specific actor options."""
    if worker_mode != "ray":
        pytest.skip("Ray-specific feature")
    
    w = MyWorker.options(
        mode="ray",
        actor_options={"num_cpus": 2, "num_gpus": 0}
    ).init()
    
    # Test Ray-specific functionality
    result = w.method().result()
    assert result == expected
    
    w.stop()
```

### Handling Mode-Specific Exceptions

When different modes raise different exceptions, test all variants:

```python
def test_nonexistent_method(self, worker_mode):
    """Test calling non-existent method across modes."""
    w = MyWorker.options(mode=worker_mode).init()
    
    if worker_mode in ("sync", "ray"):
        # Sync and Ray fail immediately
        with pytest.raises(AttributeError):
            w.nonexistent_method()
    else:
        # Thread, asyncio, process return future with error
        future = w.nonexistent_method()
        with pytest.raises(AttributeError):
            future.result(timeout=5.0)
    
    w.stop()
```

---

## Test Organization Best Practices

### 1. Group Tests by Feature

```python
class TestBasicFeatures:
    """Test basic worker functionality."""
    
    def test_initialization(self, worker_mode):
        """Test worker initialization."""
        # ...
    
    def test_method_call(self, worker_mode):
        """Test basic method calls."""
        # ...

class TestExceptionHandling:
    """Test exception handling."""
    
    def test_method_raises_exception(self, worker_mode):
        """Test exception propagation."""
        # ...
    
    def test_return_exceptions(self, worker_mode):
        """Test exception capture."""
        # ...

class TestPoolFeatures:
    """Test worker pool features."""
    
    def test_load_balancing(self, pool_mode):
        """Test load balancing strategies."""
        # ...
```

### 2. Use Descriptive Test Names

```python
# ✅ Good: Clear what is being tested
def test_wait_returns_done_and_not_done_sets(self, worker_mode):
    """Test that wait() returns correct done and not_done sets."""
    # ...

def test_gather_preserves_input_order(self, worker_mode):
    """Test that gather() returns results in same order as input."""
    # ...

def test_worker_maintains_state_across_calls(self, worker_mode):
    """Test that worker state persists between method calls."""
    # ...

# ❌ Bad: Unclear what is tested
def test_wait(self, worker_mode):
    # ...

def test_gather_works(self, worker_mode):
    # ...
```

### 3. Always Clean Up Resources

```python
def test_feature(self, worker_mode):
    """Test feature with proper cleanup."""
    w = MyWorker.options(mode=worker_mode).init()
    
    try:
        # Test logic
        result = w.method().result()
        assert result == expected
    finally:
        # Always stop worker, even if test fails
        w.stop()
```

Or use the simpler pattern:

```python
def test_feature(self, worker_mode):
    """Test feature with proper cleanup."""
    w = MyWorker.options(mode=worker_mode).init()
    
    # Test logic
    result = w.method().result()
    assert result == expected
    
    w.stop()  # pytest will still call this even if assertion fails
```

---

## Common Testing Patterns

### Pattern 1: Testing Synchronization Primitives

```python
from concurry import wait, gather, ReturnWhen

class TestSynchronization:
    """Test wait() and gather() across all modes."""
    
    def test_wait_all_completed(self, worker_mode):
        """Test wait with ALL_COMPLETED across all modes."""
        w = ComputeWorker.options(mode=worker_mode).init(multiplier=1)
        
        futures = [w.compute(i) for i in range(10)]
        done, not_done = wait(futures, timeout=5.0)
        
        assert len(done) == 10
        assert len(not_done) == 0
        
        w.stop()
    
    def test_gather_basic(self, worker_mode):
        """Test gather() basic functionality across all modes."""
        w = ComputeWorker.options(mode=worker_mode).init(multiplier=2)
        
        futures = [w.compute(i) for i in range(5)]
        results = gather(futures, timeout=5.0)
        
        assert results == [0, 2, 4, 6, 8]
        
        w.stop()
    
    def test_gather_with_dict(self, worker_mode):
        """Test gather() with dict input across all modes."""
        w = ComputeWorker.options(mode=worker_mode).init(multiplier=1)
        
        tasks = {
            "task1": w.compute(10),
            "task2": w.compute(20),
            "task3": w.compute(30),
        }
        
        results = gather(tasks, timeout=5.0)
        
        assert isinstance(results, dict)
        assert results == {"task1": 10, "task2": 20, "task3": 30}
        
        w.stop()
```

### Pattern 2: Testing Exception Handling

```python
class TestExceptions:
    """Test exception handling across all modes."""
    
    def test_exception_propagation(self, worker_mode):
        """Test that exceptions are properly propagated."""
        w = ComputeWorker.options(mode=worker_mode).init()
        
        future = w.failing_method()
        
        with pytest.raises(ValueError, match="expected error"):
            future.result(timeout=5.0)
        
        w.stop()
    
    def test_gather_return_exceptions(self, worker_mode):
        """Test gather with return_exceptions=True."""
        w = ComputeWorker.options(mode=worker_mode).init()
        
        futures = [
            w.compute(1),
            w.failing_method(),
            w.compute(3),
        ]
        
        results = gather(futures, return_exceptions=True, timeout=5.0)
        
        assert results[0] == 1
        assert isinstance(results[1], ValueError)
        assert results[2] == 3
        
        w.stop()
```

### Pattern 3: Testing Timeouts

```python
class TestTimeouts:
    """Test timeout behavior across modes."""
    
    def test_timeout_raises_error(self, worker_mode):
        """Test that timeout raises TimeoutError."""
        if worker_mode == "sync":
            pytest.skip("Sync mode completes immediately")
        
        w = ComputeWorker.options(mode=worker_mode).init()
        
        future = w.slow_task(duration=5.0)
        
        with pytest.raises(TimeoutError):
            future.result(timeout=0.1)
        
        w.stop()
```

### Pattern 4: Testing Large Batches

```python
class TestPerformance:
    """Test performance with large batches."""
    
    def test_large_batch_processing(self, worker_mode):
        """Test processing large batch of tasks."""
        w = ComputeWorker.options(mode=worker_mode).init(multiplier=1)
        
        # Test with 100 tasks
        futures = [w.compute(i) for i in range(100)]
        results = gather(futures, timeout=30.0)
        
        assert len(results) == 100
        assert results == list(range(100))
        
        w.stop()
```

---

## Edge Cases to Test

### 1. Empty Collections

```python
def test_wait_empty_list(self, worker_mode):
    """Test wait() with empty list."""
    done, not_done = wait([])
    
    assert len(done) == 0
    assert len(not_done) == 0

def test_gather_empty_dict(self, worker_mode):
    """Test gather() with empty dict."""
    results = gather({})
    
    assert isinstance(results, dict)
    assert len(results) == 0
```

### 2. Single Items

```python
def test_wait_single_future(self, worker_mode):
    """Test wait() with single future."""
    w = ComputeWorker.options(mode=worker_mode).init()
    
    future = w.compute(42)
    done, not_done = wait(future, timeout=5.0)
    
    assert len(done) == 1
    assert len(not_done) == 0
    
    w.stop()
```

### 3. Mixed Types

```python
def test_gather_mixed_futures_and_values(self, worker_mode):
    """Test gather() with mix of futures and values."""
    w = ComputeWorker.options(mode=worker_mode).init()
    
    mixed = [w.compute(1), 42, w.compute(2)]
    results = gather(mixed, timeout=5.0)
    
    assert results == [1, 42, 2]
    
    w.stop()
```

### 4. All Polling Algorithms

```python
from concurry import PollingAlgorithm

def test_wait_with_all_polling_algorithms(self, worker_mode):
    """Test wait() with all polling strategies."""
    for algorithm in [PollingAlgorithm.Fixed, PollingAlgorithm.Adaptive,
                     PollingAlgorithm.Exponential, PollingAlgorithm.Progressive]:
        w = ComputeWorker.options(mode=worker_mode).init()
        
        futures = [w.compute(i) for i in range(5)]
        done, not_done = wait(futures, polling=algorithm, timeout=5.0)
        
        assert len(done) == 5
        assert len(not_done) == 0
        
        w.stop()
```

---

## Ray-Specific Testing

### Ray Actor Options

```python
import pytest
from concurry.utils import _IS_RAY_INSTALLED

@pytest.mark.skipif(not _IS_RAY_INSTALLED, reason="Ray not installed")
class TestRayFeatures:
    """Test Ray-specific features."""
    
    def test_ray_actor_options(self):
        """Test Ray worker with custom actor options."""
        w = MyWorker.options(
            mode="ray",
            actor_options={"num_cpus": 1, "num_gpus": 0}
        ).init()
        
        result = w.method().result(timeout=5.0)
        assert result == expected
        
        w.stop()
```

### Ray Initialization in Tests

When manually initializing Ray (not relying on conftest.py):

```python
def test_custom_ray_init(self):
    """Test with custom Ray initialization."""
    import ray
    import morphic
    import concurry
    
    # Always include runtime_env
    ray.init(
        ignore_reinit_error=True,
        num_cpus=4,
        runtime_env={"py_modules": [concurry, morphic]},
    )
    
    # Your test logic
    w = MyWorker.options(mode="ray").init()
    result = w.method().result()
    assert result == expected
    w.stop()
```

---

## Summary Checklist

When writing tests for Concurry:

- ✅ Use `worker_mode` fixture for all worker tests
- ✅ Use `pool_mode` fixture for pool-specific tests
- ✅ Test across ALL execution modes (sync, thread, process, asyncio, ray)
- ✅ NEVER skip tests due to failures - handle edge cases explicitly
- ✅ Only skip when feature is fundamentally not supported
- ✅ Use descriptive test names
- ✅ Always clean up resources (call `.stop()`)
- ✅ Test edge cases (empty, single, mixed types)
- ✅ Test exception handling with `return_exceptions`
- ✅ Test timeout behavior (skip for sync mode)
- ✅ Include Ray runtime_env when manually initializing
- ✅ Group tests by feature in classes
- ✅ Test all polling algorithms
- ✅ Test large batches (100+ items)

---

## Anti-Patterns to Avoid

❌ **Hard-coding execution mode:**
```python
def test_feature(self):
    w = MyWorker.options(mode="thread").init()  # ❌ Only tests thread mode
```

❌ **Skipping failing tests:**
```python
def test_feature(self, worker_mode):
    if worker_mode == "ray":
        pytest.skip("Fails on Ray")  # ❌ Handle the edge case instead
```

❌ **Not cleaning up:**
```python
def test_feature(self, worker_mode):
    w = MyWorker.options(mode=worker_mode).init()
    # ... test logic ...
    # ❌ Missing w.stop()
```

❌ **Unclear test names:**
```python
def test_1(self, worker_mode):  # ❌ What does this test?
    # ...
```

❌ **Testing only happy path:**
```python
def test_feature(self, worker_mode):
    # ❌ Only tests success case, no exception handling
    result = w.method().result()
    assert result == expected
```
