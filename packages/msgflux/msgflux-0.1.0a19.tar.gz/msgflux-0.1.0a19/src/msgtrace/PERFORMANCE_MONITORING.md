# msgtrace - Performance Monitoring System

**Status**: ‚úÖ Implemented
**Version**: 0.4.0
**Date**: 2025-10-15

---

## Overview

The Performance Monitoring System provides advanced analytics and metrics visualization for msgtrace. It offers real-time insights into trace latency, error rates, throughput, and workflow comparisons with beautiful interactive charts.

---

## Features

### 1. Latency Percentiles (P50/P95/P99)

**What it is:**
- P50 (Median): 50% of traces complete faster than this time
- P95: 95% of traces complete faster than this time
- P99: 99% of traces complete faster than this time

**Why it matters:**
- P50 shows typical performance
- P95 catches most slow requests
- P99 reveals outliers and worst-case scenarios

**Display:**
- Stats cards with color coding
- Blue (P50), Yellow (P95), Red (P99)
- Shows trace count and mean latency

### 2. Latency Over Time Chart

**Visualization:**
- Line chart showing P50, P95, and Mean latency
- X-axis: Time buckets
- Y-axis: Latency in milliseconds
- Auto-refreshes every 60 seconds

**Use Cases:**
- Identify performance regressions
- Monitor deployment impact
- Spot traffic patterns affecting latency

### 3. Error Rate Over Time Chart

**Visualization:**
- Stacked area chart showing error vs success rates
- Red gradient for error rate
- Green gradient for success rate
- Percentage-based (0-100%)

**Use Cases:**
- Track reliability over time
- Correlate errors with deployments
- Monitor SLA compliance

### 4. Trace Throughput Chart

**Visualization:**
- Bar chart showing trace count per time bucket
- Purple bars representing volume
- Rate per minute calculation

**Use Cases:**
- Understand traffic patterns
- Capacity planning
- Load testing validation

### 5. Workflow Performance Comparison

**Visualization:**
- Sortable table comparing all workflows
- Metrics: Count, P50, P95, Mean, Error Rate
- Color-coded error rates (green <5%, yellow 5-10%, red >10%)

**Use Cases:**
- Identify slow workflows
- Compare workflow efficiency
- Prioritize optimization efforts

---

## API Endpoints

### GET /api/v1/analytics/latency-percentiles

**Parameters:**
- `hours` (int, 1-168): Time window in hours (default: 24)
- `workflow_name` (string, optional): Filter by workflow
- `service_name` (string, optional): Filter by service

**Response:**
```json
{
  "p50": 234.56,
  "p95": 1234.78,
  "p99": 2345.89,
  "count": 1234,
  "mean": 345.67,
  "min": 12.34,
  "max": 5678.90,
  "time_window_hours": 24,
  "workflow_name": null,
  "service_name": null
}
```

### GET /api/v1/analytics/timeseries/latency

**Parameters:**
- `hours` (int, 1-168): Time window
- `bucket_minutes` (int, 5-1440): Bucket size
- `workflow_name` (string, optional): Filter

**Response:**
```json
{
  "buckets": [
    {
      "timestamp": 1697123456789,
      "time": "2025-10-15T14:30:56.789Z",
      "count": 45,
      "p50": 234.56,
      "p95": 1234.78,
      "mean": 345.67,
      "min": 12.34,
      "max": 5678.90
    }
  ],
  "total_traces": 1234,
  "time_window_hours": 24,
  "bucket_minutes": 60
}
```

### GET /api/v1/analytics/timeseries/errors

**Parameters:**
- `hours` (int): Time window
- `bucket_minutes` (int): Bucket size
- `workflow_name` (string, optional): Filter

**Response:**
```json
{
  "buckets": [
    {
      "timestamp": 1697123456789,
      "time": "2025-10-15T14:30:56.789Z",
      "total_traces": 100,
      "error_traces": 5,
      "error_rate": 5.0,
      "success_rate": 95.0
    }
  ],
  "total_traces": 2400,
  "time_window_hours": 24,
  "bucket_minutes": 60
}
```

### GET /api/v1/analytics/timeseries/throughput

**Parameters:**
- `hours` (int): Time window
- `bucket_minutes` (int): Bucket size
- `workflow_name` (string, optional): Filter

**Response:**
```json
{
  "buckets": [
    {
      "timestamp": 1697123456789,
      "time": "2025-10-15T14:30:56.789Z",
      "count": 45,
      "rate_per_minute": 0.75
    }
  ],
  "total_traces": 1080,
  "time_window_hours": 24,
  "bucket_minutes": 60
}
```

### GET /api/v1/analytics/workflow-comparison

**Parameters:**
- `hours` (int): Time window

**Response:**
```json
{
  "workflows": [
    {
      "workflow_name": "agent_workflow",
      "count": 500,
      "p50": 234.56,
      "p95": 1234.78,
      "mean": 345.67,
      "error_count": 25,
      "error_rate": 5.0
    }
  ],
  "total_workflows": 5,
  "time_window_hours": 24
}
```

---

## Frontend Implementation

### Components

#### Performance.tsx (Main View)

**Features:**
- Time window selector (1h, 6h, 24h, 3d, 7d)
- Bucket size selector (5m, 15m, 30m, 1h, 6h, 1d)
- 4 stats cards (P50, P95, P99, Mean)
- 3 interactive charts (Latency, Errors, Throughput)
- Workflow comparison table

**Charts Library:**
- Recharts (v2.x)
- Responsive design
- Dark theme integration
- Smooth animations

### Hooks

#### useAnalytics.ts

**Hooks:**
- `useLatencyPercentiles(hours, workflow, service)`
- `useLatencyTimeSeries(hours, bucketMinutes, workflow)`
- `useErrorTimeSeries(hours, bucketMinutes, workflow)`
- `useThroughputTimeSeries(hours, bucketMinutes, workflow)`
- `useWorkflowComparison(hours)`

**Features:**
- TanStack Query integration
- Auto-refresh every 60 seconds
- Caching and deduplication
- Loading states

### Types

#### analytics.ts

**Types:**
- `LatencyPercentiles`
- `TimeSeriesBucket`
- `LatencyTimeSeries`
- `ErrorTimeSeries`
- `ThroughputTimeSeries`
- `WorkflowMetrics`
- `WorkflowComparison`

**Helper Functions:**
- `formatLatency(ms)`: Smart formatting (¬µs/ms/s/m)
- `formatPercentile(value)`: Format percentile values
- `formatRate(rate)`: Format percentage
- `formatThroughput(count, minutes)`: Format rate

---

## Usage Examples

### View Performance Dashboard

1. Navigate to `/performance` in the frontend
2. Select time window (default: 24 hours)
3. Adjust bucket size for granularity
4. View real-time metrics and charts

### Filter by Workflow

Currently, workflow filtering is available via API but UI selector is coming in next iteration.

**API Example:**
```bash
curl "http://localhost:4321/api/v1/analytics/latency-percentiles?hours=24&workflow_name=agent_workflow"
```

### Customize Time Ranges

Available time windows:
- **1 hour**: Real-time monitoring
- **6 hours**: Recent trends
- **24 hours**: Daily patterns
- **3 days**: Short-term analysis
- **7 days**: Weekly trends

Available bucket sizes:
- **5 minutes**: High resolution
- **15 minutes**: Balanced
- **30 minutes**: Reduced noise
- **1 hour**: Hourly aggregation
- **6 hours**: Quarter-day buckets
- **1 day**: Daily summaries

---

## Performance Considerations

### Backend

**Query Optimization:**
- Limited to 10,000 traces per query
- Time-based filtering before processing
- In-memory calculations (no heavy DB queries)
- Percentile calculations: O(n log n) due to sorting

**Caching:**
- No caching yet (planned for future)
- Each request recalculates metrics
- Average response time: 50-200ms

### Frontend

**Bundle Size:**
- Recharts library: ~400KB (uncompressed)
- Final gzipped size: ~193KB total
- Acceptable for analytics dashboard

**Auto-Refresh:**
- 60-second interval (not overwhelming)
- Query deduplication via TanStack Query
- Stale data served during refetch

**Chart Rendering:**
- Responsive containers (resize-aware)
- Optimized for datasets up to 1000 points
- Smooth animations with CSS transitions

---

## Interpretation Guide

### Percentiles

**Healthy System:**
- P50: Fast and consistent
- P95: Within 2-3x of P50
- P99: Within 5-10x of P50

**Warning Signs:**
- P95 > 5x P50: High variance, investigate outliers
- P99 > 20x P50: Severe outliers, potential issues
- Increasing trend: Performance degradation

**Example:**
```
P50: 100ms  ‚úÖ Good
P95: 250ms  ‚úÖ Acceptable (2.5x)
P99: 800ms  ‚ö†Ô∏è  Investigate (8x)
```

### Error Rates

**Targets:**
- **SLA 99.9%**: Error rate < 0.1%
- **SLA 99%**: Error rate < 1%
- **SLA 95%**: Error rate < 5%

**Patterns:**
- **Spikes**: Temporary issues (deployment, network)
- **Sustained high**: Systemic problems
- **Gradual increase**: Degradation over time

### Throughput

**What to Look For:**
- **Daily patterns**: Peak hours vs quiet periods
- **Sudden drops**: Potential outages
- **Sustained growth**: Capacity planning needed
- **Irregular spikes**: Load testing or DDoS

---

## Troubleshooting

### No Data Showing

**Check:**
1. Time window has traces
2. Backend is running
3. API endpoints accessible
4. Browser console for errors

**Debug:**
```bash
# Check if traces exist
curl "http://localhost:4321/api/v1/traces?limit=10"

# Check analytics endpoint
curl "http://localhost:4321/api/v1/analytics/latency-percentiles?hours=24"
```

### Charts Not Rendering

**Common Causes:**
1. Empty data buckets
2. Invalid time ranges
3. Recharts import errors

**Fix:**
- Ensure traces exist in selected time window
- Check browser console for errors
- Verify Recharts is installed: `npm list recharts`

### Slow Loading

**If queries take >2 seconds:**
1. Reduce time window
2. Increase bucket size
3. Limit trace count (backend)
4. Add database indexes (future optimization)

---

## Future Enhancements

### Planned Features

1. **Workflow Dropdown Filter**
   - Select specific workflow in UI
   - Compare multiple workflows side-by-side

2. **Cost Analytics**
   - LLM cost tracking over time
   - Cost per workflow breakdown
   - Budget alerts

3. **Custom Metrics**
   - User-defined percentiles (P90, P75, etc.)
   - Custom aggregations
   - Derived metrics

4. **Export Capabilities**
   - Download charts as images
   - Export data as CSV
   - Scheduled reports

5. **Alerting Integration**
   - Alert when P95 > threshold
   - Error rate alerting
   - Anomaly detection

6. **Performance Optimization**
   - Backend caching (Redis)
   - Materialized views for common queries
   - Pre-aggregated time-series data

---

## Architecture Decisions

### Why Percentiles Over Averages?

**Problem with Averages:**
- Hides outliers
- Skewed by extreme values
- Doesn't represent user experience

**Benefits of Percentiles:**
- P50 shows typical experience
- P95/P99 catch tail latency
- Industry standard (SLOs)

### Why Time-Series Buckets?

**Benefits:**
- Reduces data transfer
- Enables trend visualization
- Aggregates similar time periods
- Scalable to large datasets

### Why Recharts?

**Alternatives Considered:**
- Chart.js: Less React-friendly
- D3.js: Too complex for needs
- Victory: Larger bundle size

**Recharts Wins:**
- React-first design
- Composable components
- Good documentation
- Reasonable bundle size

---

## Code Statistics

**Backend:**
- 1 file: `backend/api/routes/analytics.py`
- ~350 lines of code
- 5 endpoints
- Time complexity: O(n log n) for percentiles

**Frontend:**
- 3 files: Performance.tsx, useAnalytics.ts, analytics.ts
- ~600 lines of code
- 5 React hooks
- 4 chart components

**Bundle Impact:**
- Before: 292KB (83KB gzipped)
- After: 698KB (193KB gzipped)
- Increase: +406KB (+110KB gzipped)
- Recharts accounts for most of the increase

---

## Conclusion

The Performance Monitoring System provides essential observability into trace performance, enabling data-driven optimization decisions. With percentile metrics, time-series charts, and workflow comparisons, teams can quickly identify bottlenecks and track improvements over time.

**Status**: ‚úÖ Production Ready
**Bundle**: 698KB total (193KB gzipped)
**Charts**: 4 interactive visualizations
**Metrics**: P50/P95/P99, Error Rate, Throughput

**Next Steps**: Cost analytics, workflow filters, caching optimizations

---

**Happy Monitoring!** üìä
