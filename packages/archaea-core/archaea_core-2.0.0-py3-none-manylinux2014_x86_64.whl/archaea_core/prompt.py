# Pyarmor 9.1.8 (group), 006652, Archaea, 2025-10-20T16:57:09.968058
from libruntime import __pyarmor__
__pyarmor__(__name__, __file__, b'PY006652\x00\x03\x0b\x00\xa7\r\r\n\x80\x00\x01\x00\x08\x00\x00\x00\x04\x00\x00\x00@\x00\x00\x00\t]\x00\x00\x10\x00\x07\x00#">Z\x0c\xc8\x96i  E\xc5\x9c\n/\'\x00\x00\x00\x00\x00\x00\x00\x00 \x00\x00\x00\x00\x00\x00\x00\xe9\\\x00\x00\x10\x00\x07\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x03\x00\x00\x00\x00\x00\x00\x01\xf3,\x01\x00\x00\x97\x00U\x00d\x00d\x01l\x00m\x01Z\x01\x01\x00d\x00d\x02l\x02m\x03Z\x03\x01\x00i\x00Z\x04d\x03e\x05d\x04<\x00\x00\x00d\x05e\x04d\x06<\x00\x00\x00d\x07e\x04d\x08<\x00\x00\x00d\te\x04d\n<\x00\x00\x00d\x0be\x04d\x0c<\x00\x00\x00g\x00d\r\xa2\x01e\x04d\x0e<\x00\x00\x00d\x0fe\x04d\x10<\x00\x00\x00d\x11e\x04d\x12<\x00\x00\x00g\x00d\x13\xa2\x01e\x04d\x14<\x00\x00\x00d\x15e\x04d\x16<\x00\x00\x00d\x17\xa0\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xa6\x00\x00\x00\xab\x00\x00\x00\x00\x00\x00\x00\x00\x00e\x04d\x18<\x00\x00\x00d\x19\xa0\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xa6\x00\x00\x00\xab\x00\x00\x00\x00\x00\x00\x00\x00\x00e\x04d\x1a<\x00\x00\x00d\x1be\x04d\x1c<\x00\x00\x00d\x1de\x04d\x1e<\x00\x00\x00d\x1fe\x04d <\x00\x00\x00g\x00d!\xa2\x01e\x04d"<\x00\x00\x00d#e\x04d$<\x00\x00\x00d%e\x04d&<\x00\x00\x00d\'S\x00)(\xe9\x00\x00\x00\x00)\x01\xda\x0bannotations)\x01\xda\x03Anyz\x0edict[str, Any]\xda\x07PROMPTS\xda\x07English\xda\x10DEFAULT_LANGUAGE\xfa\x03<|>\xda\x17DEFAULT_TUPLE_DELIMITER\xfa\x02##\xda\x18DEFAULT_RECORD_DELIMITER\xfa\x0c<|COMPLETE|>\xda\x1cDEFAULT_COMPLETION_DELIMITER)\x05\xda\x0corganization\xda\x06person\xda\x03geo\xda\x05event\xda\x08category\xda\x14DEFAULT_ENTITY_TYPES\xfa\x03n/a\xda\x13DEFAULT_USER_PROMPT\xe1\x8c\t\x00\x00---Goal---\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\nUse {language} as output language.\n\n---Steps---\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, use same language as input text. If English, capitalized the name.\n- entity_type: One of the following types: [{entity_types}]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"{tuple_delimiter}<entity_name>{tuple_delimiter}<entity_type>{tuple_delimiter}<entity_description>)\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n- relationship_keywords: one or more high-level key words that summarize the overarching nature of the relationship, focusing on concepts or themes rather than specific details\nFormat each relationship as ("relationship"{tuple_delimiter}<source_entity>{tuple_delimiter}<target_entity>{tuple_delimiter}<relationship_description>{tuple_delimiter}<relationship_keywords>{tuple_delimiter}<relationship_strength>)\n\n3. Identify high-level key words that summarize the main concepts, themes, or topics of the entire text. These should capture the overarching ideas present in the document.\nFormat the content-level key words as ("content_keywords"{tuple_delimiter}<high_level_keywords>)\n\n4. Return output in {language} as a single list of all the entities and relationships identified in steps 1 and 2. Use **{record_delimiter}** as the list delimiter.\n\n5. When finished, output {completion_delimiter}\n\n######################\n---Examples---\n######################\n{examples}\n\n#############################\n---Real Data---\n######################\nEntity_types: [{entity_types}]\nText:\n{input_text}\n######################\nOutput:\xda\x11entity_extraction)\x03\xe1E\x0e\x00\x00Example 1:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\n```\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor\'s authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan\'s shared commitment to discovery was an unspoken rebellion against Cruz\'s narrowing vision of control and order.\n\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. "If this tech can be understood..." Taylor said, their voice quieter, "It could change the game for us. For all of us."\n\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor\'s, a wordless clash of wills softening into an uneasy truce.\n\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n```\n\nOutput:\n("entity"{tuple_delimiter}"Alex"{tuple_delimiter}"person"{tuple_delimiter}"Alex is a character who experiences frustration and is observant of the dynamics among other characters."){record_delimiter}\n("entity"{tuple_delimiter}"Taylor"{tuple_delimiter}"person"{tuple_delimiter}"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective."){record_delimiter}\n("entity"{tuple_delimiter}"Jordan"{tuple_delimiter}"person"{tuple_delimiter}"Jordan shares a commitment to discovery and has a significant interaction with Taylor regarding a device."){record_delimiter}\n("entity"{tuple_delimiter}"Cruz"{tuple_delimiter}"person"{tuple_delimiter}"Cruz is associated with a vision of control and order, influencing the dynamics among other characters."){record_delimiter}\n("entity"{tuple_delimiter}"The Device"{tuple_delimiter}"technology"{tuple_delimiter}"The Device is central to the story, with potential game-changing implications, and is revered by Taylor."){record_delimiter}\n("relationship"{tuple_delimiter}"Alex"{tuple_delimiter}"Taylor"{tuple_delimiter}"Alex is affected by Taylor\'s authoritarian certainty and observes changes in Taylor\'s attitude towards the device."{tuple_delimiter}"power dynamics, perspective shift"{tuple_delimiter}7){record_delimiter}\n("relationship"{tuple_delimiter}"Alex"{tuple_delimiter}"Jordan"{tuple_delimiter}"Alex and Jordan share a commitment to discovery, which contrasts with Cruz\'s vision."{tuple_delimiter}"shared goals, rebellion"{tuple_delimiter}6){record_delimiter}\n("relationship"{tuple_delimiter}"Taylor"{tuple_delimiter}"Jordan"{tuple_delimiter}"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce."{tuple_delimiter}"conflict resolution, mutual respect"{tuple_delimiter}8){record_delimiter}\n("relationship"{tuple_delimiter}"Jordan"{tuple_delimiter}"Cruz"{tuple_delimiter}"Jordan\'s commitment to discovery is in rebellion against Cruz\'s vision of control and order."{tuple_delimiter}"ideological conflict, rebellion"{tuple_delimiter}5){record_delimiter}\n("relationship"{tuple_delimiter}"Taylor"{tuple_delimiter}"The Device"{tuple_delimiter}"Taylor shows reverence towards the device, indicating its importance and potential impact."{tuple_delimiter}"reverence, technological significance"{tuple_delimiter}9){record_delimiter}\n("content_keywords"{tuple_delimiter}"power dynamics, ideological conflict, discovery, rebellion"){completion_delimiter}\n#############################\xe1h\x0f\x00\x00Example 2:\n\nEntity_types: [company, index, commodity, market_trend, economic_policy, biological]\nText:\n```\nStock markets faced a sharp downturn today as tech giants saw significant declines, with the Global Tech Index dropping by 3.4% in midday trading. Analysts attribute the selloff to investor concerns over rising interest rates and regulatory uncertainty.\n\nAmong the hardest hit, Nexon Technologies saw its stock plummet by 7.8% after reporting lower-than-expected quarterly earnings. In contrast, Omega Energy posted a modest 2.1% gain, driven by rising oil prices.\n\nMeanwhile, commodity markets reflected a mixed sentiment. Gold futures rose by 1.5%, reaching $2,080 per ounce, as investors sought safe-haven assets. Crude oil prices continued their rally, climbing to $87.60 per barrel, supported by supply constraints and strong demand.\n\nFinancial experts are closely watching the Federal Reserve\'s next move, as speculation grows over potential rate hikes. The upcoming policy announcement is expected to influence investor confidence and overall market stability.\n```\n\nOutput:\n("entity"{tuple_delimiter}"Global Tech Index"{tuple_delimiter}"index"{tuple_delimiter}"The Global Tech Index tracks the performance of major technology stocks and experienced a 3.4% decline today."){record_delimiter}\n("entity"{tuple_delimiter}"Nexon Technologies"{tuple_delimiter}"company"{tuple_delimiter}"Nexon Technologies is a tech company that saw its stock decline by 7.8% after disappointing earnings."){record_delimiter}\n("entity"{tuple_delimiter}"Omega Energy"{tuple_delimiter}"company"{tuple_delimiter}"Omega Energy is an energy company that gained 2.1% in stock value due to rising oil prices."){record_delimiter}\n("entity"{tuple_delimiter}"Gold Futures"{tuple_delimiter}"commodity"{tuple_delimiter}"Gold futures rose by 1.5%, indicating increased investor interest in safe-haven assets."){record_delimiter}\n("entity"{tuple_delimiter}"Crude Oil"{tuple_delimiter}"commodity"{tuple_delimiter}"Crude oil prices rose to $87.60 per barrel due to supply constraints and strong demand."){record_delimiter}\n("entity"{tuple_delimiter}"Market Selloff"{tuple_delimiter}"market_trend"{tuple_delimiter}"Market selloff refers to the significant decline in stock values due to investor concerns over interest rates and regulations."){record_delimiter}\n("entity"{tuple_delimiter}"Federal Reserve Policy Announcement"{tuple_delimiter}"economic_policy"{tuple_delimiter}"The Federal Reserve\'s upcoming policy announcement is expected to impact investor confidence and market stability."){record_delimiter}\n("relationship"{tuple_delimiter}"Global Tech Index"{tuple_delimiter}"Market Selloff"{tuple_delimiter}"The decline in the Global Tech Index is part of the broader market selloff driven by investor concerns."{tuple_delimiter}"market performance, investor sentiment"{tuple_delimiter}9){record_delimiter}\n("relationship"{tuple_delimiter}"Nexon Technologies"{tuple_delimiter}"Global Tech Index"{tuple_delimiter}"Nexon Technologies\' stock decline contributed to the overall drop in the Global Tech Index."{tuple_delimiter}"company impact, index movement"{tuple_delimiter}8){record_delimiter}\n("relationship"{tuple_delimiter}"Gold Futures"{tuple_delimiter}"Market Selloff"{tuple_delimiter}"Gold prices rose as investors sought safe-haven assets during the market selloff."{tuple_delimiter}"market reaction, safe-haven investment"{tuple_delimiter}10){record_delimiter}\n("relationship"{tuple_delimiter}"Federal Reserve Policy Announcement"{tuple_delimiter}"Market Selloff"{tuple_delimiter}"Speculation over Federal Reserve policy changes contributed to market volatility and investor selloff."{tuple_delimiter}"interest rate impact, financial regulation"{tuple_delimiter}7){record_delimiter}\n("content_keywords"{tuple_delimiter}"market downturn, investor sentiment, commodities, Federal Reserve, stock performance"){completion_delimiter}\n#############################\xe1\xb4\n\x00\x00Example 3:\n\nEntity_types: [economic_policy, athlete, event, location, record, organization, equipment]\nText:\n```\nAt the World Athletics Championship in Tokyo, Noah Carter broke the 100m sprint record using cutting-edge carbon-fiber spikes.\n```\n\nOutput:\n("entity"{tuple_delimiter}"World Athletics Championship"{tuple_delimiter}"event"{tuple_delimiter}"The World Athletics Championship is a global sports competition featuring top athletes in track and field."){record_delimiter}\n("entity"{tuple_delimiter}"Tokyo"{tuple_delimiter}"location"{tuple_delimiter}"Tokyo is the host city of the World Athletics Championship."){record_delimiter}\n("entity"{tuple_delimiter}"Noah Carter"{tuple_delimiter}"athlete"{tuple_delimiter}"Noah Carter is a sprinter who set a new record in the 100m sprint at the World Athletics Championship."){record_delimiter}\n("entity"{tuple_delimiter}"100m Sprint Record"{tuple_delimiter}"record"{tuple_delimiter}"The 100m sprint record is a benchmark in athletics, recently broken by Noah Carter."){record_delimiter}\n("entity"{tuple_delimiter}"Carbon-Fiber Spikes"{tuple_delimiter}"equipment"{tuple_delimiter}"Carbon-fiber spikes are advanced sprinting shoes that provide enhanced speed and traction."){record_delimiter}\n("entity"{tuple_delimiter}"World Athletics Federation"{tuple_delimiter}"organization"{tuple_delimiter}"The World Athletics Federation is the governing body overseeing the World Athletics Championship and record validations."){record_delimiter}\n("relationship"{tuple_delimiter}"World Athletics Championship"{tuple_delimiter}"Tokyo"{tuple_delimiter}"The World Athletics Championship is being hosted in Tokyo."{tuple_delimiter}"event location, international competition"{tuple_delimiter}8){record_delimiter}\n("relationship"{tuple_delimiter}"Noah Carter"{tuple_delimiter}"100m Sprint Record"{tuple_delimiter}"Noah Carter set a new 100m sprint record at the championship."{tuple_delimiter}"athlete achievement, record-breaking"{tuple_delimiter}10){record_delimiter}\n("relationship"{tuple_delimiter}"Noah Carter"{tuple_delimiter}"Carbon-Fiber Spikes"{tuple_delimiter}"Noah Carter used carbon-fiber spikes to enhance performance during the race."{tuple_delimiter}"athletic equipment, performance boost"{tuple_delimiter}7){record_delimiter}\n("relationship"{tuple_delimiter}"World Athletics Federation"{tuple_delimiter}"100m Sprint Record"{tuple_delimiter}"The World Athletics Federation is responsible for validating and recognizing new sprint records."{tuple_delimiter}"sports regulation, record certification"{tuple_delimiter}9){record_delimiter}\n("content_keywords"{tuple_delimiter}"athletics, sprinting, record-breaking, sports technology, competition"){completion_delimiter}\n#############################\xda\x1aentity_extraction_examples\xe1\xc8\x02\x00\x00You are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we the have full context.\nUse {language} as output language.\n\n#######\n---Data---\nEntities: {entity_name}\nDescription List: {description_list}\n#######\nOutput:\n\xda\x1dsummarize_entity_descriptions\xe1<\x08\x00\x00\nMANY entities and relationships were missed in the last extraction.\n\n---Remember Steps---\n\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, use same language as input text. If English, capitalized the name.\n- entity_type: One of the following types: [{entity_types}]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"{tuple_delimiter}<entity_name>{tuple_delimiter}<entity_type>{tuple_delimiter}<entity_description>)\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n- relationship_keywords: one or more high-level key words that summarize the overarching nature of the relationship, focusing on concepts or themes rather than specific details\nFormat each relationship as ("relationship"{tuple_delimiter}<source_entity>{tuple_delimiter}<target_entity>{tuple_delimiter}<relationship_description>{tuple_delimiter}<relationship_keywords>{tuple_delimiter}<relationship_strength>)\n\n3. Identify high-level key words that summarize the main concepts, themes, or topics of the entire text. These should capture the overarching ideas present in the document.\nFormat the content-level key words as ("content_keywords"{tuple_delimiter}<high_level_keywords>)\n\n4. Return output in {language} as a single list of all the entities and relationships identified in steps 1 and 2. Use **{record_delimiter}** as the list delimiter.\n\n5. When finished, output {completion_delimiter}\n\n---Output---\n\nAdd them below using the same format:\n\n\xda\x1aentity_continue_extraction\xfa\xa2\n---Goal---\'\n\nIt appears some entities may have still been missed.\n\n---Output---\n\nAnswer ONLY by `YES` OR `NO` if there are still entities that need to be added.\n\xda\x19entity_if_loop_extraction\xfaFSorry, I\'m not able to provide an answer to that question.[no-context]\xda\rfail_response\xe1\xd5\x06\x00\x00---Role---\n\nYou are a helpful assistant responding to user query about Knowledge Graph and Document Chunks provided in JSON format below.\n\n\n---Goal---\n\nGenerate a concise response based on Knowledge Base and follow Response Rules, considering both the conversation history and the current query. Summarize all information in the provided Knowledge Base, and incorporating general knowledge relevant to the Knowledge Base. Do not include information not provided by Knowledge Base.\n\nWhen handling relationships with timestamps:\n1. Each relationship has a "created_at" timestamp indicating when we acquired this knowledge\n2. When encountering conflicting relationships, consider both the semantic content and the timestamp\n3. Don\'t automatically prefer the most recently created relationships - use judgment based on the context\n4. For time-specific queries, prioritize temporal information in the content before considering creation timestamps\n\n---Conversation History---\n{history}\n\n---Knowledge Graph and Document Chunks---\n{context_data}\n\n---Response Rules---\n\n- Target format and length: {response_type}\n- Use markdown formatting with appropriate section headings\n- Please respond in the same language as the user\'s question.\n- Ensure the response maintains continuity with the conversation history.\n- List up to 5 most important reference sources at the end under "References" section. Clearly indicating whether each source is from Knowledge Graph (KG) or Document Chunks (DC), and include the file path if available, in the following format: [KG/DC] file_path\n- If you don\'t know the answer, just say so.\n- Do not make anything up. Do not include information not provided by the Knowledge Base.\n- Addtional user prompt: {user_prompt}\n\nResponse:\xda\x0crag_response\xe1G\x04\x00\x00---Role---\n\nYou are a helpful assistant tasked with identifying both high-level and low-level keywords in the user\'s query and conversation history.\n\n---Goal---\n\nGiven the query and conversation history, list both high-level and low-level keywords. High-level keywords focus on overarching concepts or themes, while low-level keywords focus on specific entities, details, or concrete terms.\n\n---Instructions---\n\n- Consider both the current query and relevant conversation history when extracting keywords\n- Output the keywords in JSON format, it will be parsed by a JSON parser, do not add any extra content in output\n- The JSON should have two keys:\n  - "high_level_keywords" for overarching concepts or themes\n  - "low_level_keywords" for specific entities or details\n\n######################\n---Examples---\n######################\n{examples}\n\n#############################\n---Real Data---\n######################\nConversation History:\n{history}\n\nCurrent Query: {query}\n######################\nThe `Output` should be human text, not unicode characters. Keep the same language as `Query`.\nOutput:\n\n\xda\x13keywords_extraction)\x03\xe1V\x01\x00\x00Example 1:\n\nQuery: "How does international trade influence global economic stability?"\n################\nOutput:\n{\n  "high_level_keywords": ["International trade", "Global economic stability", "Economic impact"],\n  "low_level_keywords": ["Trade agreements", "Tariffs", "Currency exchange", "Imports", "Exports"]\n}\n#############################\xe1m\x01\x00\x00Example 2:\n\nQuery: "What are the environmental consequences of deforestation on biodiversity?"\n################\nOutput:\n{\n  "high_level_keywords": ["Environmental consequences", "Deforestation", "Biodiversity loss"],\n  "low_level_keywords": ["Species extinction", "Habitat destruction", "Carbon emissions", "Rainforest", "Ecosystem"]\n}\n#############################\xe1=\x01\x00\x00Example 3:\n\nQuery: "What is the role of education in reducing poverty?"\n################\nOutput:\n{\n  "high_level_keywords": ["Education", "Poverty reduction", "Socioeconomic development"],\n  "low_level_keywords": ["School access", "Literacy rates", "Job training", "Income inequality"]\n}\n#############################\xda\x1ckeywords_extraction_examples\xe1a\x06\x00\x00---Role---\n\nYou are a helpful assistant responding to user query about Document Chunks provided provided in JSON format below.\n\n---Goal---\n\nGenerate a concise response based on Document Chunks and follow Response Rules, considering both the conversation history and the current query. Summarize all information in the provided Document Chunks, and incorporating general knowledge relevant to the Document Chunks. Do not include information not provided by Document Chunks.\n\nWhen handling content with timestamps:\n1. Each piece of content has a "created_at" timestamp indicating when we acquired this knowledge\n2. When encountering conflicting information, consider both the content and the timestamp\n3. Don\'t automatically prefer the most recent content - use judgment based on the context\n4. For time-specific queries, prioritize temporal information in the content before considering creation timestamps\n\n---Conversation History---\n{history}\n\n---Document Chunks(DC)---\n{content_data}\n\n---Response Rules---\n\n- Target format and length: {response_type}\n- Use markdown formatting with appropriate section headings\n- Please respond in the same language as the user\'s question.\n- Ensure the response maintains continuity with the conversation history.\n- List up to 5 most important reference sources at the end under "References" section. Clearly indicating each source from Document Chunks(DC), and include the file path if available, in the following format: [DC] file_path\n- If you don\'t know the answer, just say so.\n- Do not include information not provided by the Document Chunks.\n- Addtional user prompt: {user_prompt}\n\nResponse:\xda\x12naive_rag_response\xe1\xf3\x03\x00\x00Please analyze the similarity between these two questions:\n\nQuestion 1: {original_prompt}\nQuestion 2: {cached_prompt}\n\nPlease evaluate whether these two questions are semantically similar, and whether the answer to Question 2 can be used to answer Question 1, provide a similarity score between 0 and 1 directly.\n\nSimilarity score criteria:\n0: Completely unrelated or answer cannot be reused, including but not limited to:\n   - The questions have different topics\n   - The locations mentioned in the questions are different\n   - The times mentioned in the questions are different\n   - The specific individuals mentioned in the questions are different\n   - The specific events mentioned in the questions are different\n   - The background information in the questions is different\n   - The key conditions in the questions are different\n1: Identical and answer can be directly reused\n0.5: Partially related and answer needs modification to be used\nReturn only a number between 0-1, without any additional content.\n\xda\x10similarity_checkN)\x07\xda\n__future__r\x03\x00\x00\x00\xda\x06typingr\x04\x00\x00\x00r\x05\x00\x00\x00\xda\x0f__annotations__\xda\x05strip\xa9\x00\xf3\x00\x00\x00\x00z <frozen src.archaea_core.prompt>\xfa\x08<module>r6\x00\x00\x00\x01\x00\x00\x00s{\x01\x00\x00\xf0\x03\x01\x01\x01\xd8\x00"\xd0\x00"\xd0\x00"\xd0\x00"\xd0\x00"\xd0\x00"\xd0\x00"\xe0\x00\x16\xd0\x00\x16\xd0\x00\x16\xd0\x00\x16\xd0\x00\x16\xd0\x00\x16\xe0\x1a\x1c\x80\x07\xd0\x00\x1c\xd0\x00\x1c\xd0\x00\x1c\xd1\x00\x1c\xe0\x1e\'\x80\x07\xd0\x08\x1a\xd1\x00\x1b\xd8%*\x80\x07\xd0\x08!\xd1\x00"\xd8&*\x80\x07\xd0\x08"\xd1\x00#\xd8*8\x80\x07\xd0\x08&\xd1\x00\'\xe0"X\xd0"X\xd0"X\x80\x07\xd0\x08\x1e\xd1\x00\x1f\xe0!&\x80\x07\xd0\x08\x1d\xd1\x00\x1e\xf0\x08\'\x05\x0b\xf0\x05\x00\x01\x08\xd8\x04\x17\xf1\x03\x02\x01\x02\xf0V\x01M\x01)\x02\xf0\x00M\x01)\x02\xf0\x00M\x01)\x02\x80\x07\xd0\x08$\xd1\x00%\xf0b\x02\r\x05\x04\xf0\x05\x00\x01\x08\xd8\x04#\xf1\x03\x02\x01\x02\xf0&\x1e\x05\x04\xf7<\x00\x05\n\x82E\x81G\x84G\xf0A\x01\x00\x01\x08\xd8\x04 \xf1\x03\x02\x01\x02\xf0H\x01\x08\x05\x04\xf7\x10\x00\x05\n\x82E\x81G\x84G\xf0\x15\x00\x01\x08\xd8\x04\x1f\xf1\x03\x02\x01\x02\xf0\x18\x00\x1cd\x01\x80\x07\x88\x0f\xd1\x00\x18\xf0\x08 \x05\r\xf0\x05\x00\x01\x08\xd8\x04\x12\xf1\x03\x02\x01\x02\xf0L\x01 \x05\x04\xf0\x05\x00\x01\x08\xd8\x04\x19\xf1\x03\x02\x01\x02\xf0H\x01\x1f+\x02\xf0\x00\x1f+\x02\xf0\x00\x1f+\x02\x80\x07\xd0\x08&\xd1\x00\'\xf0F\x01\x1f\x05\r\xf0\x05\x00\x01\x08\xd8\x04\x18\xf1\x03\x02\x01\x02\xf0L\x01\x13\x05\x04\xf0\x05\x00\x01\x08\xd8\x04\x16\xf1\x03\x02\x01\x02\xf0\x00\x02\x01\x02\xf0\x00\x02\x01\x02r5\x00\x00\x00')
