"""This module takes care of receiving the data catalogs."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/00_io.ipynb.

# %% auto 0
__all__ = ['logger', 'v1', 'kwargs', 'v3', 'fetchers', 'postprocessor', 'get_blotch_catalog', 'get_fan_catalog',
           'get_tile_coords', 'get_meta_data', 'get_region_names', 'get_tile_urls', 'normalize_tile_id', 'get_subframe',
           'get_url_for_tile_id', 'get_url_for_tile', 'get_subframe_by_tile_id', 'get_subframe_for_tile',
           'get_fans_for_tile', 'get_blotches_for_tile', 'get_hirise_id_for_tile']

# %% ../notebooks/00_io.ipynb 2
from pathlib import Path

import matplotlib.image as mplimg
import pandas as pd
import pooch
from matplotlib import pyplot as plt

# %% ../notebooks/00_io.ipynb 3
logger = pooch.get_logger()
logger.setLevel("DEBUG")

# %% ../notebooks/00_io.ipynb 4
v1 = pooch.create(
    path=pooch.os_cache("p4tools"),
    base_url="",
    version = "v1",
    registry= {
        'fans': 'md5:71ff51ff79d6e975f704f19b1996d8ea',
        'blotches': 'md5:f4d0c101f65abbaf34e092620133d56e',
        'metadata': 'md5:c0dc46e0fc3d259c30afaec412074eae',
        'tile_coords': 'md5:6b9a917a6997f1aa01cfef4322cabd81',
        'raw_data': 'md5:39a8909590fe9f816454db93f0027d2c',
        'intermediate': 'md5:6544bf0c7851eedd4783859c0adc42d7',
        'region_names': 'md5:9101c7a0f8e248c9ffe9c07869da5635',
        'tile_urls': 'md5:5717c8379d453cf4b11a5f5775f5fb6e',
    },
    urls = {
        'fans': 'doi:10.5281/zenodo.8102805/P4_catalog_v1.1_L1C_cut_0.5_fan.csv.zip',
         'blotches': 'doi:10.5281/zenodo.8102805/P4_catalog_v1.1_L1C_cut_0.5_blotch.csv.zip',
         'metadata': 'doi:10.5281/zenodo.8102805/P4_catalog_v1.1_metadata.csv.zip',
         'tile_coords': 'doi:10.5281/zenodo.8102805/P4_catalog_v1.1_tile_coords_final.csv.zip',
         'raw_data': 'doi:10.5281/zenodo.8102805/P4_catalog_v1.0_raw_classifications.hdf.zip',
         'intermediate': 'doi:10.5281/zenodo.8102805/P4_catalog_v1.0_pipeline_products.zip',
         'region_names': 'doi:10.5281/zenodo.8102805/region_names.zip',
         'tile_urls': 'doi:10.5281/zenodo.8102805/tile_urls.csv.zip'    
    }
)

# %% ../notebooks/00_io.ipynb 5
def postprocessor(fname, action, pup):
    """
    Post-processing hook to process the downloaded v1 catalog file.

    Postprocessing steps are:
    1. unzip to CSV
    2. load CSV into pandas
    3. save as parquet file.

    This time, at the next read, the performance is much increased due to reading the parquet file instead of loading
    the CSV file every time.

    Parameters
    ----------
    fname : str
       Full path of the zipped file in local storage
    action : str
       One of "download" (file doesn't exist and will download),
       "update" (file is outdated and will download), and
       "fetch" (file exists and is updated so no download).
    pup : Pooch
       The instance of Pooch that called the processor function.

    Returns
    -------
    fname : str
       The full path to the unzipped file. (Return the same fname is your
       processor doesn't modify the file).

    """
    fpath = Path(fname)
    if pup.urls[fpath.name].endswith('.zip'):
        unzipper = pooch.Unzip()
        csvfname = unzipper(fname, action, pup)[0]
    else:
        csvfname = fname
    parquetfname = Path(csvfname).with_suffix(".parq")
    if action in ("update", "download") or not parquetfname.is_file():
        logger.info(f"Converting CSV to parquet and storing as {parquetfname}.")
        pd.read_csv(csvfname).to_parquet(parquetfname)
    return parquetfname

# %% ../notebooks/00_io.ipynb 6
kwargs = dict(processor=postprocessor, progressbar=True)

# %% ../notebooks/00_io.ipynb 10
v3 = pooch.create(
    path=pooch.os_cache("p4tools"),
    base_url = '',
    version="v3",
    registry = {
        'fans': 'md5:186c98dee8712dcab1ea08317e60ed9b',
        'blotches': 'md5:651d767533f70196ab36512eff01a941',
        'metafull': 'md5:5c2e5f34e2b9c98b18b35ed5e16f68b4',
        'tile_coords': 'md5:5c2e5f34e2b9c98b18b35ed5e16f68b4',
        'metadata': 'md5:fa1ed90fd731fabc0f760b2d51759b4f',
    },
    urls = {
        'fans': 'https://refubium.fu-berlin.de/bitstream/handle/fub188/46287/P4_catalog_Full_Release_v3.0_L1C_cut_0.5_fan_meta_merged.csv',
        'blotches': 'https://refubium.fu-berlin.de/bitstream/handle/fub188/46287/P4_catalog_Full_Release_v3.0_L1C_cut_0.5_blotch_meta_merged.csv',
        'metafull': 'https://refubium.fu-berlin.de/bitstream/handle/fub188/46287/P4_catalog_Full_Release_v3.0_EDRINDEX_metadata.csv',
        'tile_coords': 'https://refubium.fu-berlin.de/bitstream/handle/fub188/46287/P4_catalog_Full_Release_v3.0_tile_coords_final.csv',
        'metadata': 'https://refubium.fu-berlin.de/bitstream/handle/fub188/46287/P4_catalog_Full_Release_v3.0_metadata.csv'
    }
)

# %% ../notebooks/00_io.ipynb 13
fetchers = dict(v1=v1.fetch, v3=v3.fetch)

# %% ../notebooks/00_io.ipynb 14
def get_blotch_catalog(version='v3') -> pd.DataFrame:
    return pd.read_parquet(fetchers[version]('blotches', **kwargs))

def get_fan_catalog(version='v3') -> pd.DataFrame:
    return pd.read_parquet(fetchers[version]('fans', **kwargs))

def get_tile_coords(version='v3') -> pd.DataFrame:
    return pd.read_parquet(fetchers[version]("tile_coords", **kwargs))

def get_meta_data(version='v3') -> pd.DataFrame:
    return pd.read_parquet(fetchers[version]("metadata", **kwargs))

def get_region_names() -> pd.DataFrame:
    "only v1 exists"
    return pd.read_parquet(v1.fetch("region_names", **kwargs))

def get_tile_urls() -> pd.DataFrame:
    "only v1 exists"
    return pd.read_parquet(v1.fetch("tile_urls", **kwargs))

# %% ../notebooks/00_io.ipynb 20
def normalize_tile_id(tile_id: str) -> str:
    """Normalize a tile ID by adding 'APF' prefix and leading zeros if necessary.

    Parameters
    ----------
    tile_id : str
        Full or partial tile ID. If partial, it will be padded with 'APF' and leading zeros.

    Returns
    -------
    str
        Complete tile ID in format 'APF0000xxx' (always 9 characters)

    Examples
    --------
    >>> normalize_tile_id('r8y')
    'APF0000r8y'
    >>> normalize_tile_id('0000r8y')
    'APF0000r8y'
    >>> normalize_tile_id('APF0000r8y')
    'APF0000r8y'
    >>> normalize_tile_id('123r8y')
    'APF0123r8y'
    """
    # Remove 'APF' prefix if present
    if tile_id.upper().startswith("APF"):
        tile_id = tile_id[3:]

    # Calculate how many zeros we need to add
    target_length = 7  # length without 'APF'
    current_length = len(tile_id)

    if current_length > target_length:
        raise ValueError(f"Tile ID too long: {tile_id}")

    # Add necessary leading zeros
    padded_id = "0" * (target_length - current_length) + tile_id

    # Add APF prefix
    return f"APF{padded_id}"

# %% ../notebooks/00_io.ipynb 22
def get_subframe(url):
    targetpath = pooch.retrieve(
        url, path=pooch.os_cache("p4tools/tiles"), known_hash=None, progressbar=True
    )
    im = mplimg.imread(targetpath)
    return im

# %% ../notebooks/00_io.ipynb 23
def get_url_for_tile_id(tile_id):
    return get_tile_urls().set_index("tile_id").squeeze().at[normalize_tile_id(tile_id)]


def get_url_for_tile(tile_id):
    # alias for get_url_for_tile_id
    return get_url_for_tile_id(tile_id)

# %% ../notebooks/00_io.ipynb 27
def get_subframe_by_tile_id(tile_id):
    url = get_url_for_tile_id(tile_id)
    return get_subframe(url)


def get_subframe_for_tile(tile_id):
    # alias for get_subframe_by_tile_id for consistency
    return get_subframe_by_tile_id(tile_id)

# %% ../notebooks/00_io.ipynb 29
def get_fans_for_tile(tile_id, version='v3'):
    tile_id = normalize_tile_id(tile_id)
    fans = get_fan_catalog(version)
    return fans.query("tile_id == @tile_id")

# %% ../notebooks/00_io.ipynb 32
def get_blotches_for_tile(tile_id, version='v3'):
    tile_id = normalize_tile_id(tile_id)
    blotches = get_blotch_catalog(version)
    return blotches.query("tile_id == @tile_id")

# %% ../notebooks/00_io.ipynb 35
def get_hirise_id_for_tile(tile_id, version='v3'):
    tile_id = normalize_tile_id(tile_id)
    try:
        obsid = get_fan_catalog(version).query("tile_id == @tile_id").obsid.iloc[0]
    except IndexError:
        try:
            obsid = get_blotch_catalog(version).query("tile_id == @tile_id").obsid.iloc[0]
        except IndexError:
            raise ValueError(f"No obsid found for tile {tile_id}")
    else:
        return obsid
