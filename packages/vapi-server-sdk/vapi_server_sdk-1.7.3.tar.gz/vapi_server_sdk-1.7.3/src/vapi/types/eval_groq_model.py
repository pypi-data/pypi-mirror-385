# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic
import typing_extensions
from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.serialization import FieldMetadata
from ..core.unchecked_base_model import UncheckedBaseModel
from .eval_groq_model_model import EvalGroqModelModel


class EvalGroqModel(UncheckedBaseModel):
    provider: typing.Literal["groq"] = pydantic.Field(default="groq")
    """
    This is the provider of the model (`groq`).
    """

    model: EvalGroqModelModel = pydantic.Field()
    """
    This is the name of the model. Ex. gpt-4o
    """

    temperature: typing.Optional[float] = pydantic.Field(default=None)
    """
    This is the temperature of the model. For LLM-as-a-judge, it's recommended to set it between 0 - 0.3 to avoid hallucinations and ensure the model judges the output correctly based on the instructions.
    """

    max_tokens: typing_extensions.Annotated[typing.Optional[float], FieldMetadata(alias="maxTokens")] = pydantic.Field(
        default=None
    )
    """
    This is the max tokens of the model.
    If your Judge instructions return `true` or `false` takes only 1 token (as per the OpenAI Tokenizer), and therefore is recommended to set it to a low number to force the model to return a short response.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
