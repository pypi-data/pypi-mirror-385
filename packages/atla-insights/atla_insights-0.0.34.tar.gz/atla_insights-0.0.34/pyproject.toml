[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "atla-insights"
version = "0.0.34"
description = "Atla is a platform for monitoring and improving AI agents."
readme = "README.md"
requires-python = ">=3.10"
license = { text = "Apache-2.0" }
authors = [{ name = "Atla Team", email = "support@atla-ai.com" }]
classifiers = [
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
]
dependencies = [
    "cuid2>=2.0.1",
    "httpx>=0.24.0",
    "openai>=1.77.0",
    "openinference-instrumentation>=0.1.32",
    "openinference-semantic-conventions>=0.1.24",
    "opentelemetry-api>=1.32.1",
    "opentelemetry-exporter-otlp-proto-grpc>=1.32.1",
    "opentelemetry-exporter-otlp-proto-http>=1.32.1",
    "opentelemetry-instrumentation>=0.54b0",
    "pygit2>=1.16.0",
    "pydantic>=2.11.4",
    "python-dateutil>=2.8.0",
    "rich>=13.9.4",
    "wrapt>=1.17.2",
    "human-id>=0.2.0",
]

[dependency-groups]
dev = ["atla-insights[all,ci]"]

[project.optional-dependencies]
all = [
    "atla-insights[agno,anthropic,baml,bedrock,claude-code-sdk,crewai,google-adk,google-genai,google-generativeai,langchain,litellm,mcp,openai,openai-agents,pydantic-ai,smolagents]",
]
agno = ["agno>=1.5.2", "openinference-instrumentation-agno>=0.1.15"]
anthropic = [
    "anthropic[bedrock]>=0.52.1",
    "openinference-instrumentation-anthropic>=0.1.18",
]
baml = ["baml-py>=0.201.0"]
bedrock = ["boto3>=1.38.17", "openinference-instrumentation-bedrock>=0.1.26"]
ci = [
    "mypy>=1.15.0",
    "ruff>=0.11.7",
    "pytest>=8.3.4",
    "pytest-asyncio>=0.26.0",
    "pytest-httpserver>=1.1.3",
]
claude-code-sdk = ["claude-code-sdk>=0.0.21"]
crewai = [
    "crewai>=0.130.0",
    "litellm>=1.72.0,<1.74.0",
    "openinference-instrumentation-crewai==0.1.10",
]
google-adk = [
    "google-adk >= 1.2.1",
    "openinference-instrumentation-google-adk>=0.1.4",
]
google-genai = [
    "google-genai>=1.19.0",
    "openinference-instrumentation-google-genai==0.1.2",
]
google-generativeai = [
    "google-generativeai>=0.7.0",
    "openinference-instrumentation-google-genai==0.1.2",
]
langchain = [
    "langchain>=0.3.18",
    "langchain-openai>=0.3.4",
    "langgraph>=0.3.20",
    "openinference-instrumentation-langchain==0.1.43",
]
litellm = ["litellm>=1.72.0,<1.74.0"]
mcp = ["mcp>=1.9.0", "openinference-instrumentation-mcp>=1.3.0"]
openai = ["openinference-instrumentation-openai>=0.1.30"]
openai-agents = [
    "openai-agents>=0.0.7",
    "openinference-instrumentation-openai>=0.1.30",
    "openinference-instrumentation-openai-agents>=0.1.12",
]
pydantic-ai = [
    "openinference-instrumentation-pydantic-ai==0.1.8",
    "pydantic-ai>=0.2.0",
]
smolagents = [
    "openinference-instrumentation-smolagents==0.1.14",
    "smolagents<1.21.0,>=1.19.0",
]

[project.urls]
"Homepage" = "https://atla-ai.com"

[tool.uv]
required-version = ">=0.7.2"

[tool.mypy]
explicit_package_bases = true
namespace_packages = true
implicit_optional = false
follow_untyped_imports = true
plugins = ["pydantic.mypy"]
mypy_path = ["src"]
exclude = ["examples/", "src/atla_insights/client/_generated_client/"]

[tool.pydantic-mypy]
init_forbid_extra = true
init_typed = true
warn_required_dynamic_aliases = true
warn_untyped_fields = true

[[tool.mypy.overrides]]
module = [""]
follow_untyped_imports = false
ignore_missing_imports = true
follow_imports = "skip"

[tool.ruff]
exclude = [
    ".venv",
    "examples/frameworks/instrument_baml/baml_client",
    "src/atla_insights/client/_generated_client",
]
line-length = 90
indent-width = 4

[tool.ruff.format]
quote-style = "double"
exclude = ["*.ipynb"]

[tool.ruff.lint]
exclude = ["*.ipynb"]
select = ["B", "C", "E", "F", "I", "RUF", "W", "D"]
ignore = []
fixable = ["ALL"]
unfixable = []

[tool.ruff.lint.mccabe]
max-complexity = 18

[tool.ruff.lint.pydocstyle]
convention = "google"
