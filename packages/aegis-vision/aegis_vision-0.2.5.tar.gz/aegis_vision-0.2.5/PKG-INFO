Metadata-Version: 2.4
Name: aegis-vision
Version: 0.2.5
Summary: Cloud-native computer vision model training toolkit for Aegis AI
Author-email: Aegis AI Team <your-email@example.com>
License: MIT
Project-URL: Homepage, https://github.com/your-org/aegis-vision
Project-URL: Documentation, https://aegis-vision.readthedocs.io
Project-URL: Repository, https://github.com/your-org/aegis-vision
Project-URL: Bug Tracker, https://github.com/your-org/aegis-vision/issues
Keywords: computer-vision,yolo,model-training,kaggle,wandb,object-detection
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: ultralytics>=8.0.0
Requires-Dist: opencv-python<4.12.0,>=4.8.0
Requires-Dist: pillow>=10.0.0
Requires-Dist: numpy<2.0.0,>=1.24.0
Requires-Dist: wandb>=0.15.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: tqdm>=4.65.0
Requires-Dist: pycocotools>=2.0.6
Requires-Dist: psutil>=5.9.0
Requires-Dist: firebase-admin>=6.0.0
Requires-Dist: google-cloud-firestore>=2.11.0
Requires-Dist: requests>=2.31.0
Requires-Dist: kaggle>=1.5.0
Requires-Dist: kagglehub>=0.2.0
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.5.0; extra == "dev"
Provides-Extra: kaggle
Requires-Dist: kaggle>=1.5.0; extra == "kaggle"
Requires-Dist: kagglehub>=0.2.0; extra == "kaggle"
Provides-Extra: all
Requires-Dist: aegis-vision[dev,kaggle]; extra == "all"
Dynamic: license-file

# Aegis Vision

> Cloud-native computer vision model training toolkit for Aegis AI

[![PyPI version](https://badge.fury.io/py/aegis-vision.svg)](https://badge.fury.io/py/aegis-vision)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

**Aegis Vision** is a streamlined toolkit for training computer vision models in cloud environments (Kaggle, Colab, etc.) with built-in support for:

- üéØ **YOLO Models** (v8, v9, v10, v11) - Object detection training
- üìä **Wandb Integration** - Experiment tracking and visualization
- üîÑ **COCO Format** - Dataset conversion and handling
- ‚òÅÔ∏è **Cloud-Optimized** - Designed for Kaggle/Colab workflows
- üì¶ **Model Export** - ONNX, CoreML, OpenVINO, TensorRT, TFLite

## Installation

### Standard Installation

```bash
# Basic installation
pip install aegis-vision

# With Kaggle support
pip install aegis-vision[kaggle]

# Development installation
pip install aegis-vision[dev]

# All features
pip install aegis-vision[all]
```

### Nvidia DGX / High-Performance GPU Systems

For Nvidia DGX Spark or other systems with latest NVIDIA GPUs (Blackwell architecture), installation is the same:

```bash
# Standard installation with automatic environment checking
pip install aegis-vision

# Login and start (agent will auto-check and fix environment)
aegis-agent login
aegis-agent start
```

The agent automatically:
- Detects environment issues (NumPy, PyTorch compatibility)
- Explains what's wrong and why
- Offers one-click fixes
- Starts agent after fixes

See [`QUICKSTART_DGX.txt`](QUICKSTART_DGX.txt) for detailed guide.

## Quick Start

### Training a YOLO Model

```python
from aegis_vision import YOLOTrainer

# Initialize trainer
trainer = YOLOTrainer(
    model_variant="yolov11l",
    dataset_path="/kaggle/input/my-dataset",
    epochs=100,
    batch_size=16,
)

# Configure Wandb tracking (optional)
trainer.setup_wandb(
    project="my-project",
    entity="my-team",
    api_key="your-api-key"
)

# Train
results = trainer.train()

# Export to multiple formats
trainer.export(formats=["onnx", "coreml", "openvino"])
```

### Converting COCO to YOLO Format

```python
from aegis_vision import COCOConverter

# Convert dataset
converter = COCOConverter(
    annotations_file="annotations.json",
    images_dir="images/",
    output_dir="yolo_dataset/"
)

stats = converter.convert()
print(f"Converted {stats['total_annotations']} annotations")
```

### Command-Line Interface

```bash
# Train a model
aegis-train \
    --model yolov11l \
    --data /path/to/dataset \
    --epochs 100 \
    --batch 16 \
    --wandb-project my-project

# Convert COCO to YOLO
aegis-train convert-coco \
    --annotations annotations.json \
    --images images/ \
    --output yolo_dataset/
```

## Features

### üéØ YOLO Training

- **Multi-version support**: YOLOv8, v9, v10, v11
- **Fine-tuning & from-scratch** training modes
- **Automatic augmentation** configuration
- **Early stopping** with patience
- **Validation metrics**: mAP50, mAP50-95, precision, recall

### üìä Experiment Tracking

- **Wandb integration** for metrics, charts, and artifacts
- **Automatic logging** of hyperparameters, metrics, and model outputs
- **Run resumption** support

### üîÑ Dataset Handling

- **COCO format** support
- **Auto-conversion** to YOLO format
- **Label filtering** and validation
- **Dataset statistics** reporting

### üì¶ Model Export

- **ONNX** - Cross-platform inference
- **CoreML** - iOS/macOS deployment
- **OpenVINO** - Intel hardware optimization
- **TensorRT** - NVIDIA GPU optimization
- **TFLite** - Mobile/edge deployment

### ‚òÅÔ∏è Cloud Environment Support

- **Kaggle** - Kernel execution and dataset management
- **Google Colab** - Ready-to-use notebooks
- **Environment detection** - Auto-configuration for different platforms

## Configuration

### Training Configuration

```python
config = {
    # Model settings
    "model_variant": "yolov11l",
    "training_mode": "fine_tune",  # or "from_scratch"
    
    # Training hyperparameters
    "epochs": 100,
    "batch_size": 16,
    "img_size": 640,
    "learning_rate": 0.01,
    "momentum": 0.937,
    "weight_decay": 0.0005,
    
    # Augmentation
    "augmentation": {
        "hsv_h": 0.015,
        "hsv_s": 0.7,
        "hsv_v": 0.4,
        "degrees": 0.0,
        "translate": 0.1,
        "scale": 0.5,
        "shear": 0.0,
        "perspective": 0.0,
        "flipud": 0.0,
        "fliplr": 0.5,
        "mosaic": 1.0,
        "mixup": 0.0,
    },
    
    # Early stopping
    "early_stopping": {
        "enabled": True,
        "patience": 50,
        "min_delta": 0.0001
    },
    
    # Wandb
    "wandb_enabled": True,
    "wandb_project": "my-project",
    "wandb_entity": "my-team",
    
    # Export
    "output_formats": ["onnx", "coreml", "openvino"],
}

trainer = YOLOTrainer(**config)
```

## Examples

### Kaggle Kernel

```python
# In a Kaggle kernel
from aegis_vision import YOLOTrainer

trainer = YOLOTrainer(
    model_variant="yolov11l",
    dataset_path="/kaggle/input/my-dataset",
    epochs=100,
    wandb_api_key="/kaggle/input/secrets/wandb_api_key.txt"
)

results = trainer.train()
trainer.save_to_kaggle_output()
```

### Custom Dataset

```python
from aegis_vision import YOLOTrainer, COCOConverter

# 1. Convert your COCO dataset
converter = COCOConverter(
    annotations_file="my_annotations.json",
    images_dir="my_images/",
    output_dir="yolo_dataset/",
    labels_filter=["person", "car", "dog"]  # Optional filtering
)
converter.convert()

# 2. Train
trainer = YOLOTrainer(
    model_variant="yolov11m",
    dataset_path="yolo_dataset/",
    epochs=50,
)
results = trainer.train()
```

## API Reference

### YOLOTrainer

Main class for training YOLO models.

**Methods**:
- `train()` - Start training
- `setup_wandb()` - Configure Wandb tracking
- `export()` - Export trained model
- `validate()` - Run validation
- `get_metrics()` - Retrieve training metrics

### COCOConverter

Convert COCO format datasets to YOLO format.

**Methods**:
- `convert()` - Perform conversion
- `validate()` - Check dataset integrity
- `get_statistics()` - Dataset statistics

## Development

```bash
# Clone repository
git clone https://github.com/your-org/aegis-vision.git
cd aegis-vision

# Install in development mode
pip install -e ".[dev]"

# Run tests
pytest

# Format code
black src/

# Lint
ruff src/
```

## Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Roadmap

- [ ] Support for additional YOLO architectures
- [ ] Integration with Hugging Face Hub
- [ ] Distributed training support
- [ ] Auto-hyperparameter tuning
- [ ] Model quantization utilities
- [ ] Segmentation and pose estimation models
- [ ] Real-time inference utilities

## Citation

```bibtex
@software{aegis_vision,
  title = {Aegis Vision: Cloud-native Computer Vision Training Toolkit},
  author = {Aegis AI Team},
  year = {2025},
  url = {https://github.com/your-org/aegis-vision}
}
```

## Support

- üìß Email: support@aegis-ai.com
- üí¨ Discord: [Join our community](https://discord.gg/aegis-ai)
- üìö Documentation: [https://aegis-vision.readthedocs.io](https://aegis-vision.readthedocs.io)
- üêõ Issues: [GitHub Issues](https://github.com/your-org/aegis-vision/issues)


