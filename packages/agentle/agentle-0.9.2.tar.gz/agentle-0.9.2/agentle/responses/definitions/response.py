# Auto-generated from responses_api.py
# Model: Response

# generated by datamodel-codegen:
#   filename:  filtered_openapi.yaml
#   timestamp: 2025-10-18T15:02:20+00:00


from typing import List, Optional, Union

from pydantic import Field


# Model dependencies
from .conversation2 import Conversation2
from .incomplete_details import IncompleteDetails
from .input_item import InputItem
from .model_response_properties import ModelResponseProperties
from .object import Object
from .output_item import OutputItem
from .response_error import ResponseError
from .response_properties import ResponseProperties
from .response_usage import ResponseUsage
from .status10 import Status10


class Response[TextFormatT = None](ModelResponseProperties, ResponseProperties):
    id: str = Field(..., description="Unique identifier for this Response.\n")
    object: Object = Field(
        ...,
        description="The object type of this resource - always set to `response`.\n",
    )
    status: Optional[Status10] = Field(
        None,
        description="The status of the response generation. One of `completed`, `failed`,\n`in_progress`, `cancelled`, `queued`, or `incomplete`.\n",
    )
    created_at: float = Field(
        ...,
        description="Unix timestamp (in seconds) of when this Response was created.\n",
    )
    error: ResponseError
    incomplete_details: Optional[IncompleteDetails]
    output: List[OutputItem[TextFormatT]] = Field(
        ...,
        description="An array of content items generated by the model.\n\n- The length and order of items in the `output` array is dependent\n  on the model's response.\n- Rather than accessing the first item in the `output` array and\n  assuming it's an `assistant` message with the content generated by\n  the model, you might consider using the `output_text` property where\n  supported in SDKs.\n",
    )
    instructions: Optional[Union[str, List[InputItem[TextFormatT]]]]
    output_text: Optional[str] = None
    usage: Optional[ResponseUsage] = None
    parallel_tool_calls: bool = Field(
        ..., description="Whether to allow the model to run tool calls in parallel.\n"
    )
    conversation: Optional[Conversation2] = None

    def output_parsed(self) -> Optional[TextFormatT]:
        for output in self.output:
            if output.type == "message":
                for content in output.content:
                    if content.type == "output_text" and content.parsed:
                        return content.parsed

        return None
