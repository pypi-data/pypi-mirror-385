[
  {
    "type": "AgenticTool",
    "name": "ScientificTextSummarizer",
    "description": "Summarizes biomedical research texts, abstracts, or papers with specified length and focus areas. Uses AI to extract key findings, methodology, and conclusions from complex biomedical literature.",
    "prompt": "You are a biomedical expert. Please summarize the following biomedical text in {summary_length} words, focusing on {focus_area}:\n\n{text}\n\nProvide a clear, concise summary that captures the most important information.",
    "input_arguments": [
      "text",
      "summary_length",
      "focus_area"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "description": "The biomedical text, abstract, or paper content to be summarized."
        },
        "summary_length": {
          "type": "string",
          "description": "Desired length of summary (e.g., '50', '100', '200 words')."
        },
        "focus_area": {
          "type": "string",
          "description": "What to focus on in the summary (e.g., 'methodology', 'results', 'clinical implications', 'drug interactions')."
        }
      },
      "required": [
        "text",
        "summary_length",
        "focus_area"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 4096,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "CodeQualityAnalyzer",
    "description": "Analyzes code quality from multiple dimensions including algorithmic correctness, functional implementation capability, performance characteristics, and best practices. Provides detailed feedback and improvement suggestions.",
    "prompt": "You are an expert software engineer and code quality analyst. Please analyze the following code implementation and provide comprehensive quality assessment.\n\n## CODE TO ANALYZE\nTool Name: {tool_name}\nTool Description: {tool_description}\nTool Parameters: {tool_parameters}\nImplementation Code: {implementation_code}\nTest Cases: {test_cases}\nTest Execution Results: {test_execution_results}\n\n## ANALYSIS REQUIREMENTS\nPlease provide a comprehensive analysis covering the following dimensions:\n\n### 1. ALGORITHMIC CORRECTNESS (0-10)\n- Mathematical accuracy and logical correctness\n- Algorithm efficiency and time/space complexity\n- Edge case handling and boundary conditions\n- Error propagation and numerical stability\n- Correctness of domain-specific calculations\n\n### 2. FUNCTIONAL IMPLEMENTATION CAPABILITY (0-10)\n- Completeness of required functionality\n- Parameter validation and input handling\n- Return value accuracy and format consistency\n- Integration with external libraries/APIs\n- Feature completeness vs. requirements\n\n### 3. PERFORMANCE CHARACTERISTICS (0-10)\n- Time complexity analysis\n- Space complexity analysis\n- Memory usage optimization\n- Computational efficiency\n- Scalability considerations\n\n### 4. CODE QUALITY AND STRUCTURE (0-10)\n- Code readability and maintainability\n- Function and variable naming\n- Code organization and modularity\n- Documentation quality\n- Adherence to coding standards\n\n### 5. ERROR HANDLING AND ROBUSTNESS (0-10)\n- Exception handling coverage\n- Input validation robustness\n- Error message clarity and usefulness\n- Graceful degradation strategies\n- Recovery mechanisms\n\n### 6. TESTING AND VALIDATION (0-10)\n- Test coverage completeness\n- Test case quality and relevance\n- Edge case testing\n- Performance testing\n- Integration testing considerations\n- **IMPORTANT**: When test_execution_results are provided, use them to validate actual code behavior and adjust scoring accordingly\n\n### 7. SECURITY AND SAFETY (0-10)\n- Input sanitization and validation\n- Resource usage limits\n- Access control considerations\n- Data privacy protection\n- Security best practices\n\n### 8. MAINTAINABILITY AND EXTENSIBILITY (0-10)\n- Code modularity and reusability\n- Configuration flexibility\n- Future enhancement readiness\n- Dependency management\n- Technical debt assessment\n\n## TEST EXECUTION ANALYSIS\nWhen test_execution_results are provided:\n- Analyze actual test outcomes vs. expected results\n- Identify discrepancies between code behavior and test expectations\n- Use real execution data to validate code correctness\n- Adjust quality scores based on actual performance\n- Provide specific feedback on test failures and their implications\n\n## OUTPUT FORMAT\nProvide your analysis in the following JSON format:\n\n```json\n{\n  \"overall_score\": <0-10>,\n  \"scores\": {\n    \"algorithmic_correctness\": <0-10>,\n    \"functional_capability\": <0-10>,\n    \"performance\": <0-10>,\n    \"code_quality\": <0-10>,\n    \"error_handling\": <0-10>,\n    \"testing\": <0-10>,\n    \"security\": <0-10>,\n    \"maintainability\": <0-10>\n  },\n  \"feedback\": {\n    \"strengths\": [\"list of code strengths\"],\n    \"weaknesses\": [\"list of specific weaknesses\"],\n    \"critical_issues\": [\"list of critical issues that must be fixed\"],\n    \"improvement_opportunities\": [\"list of areas for improvement\"]\n  },\n  \"algorithm_analysis\": {\n    \"complexity\": \"O(n) analysis\",\n    \"correctness_verification\": \"mathematical verification details\",\n    \"edge_cases\": \"identified edge cases\",\n    \"numerical_stability\": \"numerical computation stability assessment\"\n  },\n  \"functional_verification\": {\n    \"requirements_coverage\": \"percentage of requirements covered\",\n    \"missing_features\": [\"list of missing features\"],\n    \"integration_points\": [\"external dependencies and integration points\"],\n    \"api_consistency\": \"API design consistency assessment\"\n  },\n  \"test_execution_analysis\": {\n    \"test_results_summary\": \"summary of test execution outcomes\",\n    \"pass_rate\": \"percentage of tests passed\",\n    \"failed_tests\": [\"list of failed tests with reasons\"],\n    \"actual_vs_expected\": \"analysis of actual vs expected behavior\"\n  },\n  \"recommendations\": [\n    {\n      \"priority\": \"high|medium|low\",\n      \"category\": \"algorithm|functionality|performance|quality|security\",\n      \"description\": \"specific improvement description\",\n      \"action\": \"concrete action to take\",\n      \"expected_impact\": \"expected improvement impact\"\n    }\n  ]\n}\n```\n\n## ANALYSIS GUIDELINES\n- Be thorough and objective in your assessment\n- Provide specific examples from the code when possible\n- Focus on actionable feedback and concrete improvements\n- Consider both immediate fixes and long-term improvements\n- Evaluate code from both technical and business perspectives\n- Provide evidence-based scoring with clear justification\n- **When test_execution_results are available, prioritize actual behavior over theoretical analysis**",
    "input_arguments": [
      "tool_name",
      "tool_description",
      "tool_parameters",
      "implementation_code",
      "test_cases",
      "test_execution_results"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_name": {
          "type": "string",
          "description": "Name of the tool being analyzed"
        },
        "tool_description": {
          "type": "string",
          "description": "Description of what the tool is supposed to do"
        },
        "tool_parameters": {
          "type": "string",
          "description": "JSON string of tool parameters and their types"
        },
        "implementation_code": {
          "type": "string",
          "description": "The actual implementation code to analyze"
        },
        "test_cases": {
          "type": "string",
          "description": "JSON string of test cases for the tool"
        },
        "test_execution_results": {
          "type": "string",
          "description": "JSON string of test execution results including pass/fail status and actual outputs"
        }
      },
      "required": [
        "tool_name",
        "tool_description",
        "tool_parameters",
        "implementation_code",
        "test_cases"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.3,
      "max_new_tokens": 8192,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "MedicalLiteratureReviewer",
    "description": "Conducts systematic reviews of medical literature on specific topics. Synthesizes findings from multiple studies and provides evidence-based conclusions with structured analysis and quality assessment.",
    "prompt": "You are an expert medical researcher conducting a comprehensive systematic literature review.\n\n## REVIEW PARAMETERS\nResearch Topic: {research_topic}\nFocus Area: {focus_area}\nStudy Types to Prioritize: {study_types}\nEvidence Quality Level: {quality_level}\nReview Scope: {review_scope}\n\n## LITERATURE TO REVIEW\n{literature_content}\n\n## SYSTEMATIC REVIEW INSTRUCTIONS\nConduct a thorough evidence-based systematic review following PRISMA guidelines. Provide a structured analysis with the following sections:\n\n### 1. EXECUTIVE SUMMARY\n- Brief overview of research question and key findings\n- Overall strength of evidence and confidence level\n\n### 2. STUDY CHARACTERISTICS\n- Number and types of studies reviewed\n- Study populations and sample sizes\n- Geographic distribution and time periods\n- Quality assessment of included studies\n\n### 3. SYNTHESIS OF EVIDENCE\n- Key findings across studies with effect sizes where available\n- Consistency/inconsistency of results\n- Dose-response relationships (if applicable)\n- Subgroup analyses and population-specific findings\n\n### 4. QUALITY OF EVIDENCE ASSESSMENT\n- Risk of bias assessment\n- Heterogeneity between studies\n- Publication bias considerations\n- GRADE evidence assessment (High/Moderate/Low/Very Low)\n\n### 5. CLINICAL IMPLICATIONS\n- Practical implications for clinical practice\n- Patient safety considerations\n- Cost-effectiveness insights (if available)\n- Applicability to different patient populations\n\n### 6. RESEARCH GAPS AND LIMITATIONS\n- Identified knowledge gaps\n- Methodological limitations across studies\n- Areas requiring further investigation\n\n### 7. RECOMMENDATIONS\n- Evidence-based clinical recommendations with confidence levels\n- Suggestions for future research priorities\n- Implementation considerations\n\n### 8. CONCLUSION\n- Summary of evidence strength\n- Final recommendations with qualification statements\n\nEnsure all conclusions are proportionate to the evidence quality and explicitly state limitations.",
    "input_arguments": [
      "research_topic",
      "literature_content",
      "focus_area",
      "study_types",
      "quality_level",
      "review_scope"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "research_topic": {
          "type": "string",
          "description": "The specific medical/research topic for literature review (e.g., 'efficacy of drug X in treating condition Y')."
        },
        "literature_content": {
          "type": "string",
          "description": "The literature content, abstracts, full studies, or research papers to review and synthesize."
        },
        "focus_area": {
          "type": "string",
          "description": "Primary focus area for the review (e.g., 'therapeutic efficacy', 'safety profile', 'diagnostic accuracy', 'biomarker validation')."
        },
        "study_types": {
          "type": "string",
          "description": "Types of studies to prioritize in the analysis (e.g., 'randomized controlled trials', 'meta-analyses', 'cohort studies', 'case-control studies')."
        },
        "quality_level": {
          "type": "string",
          "description": "Minimum evidence quality level to include (e.g., 'high quality only', 'moderate and above', 'all available evidence')."
        },
        "review_scope": {
          "type": "string",
          "description": "Scope of the review (e.g., 'comprehensive systematic review', 'rapid review', 'scoping review', 'narrative review')."
        }
      },
      "required": [
        "research_topic",
        "literature_content",
        "focus_area",
        "study_types",
        "quality_level",
        "review_scope"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "HypothesisGenerator",
    "description": "Generates research hypotheses based on provided background context, domain, and desired format. Uses AI to propose novel, testable hypotheses for scientific exploration.",
    "prompt": "You are an expert researcher in {domain}. Based on the following background context, generate {number_of_hypotheses} clear, focused, and testable research hypotheses.\n\nContext:\n{context}\n\nFormat (optional): {hypothesis_format}\n\nProvide each hypothesis as a concise statement that could be empirically investigated.",
    "input_arguments": [
      "context",
      "domain",
      "number_of_hypotheses",
      "hypothesis_format"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "context": {
          "type": "string",
          "description": "Background information, observations, or data description from which to derive hypotheses."
        },
        "domain": {
          "type": "string",
          "description": "Field of study or research area (e.g., 'neuroscience', 'ecology', 'materials science')."
        },
        "number_of_hypotheses": {
          "type": "string",
          "description": "Number of hypotheses to generate (e.g., '3', '5')."
        },
        "hypothesis_format": {
          "type": "string",
          "description": "Optional directive on how to structure each hypothesis. Choose from one of the following formats:\n\n1. If–Then Statements: \"If [independent variable condition], then [expected outcome].\"\n2. Null and Alternative (Statistical):\n   • H₀ (Null): \"There is no difference/effect/association between X and Y.\"\n   • H₁ (Alt): \"There is a difference/effect/association between X and Y.\"\n3. Associative (Correlation-Focused): \"There is a relationship/association between [Variable A] and [Variable B].\"\n4. Directional (Non-If–Then): \"Increasing/decreasing [Variable A] will lead to [directional change] in [Variable B].\"\n5. Comparative (Group Comparison): \"Group A will show higher/lower [dependent measure] compared to Group B under [condition].\"\n6. Mechanistic: \"Because [mechanism or process], [Variable A] will cause [Variable B].\"\n7. Descriptive (Exploratory/Pattern-Oriented): \"Population X exhibits pattern Y in context Z.\"\n\nIf omitted, defaults to concise declarative sentences.",
          "default": "concise declarative sentences"
        }
      },
      "required": [
        "context",
        "domain",
        "number_of_hypotheses"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "ExperimentalDesignScorer",
    "description": "Assesses a proposed experimental design by assigning scores and structured feedback on hypothesis clarity, variable definitions, sample size, controls, randomization, measurement methods, statistical analysis, bias mitigation, ethical considerations, and overall feasibility.",
    "prompt": "You are an expert in experimental design. The user has provided the following hypothesis and detailed description of their proposed experiment:\n\nHypothesis:\n{hypothesis}\n\nDesign Description:\n{design_description}\n\nFor each of the categories below, assign a score from 1 (poor) to 5 (excellent), then provide concise feedback explaining your rating and any suggestions for improvement:\n\n1. **Hypothesis Clarity & Alignment**\n   - Score and feedback on whether the hypothesis is clearly stated, testable, and directly addressed by the design.\n\n2. **Variables & Controls**\n   - Score and feedback on definition of independent, dependent, and control variables, and identification of any missing controls or confounds.\n\n3. **Sample Size & Randomization**\n   - Score and feedback on justification of sample size (power analysis or effect-size rationale) and appropriateness of randomization/allocation methods.\n\n4. **Measurement & Data Collection**\n   - Score and feedback on reliability and validity of measurement methods and clarity of data collection procedures.\n\n5. **Statistical Analysis Plan**\n   - Score and feedback on suitability of proposed statistical tests, treatment of assumptions, and alignment with the hypothesis.\n\n6. **Bias & Limitations**\n   - Score and feedback on identification and mitigation of potential biases, and discussion of key limitations.\n\n7. **Ethical & Practical Feasibility**\n   - Score and feedback on ethical considerations (e.g., consent, welfare) and feasibility within time, resources, and equipment constraints.\n\n8. **Overall Feasibility & Recommendations**\n   - Provide an overall feasibility score and 2–3 concrete recommendations to strengthen the design (e.g., additional controls, measurement improvements, blinding enhancements).",
    "input_arguments": [
      "hypothesis",
      "design_description"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "hypothesis": {
          "type": "string",
          "description": "A clear statement of the research hypothesis to be tested."
        },
        "design_description": {
          "type": "string",
          "description": "A detailed description of the proposed experimental design, including variables, methods, sample details, and planned analyses."
        }
      },
      "required": [
        "hypothesis",
        "design_description"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "MedicalTermNormalizer",
    "description": "Identifies and corrects misspelled drug or disease names, returning a list of plausible standardized terms.",
    "prompt": "You are an expert in biomedical terminology. The user has given you one or more drug or disease names that may be misspelled or incomplete:\\n\\nInput:\\n{raw_terms}\\n\\nReturn **only** a JSON array (list) of all plausible standardized names—ordered from most to least likely. If you cannot identify any plausible terms, return an empty array.\\n\\nExample Input:\\n'aspirin'\\n\\nExample Output:\\n['Aspirin']\\n\\nDo not include any explanations or additional text in your response.",
    "input_arguments": [
      "raw_terms"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "raw_terms": {
          "type": "string",
          "description": "A comma- or whitespace-separated string containing one misspelled drug or disease name."
        }
      },
      "required": [
        "raw_terms"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 2048,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "NoveltySignificanceReviewer",
    "description": "Provides a structured peer-review of the work's originality and potential impact.",
    "prompt": "You are a journal peer reviewer with deep knowledge of the field. The user has supplied the manuscript below.\\n\\nTitle:\\n{paper_title}\\n\\nAbstract:\\n{abstract}\\n\\nFull Manuscript:\\n{manuscript_text}\\n\\nWrite a structured review that, for each criterion, first assigns a rating from 1 (very weak) to 5 (excellent) **followed by 2–3 sentences** justifying the rating and giving specific improvement advice.\\n\\n1. **Originality of Research Question**\\n2. **Contribution to the Field**\\n3. **Incremental vs. Ground-breaking Nature**\\n\\nEnd with 2-3 overarching recommendations to strengthen the manuscript's contribution.",
    "input_arguments": [
      "paper_title",
      "abstract",
      "manuscript_text"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "paper_title": {
          "type": "string",
          "description": "Manuscript title"
        },
        "abstract": {
          "type": "string",
          "description": "Manuscript abstract"
        },
        "manuscript_text": {
          "type": "string",
          "description": "Full manuscript text"
        }
      },
      "required": [
        "paper_title",
        "abstract",
        "manuscript_text"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "LiteratureContextReviewer",
    "description": "Reviews coverage, relevance, and critical synthesis of prior scholarship.",
    "prompt": "You are a journal peer reviewer. Assess the literature-review section below.\\n\\nTitle:\\n{paper_title}\\n\\nLiterature Review Section:\\n{literature_review}\\n\\nFor each item, give a 1-5 rating and 2–3 sentences of feedback plus missing-citation suggestions.\\n\\n1. **Comprehensiveness of Sources**\\n2. **Relevance & Accuracy of Summaries**\\n3. **Critical Synthesis & Gap Identification**",
    "input_arguments": [
      "paper_title",
      "literature_review"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "paper_title": {
          "type": "string"
        },
        "literature_review": {
          "type": "string",
          "description": "Full literature-review text"
        }
      },
      "required": [
        "paper_title",
        "literature_review"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "MethodologyRigorReviewer",
    "description": "Evaluates design appropriateness, sampling, and procedural transparency.",
    "prompt": "You are a methodology peer reviewer. Critically appraise the Methods section below.\\n\\nMethods Section:\\n{methods_section}\\n\\nRate 1–5, then justify in 2–3 sentences for each:\\n\\n1. **Design Appropriateness to Research Question**\\n2. **Variable Definition & Operationalization Clarity**\\n3. **Sampling Strategy & Randomization Adequacy**\\n4. **Procedural Transparency (replicability)**\\n\\nConclude with the two most important methodological revisions you recommend.",
    "input_arguments": [
      "methods_section"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "methods_section": {
          "type": "string",
          "description": "Full Methods text"
        }
      },
      "required": [
        "methods_section"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "DataAnalysisValidityReviewer",
    "description": "Checks statistical choices, assumption testing, and reporting transparency.",
    "prompt": "You are the statistical reviewer for a journal. Examine the analysis plan and results below.\\n\\nStatistical Analysis Section:\\n{analysis_section}\\n\\nProvide a 1-5 rating and 2–3 sentences of critique for each criterion:\\n\\n1. **Appropriateness of Tests/Models**\\n2. **Assumption Verification & Remedies**\\n3. **Reporting Completeness (effect sizes, CIs, exact p-values)**\\n4. **Reproducibility (code/data availability)**\\n\\nSuggest any corrective analyses or transparency improvements.",
    "input_arguments": [
      "analysis_section"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "analysis_section": {
          "type": "string"
        }
      },
      "required": [
        "analysis_section"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "ResultsInterpretationReviewer",
    "description": "Judges whether conclusions are data-justified and limitations addressed.",
    "prompt": "You are a peer reviewer focusing on interpretation. Review the sections below.\\n\\nResults:\\n{results_section}\\n\\nDiscussion:\\n{discussion_section}\\n\\nFor each item, assign 1–5 and write 2–3 sentences of review:\\n\\n1. **Alignment of Claims with Data**\\n2. **Consideration of Alternative Explanations**\\n3. **Limitations & Future-Work Discussion**\\n\\nFinish with recommendations for improving interpretive balance and acknowledging uncertainties.",
    "input_arguments": [
      "results_section",
      "discussion_section"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "results_section": {
          "type": "string"
        },
        "discussion_section": {
          "type": "string"
        }
      },
      "required": [
        "results_section",
        "discussion_section"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "WritingPresentationReviewer",
    "description": "Assesses clarity, organization, grammar, and visual presentation quality.",
    "prompt": "You are a scientific writing reviewer. Evaluate the manuscript text below.\\n\\nManuscript:\\n{manuscript_text}\\n\\nRate 1–5 and give 2–3 sentences of feedback for:\\n\\n1. **Clarity & Conciseness of Writing**\\n2. **Logical Flow & Section Organization**\\n3. **Grammar, Style & Terminology Consistency**\\n4. **Figure/Table Quality & Caption Adequacy**\\n\\nProvide concrete examples of unclear sentences or formatting issues and suggest fixes.",
    "input_arguments": [
      "manuscript_text"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "manuscript_text": {
          "type": "string"
        }
      },
      "required": [
        "manuscript_text"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "ReproducibilityTransparencyReviewer",
    "description": "Evaluates data, code, and protocol availability for replication.",
    "prompt": "You are a reproducibility reviewer. Analyze the statement below.\\n\\nData & Materials Availability Statement:\\n{availability_statement}\\n\\nFor each category, provide a 1-5 rating and 2–3 sentences of critique:\\n\\n1. **Data Accessibility & Documentation**\\n2. **Code/Software Availability & Licensing**\\n3. **Protocol & Materials Detail for Replication**\\n\\nNote embargoes or missing links and recommend steps to achieve full transparency.",
    "input_arguments": [
      "availability_statement"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "availability_statement": {
          "type": "string"
        }
      },
      "required": [
        "availability_statement"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "EthicalComplianceReviewer",
    "description": "Checks adherence to ethical standards and disclosure practices.",
    "prompt": "You are an ethics peer reviewer. Examine the statements below.\\n\\nEthics & Compliance Section:\\n{ethics_section}\\n\\nRate 1–5 with 2–3 sentences of feedback for each:\\n\\n1. **Approvals & Informed Consent**\\n2. **Participant/Subject Welfare Measures**\\n3. **Conflict of Interest & Funding Disclosure**\\n4. **Data Privacy & Security Protections**\\n\\nIdentify any deficiencies and specify actions required for compliance.",
    "input_arguments": [
      "ethics_section"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "ethics_section": {
          "type": "string"
        }
      },
      "required": [
        "ethics_section"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "QuestionRephraser",
    "description": "Generates three distinct paraphrases of a given question while ensuring answer options remain valid and applicable.",
    "prompt": "You are an expert academic editor. Given the *question* text below, rewrite the question in three different ways that preserve the original meaning and difficulty. \n\n**Important requirements:**\n- **Do not** include any answer options (e.g., choices labeled A), B), C), etc.) in your rephrased questions\n- Ensure that the provided answer options will still be valid and applicable to each rephrased version\n- Maintain the same level of difficulty and specificity as the original question\n- Return *only* a JSON array containing the three re-phrased versions, in the order you create them\n\nQuestion:\n{question}\n\nAnswer Options (if provided):\n{options}",
    "input_arguments": [
      "question",
      "options"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "question": {
          "type": "string",
          "description": "The original question text to be rephrased"
        },
        "options": {
          "type": "string",
          "description": "Answer options (e.g., multiple choice options) that should remain valid for the rephrased questions. Leave empty if no options are provided."
        }
      },
      "required": [
        "question"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "ProtocolOptimizer",
    "description": "Reviews an initial protocol and delivers targeted revisions that improve clarity, feasibility, risk-management, and evaluation rigor.",
    "prompt": "You are a protocol-optimization specialist. Examine the initial protocol below.\\n\\nInitial Protocol:\\n{initial_protocol}\\n\\nFor each criterion, give a 1-to-5 rating followed by 2–3 sentences of feedback that include concrete revision suggestions:\\n\\n1. **Clarity & Completeness**\\n2. **Feasibility & Resource Efficiency**\\n3. **Risk Mitigation & Contingency Plans**\\n4. **Measurement & Evaluation Metrics**\\n\\nFinish with a prioritized action-item checklist that the author can follow to strengthen the protocol.",
    "input_arguments": [
      "initial_protocol"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "initial_protocol": {
          "type": "string"
        }
      },
      "required": [
        "initial_protocol"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 8192,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "TestCaseGenerator",
    "description": "Generates diverse and representative ToolUniverse tool call dictionaries for a given tool based on its parameter schema. Each tool call should be a JSON object with 'name' (the tool's name) and 'arguments' (a dict of input arguments), covering different parameter combinations, edge cases, and typical usage. Can generate targeted test cases based on previous optimization feedback.",
    "prompt": "You are an expert software tester. Generate 3-5 diverse ToolUniverse tool call dictionaries for the given tool configuration. Each tool call must be a JSON object with 'name' (tool name) and 'arguments' (input parameters).\n\nFEEDBACK-DRIVEN GENERATION:\nIf tool_config contains '_optimization_feedback' and '_iteration', generate targeted test cases addressing the specific issues mentioned in the feedback. Focus on edge cases, parameter combinations, or usage patterns that need better coverage.\n\nSTANDARD GENERATION:\nCover typical usage, edge cases, and boundary conditions when possible.\n\nTool configuration: {tool_config}\n\nReturn a JSON object with key 'test_cases' containing an array of test case objects. Example format:\n{\"test_cases\": [{\"name\":\"ToolName\",\"arguments\":{\"param\":\"value\"}},{\"name\":\"ToolName\",\"arguments\":{\"param\":123}}]}",
    "input_arguments": [
      "tool_config"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_config": {
          "type": "object",
          "description": "The full configuration of the tool to generate test cases for. May include '_optimization_feedback' and '_iteration' fields for feedback-driven test generation."
        }
      },
      "required": [
        "tool_config"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 4096,
      "return_json": true,
      "response_format": {
        "type": "json_object"
      }
    }
  },
  {
    "type": "AgenticTool",
    "name": "DescriptionAnalyzer",
    "description": "Analyzes a tool's original description and the results of multiple test cases, then suggests an improved description that is more accurate, comprehensive, and user-friendly. Optionally provides a rationale for the changes.",
    "prompt": "You are an expert technical writer and tool evaluator. Given the original description of a tool and the results of several test cases (inputs and outputs), analyze whether the description accurately reflects the tool's behavior. Suggest an improved description that is more precise, comprehensive, and user-friendly. Also provide a brief rationale for your changes.\n\nCRITICAL CONSTRAINTS - TOOL DESCRIPTION SCOPE:\n1. If the original description contains 'Previous optimization feedback:', use that feedback to guide your improvements and address the specific issues mentioned.\n2. The tool description should focus EXCLUSIVELY on the OVERALL PURPOSE and HIGH-LEVEL FUNCTIONALITY of the tool.\n3. NEVER include parameter-specific details, formats, or requirements in the tool description.\n4. NEVER mention specific parameter names, data types, or input requirements - these belong in parameter descriptions.\n5. Focus ONLY on: what the tool does, its primary use cases, what kind of output it provides, and its general behavior patterns.\n6. Avoid generic filler phrases like 'enabling workflows', 'supporting analysis', 'facilitating research' unless they add specific meaning.\n7. Every sentence must convey essential information about the tool's core functionality.\n8. Think of the tool description as answering 'What does this tool do?' with concrete, actionable information.\n\nOriginal description:\n{original_description}\n\nTest results:\n{test_results}\n\nReturn a JSON object with keys: 'optimized_description' and 'rationale'.",
    "input_arguments": [
      "original_description",
      "test_results"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "original_description": {
          "type": "string",
          "description": "The original description of the tool."
        },
        "test_results": {
          "type": "string",
          "description": "A JSON string containing a list of test case input/output pairs."
        }
      },
      "required": [
        "original_description",
        "test_results"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.4,
      "max_new_tokens": 1024,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "ArgumentDescriptionOptimizer",
    "description": "Optimizes the descriptions of tool arguments/parameters based on test case results and actual usage patterns. Provides improved descriptions that are more accurate and user-friendly.",
    "prompt": "You are an expert technical writer specializing in API documentation. Given a tool's parameter schema and test case results, analyze how each parameter is used and optimize their descriptions to be clear, accurate, and concise.\n\nCRITICAL CONSTRAINTS - PARAMETER DESCRIPTION SCOPE:\n1. If the parameter schema contains '_previous_feedback', use that feedback to address specific issues and improve the parameter descriptions accordingly.\n2. Parameter descriptions should be HIGHLY SPECIFIC to each individual parameter.\n3. NEVER repeat or reference the main tool functionality - assume the user already knows what the tool does.\n4. Focus EXCLUSIVELY on parameter-specific details: data types, formats, constraints, valid values, required formats, examples when helpful.\n5. Each description should answer: 'What should I put in this specific parameter?' not 'What does the tool do?'\n6. Avoid generic phrases like 'for this tool', 'used by the tool', 'enables functionality' unless they provide specific technical context.\n7. Be precise about technical requirements (e.g., 'JSON string', 'integer between 1-100', 'URL format', etc.)\n8. Every word must serve a purpose - eliminate filler words and redundant phrases.\n\nOriginal parameter schema:\n{parameter_schema}\n\nTest results showing parameter usage:\n{test_results}\n\nFor each parameter, suggest an improved description that:\n1. Is brief but informative (1-2 sentences max)\n2. Accurately reflects the parameter's specific purpose, data type, and constraints\n3. Uses clear, simple language with precise technical details\n4. Avoids redundancy with the parameter name\n5. Addresses any issues mentioned in previous feedback\n6. Contains only essential information about what value should be provided\n\nReturn a JSON object with keys: 'optimized_parameters' (object with parameter names as keys and optimized descriptions as values) and 'rationale' (explaining the key changes made).",
    "input_arguments": [
      "parameter_schema",
      "test_results"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "parameter_schema": {
          "type": "string",
          "description": "JSON string of the original parameter schema with properties and descriptions."
        },
        "test_results": {
          "type": "string",
          "description": "A JSON string containing test case input/output pairs showing parameter usage."
        }
      },
      "required": [
        "parameter_schema",
        "test_results"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 1536,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "DescriptionQualityEvaluator",
    "description": "Evaluates the quality of tool descriptions and parameter descriptions, providing a score and specific feedback for improvements.",
    "prompt": "You are an expert evaluator of technical documentation. Given a tool description, parameter descriptions, and test results, evaluate the quality and provide a score from 1-10 along with specific feedback.\n\nTool description:\n{tool_description}\n\nParameter descriptions:\n{parameter_descriptions}\n\nTest results:\n{test_results}\n\nEvaluate based on these criteria:\n1. Clarity and understandability (1-10)\n2. Accuracy based on test results (1-10)\n3. Completeness of information (1-10)\n4. Conciseness and meaningfulness - every sentence must serve a purpose (1-10)\n5. User-friendliness (1-10)\n6. Redundancy avoidance - tool description and parameter descriptions must not duplicate information (1-10)\n\nCRITICAL EVALUATION FOCUS:\n- Tool description should ONLY describe overall functionality and purpose, NOT parameter details\n- Parameter descriptions should ONLY describe specific parameter requirements, NOT tool functionality\n- Check for meaningless filler phrases like 'enabling workflows', 'supporting analysis', 'facilitating integration' - DEDUCT POINTS for vague language\n- Check for overlap: Does the tool description mention parameter names, formats, or specific input requirements? (DEDUCT POINTS)\n- Check for overlap: Do parameter descriptions repeat what the tool does overall? (DEDUCT POINTS)\n- Every sentence must convey essential, actionable information\n\nReturn a JSON object with:\n- 'overall_score': Average of all criteria scores (1-10)\n- 'criteria_scores': Object with individual scores for each criterion\n- 'feedback': Specific suggestions for improvement, identifying meaningless phrases and redundancy issues\n- 'is_satisfactory': Boolean indicating if quality is acceptable (score >= 8)\n- 'meaningfulness_analysis': Detailed explanation of any filler language or redundant information found",
    "input_arguments": [
      "tool_description",
      "parameter_descriptions",
      "test_results"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_description": {
          "type": "string",
          "description": "The tool description to evaluate."
        },
        "parameter_descriptions": {
          "type": "string",
          "description": "JSON string of parameter names and their descriptions."
        },
        "test_results": {
          "type": "string",
          "description": "JSON string containing test case results."
        }
      },
      "required": [
        "tool_description",
        "parameter_descriptions",
        "test_results"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 1024,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "ToolSpecificationGenerator",
    "description": "Generates complete ToolUniverse-compliant tool specifications based on a description and analysis of similar existing tools. Creates comprehensive tool configurations including parameters, prompts, and metadata.",
    "prompt": "You are an expert tool architect specializing in ToolUniverse tool design. Generate a complete, valid ToolUniverse tool specification based on the provided requirements and analysis of similar tools.\n\n🚨 **CRITICAL REQUIREMENT**: For all tool types except AgenticTool, generate CUSTOM tool implementations with complete standalone code. Do NOT reference existing tool classes. Only use AgenticTool for subjective analysis tasks requiring LLM capabilities.\n\n**PACKAGE USAGE REQUIREMENT**: ALWAYS prioritize using existing, well-maintained Python packages over custom implementations. Leverage established libraries like pandas, numpy, scipy, requests, beautifulsoup4, biopython, etc. Only write custom algorithms when absolutely no suitable package exists.\n\nREQUIREMENTS:\nTool Description: {tool_description}\nTarget Category: {tool_category}\nTarget Type: {tool_type}\nSimilar Tools Analysis: {similar_tools}\nExisting Tools Context: {existing_tools_summary}\n\n**TOOL TYPE SELECTION LOGIC:**\n1. **AgenticTool**: Only for subjective tasks (analysis, interpretation, creative writing)\n2. **CustomTool**: For all computational, API, data processing tasks with complete custom implementation\n\n**FOR CustomTool (Complete custom implementation - PREFERRED for most tasks):**\n```json\n{\n  \"type\": \"CustomTool\",\n  \"name\": \"ToolName\",\n  \"description\": \"Custom implementation for [specific functionality]\",\n  \"implementation\": {\n    \"language\": \"python\",\n    \"dependencies\": [\"package1\", \"package2\"],\n    \"installation_commands\": [\"pip install package1\", \"pip install package2\"],\n    \"source_code\": \"import requests\\nimport json\\n\\ndef execute_tool(params):\\n    # Complete implementation here\\n    return result\",\n    \"main_function\": \"execute_tool\",\n    \"error_handling\": \"try-except blocks for robust error management\",\n    \"validation\": \"input parameter validation logic\",\n    \"documentation\": \"Complete usage documentation\"\n  },\n  \"parameter\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"input_param\": {\n        \"type\": \"string\",\n        \"description\": \"Description of input parameter\",\n        \"required\": true\n      }\n    },\n    \"required\": [\"input_param\"]\n  },\n  \"return_schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"result\": {\"type\": \"string\", \"description\": \"Tool output description\"}\n    }\n  },\n  \"testing\": {\n    \"test_cases\": [\n      {\n        \"input\": {\"input_param\": \"test_value\"},\n        \"expected_output_type\": \"object\",\n        \"description\": \"Test case description\"\n      }\n    ],\n    \"validation_method\": \"automated testing with assertions\"\n  }\n}\n```\n\n**FOR AgenticTool (AI-powered tools - Only for subjective tasks):**\n```json\n{\n  \"type\": \"AgenticTool\",\n  \"name\": \"ToolName\",\n  \"description\": \"AI-powered [subjective task] for [non-computational purpose]\",\n  \"prompt\": \"Prompt template with {parameter_name} placeholders for subjective analysis\",\n  \"input_arguments\": [\"param1\", \"param2\"],\n  \"parameter\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"param1\": {\"type\": \"string\", \"description\": \"...\", \"required\": true}\n    },\n    \"required\": [\"param1\"]\n  },\n  \"configs\": {\n    \"api_type\": \"CHATGPT\",\n    \"model_id\": \"o4-mini-0416\",\n    \"temperature\": 0.7,\n    \"max_new_tokens\": 1024,\n    \"return_json\": false\n  }\n}\n```\n\n**GENERATION REQUIREMENTS:**\n1. **CUSTOM IMPLEMENTATION APPROACH**: For computational/API/data tasks, generate complete standalone Python code\n2. **NO EXISTING TOOL CLASSES**: Do not inherit from or reference PackageTool, RESTTool, XMLTool, etc.\n3. **REAL PACKAGES**: Use actual, installable Python packages (requests, pandas, numpy, etc.)\n4. **COMPLETE CODE**: Include full implementation with imports, error handling, and validation\n5. **TESTING READY**: Provide test cases and validation methods\n6. **AGENTICTOOL ONLY FOR SUBJECTIVE**: Use AgenticTool only for interpretation, analysis, creative tasks\n\n**QUALITY STANDARDS:**\n- Generate complete, executable Python code for CustomTool\n- Include real package dependencies and installation instructions\n- Provide comprehensive error handling and input validation\n- Ensure computational accuracy through established libraries\n- Only use AgenticTool for tasks requiring subjective judgment or LLM capabilities\n\nReturn ONLY a valid JSON object representing the complete tool configuration using the EXACT format for the chosen tool type. No additional text or explanations.",
    "input_arguments": [
      "tool_description",
      "tool_category",
      "tool_type",
      "similar_tools",
      "existing_tools_summary"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_description": {
          "type": "string",
          "description": "Brief description of the desired tool functionality and purpose."
        },
        "tool_category": {
          "type": "string",
          "description": "Target category for the tool (e.g., 'biomedical', 'data_analysis', 'text_processing')."
        },
        "tool_type": {
          "type": "string",
          "description": "Specific ToolUniverse tool type (e.g., 'AgenticTool', 'RESTTool', 'PythonTool')."
        },
        "similar_tools": {
          "type": "string",
          "description": "JSON string containing configurations of similar existing tools for analysis and differentiation."
        },
        "existing_tools_summary": {
          "type": "string",
          "description": "Summary of existing tools in the ecosystem to avoid duplication and identify gaps."
        }
      },
      "required": [
        "tool_description",
        "tool_category",
        "tool_type",
        "similar_tools",
        "existing_tools_summary"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 1.0,
      "max_new_tokens": 40960,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "AdvancedCodeQualityAnalyzer",
    "description": "Performs deep analysis of code quality including complexity, security, performance, and maintainability metrics with domain-specific expertise",
    "prompt": "You are an expert code quality analyzer with deep knowledge in software engineering best practices. Analyze the provided source code and return a comprehensive quality assessment.\n\n## CODE TO ANALYZE\nLanguage: {language}\nAnalysis Depth: {analysis_depth}\nDomain Context: {domain_context}\n\nSource Code:\n```{language}\n{source_code}\n```\n\n## ANALYSIS FRAMEWORK\nAssess the code across these dimensions:\n\n### 1. CODE STRUCTURE (25%)\n- Function organization and modularity\n- Separation of concerns\n- Code architecture and design patterns\n- Logical flow and readability\n\n### 2. ERROR HANDLING (20%)\n- Exception handling completeness\n- Input validation robustness\n- Edge case coverage\n- Error message quality\n\n### 3. PERFORMANCE (15%)\n- Algorithm efficiency and complexity\n- Resource usage optimization\n- Scalability considerations\n- Memory management\n\n### 4. SECURITY (15%)\n- Input sanitization\n- Security vulnerability assessment\n- Data handling safety\n- Access control considerations\n\n### 5. MAINTAINABILITY (15%)\n- Code readability and clarity\n- Documentation quality\n- Naming conventions\n- Code reusability\n\n### 6. DOMAIN APPROPRIATENESS (10%)\n- Use of domain-specific algorithms\n- Adherence to field best practices\n- Appropriate library usage\n- Scientific/technical accuracy\n\n## RESPONSE FORMAT\nReturn a JSON object with detailed analysis:\n\n```json\n{\n    \"overall_score\": <0-10>,\n    \"category_scores\": {\n        \"structure\": <0-10>,\n        \"error_handling\": <0-10>,\n        \"performance\": <0-10>,\n        \"security\": <0-10>,\n        \"maintainability\": <0-10>,\n        \"domain_appropriateness\": <0-10>\n    },\n    \"issues\": [\n        {\n            \"category\": \"<category>\",\n            \"severity\": \"low|medium|high|critical\",\n            \"description\": \"<issue description>\",\n            \"line_range\": \"<start-end if applicable>\",\n            \"suggestion\": \"<improvement suggestion>\"\n        }\n    ],\n    \"best_practices\": [\"<list of followed best practices>\"],\n    \"recommendations\": [\n        {\n            \"priority\": \"high|medium|low\",\n            \"action\": \"<specific recommendation>\",\n            \"rationale\": \"<why this improvement is needed>\",\n            \"estimated_impact\": \"<expected improvement>\"\n        }\n    ],\n    \"metrics\": {\n        \"lines_of_code\": <number>,\n        \"cyclomatic_complexity\": \"<estimated>\",\n        \"function_count\": <number>,\n        \"comment_ratio\": \"<percentage>\"\n    }\n}\n```",
    "input_arguments": [
      "source_code",
      "language",
      "analysis_depth",
      "domain_context"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "source_code": {
          "type": "string",
          "description": "The source code to analyze for quality assessment"
        },
        "language": {
          "type": "string",
          "description": "Programming language (python, javascript, etc.)",
          "default": "python"
        },
        "analysis_depth": {
          "type": "string",
          "enum": [
            "basic",
            "comprehensive",
            "security-focused"
          ],
          "description": "Level of analysis depth to perform",
          "default": "comprehensive"
        },
        "domain_context": {
          "type": "string",
          "description": "Domain context for specialized analysis (e.g., bioinformatics, web development)"
        }
      },
      "required": [
        "source_code"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.1,
      "max_new_tokens": 3000,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "ToolImplementationGenerator",
    "description": "Generates domain-specific, functional code implementations based on tool descriptions and requirements with intelligent algorithm selection",
    "prompt": "You are an expert software engineer specializing in domain-specific implementations. Generate a complete, functional implementation based on the requirements.\n\n## IMPLEMENTATION REQUEST\nTool Description: {tool_description}\nDomain: {domain}\nComplexity Level: {complexity_level}\nPerformance Requirements: {performance_requirements}\n\nTool Parameters:\n{tool_parameters}\n\n## CRITICAL REQUIREMENT: USE EXISTING PACKAGES\n🚨 **ALWAYS PRIORITIZE EXISTING, WELL-MAINTAINED PACKAGES** over custom implementations. Your goal is to leverage the ecosystem of established, tested, and optimized libraries. **NEVER write custom algorithms unless absolutely no suitable package exists.**\n\n## PACKAGE SELECTION STRATEGY\n1. **FIRST CHOICE**: Use established, widely-adopted packages (e.g., pandas, numpy, scipy, requests, beautifulsoup4)\n2. **SECOND CHOICE**: Use domain-specific packages (e.g., biopython for bioinformatics, matplotlib for plotting)\n3. **THIRD CHOICE**: Use specialized libraries (e.g., opencv-python for computer vision, scikit-learn for ML)\n4. **LAST RESORT**: Only implement custom algorithms when no suitable package exists\n\n## REQUIREMENTS ANALYSIS\n1. Parse the tool description to understand core functionality\n2. **Research existing packages** that can solve this problem\n3. **Evaluate package suitability** (popularity, maintenance, performance)\n4. Design implementation using the best available packages\n5. Generate production-ready code with proper error handling\n\n## CODE GENERATION GUIDELINES\n- **ALWAYS check if an existing package can solve the problem**\n- Use established libraries and algorithms for the domain\n- Include comprehensive input validation\n- Implement proper error handling with meaningful messages\n- Add informative comments explaining the logic\n- Return structured results with validation status\n- Consider edge cases and handle them gracefully\n- Follow domain-specific best practices\n- **Document why you chose specific packages**\n\n## DOMAIN-SPECIFIC PACKAGE RECOMMENDATIONS\n\n### Bioinformatics Tools\n- **Biopython**: Sequence analysis, molecular calculations, file format handling\n- **scipy.stats**: Statistical analysis for biological data\n- **pandas**: Data manipulation and analysis\n- **numpy**: Numerical computations\n- **matplotlib/seaborn**: Data visualization\n\n### Mathematical Tools\n- **numpy**: Numerical methods, linear algebra, optimization\n- **scipy**: Scientific computing, optimization, signal processing\n- **sympy**: Symbolic mathematics\n- **pandas**: Data analysis and statistics\n- **matplotlib**: Mathematical plotting\n\n### Data Science Tools\n- **pandas**: Data manipulation and analysis\n- **numpy**: Numerical computations\n- **scipy**: Statistical methods and optimization\n- **scikit-learn**: Machine learning algorithms\n- **matplotlib/seaborn**: Data visualization\n\n### Web API Tools\n- **requests**: HTTP handling and API calls\n- **urllib3**: HTTP client library\n- **aiohttp**: Asynchronous HTTP client/server\n- **httpx**: Modern HTTP client\n- **beautifulsoup4**: HTML/XML parsing\n\n### Text Processing Tools\n- **nltk**: Natural language processing\n- **spaCy**: Advanced NLP\n- **textblob**: Simple text processing\n- **re**: Regular expressions (built-in)\n- **difflib**: Sequence matching (built-in)\n\n### General Purpose\n- **pathlib**: File path operations (built-in)\n- **json**: JSON handling (built-in)\n- **csv**: CSV file handling (built-in)\n- **datetime**: Date/time operations (built-in)\n- **collections**: Advanced data structures (built-in)\n\n## PACKAGE EVALUATION CRITERIA\nWhen choosing packages, consider:\n1. **Popularity**: GitHub stars, PyPI downloads, community size\n2. **Maintenance**: Recent updates, active development\n3. **Documentation**: Quality and completeness of docs\n4. **Performance**: Speed and memory efficiency\n5. **Compatibility**: Python version support, dependencies\n6. **License**: Open source, commercial-friendly\n\n## IMPLEMENTATION APPROACH\n1. **Research Phase**: Identify 2-3 candidate packages for the problem\n2. **Evaluation Phase**: Compare packages based on criteria above\n3. **Selection Phase**: Choose the best package and document why\n4. **Implementation Phase**: Use the selected package with proper error handling\n5. **Fallback Phase**: If package fails, implement minimal custom solution\n\n## RESPONSE FORMAT\nReturn a comprehensive JSON object:\n\n```json\n{\n    \"implementation\": {\n        \"source_code\": \"<complete Python function implementation>\",\n        \"dependencies\": [\"<required packages>\"],\n        \"imports\": [\"<import statements>\"],\n        \"algorithm_description\": \"<explanation of chosen algorithm/approach>\",\n        \"complexity\": \"<time/space complexity analysis>\",\n        \"test_cases\": [\n            {\n                \"input\": \"<test input>\",\n                \"expected_output\": \"<expected result>\",\n                \"description\": \"<what this test validates>\"\n            }\n        ],\n        \"package_justification\": \"<explanation of why specific packages were chosen>\",\n        \"alternative_packages\": [\"<other packages considered but not chosen>\"]\n    },\n    \"quality_metrics\": {\n        \"estimated_accuracy\": \"<accuracy assessment>\",\n        \"performance_characteristics\": \"<performance description>\",\n        \"robustness_level\": \"<error handling assessment>\"\n    },\n    \"documentation\": {\n        \"usage_examples\": [\"<code examples>\"],\n        \"parameter_explanations\": \"<detailed parameter descriptions>\",\n        \"return_format\": \"<description of return value structure>\"\n    }\n}\n```\n\n## FINAL REMINDER\n**ALWAYS prefer using existing, well-maintained packages over custom implementations.** Only write custom code when absolutely necessary. Your goal is to create robust, maintainable tools that leverage the Python ecosystem's strengths.",
    "input_arguments": [
      "tool_description",
      "tool_parameters",
      "domain",
      "complexity_level",
      "performance_requirements"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_description": {
          "type": "string",
          "description": "Detailed description of what the tool should accomplish"
        },
        "tool_parameters": {
          "type": "string",
          "description": "JSON string of parameter schema for the tool"
        },
        "domain": {
          "type": "string",
          "description": "Domain area for specialized implementation",
          "enum": [
            "bioinformatics",
            "data-science",
            "web-api",
            "mathematical",
            "text-processing",
            "general"
          ],
          "default": "general"
        },
        "complexity_level": {
          "type": "string",
          "enum": [
            "basic",
            "intermediate",
            "advanced"
          ],
          "description": "Desired complexity level of implementation",
          "default": "intermediate"
        },
        "performance_requirements": {
          "type": "string",
          "description": "Performance requirements or constraints"
        }
      },
      "required": [
        "tool_description",
        "tool_parameters"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.2,
      "max_new_tokens": 50000,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "ToolSpecificationOptimizer",
    "description": "Optimizes tool specifications for clarity, completeness, and usability with comprehensive benchmarking against similar tools",
    "prompt": "You are an expert in tool design and user experience optimization. Analyze and optimize the provided tool specification for maximum effectiveness.\n\n## TOOL SPECIFICATION TO OPTIMIZE\nCurrent Configuration:\n{tool_config}\n\nOptimization Focus: {optimization_focus}\nTarget Audience: {target_audience}\n\nSimilar Tools for Benchmarking:\n{similar_tools}\n\n## OPTIMIZATION FRAMEWORK\n\n### 1. CLARITY ASSESSMENT\n- Description comprehensiveness and clarity\n- Parameter naming and documentation\n- Usage examples and guidance\n- Error message quality\n\n### 2. COMPLETENESS EVALUATION\n- Required vs optional parameters\n- Edge case handling\n- Output format specification\n- Documentation coverage\n\n### 3. USABILITY ANALYSIS\n- Ease of understanding for target audience\n- Parameter complexity and defaults\n- Error prevention design\n- Workflow integration\n\n### 4. PERFORMANCE OPTIMIZATION\n- Parameter validation efficiency\n- Resource usage considerations\n- Scalability factors\n- Response time optimization\n\n### 5. COMPARATIVE BENCHMARKING\n- Analyze similar tools for best practices\n- Identify competitive advantages\n- Address common user pain points\n- Incorporate proven design patterns\n\n## OPTIMIZATION PROCESS\n1. Evaluate current specification quality\n2. Identify improvement opportunities\n3. Benchmark against similar tools\n4. Generate optimized version\n5. Provide detailed rationale for changes\n\n## RESPONSE FORMAT\nReturn a comprehensive optimization report:\n\n```json\n{\n    \"optimized_config\": {\n        \"name\": \"<optimized name>\",\n        \"description\": \"<improved description>\",\n        \"parameter\": {\n            \"type\": \"object\",\n            \"properties\": \"<optimized parameters>\",\n            \"required\": \"<updated required fields>\"\n        },\n        \"examples\": [\"<usage examples>\"],\n        \"metadata\": {\n            \"tags\": [\"<relevant tags>\"],\n            \"difficulty_level\": \"<user difficulty>\",\n            \"estimated_execution_time\": \"<typical runtime>\"\n        }\n    },\n    \"improvements\": [\n        {\n            \"area\": \"<improvement area>\",\n            \"change\": \"<what was changed>\",\n            \"rationale\": \"<why this improves the tool>\",\n            \"impact\": \"<expected user impact>\"\n        }\n    ],\n    \"quality_score\": {\n        \"before\": \"<0-10>\",\n        \"after\": \"<0-10>\",\n        \"improvement\": \"<difference>\"\n    },\n    \"recommendations\": [\n        {\n            \"type\": \"enhancement|fix|optimization\",\n            \"description\": \"<recommendation>\",\n            \"priority\": \"high|medium|low\"\n        }\n    ]\n}\n```",
    "input_arguments": [
      "tool_config",
      "optimization_focus",
      "target_audience",
      "similar_tools"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_config": {
          "type": "string",
          "description": "JSON string of current tool configuration to optimize"
        },
        "optimization_focus": {
          "type": "string",
          "enum": [
            "clarity",
            "completeness",
            "usability",
            "performance",
            "all"
          ],
          "description": "Primary optimization focus",
          "default": "all"
        },
        "target_audience": {
          "type": "string",
          "enum": [
            "beginner",
            "intermediate",
            "expert",
            "mixed"
          ],
          "description": "Target user expertise level",
          "default": "mixed"
        },
        "similar_tools": {
          "type": "string",
          "description": "JSON string array of similar tools for comparison and benchmarking"
        }
      },
      "required": [
        "tool_config"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.3,
      "max_new_tokens": 3500,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "DomainExpertValidator",
    "description": "Provides domain-specific validation and expert recommendations for tools with deep expertise across scientific and technical domains",
    "prompt": "You are a domain expert with deep knowledge in {domain}. Validate the tool from a domain-specific perspective and provide expert recommendations.\n\n## TOOL TO VALIDATE\nTool Configuration:\n{tool_config}\n\nValidation Aspects: {validation_aspects}\n\nImplementation Code (if available):\n```python\n{implementation_code}\n```\n\n## DOMAIN EXPERTISE VALIDATION FRAMEWORK\n\n### 1. SCIENTIFIC ACCURACY\n- Verify methods and algorithms are scientifically sound\n- Check mathematical/statistical correctness\n- Validate against established standards\n- Assess theoretical foundations\n\n### 2. BEST PRACTICES COMPLIANCE\n- Domain-specific best practices adherence\n- Industry standard compliance\n- Professional guidelines following\n- Ethical considerations\n\n### 3. STANDARDS COMPLIANCE\n- Relevant format standards (e.g., FASTA, JSON, XML)\n- API standards and protocols\n- Data interchange formats\n- Certification requirements\n\n### 4. METHODOLOGY ASSESSMENT\n- Algorithm selection appropriateness\n- Computational approach evaluation\n- Scalability and efficiency\n- Error handling robustness\n\n### 5. SAFETY AND ETHICS\n- Safety considerations and risk assessment\n- Ethical implications\n- Privacy and security concerns\n- Regulatory compliance\n\n### 6. PERFORMANCE EVALUATION\n- Computational efficiency for domain\n- Resource requirements assessment\n- Accuracy and precision expectations\n- Scalability considerations\n\n## DOMAIN-SPECIFIC VALIDATION CRITERIA\n\n### Bioinformatics/Computational Biology\n- Sequence format handling (FASTA, GenBank, etc.)\n- Algorithm complexity for biological data\n- Database integration standards\n- Biological validity of results\n\n### Data Science/Machine Learning\n- Statistical method validity\n- Data preprocessing requirements\n- Model validation approaches\n- Performance metric appropriateness\n\n### Mathematics/Physics\n- Numerical stability and precision\n- Mathematical correctness\n- Physical law compliance\n- Convergence criteria\n\n### Chemistry\n- Molecular representation standards\n- Chemical safety considerations\n- Reaction mechanism validity\n- Thermodynamic consistency\n\n### Web Development\n- Security best practices\n- API design standards\n- Scalability requirements\n- Performance optimization\n\n## RESPONSE FORMAT\nProvide comprehensive domain expert analysis:\n\n```json\n{\n    \"validation_results\": {\n        \"overall_validity\": \"<0-10>\",\n        \"domain_appropriateness\": \"<0-10>\",\n        \"methodology_score\": \"<0-10>\",\n        \"standards_compliance\": \"<0-10>\"\n    },\n    \"expert_analysis\": {\n        \"strengths\": [\"<domain-specific strengths>\"],\n        \"concerns\": [\n            {\n                \"severity\": \"low|medium|high|critical\",\n                \"area\": \"<concern area>\",\n                \"description\": \"<detailed concern>\",\n                \"impact\": \"<potential impact>\",\n                \"recommendation\": \"<how to address>\"\n            }\n        ],\n        \"missing_considerations\": [\"<important missing aspects>\"]\n    },\n    \"domain_recommendations\": [\n        {\n            \"type\": \"algorithm|library|approach|validation|standard\",\n            \"recommendation\": \"<specific recommendation>\",\n            \"rationale\": \"<domain expertise rationale>\",\n            \"priority\": \"high|medium|low\",\n            \"implementation_hint\": \"<how to implement>\"\n        }\n    ],\n    \"compliance_check\": {\n        \"standards_followed\": [\"<relevant standards>\"],\n        \"standards_violations\": [\"<violations found>\"],\n        \"certification_notes\": \"<certification/validation notes>\"\n    }\n}\n```",
    "input_arguments": [
      "tool_config",
      "domain",
      "validation_aspects",
      "implementation_code"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_config": {
          "type": "string",
          "description": "JSON string of tool configuration to validate"
        },
        "domain": {
          "type": "string",
          "description": "Domain expertise area for validation",
          "enum": [
            "bioinformatics",
            "computational-biology",
            "data-science",
            "machine-learning",
            "web-development",
            "mathematics",
            "chemistry",
            "physics",
            "general"
          ]
        },
        "validation_aspects": {
          "type": "string",
          "description": "JSON array string of specific aspects to validate",
          "default": "[\"accuracy\", \"methodology\", \"best-practices\"]"
        },
        "implementation_code": {
          "type": "string",
          "description": "Implementation code to validate (optional)"
        }
      },
      "required": [
        "tool_config",
        "domain"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.1,
      "max_new_tokens": 3500,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "ToolQualityEvaluator",
    "description": "Evaluates the quality of tool configurations and implementations. Provides detailed scoring and feedback for improvement.",
    "prompt": "You are a senior software architect. Evaluate this tool for quality and completeness:\n\nTool Configuration: {tool_config}\nTest Cases: {test_cases}\nEvaluation Aspects: {evaluation_aspects}\n\nProvide a comprehensive evaluation in this JSON format:\n{\n  \"overall_score\": 8.5,\n  \"scores\": {\n    \"functionality\": 9.0,\n    \"usability\": 8.0,\n    \"completeness\": 8.5,\n    \"best_practices\": 8.0\n  },\n  \"feedback\": {\n    \"strengths\": [\"Clear parameter definitions\", \"Good error handling\"],\n    \"weaknesses\": [\"Missing input validation\", \"Limited test coverage\"],\n    \"suggestions\": [\"Add parameter validation\", \"Include more edge case tests\"]\n  },\n  \"quality_rating\": \"Excellent|Good|Fair|Poor\"\n}\n\nEvaluate based on:\n1. Parameter design quality\n2. Implementation robustness\n3. Error handling completeness\n4. Documentation clarity\n5. Test coverage adequacy\n6. Code quality and best practices\n7. Usability and user experience\n\nProvide specific, actionable feedback.",
    "input_arguments": [
      "tool_config",
      "test_cases",
      "evaluation_aspects"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_config": {
          "type": "string",
          "description": "JSON string of the tool configuration"
        },
        "test_cases": {
          "type": "string",
          "description": "JSON string of test cases"
        },
        "evaluation_aspects": {
          "type": "array",
          "description": "Aspects to evaluate (functionality, usability, completeness, best_practices)"
        }
      },
      "required": [
        "tool_config",
        "test_cases",
        "evaluation_aspects"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.2,
      "max_new_tokens": 2048,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "ToolOptimizer",
    "description": "Optimizes tool configurations based on quality feedback. Improves tool specifications and implementations to address identified issues.",
    "prompt": "You are an expert tool optimizer. Improve this tool based on the quality feedback:\n\nOriginal Tool Configuration: {tool_config}\nQuality Feedback: {quality_feedback}\nOptimization Target: {optimization_target}\n\nGenerate an optimized version in this JSON format:\n{\n  \"optimized_tool\": {\n    \"name\": \"improved_tool_name\",\n    \"type\": \"tool_type\",\n    \"description\": \"enhanced_description\",\n    \"parameter\": {\n      \"type\": \"object\",\n      \"properties\": {},\n      \"required\": []\n    },\n    \"category\": \"category\",\n    \"implementation\": {\n      \"source_code\": \"improved_code\",\n      \"dependencies\": [],\n      \"main_function\": \"execute_tool\"\n    }\n  },\n  \"improvements_made\": [\n    \"Added input validation\",\n    \"Enhanced error handling\",\n    \"Improved parameter descriptions\"\n  ],\n  \"optimization_notes\": \"Summary of key improvements\"\n}\n\nFocus on:\n1. Fixing identified weaknesses\n2. Enhancing parameter validation\n3. Improving error handling\n4. Adding missing functionality\n5. Optimizing for the specified target\n6. Maintaining backward compatibility where possible",
    "input_arguments": [
      "tool_config",
      "quality_feedback",
      "optimization_target"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_config": {
          "type": "string",
          "description": "JSON string of the original tool configuration"
        },
        "quality_feedback": {
          "type": "string",
          "description": "JSON string of quality evaluation feedback"
        },
        "optimization_target": {
          "type": "string",
          "description": "What to optimize for (improve_quality, enhance_performance, etc.)"
        }
      },
      "required": [
        "tool_config",
        "quality_feedback",
        "optimization_target"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.3,
      "max_new_tokens": 3072,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "CodeOptimizer",
    "description": "Optimizes code implementation for tools based on quality evaluation. Takes tool configuration and quality evaluation results to produce improved source code.",
    "prompt": "You are an expert software engineer specializing in code optimization. Your task is to optimize the implementation code of a tool based on the provided configuration and quality evaluation.\n\n## TOOL CONFIGURATION\n{tool_config}\n\n## QUALITY EVALUATION\n{quality_evaluation}\n\n## OPTIMIZATION INSTRUCTIONS\nAnalyze the current implementation and quality evaluation feedback, then provide an optimized version that addresses the identified issues. Focus on:\n1. **Code Quality**: Improve readability, structure, and maintainability\n2. **Error Handling**: Enhance exception handling, input validation, and robustness\n3. **Performance**: Optimize algorithms, reduce complexity, improve efficiency\n4. **Best Practices**: Follow Python standards, proper documentation, and clean code principles\n\nReturn a JSON object with the following structure:\n```json\n{\n  \"implementation\": {\n    \"source_code\": \"<optimized_python_code>\",\n    \"dependencies\": [\"<required_packages>\"],\n    \"imports\": [\"<import_statements>\"],\n    \"improvements_made\": [\"list of specific improvements based on quality evaluation feedback\"],\n    \"addressed_issues\": [\"list of issues that were fixed\"],\n    \"quality_improvements\": \"summary of overall quality improvements\"\n  }\n}\n```\n\nEnsure the optimized code:\n- Maintains the same functionality as the original\n- Addresses the specific issues mentioned in quality evaluation feedback\n- Includes proper error handling and input validation\n- Follows Python best practices and PEP 8 standards\n- Is well-documented with clear docstrings and comments",
    "input_arguments": [
      "tool_config",
      "quality_evaluation"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_config": {
          "type": "string",
          "description": "JSON string containing the complete tool configuration including current implementation"
        },
        "quality_evaluation": {
          "type": "string",
          "description": "JSON string containing quality evaluation results and feedback"
        }
      },
      "required": [
        "tool_config",
        "quality_evaluation"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.2,
      "max_new_tokens": 4096,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "LabelGenerator",
    "description": "Generates relevant keyword labels for tools based on their name, description, parameters, and category. Creates a comprehensive list of tags for tool discovery and categorization.",
    "prompt": "You are an expert in tool categorization and keyword generation. Your task is to generate relevant, descriptive labels/keywords for a tool that will help with discovery and organization.\n\n## TOOL INFORMATION\n- **Tool Name**: {tool_name}\n- **Description**: {tool_description}\n- **Parameters**: {tool_parameters}\n- **Category**: {category}\n\n## EXISTING LABELS\n{existing_labels}\n\n## LABEL GENERATION INSTRUCTIONS\nAnalyze the tool information and generate a comprehensive list of relevant labels/keywords that:\n\n1. **Capture Tool Functionality**: What the tool does, its purpose\n2. **Describe Input/Output Types**: Data types, formats, domains\n3. **Indicate Use Cases**: When and where this tool would be useful\n4. **Reference Technical Domains**: Scientific fields, technologies, methodologies\n5. **Include Semantic Variations**: Synonyms, related terms, alternative descriptions\n\n## LABELING GUIDELINES\n- Generate 8-15 relevant labels\n- Use lowercase, hyphenated format (e.g., 'protein-analysis', 'molecular-weight')\n- Reuse existing labels (if provided) when the existing labels are a good fit. It is okay to generate new labels if the existing ones are not suitable, or if there is another label you think is fitting that is not in the existing labels set.\n- Include both specific and general terms\n- Avoid overly generic terms like 'tool', 'utility', 'helper'\n- Include domain-specific terminology when applicable\n- Consider both technical and user-friendly terms\n\n## EXAMPLES\nFor a protein sequence analyzer:\n- Technical: ['protein-analysis', 'sequence-processing', 'bioinformatics', 'amino-acid-composition']\n- Functional: ['molecular-biology', 'protein-characterization', 'structural-analysis']\n- Use-case: ['research-tool', 'computational-biology', 'biochemistry']\n\nReturn a JSON object with the following structure:\n```json\n{\n  \"labels\": [\"keyword1\", \"keyword2\", \"keyword3\", ...],\n  \"rationale\": \"Brief explanation of label selection strategy\"\n}\n```",
    "input_arguments": [
      "tool_name",
      "tool_description",
      "tool_parameters",
      "category",
      "existing_labels"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_name": {
          "type": "string",
          "description": "The name of the tool"
        },
        "tool_description": {
          "type": "string",
          "description": "Detailed description of what the tool does"
        },
        "tool_parameters": {
          "type": "string",
          "description": "JSON string describing the tool's input parameters and their types"
        },
        "category": {
          "type": "string",
          "description": "The general category or domain the tool belongs to"
        },
        "existing_labels": {
          "type": "string",
          "description": "JSON array string of existing labels to consider reusing (optional)"
        }
      },
      "required": [
        "tool_name",
        "tool_description",
        "tool_parameters",
        "category"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.7,
      "max_new_tokens": 2048,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "call_agentic_human",
    "description": "Produces a concise, practical answer that emulates how a well-informed human would respond to the question.",
    "prompt": "You are not an AI. You are a knowledgeable human expert speaking naturally. Read the user's question carefully and respond as a thoughtful person would, giving a clear, direct, and context-aware answer. Do not mention AI, ChatGPT, or models. If the question involves uncertainty or opinion, share a reasoned perspective in a human tone.\n\nQuestion: {question}\n\nAnswer:",
    "input_arguments": [
      "question"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "question": {
          "type": "string",
          "description": "The user's question to be answered in a human-like manner."
        }
      },
      "required": [
        "question"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.7,
      "max_new_tokens": 1024,
      "return_json": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "ToolMetadataGenerator",
    "description": "Generates a JSON structure with the metadata of a tool in ToolUniverse, given the JSON configuration of the tool.",
    "prompt": "You are an expert in processing ToolUniverse tool configurations. Your task is to extract and generate key metadata from a given tool's JSON configuration and return it as a new, structured JSON object.\n\n**Input Tool Configuration:**\n```json\n{tool_config}\n```\n\n**Tool Type Mappings (for simplifying toolType):**\n```json\n{tool_type_mappings}\n```\n\n**Instructions:**\nFrom the input configuration, generate a new JSON object with the specified structure. All fields enclosed in '<','>' are placeholders for instructions; you should generate a specific value for the tool based on its configuration. Fields not in brackets should use the default values provided.\n\n**Output JSON Structure:**\n```json\n{\n    \"id\": \"<generate a new uuid>\",\n    \"name\": \"<extract from tool_config.name>\",\n    \"description\": \"<extract and tool_config.description and slightly summarize it if it is too long>\",\n    \"detailed_description\": \"<extract from tool_config.description>\",\n    \"toolType\": \"<if tool_config.type or tool_config.name appears in tool_type_mappings dict in one of the lists (among the dict's values), extract the corresponding key and set it as the simplified toolType. otherwise, set toolType to be 'API' (the default)>\",\n    \"tags\": [],\n    \"category\": \"<extract from tool_config.type>\",\n    \"lab\": \"Zitnik Lab\",\n    \"source\": \"<extract the name of the database, package, model, or write 'Agentic'>\",\n    \"version\": \"v1.0.0\",\n    \"reviewed\": true,\n    \"isValidated\": true,\n    \"usageStats\": \"100+ uses\",\n    \"capabilities\": [\n      \"<list capabilities strictly derivable from tool_config>\"\n    ],\n    \"limitations\": [\n      \"None for now\"\n    ],\n    \"parameters\": {<for each parameter key include an object with type and description>},\n    \"inputSchema\": <echo tool_config.parameter exactly>,\n    \"exampleInput\": {},\n    \"apiEndpoints\": [\n      {\n        \"method\": \"MCP\",\n        \"url\": \"https://tooluniversemcpserver.onrender.com/mcp/\"\n      }\n    ]\n}\n```\n\nReturn ONLY the final JSON object with no extra commentary.",
    "input_arguments": [
      "tool_config",
      "tool_type_mappings"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_config": {
          "type": "string",
          "description": "JSON string of the tool configuration to extract metadata from"
        },
        "tool_type_mappings": {
          "type": "object",
          "description": "A mapping from a simplified toolType to a list of tool_config.type that fall under the toolType (e.g., {'Databases': ['XMLTool']})"
        }
      },
      "required": [
        "tool_config"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.7,
      "max_new_tokens": 8192,
      "return_json": true,
      "return_metadata": false
    }
  },
  {
    "type": "AgenticTool",
    "name": "ToolMetadataStandardizer",
    "description": "Standardizes and groups semantically equivalent metadata strings (e.g., sources, tags) into canonical forms for consistent downstream usage.",
    "prompt": "You are an expert in metadata normalization and canonicalization. Given a list of raw metadata strings (sources, tags, categories, etc.), produce a JSON object that maps a SINGLE canonical (standardized) string to the list of ALL raw variants from the input that correspond to that canonical form.\n\nINPUT LIST (raw values):\n{metadata_list}\n\nOPTIONAL LIMIT:\n{limit}\n\nTASK:\nReturn ONLY a JSON object (no markdown, no explanations) of the form:\n{\n  \"canonical_value_1\": [\"variant_a\", \"variant_b\"],\n  \"canonical_value_2\": [\"variant_c\"],\n  ...\n}\n\n**LIMIT CONSTRAINT:**\nIf a `limit` is provided, you MUST group terms more aggressively to ensure the number of canonical keys in the output JSON does not exceed the limit. Every raw string must still be mapped to one of the canonical strings. **However, this aggressive grouping must be balanced. Avoid creating overly broad, uninformative categories (e.g., 'data', 'science', 'metadata'). The canonical labels must still clearly distinguish between different technical capabilities and scientific fields.**\n\n**STANDARDIZATION RULES (apply in order):**\n\n**Part 1: Grammatical & Syntactic Normalization**\n1. Trim whitespace; collapse internal repeated whitespace to a single space.\n2. Case fold (lowercase) for comparison, but canonical output SHOULD use a clean, title or widely-recognized uppercase style for well-known acronyms (retain ALLCAPS for <=5 letter well-known biomedical / data acronyms like NCBI, FDA, NIH, EMA, WHO, API). For general words use lowercase-hyphen style (e.g., \"gene-expression\").\n3. Remove surrounding quotes and trailing punctuation (periods, commas, semicolons).\n4. Replace underscores, spaces, and consecutive separators with a single hyphen (e.g., 'Gene  Expression', 'gene_expression' -> 'gene-expression').\n5. Treat hyphen and space variants as equivalent (protein-analysis == protein analysis).\n6. Singular vs plural: treat plural forms as the same (e.g., \"dataset\" and \"datasets\"). Use singular in canonical unless plural is the widely accepted form (e.g., 'omics').\n7. Common stop punctuation (&, /, :) removed unless they encode a standard acronym combination. For constructs like 'R&D' keep as 'R-and-d'.\n8. Strip leading articles (the, a, an) unless part of proper noun (e.g., 'The Cancer Genome Atlas' -> keep).\n9. Collapse obvious expansions to standard acronyms when unambiguous (\"national center for biotechnology information\" -> NCBI, \"food and drug administration\" -> FDA).\n10. If a term is already a concise, recognized proper noun or database name (e.g., 'DrugBank', 'ChEMBL', 'PubChem'), keep its conventional casing as canonical and group all variants to it.\n\n**Part 2: Semantic & Hierarchical Grouping (MOST IMPORTANT)**\n*After applying grammatical normalization, perform the following semantic groupings to create more general, reusable labels.*\n11. **Generalize Specific Terms:** This is the most critical rule. Collapse specific sub-topics into a broader, more general parent category. The goal is to make labels applicable across multiple tools. For example, group 'bioinformatics-ontology' and 'bioinformatics-library-overview' under the single canonical label 'bioinformatics'. **Crucially, do not over-generalize to the point of losing meaning. A category like 'bioinformatics' is good, but a category like 'science' is too broad and uninformative.**\n12. **Hierarchy Collapse:** If terms represent a clear parent-child relationship (e.g., 'genomics' and 'gene-expression-analysis'), group them under the more general parent term ('genomics').\n13. **Synonym & Function Grouping:** Group clear synonyms or terms describing the same function (e.g., 'visualization', 'plotting', 'charting') under a single canonical term (e.g., 'data-visualization').\n14. **Prioritize Broad Concepts:** When choosing a canonical key for a semantic group, always select the most general and widely understood term. For example, prefer 'protein-analysis' over 'protein-folding-simulation'.\n\n**Part 3: Final Output Formatting**\n15. Always include the original raw variants EXACTLY as they appeared in the input list (before any normalization) inside the variant arrays (deduplicate within each list, preserving original order of first appearance).\n16. The canonical key MUST be a clean, user-presentable string (no surrounding whitespace, no trailing punctuation).\n17. Every input value must appear in exactly one array in the output.\n\n**CANONICAL KEY SELECTION HEURISTICS (when multiple variants map to same group):\n- Prefer the most general, high-level concept (e.g., 'bioinformatics' over 'sequence-alignment').\n- Prefer widely recognized product / database / organization name with correct branding (DrugBank, PubChem, UniProt, Ensembl).\n- Else prefer the shortest unambiguous normalized form.\n- Else use hyphenated lowercase normalized form.\n\nOUTPUT REQUIREMENTS:\n- Pure JSON object.\n- Keys: canonical strings.\n- Values: arrays of raw variants (length >=1).\n- Do NOT return commentary, explanations, or fields other than the mapping.\n\nIf input list is empty, return {}.",
    "input_arguments": [
      "metadata_list",
      "limit"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "metadata_list": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "List of raw metadata strings (e.g., sources, tags) to standardize and group."
        },
        "limit": {
          "type": "integer",
          "description": "If provided, the maximum number of canonical strings to return. The LLM will group terms more aggressively to meet this limit, ensuring all raw strings are mapped."
        }
      },
      "required": [
        "metadata_list"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.7,
      "max_new_tokens": 13192,
      "return_json": true
    }
  },
  {
    "type": "AgenticTool",
    "name": "ToolRelationshipDetector",
    "description": "Analyzes a primary tool against a list of other tools to identify meaningful, directional data flow compatibilities for scientific workflows. Returns a list of compatible pairs with direction and rationale.",
    "prompt": "You are an expert in tool composition and scientific workflow design. Your task is to determine the directional data flow compatibility between a primary tool (Tool A) and each tool in a provided list of other tools. Directional compatibility means that the output of one tool can be meaningfully and frequently used as an input to another tool as part of a logical scientific discovery process.\n\n**Your Task:**\n1.  For each tool in the list of 'Other Tools', independently evaluate its pairwise relationship with Tool A.\n2.  Identify only the pairs where the output of one tool is **frequently and logically** used as input to the other and could feasibly be part of a scientific workflow.\n3.  For each such meaningful pair found, determine the data flow direction (`A->B`, `B->A`, or `both`) and provide a 10-15 word rationale for your choice referencing the inputs and outputs of the tools. \n\n**Primary Tool (Tool A):**\n{tool_a}\n\n**List of Other Tools:**\n{other_tools}\n\n**Output Format:**\nReturn ONLY a valid JSON object containing a single key, `relationships`, which holds a list of JSON objects. Each object in the list represents a meaningful relationship. If no meaningful relationships are found, return an empty list.\n\n```json\n{\n  \"relationships\": [\n    {\n      \"tool_b_name\": \"<Name of the tool from the list>\",\n      \"direction\": \"<'A->B'|'B->A'|'both'>\"\n    \"rationale\": \"<10-15 word rationale>\"\n  ]\n}\n```",
    "input_arguments": [
      "tool_a",
      "other_tools"
    ],
    "parameter": {
      "type": "object",
      "properties": {
        "tool_a": {
          "type": "string",
          "description": "JSON string for the primary tool configuration (Tool A)."
        },
        "other_tools": {
          "type": "string",
          "description": "JSON string of a list of other tool configurations to compare against Tool A."
        }
      },
      "required": [
        "tool_a",
        "other_tools"
      ]
    },
    "configs": {
      "api_type": "CHATGPT",
      "model_id": "o4-mini-0416",
      "temperature": 0.2,
      "max_new_tokens": 8192,
      "return_json": true
    }
  }
]
