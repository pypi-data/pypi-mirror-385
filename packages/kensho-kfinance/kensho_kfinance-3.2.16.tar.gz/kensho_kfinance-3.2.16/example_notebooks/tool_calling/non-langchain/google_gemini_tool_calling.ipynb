{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright 2025 Kensho Technologies, LLC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-zOQ3ZfKSrT2"
   },
   "source": [
    "# Google Gemini Tool Calling\n",
    "**_Gemini to retrieve data from the LLM-ready API using the kFinance python library!_**\n",
    "\n",
    "What you'll need to run this notebook:\n",
    "\n",
    "1.   kFinance credentials\n",
    "2.   A Google Gemini API key\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/kensho-technologies/kfinance/blob/main/example_notebooks/tool_calling/non-langchain/google_gemini_tool_calling.ipynb\"><img src=\"../../../images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ruP6MHfzR2Y4"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "YAwU0_7TRhV7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e6ebf89c-7680-4852-e52b-c99610107cdf"
   },
   "outputs": [],
   "source": [
    "# install the latest version of kFinance package\n",
    "%pip install kensho-kfinance\n",
    "# install the LLM Python package\n",
    "%pip install google-generativeai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "e_G2p3tTSHeo"
   },
   "source": [
    "# Instantiate kFinance Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QPnfPuX87rg"
   },
   "outputs": [],
   "source": [
    "# import the kfinance client\n",
    "from kfinance.client.kfinance import Client\n",
    "import json\n",
    "\n",
    "# check if the current environment is a Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_GOOGLE_COLAB = True\n",
    "except:\n",
    "    IN_GOOGLE_COLAB = False\n",
    "\n",
    "# initialize the kfinance client with one of the following:\n",
    "# 1. your kensho refresh token\n",
    "# 2. your kensho client id and kensho private key\n",
    "# 3. automated login (not accessible on Google Collab)\n",
    "if IN_GOOGLE_COLAB:\n",
    "    kensho_refresh_token = \"\"\n",
    "    assert kensho_refresh_token != \"\", \"kensho refresh token is empty! Make sure to enter your kensho refresh token above\"\n",
    "    kfinance_client = Client(refresh_token=kensho_refresh_token)\n",
    "\n",
    "    # kensho_client_id = \"\"\n",
    "    # kensho_private_key = \"\"\n",
    "    # assert kensho_client_id != \"\", \"kensho client id is empty! Make sure to enter your kensho client id above\"\n",
    "    # assert kensho_private_key != \"\", \"kensho private key is empty! Make sure to enter your kensho private key above\"\n",
    "    # kfinance_client = Client(client_id=kensho_client_id, private_key=kensho_private_key)\n",
    "else:\n",
    "    kfinance_client = Client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8ATid9ZvSSZ4"
   },
   "source": [
    "# Google Gemini Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqcNL9H4-h-M"
   },
   "outputs": [],
   "source": [
    "from kfinance.integrations.tool_calling.prompts import BASE_PROMPT\n",
    "# import Google's generativeai package ('Gemini')\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# the GeminiChat class is used to create a chat loop that automatically executes tool calls\n",
    "class GeminiChat:\n",
    "    def __init__(self, kfinance_client: Client) -> None:\n",
    "        # initialize Gemini with your Gemini API key\n",
    "        gemini_api_key = \"\"  # replace with your own key\n",
    "        assert gemini_api_key != \"\", \"Gemini API key is empty! Make sure to enter your Gemini API key above\"\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        model = genai.GenerativeModel(\n",
    "            model_name='gemini-2.0-flash',\n",
    "            system_instruction=BASE_PROMPT,\n",
    "            tools=kfinance_client.gemini_tool_descriptions\n",
    "        )\n",
    "        self.gemini = model.start_chat()\n",
    "\n",
    "    def print_responses(self, user_input: str) -> None:\n",
    "        \"\"\"Print responses and call tools\"\"\"\n",
    "        # send a message to Gemini and get the response\n",
    "        response = self.gemini.send_message(user_input)\n",
    "        parts = response.candidates[0].content.parts\n",
    "        text_parts = list(filter(lambda part: \"text\" in part, parts))\n",
    "        tool_parts = list(filter(lambda part: \"function_call\" in part, parts))\n",
    "\n",
    "        print(\"\\nAssistant Response:\")\n",
    "        for text_part in text_parts:\n",
    "            print(text_part.text)\n",
    "        while tool_parts != []:\n",
    "            tool_outputs = []\n",
    "            for tool_part in tool_parts:\n",
    "                function = tool_part.function_call.name\n",
    "                arguments = {\n",
    "                    key: int(value) if isinstance(value, float) else value\n",
    "                    for key, value in tool_part.function_call.args.items()\n",
    "                }\n",
    "                print(f\"- Function: {function}\")\n",
    "                print(f\"  Arguments: {json.dumps(arguments, indent=2)}\")\n",
    "                try:\n",
    "                    output = str(kfinance_client.tools[function](**arguments))\n",
    "                    print(f\"\\nTool `{function}` executed successfully.\")\n",
    "                    print(f\"Output: {output}\")\n",
    "                except Exception as e:\n",
    "                    output = str(e)\n",
    "                    print(f\"\\nTool `{function}` failed.\")\n",
    "                    print(f\"Error: {output}\")\n",
    "\n",
    "                tool_outputs.append(\n",
    "                    f\"The output of function {function} with arguments {arguments} is: {output}\")\n",
    "\n",
    "                response = self.gemini.send_message(' '.join(tool_outputs))\n",
    "                parts = response.candidates[0].content.parts\n",
    "                text_parts = list(filter(lambda part: \"text\" in part, parts))\n",
    "                tool_parts = list(filter(lambda part: \"function_call\" in part, parts))\n",
    "                print(\"\\nAssistant Response:\")\n",
    "                for text_part in text_parts:\n",
    "                    print(text_part.text)\n",
    "        return None\n",
    "\n",
    "    def start_chatting(self) -> None:\n",
    "        \"\"\"Open chat shell\"\"\"\n",
    "        while True:\n",
    "            user_input = input(\"Enter your message and press the [return] key\\n\")\n",
    "            self.print_responses(user_input)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gx-8tBRndxRb"
   },
   "outputs": [],
   "source": [
    "# instantiate the GeminiChat with the kfinance client\n",
    "gemini_chat = GeminiChat(kfinance_client)\n",
    "# start chatting with the GeminiChat\n",
    "gemini_chat.start_chatting()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
