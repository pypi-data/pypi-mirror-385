# coding: utf-8

"""
    DLCM Solution API

    Repository for Research Datasets

    The version of the OpenAPI document: 3.1.1-SNAPSHOT
    Contact: admin@dlcm.ch
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import date, datetime
from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from dlcm_api_client.models.change_info import ChangeInfo
from dlcm_api_client.models.checksum_check import ChecksumCheck
from dlcm_api_client.models.data_file_checksum import DataFileChecksum
from dlcm_api_client.models.file_format import FileFormat
from dlcm_api_client.models.link import Link
from dlcm_api_client.models.representation_info import RepresentationInfo
from dlcm_api_client.models.virus_check import VirusCheck
from typing import Optional, Set
from typing_extensions import Self

class ArchivalInfoPackage(BaseModel):
    """
    Archival Information Package (AIP)
    """ # noqa: E501
    creation: Optional[ChangeInfo] = None
    last_update: Optional[ChangeInfo] = Field(default=None, alias="lastUpdate")
    res_id: Optional[Annotated[str, Field(min_length=0, strict=True, max_length=50)]] = Field(default=None, description="The identifier of the resource. The default format is a Universally Unique IDentifier (UUID).", alias="resId")
    disposition_approval: Optional[StrictBool] = Field(default=None, description="If the approval step the AIP disposal is mandatory.", alias="dispositionApproval")
    retention: Optional[StrictInt] = Field(default=None, description="The retention duration in days of the AIP: O means forever.")
    archive_container: Optional[StrictStr] = Field(default=None, description="The container type of the AIP.", alias="archiveContainer")
    archival_unit: Optional[StrictBool] = Field(default=None, description="if the AIP is an unit (AIU) or a collection (AIC).", alias="archivalUnit")
    archive_id: Optional[StrictStr] = Field(default=None, description="The storage URI of the AIP.", alias="archiveId")
    archive_file_number: Optional[StrictInt] = Field(default=None, description="The total number of files in the AIP.", alias="archiveFileNumber")
    update_number: Optional[StrictInt] = Field(default=None, description="The number of updates in the AIP.", alias="updateNumber")
    collection_file_number: Optional[StrictInt] = Field(default=None, description="The total number of filed in the collection AIP.", alias="collectionFileNumber")
    archive_size: Optional[StrictInt] = Field(default=None, description="The size in bytes of the AIP.", alias="archiveSize")
    tombstone_size: Optional[StrictInt] = Field(default=None, description="The size in bytes of the tombstone AIP.", alias="tombstoneSize")
    collection_archive_size: Optional[StrictInt] = Field(default=None, description="The total size in bytes of the collection AIP.", alias="collectionArchiveSize")
    checksum_check: Optional[ChecksumCheck] = Field(default=None, alias="checksumCheck")
    checksums: Optional[List[DataFileChecksum]] = Field(default=None, description="The checksum list of the AIP.")
    file_format: Optional[FileFormat] = Field(default=None, alias="fileFormat")
    info: Optional[RepresentationInfo] = None
    sip_ids: Optional[List[StrictStr]] = Field(default=None, description="The source SIP list (IDs) of the AIP.", alias="sipIds")
    virus_check: Optional[VirusCheck] = Field(default=None, alias="virusCheck")
    publication_date: Optional[date] = Field(default=None, description="The publication date of the AIP.", alias="publicationDate")
    last_archiving: Optional[datetime] = Field(default=None, description="The last archiving process date of the AIP: the first archiving date or the last metadata edition.", alias="lastArchiving")
    ready: Optional[StrictBool] = Field(default=None, description="If AIP package is ready.")
    compliance_level: Optional[StrictStr] = Field(default=None, description="Compliance level to define the preservation quality based on data file format: - NOT_ASSESSED => The format could not be evaluated - NO_COMPLIANCE => The format could not be determined - WEAK_COMPLIANCE => The format was determined: content type detected - AVERAGE_COMPLIANCE => The format was determined: WEAK_COMPLIANCE + PRONOM identifier detected - FULL_COMPLIANCE => The format was determined: AVERAGE_COMPLIANCE + the format is part of golden formats ", alias="complianceLevel")
    data_file_number: Optional[StrictInt] = Field(default=None, description="The number of AIP data files.", alias="dataFileNumber")
    smart_size: Optional[StrictStr] = Field(default=None, description="The size in human-readable format of the AIP.", alias="smartSize")
    retention_end: Optional[datetime] = Field(default=None, description="The end of the AIP retention.", alias="retentionEnd")
    collection_size: Optional[StrictInt] = Field(default=None, description="The number of AIPs in collection AIP.", alias="collectionSize")
    smart_tombstone_size: Optional[StrictStr] = Field(default=None, description="The size in human-readable format of the tombstone AIP.", alias="smartTombstoneSize")
    smart_collection_archive_size: Optional[StrictStr] = Field(default=None, description="The total size in human-readable format of the collection AIP.", alias="smartCollectionArchiveSize")
    package_status: Optional[StrictStr] = Field(default=None, description="OAIS Package Status: - CHECKED => Checked package during archiving process - CHECKING => A package verification is in progress during checking process - CHECK_PENDING => A package verification is pending during checking process - CLEANED => Cleaned package during cleaning process for SIP only - CLEANING => A package clean is in progress during cleaning process for SIP only - COMPLIANCE_LEVEL_UPDATE_PENDING => A package compliance update is pending - COMPLIANCE_LEVEL_UPDATED => The compliance levels of the package have been updated - COMPLETED => Completed package - DISPOSABLE => The Package is candidate for disposal process for AIP only - DISPOSAL_APPROVED_BY_ORGUNIT => Disposal org. unit approval done during disposal process for AIP only - DISPOSAL_APPROVED => Disposal approval done during disposal process for AIP only - DISPOSED => Disposed package for AIP only - DOWNLOADING => A package download is in progress - EDITING_METADATA => A package metadata edition is in progress - FIXING => A package correction is in progress - FIXITY_ERROR => Error when checking checksums - FIX_PENDING => A package correction is pending - INDEXING => A package indexing is in progress - IN_ERROR => Package in error during archiving process - IN_PREPARATION => Package in preparation during archiving process - IN_PROGRESS => A package archiving process is in progress - METADATA_EDITION_PENDING => A metadata edition is pending - METADATA_UPGRADE_PENDING => A metadata version upgrade is pending - PACKAGE_REPLICATION_PENDING => A package replication is pending - PRESERVATION_ERROR => Package in error during checking process - READY => Package Ready - REINDEXING => A package re-indexing is in progress - RELOADED => Reloaded package from storage location - REPLICATING_PACKAGE => A package replication is in progress - REPLICATING_TOMBSTONE => A tombstone package replication is in progress - RESUBMITTING => A package re-submission is in progress - STORED => Package stored on storage location - TOMBSTONE_REPLICATION_PENDING => A tombstone replication is pending - UPDATING_COMPLIANCE_LEVEL => A package compliance update is in progress - UPDATING_RETENTION => A package retention update is in progress during disposal process - UPGRADING_METADATA => A metadata version upgrade is in progress ", alias="packageStatus")
    smart_retention: Optional[StrictStr] = Field(default=None, description="The retention duration in human-readable format of the package.", alias="smartRetention")
    links: Optional[Dict[str, Link]] = Field(default=None, alias="_links")
    __properties: ClassVar[List[str]] = ["creation", "lastUpdate", "resId", "dispositionApproval", "retention", "archiveContainer", "archivalUnit", "archiveId", "archiveFileNumber", "updateNumber", "collectionFileNumber", "archiveSize", "tombstoneSize", "collectionArchiveSize", "checksumCheck", "checksums", "fileFormat", "info", "sipIds", "virusCheck", "publicationDate", "lastArchiving", "ready", "complianceLevel", "dataFileNumber", "smartSize", "retentionEnd", "collectionSize", "smartTombstoneSize", "smartCollectionArchiveSize", "packageStatus", "smartRetention", "_links"]

    @field_validator('archive_container')
    def archive_container_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['UNDEFINED', 'ZIP', 'BAG_IT']):
            raise ValueError("must be one of enum values ('UNDEFINED', 'ZIP', 'BAG_IT')")
        return value

    @field_validator('compliance_level')
    def compliance_level_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['NOT_ASSESSED', 'NO_COMPLIANCE', 'WEAK_COMPLIANCE', 'AVERAGE_COMPLIANCE', 'FULL_COMPLIANCE']):
            raise ValueError("must be one of enum values ('NOT_ASSESSED', 'NO_COMPLIANCE', 'WEAK_COMPLIANCE', 'AVERAGE_COMPLIANCE', 'FULL_COMPLIANCE')")
        return value

    @field_validator('package_status')
    def package_status_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['CHECK_PENDING', 'CHECKING', 'CHECKED', 'CLEANING', 'CLEANED', 'COMPLETED', 'DOWNLOADING', 'IN_PREPARATION', 'IN_PROGRESS', 'STORED', 'INDEXING', 'READY', 'IN_ERROR', 'PRESERVATION_ERROR', 'FIXITY_ERROR', 'DISPOSABLE', 'DISPOSAL_APPROVED_BY_ORGUNIT', 'DISPOSAL_APPROVED', 'DISPOSED', 'FIX_PENDING', 'FIXING', 'METADATA_EDITION_PENDING', 'EDITING_METADATA', 'UPDATING_RETENTION', 'METADATA_UPGRADE_PENDING', 'UPGRADING_METADATA', 'COMPLIANCE_LEVEL_UPDATE_PENDING', 'UPDATING_COMPLIANCE_LEVEL', 'COMPLIANCE_LEVEL_UPDATED', 'REINDEXING', 'RELOADED', 'RESUBMITTING', 'PACKAGE_REPLICATION_PENDING', 'REPLICATING_PACKAGE', 'TOMBSTONE_REPLICATION_PENDING', 'REPLICATING_TOMBSTONE']):
            raise ValueError("must be one of enum values ('CHECK_PENDING', 'CHECKING', 'CHECKED', 'CLEANING', 'CLEANED', 'COMPLETED', 'DOWNLOADING', 'IN_PREPARATION', 'IN_PROGRESS', 'STORED', 'INDEXING', 'READY', 'IN_ERROR', 'PRESERVATION_ERROR', 'FIXITY_ERROR', 'DISPOSABLE', 'DISPOSAL_APPROVED_BY_ORGUNIT', 'DISPOSAL_APPROVED', 'DISPOSED', 'FIX_PENDING', 'FIXING', 'METADATA_EDITION_PENDING', 'EDITING_METADATA', 'UPDATING_RETENTION', 'METADATA_UPGRADE_PENDING', 'UPGRADING_METADATA', 'COMPLIANCE_LEVEL_UPDATE_PENDING', 'UPDATING_COMPLIANCE_LEVEL', 'COMPLIANCE_LEVEL_UPDATED', 'REINDEXING', 'RELOADED', 'RESUBMITTING', 'PACKAGE_REPLICATION_PENDING', 'REPLICATING_PACKAGE', 'TOMBSTONE_REPLICATION_PENDING', 'REPLICATING_TOMBSTONE')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ArchivalInfoPackage from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "ready",
            "data_file_number",
            "smart_size",
            "retention_end",
            "collection_size",
            "smart_tombstone_size",
            "smart_collection_archive_size",
            "smart_retention",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of creation
        if self.creation:
            _dict['creation'] = self.creation.to_dict()
        # override the default output from pydantic by calling `to_dict()` of last_update
        if self.last_update:
            _dict['lastUpdate'] = self.last_update.to_dict()
        # override the default output from pydantic by calling `to_dict()` of checksum_check
        if self.checksum_check:
            _dict['checksumCheck'] = self.checksum_check.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in checksums (list)
        _items = []
        if self.checksums:
            for _item_checksums in self.checksums:
                if _item_checksums:
                    _items.append(_item_checksums.to_dict())
            _dict['checksums'] = _items
        # override the default output from pydantic by calling `to_dict()` of file_format
        if self.file_format:
            _dict['fileFormat'] = self.file_format.to_dict()
        # override the default output from pydantic by calling `to_dict()` of info
        if self.info:
            _dict['info'] = self.info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of virus_check
        if self.virus_check:
            _dict['virusCheck'] = self.virus_check.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each value in links (dict)
        _field_dict = {}
        if self.links:
            for _key_links in self.links:
                if self.links[_key_links]:
                    _field_dict[_key_links] = self.links[_key_links].to_dict()
            _dict['_links'] = _field_dict
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ArchivalInfoPackage from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "creation": ChangeInfo.from_dict(obj["creation"]) if obj.get("creation") is not None else None,
            "lastUpdate": ChangeInfo.from_dict(obj["lastUpdate"]) if obj.get("lastUpdate") is not None else None,
            "resId": obj.get("resId"),
            "dispositionApproval": obj.get("dispositionApproval"),
            "retention": obj.get("retention"),
            "archiveContainer": obj.get("archiveContainer"),
            "archivalUnit": obj.get("archivalUnit"),
            "archiveId": obj.get("archiveId"),
            "archiveFileNumber": obj.get("archiveFileNumber"),
            "updateNumber": obj.get("updateNumber"),
            "collectionFileNumber": obj.get("collectionFileNumber"),
            "archiveSize": obj.get("archiveSize"),
            "tombstoneSize": obj.get("tombstoneSize"),
            "collectionArchiveSize": obj.get("collectionArchiveSize"),
            "checksumCheck": ChecksumCheck.from_dict(obj["checksumCheck"]) if obj.get("checksumCheck") is not None else None,
            "checksums": [DataFileChecksum.from_dict(_item) for _item in obj["checksums"]] if obj.get("checksums") is not None else None,
            "fileFormat": FileFormat.from_dict(obj["fileFormat"]) if obj.get("fileFormat") is not None else None,
            "info": RepresentationInfo.from_dict(obj["info"]) if obj.get("info") is not None else None,
            "sipIds": obj.get("sipIds"),
            "virusCheck": VirusCheck.from_dict(obj["virusCheck"]) if obj.get("virusCheck") is not None else None,
            "publicationDate": obj.get("publicationDate"),
            "lastArchiving": obj.get("lastArchiving"),
            "ready": obj.get("ready"),
            "complianceLevel": obj.get("complianceLevel"),
            "dataFileNumber": obj.get("dataFileNumber"),
            "smartSize": obj.get("smartSize"),
            "retentionEnd": obj.get("retentionEnd"),
            "collectionSize": obj.get("collectionSize"),
            "smartTombstoneSize": obj.get("smartTombstoneSize"),
            "smartCollectionArchiveSize": obj.get("smartCollectionArchiveSize"),
            "packageStatus": obj.get("packageStatus"),
            "smartRetention": obj.get("smartRetention"),
            "_links": dict(
                (_k, Link.from_dict(_v))
                for _k, _v in obj["_links"].items()
            )
            if obj.get("_links") is not None
            else None
        })
        return _obj


