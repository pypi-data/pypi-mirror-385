"""Tests for the Redis-based locking mechanism in the hotcore model.

These tests verify that the optimistic locking mechanism works correctly
when multiple clients attempt to modify the same entity concurrently.
Requires a real Redis server.
"""

import logging
import os
import ssl
import threading
import time
import uuid

import pytest
from redis import RedisError, WatchError

from hotcore import EntityStorage, Model, RedisConnectionManager

logging.basicConfig(
    format="%(asctime)s %(levelname)s [%(name)s] %(message)s", level=logging.DEBUG
)


def _connection_settings():
    """Return connection parameters factoring in TLS environment configuration."""
    host = os.environ.get("REDIS_HOST", "localhost")
    port = int(os.environ.get("REDIS_PORT", "6379"))
    use_tls = os.environ.get("REDIS_USE_TLS", "").lower() in ("true", "1", "t")

    tls_context = None
    connection_kwargs = None

    if use_tls:
        tls_context = ssl.create_default_context()
        ca_cert = os.environ.get("REDIS_TLS_CA_CERT")
        if ca_cert:
            tls_context.load_verify_locations(ca_cert)
        client_cert = os.environ.get("REDIS_TLS_CLIENT_CERT")
        client_key = os.environ.get("REDIS_TLS_CLIENT_KEY")
        if client_cert and client_key:
            tls_context.load_cert_chain(client_cert, client_key)

        tls_check_hostname = (
            os.environ.get("REDIS_TLS_CHECK_HOSTNAME", "false").lower()
            in ("true", "1", "t")
        )
        connection_kwargs = {"ssl_check_hostname": tls_check_hostname}

    return host, port, tls_context, connection_kwargs


def _new_model():
    host, port, tls_context, connection_kwargs = _connection_settings()
    return Model(
        host=host,
        port=port,
        ssl_context=tls_context,
        connection_kwargs=connection_kwargs,
        write_host=host,
        write_port=port,
        write_ssl_context=tls_context,
        write_connection_kwargs=connection_kwargs,
    )


def _new_connection_manager():
    host, port, tls_context, connection_kwargs = _connection_settings()
    return RedisConnectionManager(
        host=host,
        port=port,
        ssl_context=tls_context,
        connection_kwargs=connection_kwargs,
    )


@pytest.mark.redis_required
class TestLockingMechanism:
    """Tests for verifying the optimistic locking mechanism with a real Redis server."""

    def test_optimistic_locking_during_apply(self, model):
        """Test that concurrent apply operations are handled correctly with optimistic locking."""
        # Create a test entity
        entity = model.init({})
        entity["name"] = "test-entity"
        entity["counter"] = "0"
        model.create("root", entity)
        entity_uuid = entity["uuid"]

        # Track results from all threads
        results = []

        # Number of concurrent operations to simulate
        num_operations = 5

        # Lock for thread-safe access to results
        lock = threading.Lock()

        def update_entity():
            # Create a new model instance for this thread
            thread_model = _new_model()

            try:
                # Read current value
                current = thread_model.get(entity_uuid)
                current_counter = int(current.get("counter", "0"))

                # Simulate some processing time to increase chance of conflicts
                time.sleep(0.1)

                # Prepare the change (increment counter)
                change = {"uuid": entity_uuid, "counter": str(current_counter + 1)}

                # Try to apply the change
                thread_model.apply(change)

                # Record success with the counter value that was used
                with lock:
                    results.append(("success", current_counter))
            except WatchError:
                # Record the WatchError
                with lock:
                    results.append(("watch_error", None))
            except RedisError as e:
                # Record other Redis errors
                with lock:
                    results.append(("redis_error", str(e)))
            except Exception as e:
                # Record unexpected errors
                with lock:
                    results.append(("error", str(e)))

        # Create and start threads
        threads = []
        for _ in range(num_operations):
            thread = threading.Thread(target=update_entity)
            threads.append(thread)
            thread.start()

        # Wait for all threads to complete
        for thread in threads:
            thread.join()

        # Get final counter value
        final_entity = model.get(entity_uuid)
        final_counter = int(final_entity.get("counter", "0"))

        # Count results
        successes = [r for r in results if r[0] == "success"]
        watch_errors = [r for r in results if r[0] == "watch_error"]
        other_errors = [r for r in results if r[0] not in ("success", "watch_error")]

        # Debug log
        print(f"Final counter: {final_counter}")
        print(f"Results: {results}")
        print(
            f"Successes: {len(successes)}, WatchErrors: {len(watch_errors)}, Other errors: {len(other_errors)}"
        )

        # Verify test results

        # 1. All operations should result in either success or WatchError
        assert len(successes) + len(watch_errors) + len(other_errors) == num_operations

        # 2. The final counter value should be greater than 0 but less than the number of operations
        # This verifies that the locking mechanism is working to prevent all threads from
        # successfully incrementing the counter
        assert (
            0 < final_counter < num_operations
        ), f"Final counter should be between 0 and {num_operations}"

        # 3. Get the count of unique counter values that were used as starting points
        # This should tell us how many distinct values the counter went through
        unique_counter_values = {r[1] for r in successes if r[1] is not None}

        # For concurrent operations with proper locking, we should see fewer unique
        # counter values than successful operations, as some operations will be based on
        # the same starting counter value (race condition)
        # This is a strong indicator that operations ran concurrently
        if len(successes) > 1:
            assert len(unique_counter_values) < len(
                successes
            ), "Expected evidence of concurrent operations"

    def test_optimistic_locking_during_delete(self, model):
        """Test that concurrent delete operations are handled correctly with optimistic locking."""
        # Create a test entity
        entity = model.init({})
        entity["name"] = "test-delete-entity"
        entity["status"] = "active"
        model.create("root", entity)
        entity_uuid = entity["uuid"]

        # Track results from both threads
        results = []

        # Lock for thread-safe access to results
        lock = threading.Lock()

        def delete_entity():
            # Create a new model instance for this thread
            thread_model = _new_model()

            try:
                # Get the entity data
                current = thread_model.get(entity_uuid)

                # If entity is empty (just UUID), it's already been deleted
                if len(current) <= 1:
                    with lock:
                        results.append(("already_deleted", None))
                    return

                # Add some processing time to increase chance of conflicts
                # This should happen BEFORE the delete attempt to allow for race conditions
                time.sleep(0.05)  # Reduced sleep time for faster test execution

                # Try to delete - let the WATCH mechanism handle concurrency
                thread_model.delete(current)

                # Record success
                with lock:
                    results.append(("success", None))
            except WatchError:
                # Record the WatchError - this indicates successful concurrency detection
                with lock:
                    results.append(("watch_error", None))
            except RedisError as e:
                # Record Redis errors
                with lock:
                    results.append(("redis_error", str(e)))
            except Exception as e:
                # Record unexpected errors
                with lock:
                    results.append(("error", str(e)))

        # Create and start two threads to attempt deletion concurrently
        threads = []
        for _ in range(2):
            thread = threading.Thread(target=delete_entity)
            threads.append(thread)
            thread.start()

        # Wait for all threads to complete
        for thread in threads:
            thread.join()

        # Get final entity state (should be empty or just have UUID)
        final_entity = model.get(entity_uuid)

        # Count results
        successes = [r for r in results if r[0] == "success"]
        watch_errors = [r for r in results if r[0] == "watch_error"]
        already_deleted = [r for r in results if r[0] == "already_deleted"]
        other_errors = [
            r
            for r in results
            if r[0] not in ("success", "watch_error", "already_deleted")
        ]

        # Debug log
        print(f"Final entity: {final_entity}")
        print(f"Results: {results}")
        print(
            f"Successes: {len(successes)}, WatchErrors: {len(watch_errors)}, "
            f"Already deleted: {len(already_deleted)}, Other errors: {len(other_errors)}"
        )

        # Verify test results

        # 1. The entity should be deleted (empty or just UUID)
        assert (
            len(final_entity) <= 1
        ), f"Entity should be deleted but contains: {final_entity}"

        # 2. All operations should result in either success, WatchError, or already_deleted
        assert (
            len(successes)
            + len(watch_errors)
            + len(already_deleted)
            + len(other_errors)
            == 2
        )

        # 3. We should have evidence of concurrent operations
        # Since WatchError is handled internally by retry logic, we look for:
        # - Some threads found entity already deleted, or
        # - Only one thread reported success (indicating the other was handled by retry logic)
        # - Both succeeded but with different timing (race condition evidence)
        concurrency_evidence = (
            len(already_deleted) > 0  # Some threads found entity already deleted
            or len(watch_errors)
            > 0  # Some threads got WatchErrors (if not handled internally)
            or len(successes) == 1  # Only one success (other was handled by retry)
            or len(successes)
            == 2  # Both succeeded but with retry logic handling conflicts
        )
        assert concurrency_evidence, "Expected evidence of concurrent operations"

    def test_locking_with_custom_implementation(self, model):
        """Test the locking mechanism directly using the RedisConnectionManager and EntityStorage classes."""
        # Create a connection manager and storage instance
        conn_manager = _new_connection_manager()
        storage = EntityStorage(conn_manager)

        # Create a test entity
        entity_uuid = str(uuid.uuid4())
        entity_key = conn_manager.get_entity_key(entity_uuid)
        watch_key = conn_manager.get_watch_key(entity_uuid)

        # Set up initial entity state
        client = conn_manager.get_client()
        client.hset(entity_key, "name", "test-entity")
        client.hset(entity_key, "status", "active")

        # Setup for concurrent access simulation
        results = []

        def simulate_concurrent_operation(operation_type):
            try:
                # Get a Redis client
                thread_client = conn_manager.get_client()

                with thread_client.pipeline() as pipe:
                    # Watch the entity for changes
                    pipe.watch(watch_key)

                    # Read current value
                    current_entity = pipe.hgetall(entity_key)

                    # Simulate processing delay
                    time.sleep(0.2)

                    # Start transaction
                    pipe.multi()

                    # Set watch key to mark operation in progress
                    pipe.set(watch_key, "locked")

                    if operation_type == "modify":
                        # Modify the entity
                        pipe.hset(entity_key, "status", "modified")
                    elif operation_type == "delete":
                        # Delete a field
                        pipe.hdel(entity_key, "status")

                    # Execute transaction
                    pipe.execute()
                    results.append(f"{operation_type}_success")
            except WatchError:
                results.append(f"{operation_type}_watcherror")
            except Exception as e:
                results.append(f"{operation_type}_error: {str(e)}")

        # Create threads for concurrent operations
        thread1 = threading.Thread(
            target=simulate_concurrent_operation, args=("modify",)
        )
        thread2 = threading.Thread(
            target=simulate_concurrent_operation, args=("delete",)
        )

        # Start threads
        thread1.start()
        thread2.start()

        # Wait for threads to complete
        thread1.join()
        thread2.join()

        # Verify results
        final_entity = client.hgetall(entity_key)

        # Debug log
        print(f"Final entity: {final_entity}")
        print(f"Results: {results}")

        # Check that one operation succeeded and one failed with WatchError
        assert len(results) == 2, f"Expected 2 results but got {len(results)}"

        # Exactly one operation should have succeeded
        successes = [r for r in results if r.endswith("_success")]
        assert (
            len(successes) == 1
        ), f"Expected 1 successful operation but got {len(successes)}: {successes}"

        # Exactly one operation should have failed with WatchError
        watch_errors = [r for r in results if r.endswith("_watcherror")]
        assert (
            len(watch_errors) == 1
        ), f"Expected 1 WatchError but got {len(watch_errors)}: {watch_errors}"

        # The final entity state should match the successful operation
        if "modify_success" in results:
            assert "status" in final_entity and final_entity["status"] == "modified"
        else:
            assert "status" not in final_entity

        # Clean up
        client.delete(entity_key, watch_key)
