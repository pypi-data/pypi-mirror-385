# Do not edit this file manually! It is generated by scripts/codegen.py

from __future__ import annotations

import json
import logging
import os
import uuid
from string import Formatter
from typing import Any, Literal, Mapping, NotRequired, TypedDict, cast, overload

from httpx import URL, USE_CLIENT_DEFAULT, Client, Headers, Request, Response, Timeout
from httpx._client import UseClientDefault  # type: ignore
from httpx._types import AuthTypes  # type: ignore
from httpx._types import CookieTypes  # type: ignore
from httpx._types import FileTypes  # type: ignore
from httpx._types import HeaderTypes  # type: ignore
from httpx._types import RequestContent  # type: ignore
from httpx._types import RequestExtensions  # type: ignore
from httpx._types import TimeoutTypes  # type: ignore


class ActionRecommendation(TypedDict):
    action: Literal["remove_duplicates", "detect_mislabels", "add_memories", "finetuning"]
    """
    The recommended action to take
    """
    rationale: str
    """
    Explanation for why this action was recommended
    """


class AddMemorySuggestion(TypedDict):
    value: str
    label_name: str


class AliveResponse(TypedDict):
    ok: bool


class ApiKeyMetadata(TypedDict):
    id: str
    org_id: str
    name: str
    created_by: str | None
    created_at: str
    updated_at: str
    scope: list[Literal["ADMINISTER", "PREDICT"]]


class BaseLabelPredictionResult(TypedDict):
    prediction_id: str | None
    confidence: float
    anomaly_score: float | None
    label: int
    label_name: str | None
    logits: list[float]


class BaseModel(TypedDict):
    pass


class BaseScorePredictionResult(TypedDict):
    prediction_id: str | None
    confidence: float
    anomaly_score: float | None
    score: float


class CascadeEditSuggestionsRequest(TypedDict):
    old_label: int
    new_label: int
    max_neighbors: NotRequired[int]
    max_validation_neighbors: NotRequired[int]
    similarity_threshold: NotRequired[float | None]
    only_if_has_old_label: NotRequired[bool]
    exclude_if_new_label: NotRequired[bool]
    suggestion_cooldown_time: NotRequired[float]
    label_confirmation_cooldown_time: NotRequired[float]


class ClassPattern(TypedDict):
    label: int
    name: str
    description: str


class ClassPatternsDescription(TypedDict):
    overview: str
    classes: list[ClassPattern]
    summary: str


class ClassRepresentatives(TypedDict):
    label: int
    label_name: str | None
    representative_memory_ids: list[str]


class ClassificationEvaluationRequest(TypedDict):
    datasource_name_or_id: str
    memoryset_override_name_or_id: NotRequired[str | None]
    datasource_label_column: str
    datasource_value_column: str
    record_telemetry: NotRequired[bool]
    telemetry_tags: NotRequired[list[str] | None]


class ClusterMetrics(TypedDict):
    cluster: int
    memory_count: int


ColumnType = Literal["STRING", "FLOAT", "INT", "BOOL", "ENUM", "IMAGE", "OTHER"]


class ConstraintViolationErrorResponse(TypedDict):
    status_code: NotRequired[int]
    constraint: str


class CountPredictionsRequest(TypedDict):
    model_id: NotRequired[str | None]
    tag: NotRequired[str | None]
    prediction_ids: NotRequired[list[str] | None]
    start_timestamp: NotRequired[str | None]
    end_timestamp: NotRequired[str | None]


class CreateApiKeyRequest(TypedDict):
    id: NotRequired[str]
    name: NotRequired[str]
    created_by: NotRequired[str | None]
    scope: list[Literal["ADMINISTER", "PREDICT"]]


class CreateApiKeyResponse(TypedDict):
    id: str
    org_id: str
    name: str
    created_by: str | None
    created_at: str
    updated_at: str
    scope: list[Literal["ADMINISTER", "PREDICT"]]
    api_key: str


class CreateDatasourceFromContentRequest(TypedDict):
    name: str
    description: NotRequired[str | None]
    content: Any


class CreateOrgPlanRequest(TypedDict):
    tier: Literal["FREE", "PRO", "ENTERPRISE", "CANCELLED"]


class DeleteMemoriesRequest(TypedDict):
    memory_ids: list[str]


class DeleteMemorysetsRequest(TypedDict):
    memoryset_ids: list[str]


class EmbedRequest(TypedDict):
    values: list[str] | list[bytes] | list[str | bytes]
    max_seq_length: NotRequired[int | None]
    prompt: NotRequired[str | None]


class EmbeddingEvaluationRequest(TypedDict):
    datasource_name_or_id: str
    eval_datasource_name_or_id: NotRequired[str | None]
    subsample: NotRequired[int | None]
    datasource_value_column: NotRequired[str]
    datasource_label_column: NotRequired[str | None]
    datasource_score_column: NotRequired[str | None]
    neighbor_count: NotRequired[int]
    batch_size: NotRequired[int]
    weigh_memories: NotRequired[bool]


EmbeddingFinetuningMethod = Literal["classification", "batch_triplet_loss"]


class FeedbackMetrics(TypedDict):
    avg: float | None
    count: int


FeedbackType = Literal["CONTINUOUS", "BINARY"]


class FilterItem(TypedDict):
    field: list
    op: Literal["==", "!=", ">", ">=", "<", "<=", "in", "not in", "like"]
    value: str | int | float | bool | list[str] | list[int] | list[float] | list[bool] | None


class GetMemoriesRequest(TypedDict):
    memory_ids: list[str]


class HealthyResponse(TypedDict):
    ok: bool
    checks: dict[str, bool]
    durations: dict[str, int]
    draining: bool
    config: dict[str, str | float | int | bool | None]


class InternalServerErrorResponse(TypedDict):
    status_code: NotRequired[int]
    message: str
    request_id: str


class LabelClassMetrics(TypedDict):
    label: int
    label_name: NotRequired[str | None]
    average_lookup_score: float
    memory_count: int


class LabeledExample(TypedDict):
    text: str
    label_name: str


class LabeledMemoryInsert(TypedDict):
    memory_id: NotRequired[str | None]
    value: str | bytes
    metadata: NotRequired[dict[str, str | int | float | bool | None]]
    source_id: NotRequired[str | None]
    label: int


class ListMemoriesRequest(TypedDict):
    offset: NotRequired[int]
    limit: NotRequired[int]
    filters: NotRequired[list[FilterItem]]


class LookupRequest(TypedDict):
    query: list[str]
    count: NotRequired[int]
    prompt: NotRequired[str | None]


class LookupScoreMetrics(TypedDict):
    median: float
    std: float
    quantiles: list[float]
    quantile_values: list[float]


class MemoryMetrics(TypedDict):
    is_duplicate: NotRequired[bool]
    duplicate_memory_ids: NotRequired[list[str]]
    has_potential_duplicates: NotRequired[bool]
    potential_duplicate_memory_ids: NotRequired[list[str] | None]
    cluster: NotRequired[int]
    embedding_2d: NotRequired[list]
    anomaly_score: NotRequired[float]
    neighbor_label_logits: NotRequired[list[float]]
    neighbor_predicted_label: NotRequired[int]
    neighbor_predicted_label_ambiguity: NotRequired[float]
    neighbor_predicted_label_confidence: NotRequired[float]
    current_label_neighbor_confidence: NotRequired[float]
    normalized_neighbor_label_entropy: NotRequired[float]
    neighbor_predicted_label_matches_current_label: NotRequired[bool | None]
    spread: NotRequired[float]
    uniformity: NotRequired[float]
    concept_id: NotRequired[int | None]
    subconcept_id: NotRequired[int | None]


MemoryType = Literal["LABELED", "SCORED"]


class MemorysetClassPatternsAnalysisConfig(TypedDict):
    representatives_per_class: NotRequired[int]
    enable_patterns_description: NotRequired[bool]


class MemorysetClassPatternsMetrics(TypedDict):
    class_representatives: list[ClassRepresentatives]
    patterns_description: NotRequired[ClassPatternsDescription | None]
    mean_spread: float
    variance_spread: float
    mean_uniformity: float
    variance_uniformity: float
    updated_at: str


class MemorysetClusterAnalysisConfig(TypedDict):
    min_cluster_size: NotRequired[int | None]
    max_cluster_size: NotRequired[int | None]
    clustering_method: NotRequired[Literal["density", "graph"]]
    min_cluster_distance: NotRequired[float]
    partitioning_method: NotRequired[Literal["ng", "rb", "cpm"]]
    resolution: NotRequired[float | None]
    num_iterations: NotRequired[int]
    random_state: NotRequired[int | None]


class MemorysetClusterMetrics(TypedDict):
    cluster_metrics: list[ClusterMetrics]
    num_outliers: int
    num_clusters: int
    updated_at: str


class MemorysetConceptAnalysisConfig(TypedDict):
    high_level_description: NotRequired[str | None]
    max_sample_rows: NotRequired[int]
    max_trial_count: NotRequired[int]
    min_desired_clusters_per_label: NotRequired[int]
    max_desired_clusters_per_label: NotRequired[int]
    accuracy_importance: NotRequired[float]
    noise_penalty: NotRequired[float]
    naming_examples_count: NotRequired[int]
    naming_counterexample_count: NotRequired[int]
    seed: NotRequired[int]


class MemorysetDuplicateAnalysisConfig(TypedDict):
    potential_duplicate_threshold: NotRequired[float]


class MemorysetDuplicateMetrics(TypedDict):
    num_duplicates: int
    num_potential_duplicates: int
    updated_at: str


class MemorysetLabelAnalysisConfig(TypedDict):
    normalize_logits: NotRequired[bool]


class MemorysetLabelMetrics(TypedDict):
    label_metrics: list[LabelClassMetrics]
    neighbor_prediction_accuracy: float
    mean_neighbor_label_confidence: float
    mean_neighbor_label_entropy: float
    mean_neighbor_predicted_label_ambiguity: float
    num_potential_mislabels: int
    updated_at: str


class MemorysetNeighborAnalysisConfig(TypedDict):
    neighbor_counts: NotRequired[list[int]]
    quantiles: NotRequired[list[float]]


class MemorysetNeighborMetrics(TypedDict):
    lookup_score_metrics: dict[str, LookupScoreMetrics]
    updated_at: str


class MemorysetProjectionAnalysisConfig(TypedDict):
    min_dist: NotRequired[float]
    spread: NotRequired[float]


class MemorysetProjectionMetrics(TypedDict):
    updated_at: str


class MemorysetUpdate(TypedDict):
    label_names: NotRequired[list[str]]
    description: NotRequired[str | None]
    name: NotRequired[str]
    notes: NotRequired[str | None]
    hidden: NotRequired[bool]


class NotFoundErrorResponse(TypedDict):
    status_code: NotRequired[int]
    resource: (
        Literal[
            "org",
            "api_key",
            "datasource",
            "memoryset",
            "classification_model",
            "regression_model",
            "prediction",
            "memory",
            "evaluation",
            "analysis",
            "task",
            "pretrained_embedding_model",
            "finetuned_embedding_model",
            "feedback_category",
            "embedding_evaluation",
            "org_plan",
        ]
        | None
    )


class OrgPlan(TypedDict):
    org_id: str
    created_at: str
    updated_at: str
    tier: Literal["FREE", "PRO", "ENTERPRISE", "CANCELLED"]


class PRCurve(TypedDict):
    thresholds: list[float]
    precisions: list[float]
    recalls: list[float]


class PredictionFeedback(TypedDict):
    prediction_id: str
    category_name: str
    value: float | bool
    comment: str | None
    id: str
    org_id: str
    category_id: str
    category_type: FeedbackType
    created_at: str
    updated_at: str


class PredictionFeedbackCategory(TypedDict):
    id: str
    org_id: str
    name: str
    type: FeedbackType
    created_at: str
    updated_at: str


class PredictionFeedbackRequest(TypedDict):
    prediction_id: str
    category_name: str
    value: NotRequired[float | bool | None]
    """
    The feedback value. For updates, UNSET means keep existing value. None means delete the feedback.
    """
    comment: NotRequired[str | None]
    """
    Optional comment. For updates, UNSET means keep existing comment. None means remove the comment.
    """


class PredictionFeedbackResult(TypedDict):
    prediction_ids: list[str]
    deleted_feedback_ids: list[str]
    updated_feedback_ids: list[str]
    inserted_feedback_ids: list[str]
    new_category_ids: list[str]


PredictionSort = list[list]


class PredictiveModelUpdate(TypedDict):
    description: NotRequired[str | None]
    notes: NotRequired[str | None]
    locked: NotRequired[bool]


PretrainedEmbeddingModelName = Literal[
    "CLIP_BASE",
    "GTE_BASE",
    "CDE_SMALL",
    "DISTILBERT",
    "GTE_SMALL",
    "MXBAI_LARGE",
    "E5_LARGE",
    "QWEN2_1_5B",
    "BGE_BASE",
    "GIST_LARGE",
]


RACHeadType = Literal["KNN", "MMOE", "FF", "BMMOE"]


RARHeadType = Literal["MMOE", "KNN"]


class ROCCurve(TypedDict):
    thresholds: list[float]
    false_positive_rates: list[float]
    true_positive_rates: list[float]


class ReadyResponse(TypedDict):
    ok: bool
    draining: bool


class RegressionEvaluationRequest(TypedDict):
    datasource_name_or_id: str
    memoryset_override_name_or_id: NotRequired[str | None]
    datasource_score_column: str
    datasource_value_column: str
    record_telemetry: NotRequired[bool]
    telemetry_tags: NotRequired[list[str] | None]


class RegressionMetrics(TypedDict):
    mse: float
    rmse: float
    mae: float
    r2: float
    explained_variance: float
    loss: float
    anomaly_score_mean: NotRequired[float | None]
    anomaly_score_median: NotRequired[float | None]
    anomaly_score_variance: NotRequired[float | None]


class RegressionModelMetadata(TypedDict):
    id: str
    org_id: str
    name: str
    description: str | None
    notes: str | None
    version: int
    memoryset_id: str
    memory_lookup_count: int
    storage_path: str
    memoryset_collection_name: str
    created_at: str
    updated_at: str
    locked: bool
    head_type: RARHeadType


class RegressionPredictionRequest(TypedDict):
    input_values: list[str] | list[bytes] | list[str | bytes]
    expected_scores: NotRequired[list[float] | None]
    tags: NotRequired[list[str]]
    memoryset_override_name_or_id: NotRequired[str | None]
    save_telemetry: NotRequired[bool]
    save_telemetry_synchronously: NotRequired[bool]
    prompt: NotRequired[str | None]
    use_lookup_cache: NotRequired[bool]
    consistency_level: NotRequired[Literal["Bounded", "Session", "Strong", "Eventual"] | None]


class ScorePredictionMemoryLookup(TypedDict):
    value: str | bytes
    embedding: list[float]
    source_id: str | None
    metadata: dict[str, str | int | float | bool | None]
    memory_id: str
    memory_version: int
    created_at: str
    updated_at: str
    edited_at: str
    metrics: MemoryMetrics
    lookup_score: float
    score: float
    prediction_id: str
    attention_weight: float


class ScorePredictionWithMemoriesAndFeedback(TypedDict):
    prediction_id: str
    confidence: float
    anomaly_score: float | None
    score: float
    timestamp: str
    input_value: str | bytes
    input_embedding: list[float]
    expected_score: float | None
    memories: list[ScorePredictionMemoryLookup]
    org_id: str
    memoryset_id: str
    model_id: str
    updated_at: str
    tags: list[str]
    explanation: str | None
    memory_id: str | None
    feedbacks: list[PredictionFeedback]


class ScoredMemory(TypedDict):
    value: str | bytes
    embedding: list[float]
    source_id: str | None
    metadata: dict[str, str | int | float | bool | None]
    memory_id: str
    memory_version: int
    created_at: str
    updated_at: str
    edited_at: str
    metrics: MemoryMetrics
    score: float


class ScoredMemoryInsert(TypedDict):
    memory_id: NotRequired[str | None]
    value: str | bytes
    metadata: NotRequired[dict[str, str | int | float | bool | None]]
    source_id: NotRequired[str | None]
    score: float


class ScoredMemoryLookup(TypedDict):
    value: str | bytes
    embedding: list[float]
    source_id: str | None
    metadata: dict[str, str | int | float | bool | None]
    memory_id: str
    memory_version: int
    created_at: str
    updated_at: str
    edited_at: str
    metrics: MemoryMetrics
    lookup_score: float
    score: float


class ScoredMemoryUpdate(TypedDict):
    memory_id: str
    value: NotRequired[str | bytes]
    metadata: NotRequired[dict[str, str | int | float | bool | None] | None]
    source_id: NotRequired[str | None]
    metrics: NotRequired[MemoryMetrics | None]
    score: NotRequired[float]


class ScoredMemoryWithFeedbackMetrics(TypedDict):
    value: str | bytes
    embedding: list[float]
    source_id: str | None
    metadata: dict[str, str | int | float | bool | None]
    memory_id: str
    memory_version: int
    created_at: str
    updated_at: str
    edited_at: str
    metrics: MemoryMetrics
    score: float
    feedback_metrics: dict[str, FeedbackMetrics]
    lookup_count: int


class ServiceUnavailableErrorResponse(TypedDict):
    status_code: NotRequired[int]
    service: str


class SubConceptMetrics(TypedDict):
    id: int
    name: str
    description: str | None
    primary_label: int | None
    memory_count: int


TaskStatus = Literal["INITIALIZED", "DISPATCHED", "WAITING", "PROCESSING", "COMPLETED", "FAILED", "ABORTING", "ABORTED"]


class TaskStatusInfo(TypedDict):
    status: TaskStatus
    steps_total: int | None
    steps_completed: int | None
    exception: str | None
    updated_at: str
    created_at: str


TelemetryField = list


class TelemetryFilterItem(TypedDict):
    field: TelemetryField
    op: Literal["==", "!=", ">", ">=", "<", "<=", "in", "not in"]
    value: float | list[float] | int | list[int]


class TelemetrySortOptions(TypedDict):
    field: TelemetryField
    direction: Literal["asc", "desc"]


class UnauthenticatedErrorResponse(TypedDict):
    status_code: NotRequired[int]


class UnauthorizedErrorResponse(TypedDict):
    status_code: NotRequired[int]
    reason: str


class UpdateOrgPlanRequest(TypedDict):
    tier: Literal["FREE", "PRO", "ENTERPRISE", "CANCELLED"]


class UpdatePredictionRequest(TypedDict):
    expected_label: NotRequired[int | None]
    expected_score: NotRequired[float | None]
    tags: NotRequired[list[str]]
    memory_id: NotRequired[str | None]


class ValidationError(TypedDict):
    loc: list[str | int]
    msg: str
    type: str


class DeleteAuthApiKeyByNameOrIdParams(TypedDict):
    name_or_id: str


class GetMemorysetParams(TypedDict):
    type: NotRequired[MemoryType | None]
    show_hidden: NotRequired[bool | None]


class PostMemorysetByNameOrIdCloneParams(TypedDict):
    name_or_id: str


class PatchMemorysetByNameOrIdParams(TypedDict):
    name_or_id: str


class GetMemorysetByNameOrIdParams(TypedDict):
    name_or_id: str


class DeleteMemorysetByNameOrIdParams(TypedDict):
    name_or_id: str


class GetMemorysetByNameOrIdMemoryByMemoryIdParams(TypedDict):
    name_or_id: str
    memory_id: str
    """
    ID of the memory
    """


class DeleteMemorysetByNameOrIdMemoryByMemoryIdParams(TypedDict):
    name_or_id: str
    memory_id: str
    """
    ID of the memory
    """


class GetMemorysetByNameOrIdPotentialDuplicateGroupsParams(TypedDict):
    name_or_id: str


class PostMemorysetByNameOrIdMemoriesGetParams(TypedDict):
    name_or_id: str


class PostMemorysetByNameOrIdMemoriesParams(TypedDict):
    name_or_id: str


class PostMemorysetByNameOrIdMemoriesDeleteParams(TypedDict):
    name_or_id: str


class PostMemorysetByNameOrIdAnalysisParams(TypedDict):
    name_or_id: str


class GetMemorysetByNameOrIdAnalysisParams(TypedDict):
    name_or_id: str
    status: NotRequired[TaskStatus | None]
    limit: NotRequired[int | None]
    offset: NotRequired[int | None]


class GetMemorysetByNameOrIdAnalysisByAnalysisTaskIdParams(TypedDict):
    name_or_id: str
    analysis_task_id: str


class PostMemorysetByNameOrIdMemoryByMemoryIdCascadingEditsParams(TypedDict):
    name_or_id: str
    memory_id: str


class GetFinetunedEmbeddingModelByNameOrIdParams(TypedDict):
    name_or_id: str


class DeleteFinetunedEmbeddingModelByNameOrIdParams(TypedDict):
    name_or_id: str


class PostFinetunedEmbeddingModelByNameOrIdEvaluationParams(TypedDict):
    name_or_id: str


class GetFinetunedEmbeddingModelByNameOrIdEvaluationByTaskIdParams(TypedDict):
    name_or_id: str
    task_id: str


class GetFinetunedEmbeddingModelByNameOrIdEvaluationsParams(TypedDict):
    name_or_id: str


class GetPretrainedEmbeddingModelByModelNameParams(TypedDict):
    model_name: PretrainedEmbeddingModelName


class PostPretrainedEmbeddingModelByModelNameEvaluationParams(TypedDict):
    model_name: PretrainedEmbeddingModelName


class GetPretrainedEmbeddingModelByModelNameEvaluationByTaskIdParams(TypedDict):
    model_name: PretrainedEmbeddingModelName
    task_id: str


class GetPretrainedEmbeddingModelByModelNameEvaluationsParams(TypedDict):
    model_name: PretrainedEmbeddingModelName


class PostDatasourceUploadRequest(TypedDict):
    name: str
    """
    Name for the datasource
    """
    description: NotRequired[str | None]
    """
    Optional description for the datasource
    """


class GetDatasourceByNameOrIdParams(TypedDict):
    name_or_id: str


class DeleteDatasourceByNameOrIdParams(TypedDict):
    name_or_id: str


class PostDatasourceByNameOrIdEmbeddingEvaluationParams(TypedDict):
    name_or_id: str


class GetDatasourceByNameOrIdEmbeddingEvaluationParams(TypedDict):
    name_or_id: str
    status: NotRequired[TaskStatus | None]
    limit: NotRequired[int | None]
    offset: NotRequired[int | None]


class GetDatasourceByNameOrIdEmbeddingEvaluationByTaskIdParams(TypedDict):
    name_or_id: str
    task_id: str


class GetDatasourceByNameOrIdDownloadParams(TypedDict):
    name_or_id: str
    file_type: NotRequired[Literal["hf_dataset", "json", "csv"]]
    """
    File type to download:
    * `hf_dataset`: Zipped HuggingFace dataset (default)
    * `json`: Row-oriented JSON array
    * `csv`: CSV file
    """


class PatchClassificationModelByNameOrIdParams(TypedDict):
    name_or_id: str


class GetClassificationModelByNameOrIdParams(TypedDict):
    name_or_id: str


class DeleteClassificationModelByNameOrIdParams(TypedDict):
    name_or_id: str


class PostClassificationModelByModelNameOrIdEvaluationParams(TypedDict):
    model_name_or_id: str


class GetClassificationModelByModelNameOrIdEvaluationParams(TypedDict):
    model_name_or_id: str


class GetClassificationModelByModelNameOrIdEvaluationByTaskIdParams(TypedDict):
    model_name_or_id: str
    task_id: str


class DeleteClassificationModelByModelNameOrIdEvaluationByTaskIdParams(TypedDict):
    model_name_or_id: str
    task_id: str


class PatchRegressionModelByNameOrIdParams(TypedDict):
    name_or_id: str


class GetRegressionModelByNameOrIdParams(TypedDict):
    name_or_id: str


class DeleteRegressionModelByNameOrIdParams(TypedDict):
    name_or_id: str


class PostRegressionModelByModelNameOrIdEvaluationParams(TypedDict):
    model_name_or_id: str


class GetRegressionModelByModelNameOrIdEvaluationParams(TypedDict):
    model_name_or_id: str


class GetRegressionModelByModelNameOrIdEvaluationByTaskIdParams(TypedDict):
    model_name_or_id: str
    task_id: str


class DeleteRegressionModelByModelNameOrIdEvaluationByTaskIdParams(TypedDict):
    model_name_or_id: str
    task_id: str


class GetTaskByTaskIdParams(TypedDict):
    task_id: str


class GetTaskByTaskIdStatusParams(TypedDict):
    task_id: str


class GetTaskParams(TypedDict):
    status: NotRequired[TaskStatus | list[TaskStatus] | None]
    type: NotRequired[str | list[str] | None]
    limit: NotRequired[int | None]
    offset: NotRequired[int]
    start_timestamp: NotRequired[str | None]
    end_timestamp: NotRequired[str | None]


class DeleteTaskByTaskIdAbortParams(TypedDict):
    task_id: str


class GetTelemetryPredictionByPredictionIdParams(TypedDict):
    prediction_id: str


class PatchTelemetryPredictionByPredictionIdParams(TypedDict):
    prediction_id: str


class GetTelemetryPredictionByPredictionIdExplanationParams(TypedDict):
    prediction_id: str
    refresh: NotRequired[bool]


class GetTelemetryPredictionByPredictionIdActionParams(TypedDict):
    prediction_id: str


class GetTelemetryPredictionByPredictionIdMemorySuggestionsParams(TypedDict):
    prediction_id: str
    """
    ID of the prediction to generate suggestions for
    """
    num_memories: NotRequired[int]
    """
    Number of memory suggestions to generate
    """
    refresh: NotRequired[bool]
    """
    Force the explanation agent to re-run even if a cached explanation exists
    """


class GetTelemetryFeedbackCategoryByNameOrIdParams(TypedDict):
    name_or_id: str


class DeleteTelemetryFeedbackCategoryByNameOrIdParams(TypedDict):
    name_or_id: str


PutTelemetryPredictionFeedbackRequest = list[PredictionFeedbackRequest]


class GetAgentsBootstrapClassificationModelByTaskIdParams(TypedDict):
    task_id: str


class PostGpuMemorysetByNameOrIdLookupParams(TypedDict):
    name_or_id: str


class PatchGpuMemorysetByNameOrIdMemoryParams(TypedDict):
    name_or_id: str


class PostGpuMemorysetByNameOrIdMemoryParams(TypedDict):
    name_or_id: str


PostGpuMemorysetByNameOrIdMemoryRequest = list[LabeledMemoryInsert] | list[ScoredMemoryInsert]


class PatchGpuMemorysetByNameOrIdMemoriesParams(TypedDict):
    name_or_id: str


class PostGpuClassificationModelByNameOrIdPredictionParams(TypedDict):
    name_or_id: str


class PostGpuRegressionModelByNameOrIdPredictionParams(TypedDict):
    name_or_id: str


class PostGpuFinetunedEmbeddingModelByNameOrIdEmbeddingParams(TypedDict):
    name_or_id: str


class PostGpuPretrainedEmbeddingModelByModelNameEmbeddingParams(TypedDict):
    model_name: PretrainedEmbeddingModelName


class FieldValidationError(TypedDict):
    loc: list[str | int]
    msg: str
    type: NotRequired[str]


class AddMemoryRecommendations(TypedDict):
    memories: list[AddMemorySuggestion]


class AnalyzeNeighborLabelsResult(TypedDict):
    label_metrics: list[LabelClassMetrics]
    neighbor_prediction_accuracy: float
    mean_neighbor_label_confidence: float
    mean_neighbor_label_entropy: float
    mean_neighbor_predicted_label_ambiguity: float


class BootstrapClassificationModelRequest(TypedDict):
    model_description: str
    label_names: list[str]
    initial_examples: NotRequired[list[LabeledExample]]
    num_examples_per_label: NotRequired[int]


class BootstrapClassificationModelResult(TypedDict):
    model_description: str
    label_names: list[str]
    model_name: str
    generated_examples: NotRequired[list[LabeledExample]]


class ClassificationMetrics(TypedDict):
    f1_score: float
    accuracy: float
    loss: float
    anomaly_score_mean: NotRequired[float | None]
    anomaly_score_median: NotRequired[float | None]
    anomaly_score_variance: NotRequired[float | None]
    roc_auc: NotRequired[float | None]
    pr_auc: NotRequired[float | None]
    pr_curve: NotRequired[PRCurve | None]
    roc_curve: NotRequired[ROCCurve | None]


class ClassificationModelMetadata(TypedDict):
    id: str
    org_id: str
    name: str
    description: str | None
    notes: str | None
    version: int
    memoryset_id: str
    memory_lookup_count: int
    storage_path: str
    memoryset_collection_name: str
    created_at: str
    updated_at: str
    locked: bool
    num_classes: int
    head_type: RACHeadType
    weigh_memories: bool | None
    min_memory_weight: float | None


class ClassificationPredictionRequest(TypedDict):
    input_values: list[str] | list[bytes] | list[str | bytes]
    expected_labels: NotRequired[list[int] | None]
    filters: NotRequired[list[FilterItem]]
    tags: NotRequired[list[str]]
    memoryset_override_name_or_id: NotRequired[str | None]
    save_telemetry: NotRequired[bool]
    save_telemetry_synchronously: NotRequired[bool]
    prompt: NotRequired[str | None]
    use_lookup_cache: NotRequired[bool]
    consistency_level: NotRequired[Literal["Bounded", "Session", "Strong", "Eventual"] | None]


class CloneMemorysetRequest(TypedDict):
    name: str
    description: NotRequired[str | None]
    notes: NotRequired[str | None]
    pretrained_embedding_model_name: NotRequired[PretrainedEmbeddingModelName | None]
    finetuned_embedding_model_name_or_id: NotRequired[str | None]
    max_seq_length_override: NotRequired[int | None]
    prompt: NotRequired[str]


class ColumnInfo(TypedDict):
    name: str
    type: ColumnType
    enum_options: NotRequired[list[str] | None]
    int_values: NotRequired[list[int] | None]


class ConceptMetrics(TypedDict):
    id: int
    name: str
    description: str | None
    primary_label: int | None
    memory_count: int
    subconcepts: list[SubConceptMetrics]


class CreateClassificationModelRequest(TypedDict):
    name: str
    description: NotRequired[str | None]
    notes: NotRequired[str | None]
    memoryset_name: NotRequired[str | None]
    memoryset_name_or_id: str
    memory_lookup_count: NotRequired[int | None]
    head_type: NotRequired[RACHeadType]
    weigh_memories: NotRequired[bool | None]
    min_memory_weight: NotRequired[float | None]
    num_classes: NotRequired[int | None]


class CreateMemorysetRequest(TypedDict):
    name: str
    description: NotRequired[str | None]
    notes: NotRequired[str | None]
    datasource_name_or_id: str
    datasource_label_column: NotRequired[str | None]
    datasource_score_column: NotRequired[str | None]
    datasource_value_column: str
    datasource_source_id_column: NotRequired[str | None]
    remove_duplicates: NotRequired[bool]
    pretrained_embedding_model_name: NotRequired[PretrainedEmbeddingModelName | None]
    finetuned_embedding_model_name_or_id: NotRequired[str | None]
    max_seq_length_override: NotRequired[int | None]
    label_names: NotRequired[list[str] | None]
    index_type: NotRequired[Literal["FLAT", "IVF_FLAT", "IVF_SQ8", "IVF_PQ", "HNSW", "DISKANN"]]
    index_params: NotRequired[dict[str, int | float | str]]
    prompt: NotRequired[str]
    hidden: NotRequired[bool]


class CreateRegressionModelRequest(TypedDict):
    name: str
    description: NotRequired[str | None]
    notes: NotRequired[str | None]
    memoryset_name_or_id: str
    memory_lookup_count: NotRequired[int | None]
    head_type: NotRequired[RARHeadType]


class DatasourceEmbeddingEvaluationsRequest(TypedDict):
    value_column: str
    label_column: str
    source_id_column: str | None
    neighbor_count: NotRequired[int]
    label_names: NotRequired[list[str] | None]
    embedding_models: NotRequired[list[PretrainedEmbeddingModelName | str] | None]


class DatasourceEmbeddingEvaluationsTaskPayload(TypedDict):
    value_column: str
    label_column: str
    source_id_column: str | None
    neighbor_count: NotRequired[int]
    label_names: NotRequired[list[str] | None]
    embedding_models: NotRequired[list[PretrainedEmbeddingModelName | str] | None]
    datasource_id: str


class DatasourceMetadata(TypedDict):
    id: str
    org_id: str
    name: str
    description: str | None
    storage_path: str
    length: int
    columns: list[ColumnInfo]
    created_at: str
    updated_at: str


class EmbeddingEvaluationResponse(TypedDict):
    task_id: str
    org_id: str
    status: TaskStatus
    result: ClassificationMetrics | RegressionMetrics | None
    created_at: str
    updated_at: str


class EmbeddingEvaluationResponseUnionClassificationMetricsRegressionMetrics(TypedDict):
    task_id: str
    org_id: str
    status: TaskStatus
    result: ClassificationMetrics | RegressionMetrics | None
    created_at: str
    updated_at: str


class EmbeddingModelResult(TypedDict):
    embedding_model_name: str
    embedding_model_path: str
    analysis_result: AnalyzeNeighborLabelsResult
    memoryset_name: NotRequired[str | None]
    is_finetuned: NotRequired[bool]


class EvaluationResponse(TypedDict):
    task_id: str
    org_id: str
    status: TaskStatus
    result: ClassificationMetrics | RegressionMetrics | None
    created_at: str
    updated_at: str


class EvaluationResponseClassificationMetrics(TypedDict):
    task_id: str
    org_id: str
    status: TaskStatus
    result: ClassificationMetrics | None
    created_at: str
    updated_at: str


class EvaluationResponseRegressionMetrics(TypedDict):
    task_id: str
    org_id: str
    status: TaskStatus
    result: RegressionMetrics | None
    created_at: str
    updated_at: str


class FinetuneEmbeddingModelRequest(TypedDict):
    name: str
    base_model: PretrainedEmbeddingModelName
    train_memoryset_name_or_id: NotRequired[str | None]
    train_datasource_name_or_id: NotRequired[str | None]
    eval_datasource_name_or_id: NotRequired[str | None]
    label_column: NotRequired[str]
    value_column: NotRequired[str]
    training_method: NotRequired[EmbeddingFinetuningMethod]
    training_args: NotRequired[dict[str, str | int | float | bool]]


class FinetunedEmbeddingModelMetadata(TypedDict):
    embedding_dim: int
    max_seq_length: int
    uses_context: bool
    id: str
    org_id: str
    name: str
    storage_path: str
    created_at: str
    updated_at: str
    base_model: PretrainedEmbeddingModelName
    finetuning_task_id: str
    finetuning_status: TaskStatus


class HTTPValidationError(TypedDict):
    detail: NotRequired[list[ValidationError]]


class InvalidInputErrorResponse(TypedDict):
    status_code: NotRequired[int]
    validation_issues: list[FieldValidationError]


class LabelPredictionMemoryLookup(TypedDict):
    value: str | bytes
    embedding: list[float]
    source_id: str | None
    metadata: dict[str, str | int | float | bool | None]
    memory_id: str
    memory_version: int
    created_at: str
    updated_at: str
    edited_at: str
    metrics: MemoryMetrics
    label: int
    label_name: str | None
    lookup_score: float
    prediction_id: str
    attention_weight: float


class LabelPredictionWithMemoriesAndFeedback(TypedDict):
    prediction_id: str
    confidence: float
    anomaly_score: float | None
    label: int
    label_name: str | None
    logits: list[float]
    timestamp: str
    input_value: str | bytes
    input_embedding: list[float]
    expected_label: int | None
    expected_label_name: str | None
    memories: list[LabelPredictionMemoryLookup]
    org_id: str
    memoryset_id: str
    model_id: str
    updated_at: str
    tags: list[str]
    explanation: str | None
    memory_id: str | None
    feedbacks: list[PredictionFeedback]


class LabeledMemory(TypedDict):
    value: str | bytes
    embedding: list[float]
    source_id: str | None
    metadata: dict[str, str | int | float | bool | None]
    memory_id: str
    memory_version: int
    created_at: str
    updated_at: str
    edited_at: str
    metrics: MemoryMetrics
    label: int
    label_name: str | None


class LabeledMemoryLookup(TypedDict):
    value: str | bytes
    embedding: list[float]
    source_id: str | None
    metadata: dict[str, str | int | float | bool | None]
    memory_id: str
    memory_version: int
    created_at: str
    updated_at: str
    edited_at: str
    metrics: MemoryMetrics
    label: int
    label_name: str | None
    lookup_score: float


class LabeledMemoryUpdate(TypedDict):
    memory_id: str
    value: NotRequired[str | bytes]
    metadata: NotRequired[dict[str, str | int | float | bool | None] | None]
    source_id: NotRequired[str | None]
    metrics: NotRequired[MemoryMetrics | None]
    label: NotRequired[int]


class LabeledMemoryWithFeedbackMetrics(TypedDict):
    value: str | bytes
    embedding: list[float]
    source_id: str | None
    metadata: dict[str, str | int | float | bool | None]
    memory_id: str
    memory_version: int
    created_at: str
    updated_at: str
    edited_at: str
    metrics: MemoryMetrics
    label: int
    label_name: str | None
    feedback_metrics: dict[str, FeedbackMetrics]
    lookup_count: int


class ListPredictionsRequest(TypedDict):
    model_id: NotRequired[str | None]
    tag: NotRequired[str | None]
    prediction_ids: NotRequired[list[str] | None]
    start_timestamp: NotRequired[str | None]
    end_timestamp: NotRequired[str | None]
    limit: NotRequired[int | None]
    offset: NotRequired[int | None]
    sort: NotRequired[PredictionSort]
    expected_label_match: NotRequired[bool | None]


class MemorysetAnalysisConfigs(TypedDict):
    neighbor: NotRequired[MemorysetNeighborAnalysisConfig | None]
    label: NotRequired[MemorysetLabelAnalysisConfig | None]
    duplicate: NotRequired[MemorysetDuplicateAnalysisConfig | None]
    projection: NotRequired[MemorysetProjectionAnalysisConfig | None]
    cluster: NotRequired[MemorysetClusterAnalysisConfig | None]
    class_patterns: NotRequired[MemorysetClassPatternsAnalysisConfig | None]
    concepts: NotRequired[MemorysetConceptAnalysisConfig | None]


class MemorysetAnalysisRequest(TypedDict):
    lookup_count: NotRequired[int]
    batch_size: NotRequired[int]
    clear_metrics: NotRequired[bool]
    configs: MemorysetAnalysisConfigs


class MemorysetConceptMetrics(TypedDict):
    concepts: list[ConceptMetrics]
    num_outliers: int
    updated_at: str


class MemorysetMetrics(TypedDict):
    neighbor: NotRequired[MemorysetNeighborMetrics | None]
    label: NotRequired[MemorysetLabelMetrics | None]
    duplicate: NotRequired[MemorysetDuplicateMetrics | None]
    projection: NotRequired[MemorysetProjectionMetrics | None]
    cluster: NotRequired[MemorysetClusterMetrics | None]
    class_patterns: NotRequired[MemorysetClassPatternsMetrics | None]
    concepts: NotRequired[MemorysetConceptMetrics | None]


class PaginatedUnionLabeledMemoryWithFeedbackMetricsScoredMemoryWithFeedbackMetrics(TypedDict):
    items: list[LabeledMemoryWithFeedbackMetrics | ScoredMemoryWithFeedbackMetrics]
    total: int
    offset: int
    limit: int


class PretrainedEmbeddingModelMetadata(TypedDict):
    embedding_dim: int
    max_seq_length: int
    uses_context: bool
    name: PretrainedEmbeddingModelName
    experimental: NotRequired[bool]
    supports_instructions: bool
    num_params: int


class Task(TypedDict):
    status: TaskStatus
    steps_total: int | None
    steps_completed: int | None
    exception: str | None
    updated_at: str
    created_at: str
    id: str
    org_id: str
    type: str
    payload: BaseModel
    result: BaseModel | None


class TelemetryMemoriesRequest(TypedDict):
    memoryset_id: str
    offset: NotRequired[int]
    limit: NotRequired[int]
    filters: NotRequired[list[FilterItem | TelemetryFilterItem]]
    sort: NotRequired[list[TelemetrySortOptions] | None]


PatchGpuMemorysetByNameOrIdMemoryRequest = LabeledMemoryUpdate | ScoredMemoryUpdate


PatchGpuMemorysetByNameOrIdMemoriesRequest = list[LabeledMemoryUpdate] | list[ScoredMemoryUpdate]


class CascadingEditSuggestion(TypedDict):
    neighbor: LabeledMemoryLookup
    suggested_label: int
    lookup_score: float


class EmbeddingEvaluationResult(TypedDict):
    evaluation_results: list[EmbeddingModelResult]


class MemorysetAnalysisResponse(TypedDict):
    task_id: str
    org_id: str
    memoryset_id: str
    status: TaskStatus
    lookup_count: int
    batch_size: int
    clear_metrics: bool
    configs: MemorysetAnalysisConfigs
    results: MemorysetMetrics | None
    created_at: str
    updated_at: str


class MemorysetMetadata(TypedDict):
    id: str
    org_id: str
    collection_name: str
    name: str
    description: str | None
    notes: str | None
    length: int
    pretrained_embedding_model_name: PretrainedEmbeddingModelName | None
    finetuned_embedding_model_id: str | None
    created_at: str
    updated_at: str
    memories_updated_at: str
    insertion_task_id: str
    insertion_status: TaskStatus
    metrics: MemorysetMetrics
    memory_type: MemoryType
    label_names: list[str] | None
    index_type: Literal["FLAT", "IVF_FLAT", "IVF_SQ8", "IVF_PQ", "HNSW", "DISKANN"]
    index_params: dict[str, Any]
    database_uri: str | None
    document_prompt_override: str | None
    query_prompt_override: str | None
    hidden: bool


class PaginatedTask(TypedDict):
    items: list[Task]
    total: int
    offset: int
    limit: int


class BootstrapClassificationModelMeta(TypedDict):
    datasource_meta: DatasourceMetadata
    memoryset_meta: MemorysetMetadata
    model_meta: ClassificationModelMetadata
    agent_output: BootstrapClassificationModelResult


class BootstrapClassificationModelResponse(TypedDict):
    task_id: str
    org_id: str
    status: TaskStatus
    result: BootstrapClassificationModelMeta | None
    input: BootstrapClassificationModelRequest | None


class DatasourceEmbeddingEvaluationsResponse(TypedDict):
    task_id: str
    org_id: str
    datasource_id: str
    status: TaskStatus
    result: EmbeddingEvaluationResult | None
    payload: DatasourceEmbeddingEvaluationsTaskPayload
    created_at: str
    updated_at: str


class OrcaClient(Client):
    @staticmethod
    def _parse_params(
        params: Mapping[str, Any],
        path: str,
    ) -> tuple[dict[str, Any], dict[str, Any]]:
        placeholders = {name for _, name, _, _ in Formatter().parse(path) if name}
        path_params = {k: v for k, v in params.items() if k in placeholders}
        query_params = {k: v for k, v in params.items() if k not in placeholders and v is not None}
        if placeholders - path_params.keys():
            raise ValueError(f"Missing path params: {', '.join(placeholders - path_params.keys())}")
        return path_params, query_params

    @overload
    def GET(
        self,
        path: Literal["/check/alive"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> AliveResponse:
        pass

    @overload
    def GET(
        self,
        path: Literal["/check/ready"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> ReadyResponse:
        pass

    @overload
    def GET(
        self,
        path: Literal["/gpu/check/healthy"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> HealthyResponse:
        pass

    @overload
    def GET(
        self,
        path: Literal["/check/healthy"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> HealthyResponse:
        pass

    @overload
    def GET(
        self,
        path: Literal["/gpu/config"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> dict[str, str | float | int | bool | None]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/config"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> dict[str, str | float | int | bool | None]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/gpu/"],
        *,
        params: None = None,
        parse_as: Literal["text"],
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> str:
        pass

    @overload
    def GET(
        self,
        path: Literal["/"],
        *,
        params: None = None,
        parse_as: Literal["text"],
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> str:
        pass

    @overload
    def GET(
        self,
        path: Literal["/auth/root"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> bool:
        """Return true only when called with a valid root API key; otherwise 401 Unauthenticated."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/auth/api_key"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[ApiKeyMetadata]:
        """List all API keys for the organization."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/auth"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> bool:
        """Returns true if the api key header is valid for the org (will be false for admin api key)"""
        pass

    @overload
    def GET(
        self,
        path: Literal["/auth/org/plan"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> OrgPlan:
        """Get the organization plan."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/memoryset"],
        *,
        params: GetMemorysetParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[MemorysetMetadata]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/memoryset/{name_or_id}"],
        *,
        params: GetMemorysetByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> MemorysetMetadata:
        pass

    @overload
    def GET(
        self,
        path: Literal["/memoryset/{name_or_id}/memory/{memory_id}"],
        *,
        params: GetMemorysetByNameOrIdMemoryByMemoryIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> LabeledMemory | ScoredMemory:
        pass

    @overload
    def GET(
        self,
        path: Literal["/memoryset/{name_or_id}/potential_duplicate_groups"],
        *,
        params: GetMemorysetByNameOrIdPotentialDuplicateGroupsParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[list[LabeledMemory]] | list[list[ScoredMemory]]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/memoryset/{name_or_id}/analysis"],
        *,
        params: GetMemorysetByNameOrIdAnalysisParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[MemorysetAnalysisResponse]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/memoryset/{name_or_id}/analysis/{analysis_task_id}"],
        *,
        params: GetMemorysetByNameOrIdAnalysisByAnalysisTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> MemorysetAnalysisResponse:
        pass

    @overload
    def GET(
        self,
        path: Literal["/finetuned_embedding_model"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[FinetunedEmbeddingModelMetadata]:
        """List all finetuned embedding models for the organization."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/finetuned_embedding_model/{name_or_id}"],
        *,
        params: GetFinetunedEmbeddingModelByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> FinetunedEmbeddingModelMetadata:
        """Get a finetuned embedding model by name or ID."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/finetuned_embedding_model/{name_or_id}/evaluation/{task_id}"],
        *,
        params: GetFinetunedEmbeddingModelByNameOrIdEvaluationByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> EmbeddingEvaluationResponseUnionClassificationMetricsRegressionMetrics:
        """Get evaluation results for a finetuned embedding model by task ID."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/finetuned_embedding_model/{name_or_id}/evaluations"],
        *,
        params: GetFinetunedEmbeddingModelByNameOrIdEvaluationsParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[EmbeddingEvaluationResponseUnionClassificationMetricsRegressionMetrics]:
        """List all evaluation results for a finetuned embedding model."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/pretrained_embedding_model"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[PretrainedEmbeddingModelMetadata]:
        """List all available pretrained embedding models."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/pretrained_embedding_model/{model_name}"],
        *,
        params: GetPretrainedEmbeddingModelByModelNameParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> PretrainedEmbeddingModelMetadata:
        """Get metadata for a specific pretrained embedding model."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/pretrained_embedding_model/{model_name}/evaluation/{task_id}"],
        *,
        params: GetPretrainedEmbeddingModelByModelNameEvaluationByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> EmbeddingEvaluationResponseUnionClassificationMetricsRegressionMetrics:
        """Get evaluation results for a pretrained embedding model by task ID."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/pretrained_embedding_model/{model_name}/evaluations"],
        *,
        params: GetPretrainedEmbeddingModelByModelNameEvaluationsParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[EmbeddingEvaluationResponseUnionClassificationMetricsRegressionMetrics]:
        """List all evaluation results for a pretrained embedding model."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/datasource"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[DatasourceMetadata]:
        """List all datasources for the organization."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/datasource/{name_or_id}"],
        *,
        params: GetDatasourceByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> DatasourceMetadata:
        """Get a datasource by name or ID."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/datasource/{name_or_id}/embedding_evaluation"],
        *,
        params: GetDatasourceByNameOrIdEmbeddingEvaluationParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[DatasourceEmbeddingEvaluationsResponse]:
        """List embedding evaluation tasks for a datasource."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/datasource/{name_or_id}/embedding_evaluation/{task_id}"],
        *,
        params: GetDatasourceByNameOrIdEmbeddingEvaluationByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> DatasourceEmbeddingEvaluationsResponse:
        """Get an embedding evaluation task by ID."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/datasource/{name_or_id}/download"],
        *,
        params: GetDatasourceByNameOrIdDownloadParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[dict[str, Any]]:
        """Download datasource in the specified format."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/datasource/{name_or_id}/download"],
        *,
        params: GetDatasourceByNameOrIdDownloadParams,
        parse_as: Literal["text"],
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> str:
        """Download datasource in the specified format."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/datasource/{name_or_id}/download"],
        *,
        params: GetDatasourceByNameOrIdDownloadParams,
        parse_as: None,
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> bytes:
        """Download datasource in the specified format."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/predictive_model"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[ClassificationModelMetadata | RegressionModelMetadata]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/classification_model"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[ClassificationModelMetadata]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/classification_model/{name_or_id}"],
        *,
        params: GetClassificationModelByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> ClassificationModelMetadata:
        pass

    @overload
    def GET(
        self,
        path: Literal["/classification_model/{model_name_or_id}/evaluation"],
        *,
        params: GetClassificationModelByModelNameOrIdEvaluationParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[EvaluationResponseClassificationMetrics]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/classification_model/{model_name_or_id}/evaluation/{task_id}"],
        *,
        params: GetClassificationModelByModelNameOrIdEvaluationByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> EvaluationResponseClassificationMetrics:
        pass

    @overload
    def GET(
        self,
        path: Literal["/regression_model"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[RegressionModelMetadata]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/regression_model/{name_or_id}"],
        *,
        params: GetRegressionModelByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> RegressionModelMetadata:
        pass

    @overload
    def GET(
        self,
        path: Literal["/regression_model/{model_name_or_id}/evaluation"],
        *,
        params: GetRegressionModelByModelNameOrIdEvaluationParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[EvaluationResponseRegressionMetrics]:
        pass

    @overload
    def GET(
        self,
        path: Literal["/regression_model/{model_name_or_id}/evaluation/{task_id}"],
        *,
        params: GetRegressionModelByModelNameOrIdEvaluationByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> EvaluationResponseRegressionMetrics:
        pass

    @overload
    def GET(
        self,
        path: Literal["/task/{task_id}"],
        *,
        params: GetTaskByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Task:
        pass

    @overload
    def GET(
        self,
        path: Literal["/task/{task_id}/status"],
        *,
        params: GetTaskByTaskIdStatusParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> TaskStatusInfo:
        pass

    @overload
    def GET(
        self,
        path: Literal["/task"],
        *,
        params: GetTaskParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> PaginatedTask:
        pass

    @overload
    def GET(
        self,
        path: Literal["/telemetry/prediction/{prediction_id}"],
        *,
        params: GetTelemetryPredictionByPredictionIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> LabelPredictionWithMemoriesAndFeedback | ScorePredictionWithMemoriesAndFeedback:
        """Get a specific prediction by ID."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/telemetry/prediction/{prediction_id}/explanation"],
        *,
        params: GetTelemetryPredictionByPredictionIdExplanationParams,
        parse_as: Literal["text"],
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> str:
        """Get explanation for a prediction, optionally streaming the response."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/telemetry/prediction/{prediction_id}/action"],
        *,
        params: GetTelemetryPredictionByPredictionIdActionParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> ActionRecommendation:
        """Get action recommendation for improving a specific prediction."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/telemetry/prediction/{prediction_id}/memory_suggestions"],
        *,
        params: GetTelemetryPredictionByPredictionIdMemorySuggestionsParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> AddMemoryRecommendations:
        """
        Generate synthetic memory suggestions to improve a specific prediction.

        The returned suggestions have labels as string representations of integer indices
        corresponding to the memoryset's label_names.
        """
        pass

    @overload
    def GET(
        self,
        path: Literal["/telemetry/feedback_category"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[PredictionFeedbackCategory]:
        """List all feedback categories for the organization."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/telemetry/feedback_category/{name_or_id}"],
        *,
        params: GetTelemetryFeedbackCategoryByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> PredictionFeedbackCategory:
        """Get a feedback category by name or ID."""
        pass

    @overload
    def GET(
        self,
        path: Literal["/agents/bootstrap_classification_model/{task_id}"],
        *,
        params: GetAgentsBootstrapClassificationModelByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> BootstrapClassificationModelResponse:
        """Get the status of a bootstrap classification model task"""
        pass

    def GET(
        self,
        path: str,
        *,
        params: Mapping[str, Any] | None = None,
        parse_as: Literal["json", "text"] | None = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Any:
        path_params, query_params = self._parse_params(params or {}, path)
        res = self.get(
            path.format(**path_params),
            params=query_params,
            headers=headers,
            cookies=cookies,
            auth=auth,
            follow_redirects=follow_redirects,
            timeout=timeout,
            extensions=extensions,
        ).raise_for_status()
        return (
            None
            if res.status_code == 204
            else res.json() if parse_as == "json" else res.text if parse_as == "text" else res.content
        )

    @overload
    def POST(
        self,
        path: Literal["/auth/api_key"],
        *,
        params: None = None,
        json: CreateApiKeyRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> CreateApiKeyResponse:
        """Create a new API key for the organization."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/auth/org/plan"],
        *,
        params: None = None,
        json: CreateOrgPlanRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> OrgPlan:
        """Create an organization plan."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/memoryset"],
        *,
        params: None = None,
        json: CreateMemorysetRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> MemorysetMetadata:
        pass

    @overload
    def POST(
        self,
        path: Literal["/memoryset/{name_or_id}/clone"],
        *,
        params: PostMemorysetByNameOrIdCloneParams,
        json: CloneMemorysetRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> MemorysetMetadata:
        pass

    @overload
    def POST(
        self,
        path: Literal["/batch_delete_memoryset"],
        *,
        params: None = None,
        json: DeleteMemorysetsRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def POST(
        self,
        path: Literal["/memoryset/{name_or_id}/memories/get"],
        *,
        params: PostMemorysetByNameOrIdMemoriesGetParams,
        json: GetMemoriesRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[LabeledMemory] | list[ScoredMemory]:
        pass

    @overload
    def POST(
        self,
        path: Literal["/memoryset/{name_or_id}/memories"],
        *,
        params: PostMemorysetByNameOrIdMemoriesParams,
        json: ListMemoriesRequest | None = None,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[LabeledMemory] | list[ScoredMemory]:
        pass

    @overload
    def POST(
        self,
        path: Literal["/memoryset/{name_or_id}/memories/delete"],
        *,
        params: PostMemorysetByNameOrIdMemoriesDeleteParams,
        json: DeleteMemoriesRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def POST(
        self,
        path: Literal["/memoryset/{name_or_id}/analysis"],
        *,
        params: PostMemorysetByNameOrIdAnalysisParams,
        json: MemorysetAnalysisRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> MemorysetAnalysisResponse:
        pass

    @overload
    def POST(
        self,
        path: Literal["/memoryset/{name_or_id}/memory/{memory_id}/cascading_edits"],
        *,
        params: PostMemorysetByNameOrIdMemoryByMemoryIdCascadingEditsParams,
        json: CascadeEditSuggestionsRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[CascadingEditSuggestion]:
        pass

    @overload
    def POST(
        self,
        path: Literal["/finetuned_embedding_model"],
        *,
        params: None = None,
        json: FinetuneEmbeddingModelRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> FinetunedEmbeddingModelMetadata:
        """Create a finetuned embedding model."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/finetuned_embedding_model/{name_or_id}/evaluation"],
        *,
        params: PostFinetunedEmbeddingModelByNameOrIdEvaluationParams,
        json: EmbeddingEvaluationRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> EmbeddingEvaluationResponse:
        """Evaluate a finetuned embedding model as a KNN classifier or regressor."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/pretrained_embedding_model/{model_name}/evaluation"],
        *,
        params: PostPretrainedEmbeddingModelByModelNameEvaluationParams,
        json: EmbeddingEvaluationRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> EmbeddingEvaluationResponse:
        """Evaluate a pretrained embedding model as a KNN classifier or regressor."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/datasource/upload"],
        *,
        params: None = None,
        json: None = None,
        data: PostDatasourceUploadRequest,
        files: dict[Literal["files"], FileTypes] | list[tuple[Literal["files"], FileTypes]],
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> DatasourceMetadata:
        """
        Create a datasource by uploading files.

        Supports multiple file upload scenarios:
        - Multiple files: HuggingFace Dataset format (dataset_info.json, state.json, .arrow files, etc.)
        - Single file: CSV, JSON, JSONL, Parquet, or Pickle files
        """
        pass

    @overload
    def POST(
        self,
        path: Literal["/datasource"],
        *,
        params: None = None,
        json: CreateDatasourceFromContentRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> DatasourceMetadata:
        """
        Create a datasource from JSON content.

        Automatically detects and supports multiple JSON formats:
        - List of records: [{"col1": val1, "col2": val2}, {"col1": val3, "col2": val4}, ...]
        - Dictionary of columns: {"col1": [val1, val3, ...], "col2": [val2, val4, ...]}
        """
        pass

    @overload
    def POST(
        self,
        path: Literal["/datasource/{name_or_id}/embedding_evaluation"],
        *,
        params: PostDatasourceByNameOrIdEmbeddingEvaluationParams,
        json: DatasourceEmbeddingEvaluationsRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> DatasourceEmbeddingEvaluationsResponse:
        """Create an embedding evaluation task for a datasource."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/classification_model"],
        *,
        params: None = None,
        json: CreateClassificationModelRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> ClassificationModelMetadata:
        pass

    @overload
    def POST(
        self,
        path: Literal["/classification_model/{model_name_or_id}/evaluation"],
        *,
        params: PostClassificationModelByModelNameOrIdEvaluationParams,
        json: ClassificationEvaluationRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> EvaluationResponse:
        pass

    @overload
    def POST(
        self,
        path: Literal["/regression_model"],
        *,
        params: None = None,
        json: CreateRegressionModelRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> RegressionModelMetadata:
        pass

    @overload
    def POST(
        self,
        path: Literal["/regression_model/{model_name_or_id}/evaluation"],
        *,
        params: PostRegressionModelByModelNameOrIdEvaluationParams,
        json: RegressionEvaluationRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> EvaluationResponse:
        pass

    @overload
    def POST(
        self,
        path: Literal["/telemetry/prediction"],
        *,
        params: None = None,
        json: ListPredictionsRequest | None = None,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[LabelPredictionWithMemoriesAndFeedback | ScorePredictionWithMemoriesAndFeedback]:
        """List predictions with optional filtering and sorting."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/telemetry/prediction/count"],
        *,
        params: None = None,
        json: CountPredictionsRequest | None = None,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> int:
        """Count predictions with optional filtering."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/telemetry/memories"],
        *,
        params: None = None,
        json: TelemetryMemoriesRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> PaginatedUnionLabeledMemoryWithFeedbackMetricsScoredMemoryWithFeedbackMetrics:
        """
        List memories with feedback metrics.
        **Note**: This endpoint will ONLY return memories that have been used in a prediction.
        If you want to query ALL memories WITHOUT feedback metrics, use the query_memoryset endpoint.
        """
        pass

    @overload
    def POST(
        self,
        path: Literal["/agents/bootstrap_classification_model"],
        *,
        params: None = None,
        json: BootstrapClassificationModelRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> BootstrapClassificationModelResponse:
        """
        Bootstrap a classification model by creating a memoryset with generated memories and a classification model.

        This endpoint uses the bootstrap_classification_model agent to generate:
        1. Memoryset configuration with appropriate settings
        2. Model configuration with optimal parameters
        3. High-quality training memories for each label

        The process involves:
        1. Calling the agent to generate configurations and memories
        2. Creating a datasource from the generated memories
        3. Creating a memoryset from the datasource
        4. Creating a classification model from the memoryset
        """
        pass

    @overload
    def POST(
        self,
        path: Literal["/gpu/memoryset/{name_or_id}/lookup"],
        *,
        params: PostGpuMemorysetByNameOrIdLookupParams,
        json: LookupRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[list[LabeledMemoryLookup | ScoredMemoryLookup]]:
        pass

    @overload
    def POST(
        self,
        path: Literal["/gpu/memoryset/{name_or_id}/memory"],
        *,
        params: PostGpuMemorysetByNameOrIdMemoryParams,
        json: PostGpuMemorysetByNameOrIdMemoryRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[str]:
        pass

    @overload
    def POST(
        self,
        path: Literal["/gpu/classification_model/{name_or_id}/prediction"],
        *,
        params: PostGpuClassificationModelByNameOrIdPredictionParams,
        json: ClassificationPredictionRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[BaseLabelPredictionResult]:
        pass

    @overload
    def POST(
        self,
        path: Literal["/gpu/regression_model/{name_or_id}/prediction"],
        *,
        params: PostGpuRegressionModelByNameOrIdPredictionParams,
        json: RegressionPredictionRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[BaseScorePredictionResult]:
        pass

    @overload
    def POST(
        self,
        path: Literal["/gpu/finetuned_embedding_model/{name_or_id}/embedding"],
        *,
        params: PostGpuFinetunedEmbeddingModelByNameOrIdEmbeddingParams,
        json: EmbedRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[list[float]]:
        """Embed values using a finetuned embedding model."""
        pass

    @overload
    def POST(
        self,
        path: Literal["/gpu/pretrained_embedding_model/{model_name}/embedding"],
        *,
        params: PostGpuPretrainedEmbeddingModelByModelNameEmbeddingParams,
        json: EmbedRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[list[float]]:
        """Embed values using a pretrained embedding model."""
        pass

    def POST(
        self,
        path: str,
        *,
        params: Mapping[str, Any] | None = None,
        json: Any | None = None,
        data: Mapping[str, Any] | None = None,
        content: RequestContent | None = None,
        files: dict[Any, FileTypes] | list[tuple[Any, FileTypes]] | None = None,
        parse_as: Literal["json", "text"] | None = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Any:
        path_params, query_params = self._parse_params(params or {}, path)
        res = self.post(
            path.format(**path_params),
            params=query_params,
            content=content,
            data=data,
            files=files,
            json=json,
            headers=headers,
            cookies=cookies,
            auth=auth,
            follow_redirects=follow_redirects,
            timeout=timeout,
            extensions=extensions,
        ).raise_for_status()
        return (
            None
            if res.status_code == 204
            else res.json() if parse_as == "json" else res.text if parse_as == "text" else res.content
        )

    @overload
    def DELETE(
        self,
        path: Literal["/auth/api_key/{name_or_id}"],
        *,
        params: DeleteAuthApiKeyByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        """Delete an API key by name or ID."""
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/auth/org"],
        *,
        params: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        """Deletes the org and all associated resources"""
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/memoryset/{name_or_id}"],
        *,
        params: DeleteMemorysetByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/memoryset/{name_or_id}/memory/{memory_id}"],
        *,
        params: DeleteMemorysetByNameOrIdMemoryByMemoryIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/finetuned_embedding_model/{name_or_id}"],
        *,
        params: DeleteFinetunedEmbeddingModelByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        """Delete a finetuned embedding model by name or ID."""
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/datasource/{name_or_id}"],
        *,
        params: DeleteDatasourceByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        """Delete a datasource by name or ID."""
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/classification_model/{name_or_id}"],
        *,
        params: DeleteClassificationModelByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/classification_model/{model_name_or_id}/evaluation/{task_id}"],
        *,
        params: DeleteClassificationModelByModelNameOrIdEvaluationByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/regression_model/{name_or_id}"],
        *,
        params: DeleteRegressionModelByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/regression_model/{model_name_or_id}/evaluation/{task_id}"],
        *,
        params: DeleteRegressionModelByModelNameOrIdEvaluationByTaskIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/task/{task_id}/abort"],
        *,
        params: DeleteTaskByTaskIdAbortParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        pass

    @overload
    def DELETE(
        self,
        path: Literal["/telemetry/feedback_category/{name_or_id}"],
        *,
        params: DeleteTelemetryFeedbackCategoryByNameOrIdParams,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> None:
        """Delete a feedback category and all associated feedback records."""
        pass

    def DELETE(
        self,
        path: str,
        *,
        params: Mapping[str, Any] | None = None,
        parse_as: Literal["json", "text"] | None = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Any:
        path_params, query_params = self._parse_params(params or {}, path)
        res = self.delete(
            path.format(**path_params),
            params=query_params,
            headers=headers,
            cookies=cookies,
            auth=auth,
            follow_redirects=follow_redirects,
            timeout=timeout,
            extensions=extensions,
        ).raise_for_status()
        return (
            None
            if res.status_code == 204
            else res.json() if parse_as == "json" else res.text if parse_as == "text" else res.content
        )

    @overload
    def PUT(
        self,
        path: Literal["/auth/org/plan"],
        *,
        params: None = None,
        json: UpdateOrgPlanRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> OrgPlan:
        """Update the organization plan."""
        pass

    @overload
    def PUT(
        self,
        path: Literal["/telemetry/prediction/feedback"],
        *,
        params: None = None,
        json: PutTelemetryPredictionFeedbackRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> PredictionFeedbackResult:
        """Record feedback for predictions, handling updates, deletions, and insertions."""
        pass

    def PUT(
        self,
        path: str,
        *,
        params: Mapping[str, Any] | None = None,
        json: Any | None = None,
        data: Mapping[str, Any] | None = None,
        content: RequestContent | None = None,
        files: dict[Any, FileTypes] | list[tuple[Any, FileTypes]] | None = None,
        parse_as: Literal["json", "text"] | None = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Any:
        path_params, query_params = self._parse_params(params or {}, path)
        res = self.put(
            path.format(**path_params),
            params=query_params,
            content=content,
            data=data,
            files=files,
            json=json,
            headers=headers,
            cookies=cookies,
            auth=auth,
            follow_redirects=follow_redirects,
            timeout=timeout,
            extensions=extensions,
        ).raise_for_status()
        return (
            None
            if res.status_code == 204
            else res.json() if parse_as == "json" else res.text if parse_as == "text" else res.content
        )

    @overload
    def PATCH(
        self,
        path: Literal["/memoryset/{name_or_id}"],
        *,
        params: PatchMemorysetByNameOrIdParams,
        json: MemorysetUpdate,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> MemorysetMetadata:
        pass

    @overload
    def PATCH(
        self,
        path: Literal["/classification_model/{name_or_id}"],
        *,
        params: PatchClassificationModelByNameOrIdParams,
        json: PredictiveModelUpdate,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> ClassificationModelMetadata:
        pass

    @overload
    def PATCH(
        self,
        path: Literal["/regression_model/{name_or_id}"],
        *,
        params: PatchRegressionModelByNameOrIdParams,
        json: PredictiveModelUpdate,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> RegressionModelMetadata:
        pass

    @overload
    def PATCH(
        self,
        path: Literal["/telemetry/prediction/{prediction_id}"],
        *,
        params: PatchTelemetryPredictionByPredictionIdParams,
        json: UpdatePredictionRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Any:
        """Update a prediction with new expected values, tags, or memory ID."""
        pass

    @overload
    def PATCH(
        self,
        path: Literal["/gpu/memoryset/{name_or_id}/memory"],
        *,
        params: PatchGpuMemorysetByNameOrIdMemoryParams,
        json: PatchGpuMemorysetByNameOrIdMemoryRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> LabeledMemory | ScoredMemory:
        pass

    @overload
    def PATCH(
        self,
        path: Literal["/gpu/memoryset/{name_or_id}/memories"],
        *,
        params: PatchGpuMemorysetByNameOrIdMemoriesParams,
        json: PatchGpuMemorysetByNameOrIdMemoriesRequest,
        data: None = None,
        files: None = None,
        content: None = None,
        parse_as: Literal["json"] = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> list[LabeledMemory] | list[ScoredMemory]:
        pass

    def PATCH(
        self,
        path: str,
        *,
        params: Mapping[str, Any] | None = None,
        json: Any | None = None,
        data: Mapping[str, Any] | None = None,
        content: RequestContent | None = None,
        files: dict[Any, FileTypes] | list[tuple[Any, FileTypes]] | None = None,
        parse_as: Literal["json", "text"] | None = "json",
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Any:
        path_params, query_params = self._parse_params(params or {}, path)
        res = self.patch(
            path.format(**path_params),
            params=query_params,
            content=content,
            data=data,
            files=files,
            json=json,
            headers=headers,
            cookies=cookies,
            auth=auth,
            follow_redirects=follow_redirects,
            timeout=timeout,
            extensions=extensions,
        ).raise_for_status()
        return (
            None
            if res.status_code == 204
            else res.json() if parse_as == "json" else res.text if parse_as == "text" else res.content
        )

    @property
    def base_url(self) -> URL:
        # lazy init base_url from environment variable
        if str(self._base_url) == "":
            self.base_url = os.environ.get("ORCA_API_URL", "https://api.orcadb.ai/")
        return self._base_url

    @base_url.setter
    def base_url(self, url: URL | str) -> None:
        Client.base_url.__set__(self, url)

    @property
    def headers(self) -> Headers:
        # lazy init headers from environment variable
        if not self._headers.get("Api-Key"):
            Client.headers.__set__(self, Headers({"Api-Key": os.environ.get("ORCA_API_KEY", "")}))
        return self._headers

    @headers.setter
    def headers(self, headers: HeaderTypes) -> None:
        Client.headers.__set__(self, headers)


def _read_json_response(response: Response) -> dict[str, Any]:
    content = response.read()
    text = content.decode(response.encoding or "utf-8")
    return json.loads(text)


def _raise_error_for_response(response: Response) -> None:
    if response.status_code == 401:
        raise ValueError("Invalid API key")
    # elif response.status_code == 402:
    #     res = cast(QuotaExceededErrorResponse, _read_json_response(response))
    #     raise RuntimeError(
    #         f"{res['quota_type'].replace('_', ' ').title()} limit reached ({res['current']}/{res['quota_limit']})"
    #     )
    elif response.status_code == 403:
        raise PermissionError(_read_json_response(response)["reason"])
    elif response.status_code == 404:
        res = cast(NotFoundErrorResponse, _read_json_response(response))
        if res["resource"] is not None:
            raise LookupError(f"The {res['resource']} you are looking for does not exist")
        else:
            raise RuntimeError(f"Unknown API route: {response.url}")
    elif response.status_code == 405:
        raise RuntimeError(f"Unknown method {response.request.method} for API route: {response.url}")
    elif response.status_code == 409:
        res = cast(ConstraintViolationErrorResponse, _read_json_response(response))
        raise RuntimeError(res["constraint"])
    elif response.status_code == 422:
        res = cast(InvalidInputErrorResponse, _read_json_response(response))
        issues = [f"{issue['loc'][-1]}: {issue['msg']}" for issue in res["validation_issues"]]
        raise ValueError("Invalid input:\n\t" + "\n\t".join(issues))
    elif response.status_code == 500:
        res = cast(InternalServerErrorResponse, _read_json_response(response))
        raise RuntimeError(f"Unexpected server error: {res['message']}")
    elif response.status_code == 503:
        raise RuntimeError("Orca API is currently unavailable, please try again later")
    elif response.status_code >= 400:
        raise RuntimeError(f"Unexpected status code: {response.status_code}")


def _instrument_request(request: Request) -> None:
    request.headers["X-Request-ID"] = str(uuid.uuid4())


logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.ERROR)

orca_api = OrcaClient(
    event_hooks={"request": [_instrument_request], "response": [_raise_error_for_response]},
    follow_redirects=True,
    timeout=Timeout(connect=3, read=20, write=10, pool=5),
)
"""Typed client for the Orca API"""
