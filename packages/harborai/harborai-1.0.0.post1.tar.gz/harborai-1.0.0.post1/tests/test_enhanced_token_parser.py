#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºTokenè§£æå™¨æµ‹è¯•

æµ‹è¯•å„å‚å•†ç‰¹æ®Šæ ¼å¼çš„Tokenè§£æåŠŸèƒ½ï¼ŒåŒ…æ‹¬é™çº§ç­–ç•¥å’Œé”™è¯¯æ¢å¤æœºåˆ¶ã€‚
"""

import pytest
import json
from typing import Dict, Any
from unittest.mock import patch, MagicMock

from harborai.core.enhanced_token_parser import (
    EnhancedTokenParser,
    TokenParsingResult,
    VendorType,
    parse_token_usage,
    get_token_parsing_stats
)


class TestEnhancedTokenParser:
    """å¢å¼ºTokenè§£æå™¨æµ‹è¯•ç±»"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.parser = EnhancedTokenParser()
        self.parser.reset_statistics()
        self.parser.clear_cache()
    
    def test_openai_standard_format(self):
        """æµ‹è¯•OpenAIæ ‡å‡†æ ¼å¼è§£æ"""
        response_data = {
            "usage": {
                "prompt_tokens": 100,
                "completion_tokens": 50,
                "total_tokens": 150
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.OPENAI)
        
        assert result.prompt_tokens == 100
        assert result.completion_tokens == 50
        assert result.total_tokens == 150
        assert result.vendor == VendorType.OPENAI
        assert result.parsing_method == "standard"
        assert result.confidence > 0.8
        assert not result.fallback_used
    
    def test_deepseek_reasoning_tokens(self):
        """æµ‹è¯•DeepSeekæ¨ç†Tokenæ ¼å¼"""
        response_data = {
            "usage": {
                "prompt_tokens": 100,
                "completion_tokens": 50,
                "reasoning_tokens": 25,
                "total_tokens": 175
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.DEEPSEEK)
        
        assert result.prompt_tokens == 100
        assert result.completion_tokens == 75  # completion + reasoning
        assert result.total_tokens == 175
        assert result.vendor == VendorType.DEEPSEEK
        assert "deepseek_reasoning" in result.parsing_method
        assert result.confidence > 0.8
    
    def test_baidu_ernie_format(self):
        """æµ‹è¯•ç™¾åº¦ERNIEæ ¼å¼"""
        response_data = {
            "result": {
                "usage": {
                    "prompt_tokens": 80,
                    "completion_tokens": 40,
                    "total_tokens": 120
                }
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.BAIDU)
        
        assert result.prompt_tokens == 80
        assert result.completion_tokens == 40
        assert result.total_tokens == 120
        assert result.vendor == VendorType.BAIDU
        assert "baidu_ernie" in result.parsing_method
        assert result.confidence > 0.8
    
    def test_doubao_answer_tokens(self):
        """æµ‹è¯•è±†åŒ…answer_tokensæ ¼å¼"""
        response_data = {
            "usage": {
                "prompt_tokens": 90,
                "answer_tokens": 45,
                "total_tokens": 135
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.BYTEDANCE)
        
        assert result.prompt_tokens == 90
        assert result.completion_tokens == 45
        assert result.total_tokens == 135
        assert result.vendor == VendorType.BYTEDANCE
        assert "doubao_format" in result.parsing_method
        assert result.confidence > 0.8
    
    def test_claude_input_output_tokens(self):
        """æµ‹è¯•Claude input/output tokensæ ¼å¼"""
        response_data = {
            "usage": {
                "input_tokens": 120,
                "output_tokens": 60
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.ANTHROPIC)
        
        assert result.prompt_tokens == 120
        assert result.completion_tokens == 60
        assert result.total_tokens == 180
        assert result.vendor == VendorType.ANTHROPIC
        assert "claude_format" in result.parsing_method
        assert result.confidence > 0.8
    
    def test_gemini_usage_metadata(self):
        """æµ‹è¯•Gemini usage_metadataæ ¼å¼"""
        response_data = {
            "usage_metadata": {
                "prompt_token_count": 110,
                "candidates_token_count": 55,
                "total_token_count": 165
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.GOOGLE)
        
        assert result.prompt_tokens == 110
        assert result.completion_tokens == 55
        assert result.total_tokens == 165
        assert result.vendor == VendorType.GOOGLE
        assert "gemini_format" in result.parsing_method
        assert result.confidence > 0.8
    
    def test_alternative_field_mapping(self):
        """æµ‹è¯•å¤‡é€‰å­—æ®µæ˜ å°„"""
        response_data = {
            "token_usage": {
                "input_tokens": 100,
                "output_tokens": 50,
                "total_tokens": 150
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.OPENAI)
        
        assert result.prompt_tokens == 100
        assert result.completion_tokens == 50
        assert result.total_tokens == 150
        assert "alternative" in result.parsing_method
        assert result.confidence > 0.8
    
    def test_fallback_extraction(self):
        """æµ‹è¯•é™çº§æå–ç­–ç•¥"""
        response_data = {
            "data": {
                "prompt_tokens": 80,
                "completion_tokens": 40,
                "total_tokens": 120
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.UNKNOWN)
        
        assert result.prompt_tokens == 80
        assert result.completion_tokens == 40
        assert result.total_tokens == 120
        assert result.parsing_method == "fallback_extraction"
        assert result.confidence == 0.7
        assert result.fallback_used
    
    def test_content_estimation(self):
        """æµ‹è¯•åŸºäºå†…å®¹çš„Tokenä¼°ç®—"""
        response_data = {
            "choices": [
                {
                    "message": {
                        "content": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“åº”å†…å®¹ï¼Œç”¨äºéªŒè¯Tokenä¼°ç®—åŠŸèƒ½ã€‚"
                    }
                }
            ]
        }
        
        request_data = {
            "messages": [
                {
                    "role": "user",
                    "content": "è¯·ç”Ÿæˆä¸€ä¸ªæµ‹è¯•å“åº”"
                }
            ]
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.UNKNOWN, request_data=request_data)
        
        assert result.prompt_tokens > 0
        assert result.completion_tokens > 0
        assert result.total_tokens > 0
        assert result.parsing_method == "content_estimation"
        assert result.confidence == 0.5
        assert result.fallback_used
    
    def test_vendor_detection_from_model(self):
        """æµ‹è¯•ä»æ¨¡å‹åç§°æ£€æµ‹å‚å•†"""
        test_cases = [
            ("gpt-4", VendorType.OPENAI),
            ("deepseek-chat", VendorType.DEEPSEEK),
            ("ernie-bot", VendorType.BAIDU),
            ("doubao-pro", VendorType.BYTEDANCE),
            ("claude-3", VendorType.ANTHROPIC),
            ("gemini-pro", VendorType.GOOGLE),
            ("unknown-model", VendorType.UNKNOWN)
        ]
        
        for model, expected_vendor in test_cases:
            detected = self.parser._detect_vendor_from_response({}, model)
            assert detected == expected_vendor, f"æ¨¡å‹ {model} åº”è¯¥æ£€æµ‹ä¸º {expected_vendor}"
    
    def test_vendor_detection_from_response_structure(self):
        """æµ‹è¯•ä»å“åº”ç»“æ„æ£€æµ‹å‚å•†"""
        # Geminiæ ¼å¼
        response_data = {"usage_metadata": {}}
        detected = self.parser._detect_vendor_from_response(response_data)
        assert detected == VendorType.GOOGLE
        
        # ç™¾åº¦æ ¼å¼
        response_data = {"result": {"usage": {}}}
        detected = self.parser._detect_vendor_from_response(response_data)
        assert detected == VendorType.BAIDU
    
    def test_token_validation(self):
        """æµ‹è¯•Tokenæ•°æ®éªŒè¯"""
        # æœ‰æ•ˆæ•°æ®
        assert self.parser._validate_token_data(100, 50, 150)
        assert self.parser._validate_token_data(0, 0, 0)
        
        # æ— æ•ˆæ•°æ®
        assert not self.parser._validate_token_data(-1, 50, 150)  # è´Ÿæ•°
        assert not self.parser._validate_token_data(100, 50, 200)  # æ€»æ•°ä¸åŒ¹é…
        assert not self.parser._validate_token_data(1000000, 50, 1000050)  # è¿‡å¤§å€¼
        assert not self.parser._validate_token_data("invalid", 50, 150)  # éæ•°å­—
    
    def test_vendor_estimation_ratios(self):
        """æµ‹è¯•å‚å•†ç‰¹å®šçš„ä¼°ç®—æ¯”ä¾‹"""
        ratios = {
            VendorType.OPENAI: 0.25,
            VendorType.DEEPSEEK: 0.25,
            VendorType.BAIDU: 0.5,
            VendorType.BYTEDANCE: 0.4,
            VendorType.ANTHROPIC: 0.25,
            VendorType.GOOGLE: 0.3,
            VendorType.UNKNOWN: 0.25
        }
        
        for vendor, expected_ratio in ratios.items():
            actual_ratio = self.parser._get_vendor_estimation_ratio(vendor)
            assert actual_ratio == expected_ratio
    
    def test_caching_mechanism(self):
        """æµ‹è¯•ç¼“å­˜æœºåˆ¶"""
        response_data = {
            "usage": {
                "prompt_tokens": 100,
                "completion_tokens": 50,
                "total_tokens": 150
            }
        }
        
        # ç¬¬ä¸€æ¬¡è§£æ
        result1 = self.parser.parse_token_usage(response_data, VendorType.OPENAI)
        stats1 = self.parser.get_parsing_statistics()
        
        # ç¬¬äºŒæ¬¡è§£æï¼ˆåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼‰
        result2 = self.parser.parse_token_usage(response_data, VendorType.OPENAI)
        stats2 = self.parser.get_parsing_statistics()
        
        assert result1.prompt_tokens == result2.prompt_tokens
        assert result1.completion_tokens == result2.completion_tokens
        assert stats2['cache_hits'] > stats1['cache_hits']
    
    def test_statistics_tracking(self):
        """æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯è·Ÿè¸ª"""
        # æˆåŠŸè§£æ
        response_data = {
            "usage": {
                "prompt_tokens": 100,
                "completion_tokens": 50,
                "total_tokens": 150
            }
        }
        self.parser.parse_token_usage(response_data, VendorType.OPENAI)
        
        # é™çº§è§£æ
        response_data = {"unknown_field": "value"}
        self.parser.parse_token_usage(response_data, VendorType.UNKNOWN)
        
        stats = self.parser.get_parsing_statistics()
        
        assert stats['total_parsed'] == 2
        assert stats['successful_parsed'] == 1
        assert stats['fallback_used'] == 1
        assert stats['success_rate'] == 0.5
        assert stats['fallback_rate'] == 0.5
        assert 'openai' in stats['vendor_stats']
        assert 'unknown' in stats['vendor_stats']
    
    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        # æ— æ•ˆå“åº”æ•°æ®
        result = self.parser.parse_token_usage(None, VendorType.OPENAI)
        assert result.error_message is not None
        assert result.parsing_method == "error"
        
        # ç©ºå“åº”æ•°æ®
        result = self.parser.parse_token_usage({}, VendorType.OPENAI)
        assert result.fallback_used
        assert result.confidence < 0.5
    
    def test_special_characters_in_content(self):
        """æµ‹è¯•å†…å®¹ä¸­çš„ç‰¹æ®Šå­—ç¬¦å¤„ç†"""
        response_data = {
            "choices": [
                {
                    "message": {
                        "content": "æµ‹è¯•å†…å®¹åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼š\n\t\"å¼•å·\"ã€'å•å¼•å·'ã€\\åæ–œæ ã€emojiğŸ˜€"
                    }
                }
            ]
        }
        
        request_data = {
            "messages": [
                {
                    "role": "user", 
                    "content": "ç”ŸæˆåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å†…å®¹"
                }
            ]
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.UNKNOWN, request_data=request_data)
        
        assert result.prompt_tokens > 0
        assert result.completion_tokens > 0
        assert result.parsing_method == "content_estimation"
    
    def test_large_token_counts(self):
        """æµ‹è¯•å¤§Tokenæ•°é‡å¤„ç†"""
        response_data = {
            "usage": {
                "prompt_tokens": 50000,
                "completion_tokens": 25000,
                "total_tokens": 75000
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.OPENAI)
        
        assert result.prompt_tokens == 50000
        assert result.completion_tokens == 25000
        assert result.total_tokens == 75000
        assert result.confidence > 0.8
    
    def test_zero_token_counts(self):
        """æµ‹è¯•é›¶Tokenæ•°é‡å¤„ç†"""
        response_data = {
            "usage": {
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "total_tokens": 0
            }
        }
        
        result = self.parser.parse_token_usage(response_data, VendorType.OPENAI)
        
        assert result.prompt_tokens == 0
        assert result.completion_tokens == 0
        assert result.total_tokens == 0
        assert result.confidence > 0.8


class TestConvenienceFunctions:
    """ä¾¿æ·å‡½æ•°æµ‹è¯•ç±»"""
    
    def test_parse_token_usage_function(self):
        """æµ‹è¯•parse_token_usageä¾¿æ·å‡½æ•°"""
        response_data = {
            "usage": {
                "prompt_tokens": 100,
                "completion_tokens": 50,
                "total_tokens": 150
            }
        }
        
        result = parse_token_usage(response_data, "openai")
        
        assert result.prompt_tokens == 100
        assert result.completion_tokens == 50
        assert result.total_tokens == 150
        assert result.vendor == VendorType.OPENAI
    
    def test_get_token_parsing_stats_function(self):
        """æµ‹è¯•get_token_parsing_statsä¾¿æ·å‡½æ•°"""
        # å…ˆè¿›è¡Œä¸€äº›è§£ææ“ä½œ
        response_data = {
            "usage": {
                "prompt_tokens": 100,
                "completion_tokens": 50,
                "total_tokens": 150
            }
        }
        parse_token_usage(response_data, "openai")
        
        stats = get_token_parsing_stats()
        
        assert 'total_parsed' in stats
        assert 'successful_parsed' in stats
        assert 'success_rate' in stats
        assert stats['total_parsed'] > 0


class TestIntegrationScenarios:
    """é›†æˆåœºæ™¯æµ‹è¯•ç±»"""
    
    def test_multi_vendor_batch_processing(self):
        """æµ‹è¯•å¤šå‚å•†æ‰¹é‡å¤„ç†"""
        parser = EnhancedTokenParser()
        parser.reset_statistics()
        
        test_cases = [
            # OpenAIæ ¼å¼
            ({
                "usage": {
                    "prompt_tokens": 100,
                    "completion_tokens": 50,
                    "total_tokens": 150
                }
            }, VendorType.OPENAI),
            
            # DeepSeekæ ¼å¼
            ({
                "usage": {
                    "prompt_tokens": 80,
                    "completion_tokens": 40,
                    "reasoning_tokens": 20,
                    "total_tokens": 140
                }
            }, VendorType.DEEPSEEK),
            
            # ç™¾åº¦æ ¼å¼
            ({
                "result": {
                    "usage": {
                        "prompt_tokens": 90,
                        "completion_tokens": 45,
                        "total_tokens": 135
                    }
                }
            }, VendorType.BAIDU),
        ]
        
        results = []
        for response_data, vendor in test_cases:
            result = parser.parse_token_usage(response_data, vendor)
            results.append(result)
        
        # éªŒè¯æ‰€æœ‰è§£æéƒ½æˆåŠŸ
        for result in results:
            assert result.confidence > 0.8
            assert not result.fallback_used
            assert result.error_message is None
        
        # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
        stats = parser.get_parsing_statistics()
        assert stats['total_parsed'] == 3
        assert stats['successful_parsed'] == 3
        assert stats['success_rate'] == 1.0
    
    def test_degradation_chain(self):
        """æµ‹è¯•é™çº§é“¾å¤„ç†"""
        parser = EnhancedTokenParser()
        
        # å®Œå…¨æ— æ³•è¯†åˆ«çš„å“åº”æ ¼å¼
        response_data = {
            "completely_unknown": {
                "some_field": "some_value"
            }
        }
        
        request_data = {
            "messages": [
                {
                    "role": "user",
                    "content": "æµ‹è¯•è¯·æ±‚å†…å®¹"
                }
            ]
        }
        
        result = parser.parse_token_usage(response_data, VendorType.UNKNOWN, request_data=request_data)
        
        # åº”è¯¥ä½¿ç”¨å†…å®¹ä¼°ç®—é™çº§ç­–ç•¥
        assert result.fallback_used
        assert result.parsing_method == "content_estimation"
        assert result.confidence == 0.5
        assert result.prompt_tokens > 0
        assert result.completion_tokens >= 0  # å¯èƒ½ä¸º0ï¼Œå› ä¸ºå“åº”ä¸­æ²¡æœ‰å†…å®¹
    
    def test_performance_with_large_dataset(self):
        """æµ‹è¯•å¤§æ•°æ®é›†æ€§èƒ½"""
        parser = EnhancedTokenParser()
        parser.reset_statistics()
        
        # æ¨¡æ‹Ÿå¤§é‡è§£æè¯·æ±‚
        response_template = {
            "usage": {
                "prompt_tokens": 100,
                "completion_tokens": 50,
                "total_tokens": 150
            }
        }
        
        import time
        start_time = time.time()
        
        for i in range(1000):
            # ç¨å¾®å˜åŒ–æ•°æ®ä»¥é¿å…ç¼“å­˜
            response_data = {
                "usage": {
                    "prompt_tokens": 100 + i % 10,
                    "completion_tokens": 50 + i % 5,
                    "total_tokens": 150 + i % 15
                }
            }
            result = parser.parse_token_usage(response_data, VendorType.OPENAI)
            assert result.confidence > 0.8
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # éªŒè¯æ€§èƒ½ï¼ˆåº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼‰
        assert processing_time < 5.0  # 1000æ¬¡è§£æåº”è¯¥åœ¨5ç§’å†…å®Œæˆ
        
        stats = parser.get_parsing_statistics()
        assert stats['total_parsed'] == 1000
        assert stats['successful_parsed'] == 1000
        assert stats['success_rate'] == 1.0


if __name__ == "__main__":
    pytest.main([__file__, "-v"])