# AI Code Review Configuration
# Copy this file to .env and customize the values for your setup

#==============================================================================
# GitLab Configuration
#==============================================================================

# GitLab Personal Access Token (required)
# Create one at: https://gitlab.com/-/profile/personal_access_tokens
# Required scopes: api, read_user, read_repository
GITLAB_TOKEN=glpat-xxxxxxxxxxxxxxxxxxxx

# GitLab instance URL
# Default: https://gitlab.com
# Examples: https://gitlab.company.com, http://localhost:8080
# Note: In CI/CD, CI_SERVER_URL takes precedence if available
GITLAB_URL=https://gitlab.com

# SSL Configuration (for custom or internal GitLab instances)
# SSL certificate verification (default: true)
# Set to false to disable SSL verification (NOT recommended for production)
SSL_VERIFY=true

# Option 1: Path to existing SSL certificate file (manual approach)
# Use this for internal GitLab instances with self-signed or custom CA certificates
# Example: SSL_CERT_PATH=/path/to/company-ca.crt
SSL_CERT_PATH=

# Option 2: URL to download SSL certificate automatically (recommended for CI/CD)
# Tool will download and cache certificate automatically
# Example: SSL_CERT_URL=https://internal-gitlab.company.com/ca-bundle.crt
SSL_CERT_URL=

# Directory to cache downloaded SSL certificates (default: .ssl_cache)
# Only used when SSL_CERT_URL is set
SSL_CERT_CACHE_DIR=.ssl_cache

#==============================================================================
# GitLab CI/CD Automatic Variables
#==============================================================================
# These variables are automatically set by GitLab CI/CD and take precedence
# over manual configuration. Do not set these manually unless testing.

# GitLab CI project path (format: "group/subgroup/project")
# Automatically set by GitLab CI/CD as CI_PROJECT_PATH
# Only set manually for local testing of CI mode
CI_PROJECT_PATH=

# GitLab CI merge request IID (internal ID, not global ID)
# Automatically set by GitLab CI/CD as CI_MERGE_REQUEST_IID
# Only set manually for local testing of CI mode
CI_MERGE_REQUEST_IID=

# GitLab CI server URL
# Automatically set by GitLab CI/CD as CI_SERVER_URL
# Takes precedence over GITLAB_URL when available
CI_SERVER_URL=

#==============================================================================
# GitHub Configuration
#==============================================================================

# GitHub Personal Access Token (required for GitHub platform)
# Create one at: https://github.com/settings/tokens
# Required scopes: repo, read:org
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxx

# GitHub API URL
# Default: https://api.github.com
# For GitHub Enterprise: https://your-github-enterprise.com/api/v3
GITHUB_URL=https://api.github.com

#==============================================================================
# GitHub Actions Automatic Variables
#==============================================================================
# These variables are automatically set by GitHub Actions and take precedence
# over manual configuration. Do not set these manually unless testing.

# GitHub repository path (format: "owner/repository")
# Automatically set by GitHub Actions as GITHUB_REPOSITORY
# Only set manually for local testing of CI mode
GITHUB_REPOSITORY=

# GitHub Actions server URL
# Automatically set by GitHub Actions as GITHUB_SERVER_URL
# Takes precedence over GITHUB_URL when available
GITHUB_SERVER_URL=

#==============================================================================
# AI Provider Configuration
#==============================================================================

# AI provider to use
# Possible values: gemini, openai, anthropic, ollama
# Default: gemini (production), ollama (local development)
AI_PROVIDER=gemini

# AI model name
# For Gemini: gemini-2.5-pro, gemini-1.5-pro, gemini-2.0-flash-exp
# For OpenAI: gpt-4, gpt-3.5-turbo, gpt-4-turbo
# For Anthropic: claude-sonnet-4-20250514, claude-3-5-sonnet-20241022, claude-3-sonnet-20240229, claude-3-haiku-20240307
# For Ollama: qwen2.5-coder:7b, llama3.1:8b, codellama:13b
# Default: gemini-2.5-pro
AI_MODEL=gemini-2.5-pro

# API key for cloud AI providers (Gemini, OpenAI, Anthropic)
# Required for cloud providers, not needed for Ollama
# Get Google AI API key at: https://makersuite.google.com/app/apikey
# Get Anthropic API key at: https://console.anthropic.com/account/keys
# Default: None
AI_API_KEY=your_api_key_here

#==============================================================================
# Ollama Configuration (for local AI)
#==============================================================================

# Ollama server URL
# Default: http://localhost:11434
# Examples: http://localhost:11434, http://ollama-server:11434
OLLAMA_BASE_URL=http://localhost:11434

# HTTP request timeout in seconds for API calls
# Range: > 0.0 (recommended: 5.0-30.0)
# Default: 5.0 (Anthropic uses min. 30.0s for better Claude reliability)
# Note: Anthropic provider will use 30.0s minimum unless you set a higher value
HTTP_TIMEOUT=5.0

#==============================================================================
# AI Model Parameters
#==============================================================================

# Temperature for AI responses
# Range: 0.0-2.0 (lower = more deterministic, higher = more creative)
# Default: 0.1 (recommended for code reviews)
TEMPERATURE=0.1

# Maximum tokens for AI response generation
# Range: 1-8192 (depending on model)
# Default: 8000
# Note: Higher values allow longer responses but may increase processing time
MAX_TOKENS=8000

#==============================================================================
# Content Processing Limits
#==============================================================================

# Maximum characters to process from diff
# Default: 100000 (100K characters)
# Increase for larger codebases, decrease for faster processing
MAX_CHARS=100000

# Maximum number of files to process in a single review
# Default: 100
# Increase for larger changesets, decrease for faster processing
MAX_FILES=100

#==============================================================================
# Optional Features
#==============================================================================

# Programming language hint for better context
# Examples: python, javascript, go, rust, java
# Default: None (auto-detect from file extensions)
LANGUAGE_HINT=

#==============================================================================
# Project Context Configuration
#==============================================================================

# Enable loading project context from file
# Possible values: true, false
# Default: true (loads context if file exists)
# When enabled, includes project-specific information in AI prompts
ENABLE_PROJECT_CONTEXT=true

# Enable CI/CD documentation fetching for context generation
# Possible values: true, false
# Default: false (disabled to reduce token consumption)
# When enabled, fetches official CI/CD documentation (GitLab CI, GitHub Actions)
# and includes it in the generated context for better CI configuration reviews.
# Recommended only for projects that heavily rely on CI/CD pipelines.
# Note: This feature is used by ai-generate-context tool, not the main review tool
ENABLE_CI_DOCS=false

# Context7 API Key for fetching library documentation
# Required for Context7 integration (optional feature)
# Sign up at: https://context7.com
# When enabled, fetches official documentation for project dependencies
# to enhance AI code reviews with authoritative API information.
# Note: This feature is used by ai-generate-context tool, not the main review tool
CONTEXT7_API_KEY=

# Path to project context file (relative to repository root)
# Default: .ai_review/project.md
# Examples: docs/ai-context.md, .cursorrules, README.md
# Use this file to provide project-specific context to the AI:
# - Architecture patterns, coding conventions
# - Domain knowledge, business rules
# - Intentional "weird" code patterns that are legitimate
# - External dependencies not visible in diffs
PROJECT_CONTEXT_FILE=.ai_review/project.md

# Include MR Summary section in reviews
# Set to false for shorter, code-focused reviews without executive summary
# Possible values: true, false
# Default: true (includes both MR Summary and Detailed Code Review)
# When disabled, only shows Detailed Code Review and Summary sections
INCLUDE_MR_SUMMARY=true

#==============================================================================
# Configuration File Options
#==============================================================================

# Skip loading configuration file (auto-detected .ai_review/config.yml or custom path)
# Possible values: true, false
# Default: false (automatically loads config file if it exists)
# When set to true, ignores both auto-detected and custom config files
NO_CONFIG_FILE=false

# Custom configuration file path
# Default: auto-detect .ai_review/config.yml if it exists
# Examples: .ai_review/config.yml, configs/custom.yml, ../shared-config.yml
# This file can contain any of the above environment variables in YAML format
# CLI arguments and environment variables take precedence over config file values
CONFIG_FILE=

#==============================================================================
# Execution Options
#==============================================================================

# Dry run mode - no actual API calls made, uses mock responses
# Possible values: true, false
# Default: false
# Useful for testing configuration without making actual AI API calls
DRY_RUN=false

# Force large context window (24K tokens) for processing big diffs
# Possible values: true, false
# Default: false
# Note: Auto-activated when diffs exceed 60K characters
# Useful for very large MRs that need maximum context
BIG_DIFFS=false

#==============================================================================
# Logging Configuration
#==============================================================================

# Logging level
# Possible values: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO

#==============================================================================
# File Filtering Configuration
#==============================================================================

# Glob patterns for files to exclude from AI review
# Comma-separated list of patterns (supports wildcards and ** for recursive)
# Default: includes common lockfiles, build artifacts, and dependency folders
# Examples:
#   "*.lock,*.min.js" - exclude lockfiles and minified JS
#   "dist/**,build/**" - exclude build directories
#   "" - disable filtering (include all files)
#
# Default patterns include:
# - All lockfiles (*.lock, package-lock.json, yarn.lock, etc.)
# - Minified files (*.min.js, *.min.css, *.map)
# - Build directories (dist/**, build/**)
# - Dependency folders (node_modules/**, __pycache__/**)
# - Generated files (*.egg-info/**)
#
# Uncomment to override with custom patterns:
# EXCLUDE_PATTERNS=*.lock,package-lock.json,yarn.lock,*.min.js,node_modules/**,dist/**

#==============================================================================
# Usage Examples
#==============================================================================

# Production with Gemini (default):
# AI_PROVIDER=gemini
# AI_MODEL=gemini-2.5-pro
# AI_API_KEY=your_gemini_api_key_here

# Local development with Ollama:
# AI_PROVIDER=ollama
# AI_MODEL=qwen2.5-coder:7b
# OLLAMA_BASE_URL=http://localhost:11434
# AI_API_KEY=  # Not needed for Ollama

# Production with Anthropic:
# AI_PROVIDER=anthropic
# AI_MODEL=claude-sonnet-4-20250514
# AI_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Production with OpenAI:
# AI_PROVIDER=openai
# AI_MODEL=gpt-4
# AI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Testing/development mode:
# DRY_RUN=true
# LOG_LEVEL=DEBUG

# Context generation with Context7 and CI/CD docs:
# AI_PROVIDER=gemini
# AI_API_KEY=your_gemini_api_key_here
# CONTEXT7_API_KEY=your_context7_api_key_here
# ENABLE_CI_DOCS=true  # Only for CI-heavy projects
