# SPHORB Performance Optimization Proposal

**Target**: 3x+ speed improvement with acceptable memory increase
**Baseline**: Current SPHORB implementation
**Comparison**: OpenCV ORB detector

---

## Performance Analysis: Current Bottlenecks

### Identified Hot Spots (in `operator()` function):

1. **Image Resizing** (`SPHORB.cpp:839`)
   - 7 levels Ã— full image resize
   - Cost: ~15-20% of total time

2. **Spherical Image Splitting** (`SPHORB.cpp:846, splitSphere2()`)
   - 5 parts Ã— 7 levels = 35 iterations
   - Nested loops with bilinear interpolation
   - Cost: ~25-30% of total time

3. **Edge Extension** (`SPHORB.cpp:850`)
   - 5 parts Ã— 7 levels
   - Cost: ~5-10% of total time

4. **FAST Corner Detection** (`SPHORB.cpp:863-866`)
   - 5 parts Ã— 7 levels
   - Cost: ~20-25% of total time

5. **Gaussian Filtering** (`SPHORB.cpp:883, filter2D()`)
   - 5 parts Ã— 7 levels
   - Cost: ~10-15% of total time

6. **Descriptor Computation** (`SPHORB.cpp:889`)
   - Per keypoint operation
   - Cost: ~15-20% of total time

---

## Optimization Strategy

### Phase 1: High-Impact, Low-Risk Optimizations (Target: 3-5x speedup)

#### 1.1 Multi-threaded Parallelization
**Implementation**: OpenMP-based parallel processing

```cpp
// Parallelize level processing (7 independent tasks)
#pragma omp parallel for schedule(dynamic)
for (int l=0; l<nlevels; l++) {
    // Level processing is independent
}

// Parallelize 5-part processing within each level
#pragma omp parallel for
for (int i=0; i<5; i++) {
    // Part processing is independent
}
```

**Expected Impact**:
- 4-core CPU: 3-4x speedup
- 8-core CPU: 5-7x speedup
- Memory: +20-30% (thread-local buffers)

**Dependencies**:
- OpenMP (already in most compilers)
- Thread-safe operations

---

#### 1.2 Grid-based Non-Maximum Suppression
**Implementation**: Replace O(nÂ²) NMS with O(n) grid-based approach (OpenCV method)

```cpp
void gridBasedNMS(vector<KeyPoint>& keypoints, int width, int height) {
    const int gridSize = 64;
    const int gridRows = (height + gridSize - 1) / gridSize;
    const int gridCols = (width + gridSize - 1) / gridSize;

    vector<vector<KeyPoint*>> grid(gridRows * gridCols);

    // Distribute keypoints to grid cells
    for (auto& kp : keypoints) {
        int cellX = kp.pt.x / gridSize;
        int cellY = kp.pt.y / gridSize;
        grid[cellY * gridCols + cellX].push_back(&kp);
    }

    // Per-cell NMS (much smaller n)
    for (auto& cell : grid) {
        if (cell.size() > 1) {
            // Local NMS within cell
        }
    }
}
```

**Expected Impact**:
- 5-10x faster NMS
- Overall: 1.5-2x speedup
- Memory: +5% (grid structure)

---

#### 1.3 Memory Pool for Dynamic Allocations
**Implementation**: Pre-allocate reusable buffers

```cpp
class SPHORB {
protected:
    // Reusable buffers to avoid new/delete in hot loop
    struct BufferPool {
        vector<xy> cornersBuffer;
        vector<int> scoreBuffer;
        vector<vector<KeyPoint>> partKeypointsBuffer;

        void reserve(size_t maxKeypoints) {
            cornersBuffer.reserve(maxKeypoints);
            scoreBuffer.reserve(maxKeypoints);
        }
    };

    BufferPool bufferPool;
};

// In detectAndCompute:
// Reuse buffers instead of new/delete (line 857-871)
bufferPool.cornersBuffer.clear();
bufferPool.scoreBuffer.clear();
// Use buffers...
```

**Expected Impact**:
- 1.2-1.3x speedup (eliminate allocation overhead)
- Memory: +10MB per instance (negligible)

---

### Phase 2: OpenCV-Inspired Optimizations (Target: 5-10x speedup)

#### 2.1 SIMD-Optimized Descriptor Computation
**Implementation**: SSE/AVX2 for `computeOrbDescriptor`

```cpp
#ifdef __AVX2__
#include <immintrin.h>

void computeOrbDescriptor_AVX2(const KeyPoint& kpt, const Mat& img,
                                const Point* pattern, uchar* desc, int dsize) {
    // Process 32 bytes (256 bits) at once
    for (int i = 0; i < dsize; i += 32) {
        __m256i result = _mm256_setzero_si256();

        // Parallel comparison of 16 pairs
        for (int j = 0; j < 16; j++) {
            int idx1 = (i + j) * 2;
            int idx2 = idx1 + 1;

            uchar v1 = GET_VALUE(pattern[idx1]);
            uchar v2 = GET_VALUE(pattern[idx2]);

            __m256i cmp = _mm256_set1_epi8(v1 < v2 ? 1 : 0);
            result = _mm256_or_si256(result,
                _mm256_slli_epi16(cmp, j));
        }

        _mm256_storeu_si256((__m256i*)(desc + i), result);
    }
}
#endif
```

**Expected Impact**:
- 4-5x faster descriptor computation
- Overall: 1.8-2.5x speedup
- Memory: No change

---

#### 2.2 Integral Image for FAST Detection
**Implementation**: O(1) region sum queries

```cpp
class SPHORB {
protected:
    vector<Mat> integralImages;

    void precomputeIntegralImages() {
        integralImages.resize(nlevels);
        for (int l = 0; l < nlevels; l++) {
            for (int i = 0; i < 5; i++) {
                Mat integral;
                cv::integral(subImg[i], integral);
                integralImages[l * 5 + i] = integral;
            }
        }
    }
};

// Use in FAST detection for O(1) circle sum
inline int circleSum(const Mat& integral, int x, int y, int radius) {
    // 4 lookups instead of pixel iteration
    return integral.at<int>(y+radius, x+radius)
         - integral.at<int>(y-radius, x+radius)
         - integral.at<int>(y+radius, x-radius)
         + integral.at<int>(y-radius, x-radius);
}
```

**Expected Impact**:
- 2-3x faster FAST detection
- Overall: 1.4-1.8x speedup
- Memory: +30MB (integral images)

---

#### 2.3 Early Termination & Adaptive Level Selection
**Implementation**: Stop processing when enough features found

```cpp
void operator()(/* ... */) const {
    int foundFeatures = 0;
    int targetFeatures = nfeatures;

    // Skip levels if image is too small
    int effectiveLevels = min(nlevels,
        (int)log2(min(temp.cols, temp.rows) / 64));

    for (int l = 0; l < effectiveLevels; l++) {
        // Process level...

        foundFeatures += levelKeyPoints.size();

        // Early exit if we have enough features
        if (foundFeatures >= targetFeatures * 1.2) {
            // Keep 20% extra for filtering, then stop
            break;
        }
    }
}
```

**Expected Impact**:
- 1.3-1.5x speedup (average case)
- Memory: No change

---

#### 2.4 SIMD-Optimized Bilinear Interpolation
**Implementation**: Process 4+ pixels simultaneously in `splitSphere2`

```cpp
void splitSphere2_SIMD(const Mat& im, Mat& oim, int idx,
                       const float* imgInfo) {
    #ifdef __SSE2__
    const __m128 ones = _mm_set1_ps(1.0f);

    for(int y = 0; y < oim.rows; y++) {
        int x = 0;

        // Process 4 pixels at once
        for(; x <= oim.cols - 4; x += 4) {
            // Load 4 coordinates
            __m128 lx = _mm_loadu_ps(&imgInfo[(x+y*oim.cols)*4]);
            __m128 ly = _mm_loadu_ps(&imgInfo[(x+y*oim.cols)*4+1]);
            __m128 wh = _mm_loadu_ps(&imgInfo[(x+y*oim.cols)*4+2]);
            __m128 wv = _mm_loadu_ps(&imgInfo[(x+y*oim.cols)*4+3]);

            // Bilinear interpolation in parallel
            // ... SIMD operations
        }

        // Handle remaining pixels
        for(; x < oim.cols; x++) {
            // Scalar fallback
        }
    }
    #else
    // Fallback to original implementation
    #endif
}
```

**Expected Impact**:
- 2-3x faster splitting
- Overall: 1.6-2x speedup
- Memory: No change

---

## Combined Performance Prediction

### Conservative Estimate (Phase 1 only):
- Multi-threading (4 cores): **3.5x**
- Grid NMS: **1.8x**
- Memory pool: **1.2x**
- **Total: ~7.5x speedup**

### Optimistic Estimate (Phase 1 + Phase 2):
- All Phase 1: **7.5x**
- SIMD descriptor: **2.0x**
- Integral image: **1.5x**
- Early termination: **1.3x**
- SIMD interpolation: **1.8x**
- **Total: ~33x speedup** (in ideal conditions)

### Realistic Target (Phase 1 + selective Phase 2):
- **10-15x speedup with 4-core CPU**
- **Memory increase: +50-80MB per instance**

---

## Implementation Plan

### Step 1: Baseline Benchmarking
```python
# benchmark_baseline.py
import time
import memory_profiler
import cv2
import pysphorb

# Test images from Image/ directory
images = ["Image/1_1.jpg", "Image/1_2.jpg"]

for img_path in images:
    img = cv2.imread(img_path)

    # SPHORB baseline
    sorb = pysphorb.SPHORB()

    start = time.perf_counter()
    kp, desc = sorb.detectAndCompute(img)
    elapsed = time.perf_counter() - start

    print(f"{img_path}: {len(kp)} kp, {elapsed*1000:.2f}ms")

    # OpenCV ORB comparison
    orb = cv2.ORB_create(nfeatures=500)

    start = time.perf_counter()
    kp_orb, desc_orb = orb.detectAndCompute(img, None)
    elapsed_orb = time.perf_counter() - start

    print(f"  ORB: {len(kp_orb)} kp, {elapsed_orb*1000:.2f}ms")
    print(f"  Speedup needed: {elapsed/elapsed_orb:.2f}x")
```

### Step 2: Phase 1 Implementation
1. Add OpenMP support to CMakeLists.txt
2. Implement multi-threading
3. Implement grid-based NMS
4. Implement memory pool
5. Benchmark and validate

### Step 3: Phase 2 Implementation (if needed)
1. Implement SIMD descriptor (conditional compilation)
2. Benchmark and validate
3. Add integral image optimization
4. Add early termination
5. Final benchmark

### Step 4: Validation
- Ensure detection quality is maintained (Â±5% keypoint count)
- No regression in descriptor quality
- Memory usage within acceptable bounds
- Thread safety verified

---

## Risk Assessment

### Low Risk:
- âœ… Memory pool
- âœ… Grid NMS
- âœ… Early termination

### Medium Risk:
- âš ï¸ Multi-threading (requires careful synchronization)
- âš ï¸ Adaptive level selection (may affect feature distribution)

### Higher Risk:
- âš ï¸âš ï¸ SIMD implementations (CPU compatibility, correctness)
- âš ï¸âš ï¸ Integral image (may change detection sensitivity)

---

## Success Metrics

### Required:
- âœ… 3x+ speedup vs baseline
- âœ… Feature count within Â±10% of baseline
- âœ… Memory increase â‰¤ 2x baseline

### Desired:
- ðŸŽ¯ Competitive with OpenCV ORB (within 2x)
- ðŸŽ¯ 5x+ speedup vs baseline
- ðŸŽ¯ Thread-safe implementation

---

## References

1. OpenCV ORB Implementation: `modules/features2d/src/orb.cpp`
2. FAST Corner Detection: Rosten & Drummond, 2006
3. ORB Paper: Rublee et al., "ORB: an efficient alternative to SIFT or SURF", ICCV 2011
4. SPHORB Paper: Zhao et al., "SPHORB: A Fast and Robust Binary Feature on the Sphere", IJCV 2015

---

**Document Version**: 1.0
**Date**: 2025-10-18
**Author**: Performance Optimization Analysis
