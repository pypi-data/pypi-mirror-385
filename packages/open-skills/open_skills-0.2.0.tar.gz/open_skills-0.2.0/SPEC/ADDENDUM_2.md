Excellent catch ‚Äî no, the **prompt-injection / context-augmentation mechanism** (the part where available skills are injected into the system prompt so the agent is context-aware) was **not yet included explicitly** in the PRD or technical spec we wrote earlier.

It was **implied** in the ‚Äúauto-selection and multi-skill composition‚Äù section, but not spelled out as a **system-prompt design requirement**. Anthropic‚Äôs own system uses this as a core layer of their architecture ‚Äî so it absolutely should be added.

---

### üß© Addendum: Skill Context Injection (v2.1)

**New Section ‚Äî ‚ÄúSkill Context Awareness‚Äù**

#### **Overview**

Agents must be aware of which skills exist before they can select and execute them. This awareness is achieved via **prompt-level skill injection**, where the metadata of all accessible skills is serialized and injected into the system prompt or equivalent structured `tools` parameter at runtime.

#### **Behavior**

- At session start, the agent receives a summary manifest of all visible skills.
- The manifest is embedded either:

  - as a text block inside the system prompt, or
  - via the structured `tools` parameter (for SDKs that support it, e.g., OpenAI, Anthropic).

- During reasoning, the agent uses this context to autonomously decide when to call a skill.

#### **Data Flow**

1. `open-skills` generates a manifest (`manifest_json()` or `.well-known/skills.json`).
2. The agent runtime serializes the manifest into:

   - a human-readable description (`manifest_to_prompt()`), or
   - a structured tools array (`manifest_to_tools()`).

3. The resulting data is merged into the agent‚Äôs **system prompt** before the first model call.

#### **Example System Prompt Injection**

```text
You are an AI agent with access to the following user-defined skills:

1. **summarize_docs** ‚Äî Summarizes multiple documents into a concise brief.
   Inputs: text (string)
   Outputs: summary (string)

2. **generate_presentation** ‚Äî Converts structured data into PowerPoint slides.
   Inputs: data (JSON)
   Outputs: pptx_file (binary)
```

#### **Dynamic Disclosure**

To manage context length:

- Only **skill metadata** (name + description) is injected by default.
- Full `SKILL.md` and entrypoint code are **loaded lazily** when the skill is actually invoked.
- After a skill run, its result and updated metadata can be re-injected into the agent‚Äôs context.

#### **API Hooks**

- `manifest_to_prompt()` ‚Üí returns system-prompt-friendly text
- `manifest_to_tools()` ‚Üí returns OpenAI/Anthropic tool schema array
- `inject_skills_context(agent)` ‚Üí adds manifest to agent initialization

#### **Integration Example (Vel or standalone FastAPI)**

```python
from open_skills.adapters.prompt_injection import manifest_to_prompt
from open_skills.core import SkillRouter

skills_prompt = manifest_to_prompt(db=db, user_id=current_user.id)
system_prompt = f"""
You are an AI agent that can use tools defined by the user.
{skills_prompt}
"""

agent = Agent(system_prompt=system_prompt)
```

#### **Observability**

- Each session logs which skills were available at initialization.
- Langfuse trace includes the manifest version to correlate reasoning to skill availability.

---

### ‚úÖ Summary

| Aspect                                    | Added in Addendum   |
| ----------------------------------------- | ------------------- |
| Context-aware prompt injection            | ‚úÖ Explicitly added |
| Dynamic disclosure (metadata vs code)     | ‚úÖ Added            |
| Manifest serialization functions          | ‚úÖ Added            |
| Integration hook for Vel / generic agents | ‚úÖ Added            |
| Logging of context injection              | ‚úÖ Added            |
