# Inference Templates

This document provides a comprehensive overview of the inference templates support matrix, organized by **Weight Source**, **Model Type**, and **Inference Stack**.

## Overview

Inference templates enable flexible model deployment by supporting various combinations of weight sources, model types, and inference stacks. This system allows for deploying models from different sources (Hugging Face, Baseten checkpoints) with different architectures (full models, LoRA adapters, Whisper models) using various inference engines.

## Support Matrix

### Currently Supported Combinations âœ…

| Weight Source | Model Type | Inference Stack | Status |
|---------------|------------|-----------------|---------|
| HF | Full | VLLM | âœ… Supported |
| BasetenCheckpoint | Full | VLLM | âœ… Supported |
| BasetenCheckpoint | Whisper | VLLM | âœ… Supported |
| BasetenCheckpoint | LoRA | VLLM | âœ… Supported |

### Planned Future Support ğŸš§

| Weight Source | Model Type | Inference Stack | Status |
|---------------|------------|-----------------|---------|
| BasetenCheckpoint | Full | BasetenInferenceStack (BIS) | ğŸš§ Planned |
| BasetenCheckpoint | LoRA | BasetenInferenceStack (BIS) | ğŸš§ Planned |
| HF | LoRA | VLLM | ğŸš§ Planned |
| HF | Full | BasetenInferenceStack (BIS) | ğŸš§ Planned |

### Not Supported âŒ

| Weight Source | Model Type | Inference Stack | Status |
|---------------|------------|-----------------|---------|
| S3 | Any | Any | âŒ No S3 support across any configuration |
