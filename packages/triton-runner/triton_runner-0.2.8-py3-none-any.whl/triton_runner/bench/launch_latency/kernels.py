# This file is adapted from:
# https://github.com/pytorch-labs/tritonbench/blob/main/tritonbench/operators/launch_latency/kernels.py
#
# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

import torch
import triton

import triton.language as tl

import triton_runner

@triton.jit
def nop_kernel():
    pass


@triton.jit
def nop_with_args_kernel(
    t1,
    t2,
    t3,
    t4,
    t5,
    i1,
    i2,
    i3,
    i4,
    i5,
    i6,
    i7,
    i8,
    i9,
    c1: tl.constexpr,
    c2: tl.constexpr,
    c3: tl.constexpr,
    c4: tl.constexpr,
    c5: tl.constexpr,
):
    pass


@triton_runner.jit
def runner_nop_kernel():
    pass


@triton_runner.jit
def runner_nop_with_args_kernel(
    t1,
    t2,
    t3,
    t4,
    t5,
    i1,
    i2,
    i3,
    i4,
    i5,
    i6,
    i7,
    i8,
    i9,
    c1: tl.constexpr,
    c2: tl.constexpr,
    c3: tl.constexpr,
    c4: tl.constexpr,
    c5: tl.constexpr,
):
    pass


def get_trivial_add_kernel():
    @torch.compile
    def trivial_add_kernel(*args):
        return sum([torch.tensor(1.0, device="cuda"), *args])

    return trivial_add_kernel
