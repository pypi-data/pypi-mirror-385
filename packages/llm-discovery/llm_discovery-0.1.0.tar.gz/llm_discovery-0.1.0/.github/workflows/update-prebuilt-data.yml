name: Update Prebuilt Model Data

on:
  # Schedule: Run daily at 00:00 UTC
  schedule:
    - cron: '0 0 * * *'

  # Allow manual trigger
  workflow_dispatch:

permissions:
  contents: write
  issues: write

jobs:
  update-data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Set up Python
        run: uv python install 3.13

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Fetch models from APIs
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        run: |
          # Create output directory
          mkdir -p temp_output

          # Fetch models and export raw ProviderSnapshot data
          # Note: This will fail-fast if any configured provider fails
          # Ensure API keys in GitHub Secrets are valid and not expired
          uv run python -c "
          import asyncio
          import json
          from llm_discovery import DiscoveryClient
          from llm_discovery.models.config import Config

          async def main():
              config = Config.from_env()
              client = DiscoveryClient(config)
              providers = await client.fetch_all_models()

              # Export ProviderSnapshot list as JSON
              with open('temp_output/providers.json', 'w') as f:
                  data = {'providers': [p.model_dump(mode='json') for p in providers]}
                  json.dump(data, f)

              print(f'Fetched {len(providers)} providers')

          asyncio.run(main())
          "

      - name: Add metadata to JSON
        run: |
          # Run metadata addition script
          uv run python scripts/add_metadata.py \
            temp_output/providers.json \
            data/prebuilt/models.json

      - name: Check for changes
        id: check_changes
        run: |
          # Check if file is tracked in git
          if ! git ls-files --error-unmatch data/prebuilt/models.json > /dev/null 2>&1; then
            # File is untracked (first run)
            echo "changed=true" >> $GITHUB_OUTPUT
          elif git diff --quiet data/prebuilt/models.json; then
            # File exists and no changes
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            # File exists with changes
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/prebuilt/models.json
          git commit -m "chore: update prebuilt model data

          Auto-generated by GitHub Actions on $(date -u +'%Y-%m-%d %H:%M:%S UTC')
          "
          git push

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const title = '⚠️ Prebuilt Data Update Failed';
            const body = `
            ## Update Failure

            The automated prebuilt data update workflow failed.

            **Workflow Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            **Triggered:** ${{ github.event_name }}
            **Time:** ${new Date().toISOString()}

            ### Possible Causes
            - API key expiration or invalid credentials
            - API rate limit exceeded
            - Network connectivity issues
            - Data validation failure

            ### Recommended Actions
            1. Check the [workflow logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            2. Verify API keys in repository secrets
            3. Check API provider status
            4. Re-run the workflow manually if needed

            ---
            *This issue was created automatically by the update-prebuilt-data workflow.*
            `;

            // Check if similar issue already exists (search by title)
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              per_page: 100
            });

            const existingIssue = issues.data.find(issue =>
              issue.title === title
            );

            if (existingIssue) {
              // Add comment to existing issue
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `Another failure occurred:\n\n${body}`
              });
            } else {
              // Create new issue (without labels to avoid label existence errors)
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body
              });
            }
