#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Copyright (C) EDF 2025

@authors: otwrapy
"""
from datetime import datetime
from tempfile import mkdtemp
import pandas as pd
import shutil
import os
import openturns as ot
import time
import math
import logging


class TempSimuDir(object):
    """
    Implement a context manager that creates a temporary working directory.

    Create a temporary working directory on `res_dir` preceded by
    `prefix` and clean up at the exit if necessary.

    Parameters
    ----------
    res_dir : str
        Path where the temporary working directory will be created.
    prefix : str (optional)
        String that preceeds the directory name.
    cleanup : bool (optional)
        If True erase the directory and its children at the exit.
    to_be_copied : list (optional)
        List of files or folders to transfer to the temporary working directory
    """

    def __init__(self, res_dir, prefix="simu_", cleanup=False, to_be_copied=None):
        date_tag = datetime.now().strftime("%Y-%m-%d_%H-%M_")
        self.simu_dir = mkdtemp(dir=res_dir, prefix=prefix + date_tag)
        self.cleanup = cleanup
        self.to_be_copied = to_be_copied

    def __enter__(self):
        if self.to_be_copied is not None:
            for file in self.to_be_copied:
                if os.path.isfile(file):
                    shutil.copy(file, self.simu_dir)
                elif os.path.isdir(file):
                    shutil.copytree(
                        file, os.path.join(self.simu_dir, file.split(os.sep)[-1])
                    )
                else:
                    raise Exception(
                        "In othpc.TempSimuDir : the current "
                        + 'path "{}" is not a file '.format(file)
                        + "nor a directory to transfer."
                    )
        return self.simu_dir

    def __exit__(self, type, value, traceback):
        if self.cleanup:
            shutil.rmtree(self.simu_dir)


def make_report_file(
    simu_dir,
    x,
    y=None,
    report_file="report.csv",
    input_description=None,
    output_description=None,
):
    """
    Writes a report file associated to one evaluation, including the input and the corresponding output.

    Parameters
    ----------
    simu_dir : str
        Path where the inputs and outputs files associated to one evaluation are stored.
    x : list of float
        Input vector evaluated.
    y : list of float
        Corresponding output vector.
    report_file : str
        Name of the output file written.
    input_description : list of str
        List of strings describing the intputs.
    output_description : list of str
        List of strings describing the outputs.
    """
    if input_description is None:
        input_description = [f"X{i}" for i in range(len(x))]
    else:
        input_description = list(input_description)
    if y is None:
        df = pd.DataFrame([], columns=input_description, index=[simu_dir])
    else:
        if output_description is None:
            output_description = [f"Y{i}" for i in range(len(y))]
        else:
            output_description = list(output_description)
        df = pd.DataFrame(
            [], columns=input_description + output_description, index=[simu_dir]
        )
    df.loc[simu_dir, input_description] = x
    if y is not None:
        df.loc[simu_dir, output_description] = y
    df.to_csv(os.path.join(simu_dir, report_file), na_rep="NaN")


def make_summary_file(res_dir, summary_file="summary.csv", report_file="report.csv"):
    """
    Writes a file including a summary table with all the inputs evaluated and their corresponding outputs.

    Parameters
    ----------
    res_dir : str
        Path where the temporary work files have beend created.
    summary_file : str
        Name of the summary file created.
    report_file : str
        Name of the files generated by the static method make_report_file.
    """
    df_table = pd.DataFrame([])
    subfolders = [f.path for f in os.scandir(res_dir) if f.is_dir()]
    for simu_dir in subfolders:
        try:
            df = pd.read_csv(
                os.path.join(simu_dir, report_file), index_col=0, na_values=["NaN", ""]
            )
            df_table = pd.concat([df_table, df])
        except FileNotFoundError:
            pass
    df_table.to_csv(os.path.join(res_dir, summary_file), na_rep="NaN")


def load_cache(function, summary_file):
    """
    Makes an openturns.MemoizeFunction including in its cache the previous evaluations written in the summary_file.

    Parameters
    ----------
    function : openturns.Function or openturns.OpenTURNSPythonFunction
        Function that will be turned into a openturns.MemoizeFunction
    summary_file : str
        Path to the summary file created by the make_summary_file method.
    """
    memoize_function = ot.MemoizeFunction(ot.Function(function))
    # load the cache from the summary file
    df = pd.read_csv(summary_file)
    df = df.drop(columns=df.columns[0])
    input_cache = ot.Sample.BuildFromDataFrame(
        df.iloc[:, : function.getInputDimension()]
    )
    output_cache = ot.Sample.BuildFromDataFrame(
        df.iloc[:, function.getInputDimension() :]
    )
    # add the cache to the function
    memoize_function.addCacheContent(input_cache, output_cache)
    return memoize_function


def evaluation_error_log(error, simulation_directory, name="evaluation_error.txt"):
    """
    Creates error logs for a given simulation directory.

    Parameters
    ----------
    error : Error
        Error message to be logged.
    simulation_directory : str
        Path where the inputs and outputs files associated to one evaluation are stored.
    name : str
        Label of the error file storing the collected logs.
    """
    logger = logging.getLogger(__name__)
    logfile = os.path.join(simulation_directory, name)
    fh = logging.FileHandler(filename=logfile, mode="w")

    # Create a formatter for the file handlers
    formatter = logging.Formatter(
        fmt="%(asctime)s %(levelname)-8s %(message)s", datefmt="%y-%m-%d %H:%M:%S"
    )
    fh.setFormatter(formatter)

    # Add the handler to the logger
    logger.addHandler(fh)
    logger.error(error)


def fake_load(duration=30):
    """
    Creates a fake computational load to keep the CPUs active and test the library.

    Parameters
    ----------
    duration : int
        Fake load duration in seconds.
    """
    start = time.time()
    while time.time() - start < duration:
        a = math.sqrt(64 * 64 * 64 * 64 * 64)
