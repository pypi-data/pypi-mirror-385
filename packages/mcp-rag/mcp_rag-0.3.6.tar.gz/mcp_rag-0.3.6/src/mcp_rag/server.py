"""
MCP æœåŠ¡å™¨ - ä¸»æœåŠ¡å™¨
=====================================

è¿™æ˜¯ä¸»è¦çš„ MCP æœåŠ¡å™¨ï¼Œé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ã€‚
ä¿ç•™äº†æ‰€æœ‰ç°æœ‰åŠŸèƒ½ï¼Œå¹¶è¿›è¡Œäº†æ›´å¥½çš„ç»„ç»‡ã€‚
ç°åœ¨æ”¯æŒç»“æ„åŒ–æ¨¡å‹ï¼ˆDocumentModel å’Œ MetadataModelï¼‰ã€‚
"""

import os
import sys
from datetime import datetime
from dotenv import load_dotenv
from mcp.server.fastmcp import FastMCP
from urllib.parse import urlparse

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„ä»¥æ”¯æŒå¯¼å…¥
# sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "src")))

# å¯¼å…¥å·¥å…·
from utils.logger import log, log_mcp_server
from utils.config import Config

# å¯¼å…¥ RAG æ ¸å¿ƒåŠŸèƒ½ï¼ˆäº‘ç«¯å®ç°ï¼‰
from rag_core_openai import (
    add_text_to_knowledge_base,
    add_text_to_knowledge_base_enhanced,
    load_document_with_fallbacks,
    get_qa_chain,
    get_vector_store,
    search_with_metadata_filters,
    create_metadata_filter,
    get_document_statistics,
    get_cache_stats,
    print_cache_stats,
    clear_embedding_cache,
    optimize_vector_store,
    get_vector_store_stats,
    reindex_vector_store,
    get_optimal_vector_store_profile,
    load_document_with_elements
)

# å¯¼å…¥ç»“æ„åŒ–æ¨¡å‹
try:
    from models import DocumentModel, MetadataModel
    MODELS_AVAILABLE = True
    log_mcp_server("âœ… ç»“æ„åŒ–æ¨¡å‹ (DocumentModel, MetadataModel) å¯ç”¨")
except ImportError as e:
    MODELS_AVAILABLE = False
    log_mcp_server(f"âš ï¸ ç»“æ„åŒ–æ¨¡å‹ä¸å¯ç”¨: {e}")

# --- åˆå§‹åŒ–æœåŠ¡å™¨å’Œé…ç½® ---
load_dotenv()
mcp = FastMCP(Config.SERVER_NAME)

# çŠ¶æ€ç°åœ¨åŒ…æ‹¬æœ‰å…³ç»“æ„åŒ–æ¨¡å‹çš„ä¿¡æ¯
rag_state = {
    "models_available": MODELS_AVAILABLE,
    "structured_processing": MODELS_AVAILABLE,
    "document_models": [],  # å·²å¤„ç†çš„ DocumentModel åˆ—è¡¨
    "metadata_cache": {}    # æ¯ä¸ªæ–‡æ¡£çš„ MetadataModel ç¼“å­˜
}

md_converter = None

def warm_up_rag_system():
    """
    é¢„åŠ è½½ RAG ç³»ç»Ÿçš„é‡å‹ç»„ä»¶ï¼Œä»¥é¿å…é¦–æ¬¡è°ƒç”¨å·¥å…·æ—¶çš„å»¶è¿Ÿå’Œå†²çªã€‚
    """
    if "warmed_up" in rag_state:
        return
    
    log_mcp_server("æ­£åœ¨é¢„çƒ­ RAG ç³»ç»Ÿ...")
    log_mcp_server("åˆå§‹åŒ–äº‘ç«¯å‘é‡å­˜å‚¨ï¼ˆOpenAI-onlyï¼‰...")
    
    rag_state["warmed_up"] = True
    log_mcp_server("RAG ç³»ç»Ÿå·²é¢„çƒ­å¹¶å‡†å¤‡å°±ç»ªã€‚")

def ensure_converted_docs_directory():
    """ç¡®ä¿å­˜åœ¨ç”¨äºå­˜å‚¨è½¬æ¢æ–‡æ¡£çš„æ–‡ä»¶å¤¹ã€‚"""
    Config.ensure_directories()
    if not os.path.exists(Config.CONVERTED_DOCS_DIR):
        os.makedirs(Config.CONVERTED_DOCS_DIR)
        log_mcp_server(f"å·²åˆ›å»ºè½¬æ¢æ–‡æ¡£æ–‡ä»¶å¤¹: {Config.CONVERTED_DOCS_DIR}")

def save_processed_copy(file_path: str, processed_content: str, processing_method: str = "unstructured") -> str:
    """
    ä¿å­˜å¤„ç†åçš„æ–‡æ¡£å‰¯æœ¬ä¸º Markdown æ ¼å¼ã€‚

    å‚æ•°ï¼š
        file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
        processed_content: å¤„ç†åçš„å†…å®¹
        processing_method: ä½¿ç”¨çš„å¤„ç†æ–¹æ³•

    è¿”å›ï¼š
        ä¿å­˜çš„ Markdown æ–‡ä»¶è·¯å¾„
    """
    ensure_converted_docs_directory()
    
    # è·å–åŸå§‹æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰
    original_filename = os.path.basename(file_path)
    name_without_ext = os.path.splitext(original_filename)[0]
    
    # åˆ›å»ºåŒ…å«æ–¹æ³•ä¿¡æ¯çš„ Markdown æ–‡ä»¶å
    md_filename = f"{name_without_ext}_{processing_method}.md"
    md_filepath = os.path.join(Config.CONVERTED_DOCS_DIR, md_filename)
    
    # ä¿å­˜å†…å®¹åˆ° Markdown æ–‡ä»¶
    try:
        with open(md_filepath, 'w', encoding='utf-8') as f:
            f.write(processed_content)
        log_mcp_server(f"å·²ä¿å­˜å¤„ç†åçš„å‰¯æœ¬: {md_filepath}")
        return md_filepath
    except Exception as e:
        log_mcp_server(f"è­¦å‘Š: æ— æ³•ä¿å­˜å¤„ç†åçš„å‰¯æœ¬: {e}")
        return ""

def initialize_rag():
    """
    ä½¿ç”¨æ ¸å¿ƒåˆå§‹åŒ– RAG ç³»ç»Ÿçš„æ‰€æœ‰ç»„ä»¶ã€‚
    """
    if "initialized" in rag_state:
        return

    log_mcp_server("é€šè¿‡æ ¸å¿ƒåˆå§‹åŒ– RAG ç³»ç»Ÿ...")
    
    # ä»äº‘ç«¯æ ¸å¿ƒè·å–å‘é‡å­˜å‚¨å’Œ QA é“¾
    vector_store = get_vector_store()
    qa_chain = get_qa_chain(vector_store)
    
    rag_state["vector_store"] = vector_store
    rag_state["qa_chain"] = qa_chain
    rag_state["initialized"] = True
    
    # å…³äºæ¨¡å‹çŠ¶æ€çš„ä¿¡æ¯
    if MODELS_AVAILABLE:
        log_mcp_server("âœ… RAG ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œæ”¯æŒç»“æ„åŒ–æ¨¡å‹")
        log_mcp_server("ğŸ§  DocumentModel å’Œ MetadataModel å¯ç”¨äºé«˜çº§å¤„ç†")
    else:
        log_mcp_server("âš ï¸ RAG ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œä½†æœªå¯ç”¨ç»“æ„åŒ–æ¨¡å‹ (ä½¿ç”¨å­—å…¸)")
    
    log_mcp_server("RAG ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸã€‚")

# --- åˆå§‹åŒ–è‡ªåŠ¨åŒ– RAG ç³»ç»Ÿ ---
log_mcp_server("è‡ªåŠ¨åˆå§‹åŒ– RAG ç³»ç»Ÿ...")
backend = "JSON"
log_mcp_server("RAG åç«¯: JSON")
initialize_rag()
warm_up_rag_system()
log_mcp_server("RAG ç³»ç»Ÿå·²åˆå§‹åŒ–å¹¶å‡†å¤‡å°±ç»ªã€‚")

# --- åœ¨åˆå§‹åŒ– RAG åé…ç½®æ¨¡å—åŒ–å·¥å…· ---
from tools import configure_rag_state, ALL_TOOLS

# é…ç½®å·¥å…·æ¨¡å—ä¸­çš„ RAG çŠ¶æ€
configure_rag_state(
    rag_state=rag_state,
    initialize_rag_func=initialize_rag,
    save_processed_copy_func=save_processed_copy
)

# --- Definir las herramientas MCP directamente en el servidor ---
@mcp.tool()
def learn_text(text: str, source_name: str = "manual_input") -> str:
    """
    å‘ RAG çŸ¥è¯†åº“æ·»åŠ ä¸€æ®µæ–°æ–‡æœ¬ä»¥ä¾›å°†æ¥å‚è€ƒã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - æ·»åŠ äº‹å®ã€å®šä¹‰æˆ–è§£é‡Š
    - å­˜å‚¨å¯¹è¯ä¸­çš„é‡è¦ä¿¡æ¯
    - ä¿å­˜ç ”ç©¶å‘ç°æˆ–ç¬”è®°
    - æ·»åŠ ç‰¹å®šä¸»é¢˜çš„ä¸Šä¸‹æ–‡

    å‚æ•°ï¼š
        text: è¦å­¦ä¹ å¹¶å­˜å‚¨åœ¨çŸ¥è¯†åº“ä¸­çš„æ–‡æœ¬å†…å®¹ã€‚
        source_name: æ¥æºçš„æè¿°æ€§åç§°ï¼ˆä¾‹å¦‚ "user_notes", "research_paper", "conversation_summary"ï¼‰ã€‚
    """
    from tools.document_tools import learn_text as learn_text_logic
    return learn_text_logic(text, source_name)

@mcp.tool()
def learn_document(file_path: str) -> str:
    """
    ä½¿ç”¨é«˜çº§éç»“æ„åŒ–å¤„ç†æŠ€æœ¯ï¼ˆåŒ…å«çœŸæ­£çš„è¯­ä¹‰åˆ†å—ï¼‰è¯»å–å’Œå¤„ç†æ–‡æ¡£æ–‡ä»¶ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°çŸ¥è¯†åº“ã€‚
    å½“æ‚¨æƒ³é€šè¿‡æ™ºèƒ½å¤„ç†æ–‡æ¡£æ–‡ä»¶æ¥è®­ç»ƒäººå·¥æ™ºèƒ½æ—¶ï¼Œå¯ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚

    æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼šPDFã€DOCXã€PPTXã€XLSXã€TXTã€HTMLã€CSVã€JSONã€XMLã€ODTã€ODPã€ODSã€RTFã€
    å›¾åƒï¼ˆPNGã€JPGã€TIFFã€å¸¦ OCR çš„ BMPï¼‰ã€ç”µå­é‚®ä»¶ï¼ˆEMLã€MSGï¼‰ä»¥åŠè¶…è¿‡ 25 ç§æ ¼å¼ã€‚

    é«˜çº§åŠŸèƒ½ï¼š
    - åŸºäºæ–‡æ¡£ç»“æ„ï¼ˆæ ‡é¢˜ã€ç« èŠ‚ã€åˆ—è¡¨ï¼‰çš„ REAL è¯­ä¹‰åˆ†å—
    - æ™ºèƒ½æ–‡æ¡£ç»“æ„ä¿å­˜ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼ï¼‰
    - è‡ªåŠ¨å»å™ªï¼ˆé¡µçœ‰ã€é¡µè„šã€æ— å…³å†…å®¹ï¼‰
    - ç»“æ„åŒ–å…ƒæ•°æ®æå–
    - é€‚ç”¨äºä»»ä½•æ–‡æ¡£ç±»å‹çš„å¼ºå¤§å›é€€ç³»ç»Ÿ
    - é€šè¿‡è¯­ä¹‰è¾¹ç•Œå¢å¼ºä¸Šä¸‹æ–‡ä¿å­˜

    ä½¿ç”¨ç¤ºä¾‹ï¼š
    - å¤„ç†å¸ƒå±€å¤æ‚çš„ç ”ç©¶è®ºæ–‡æˆ–æ–‡ç« 
    - ä»åŒ…å«è¡¨æ ¼å’Œåˆ—è¡¨çš„æŠ¥å‘Šæˆ–æ‰‹å†Œä¸­æ·»åŠ å†…å®¹
    - ä»å¸¦æ ¼å¼çš„ç”µå­è¡¨æ ¼å¯¼å…¥æ•°æ®
    - å°†æ¼”ç¤ºæ–‡ç¨¿è½¬æ¢ä¸ºå¯æœç´¢çš„çŸ¥è¯†
    - ä½¿ç”¨ OCR å¤„ç†æ‰«ææ–‡æ¡£

    æ–‡æ¡£å°†é€šè¿‡ REAL è¯­ä¹‰åˆ†å—è¿›è¡Œæ™ºèƒ½å¤„ç†ï¼Œå¹¶ä¸å¢å¼ºçš„å…ƒæ•°æ®ä¸€èµ·å­˜å‚¨ã€‚

    å°†ä¿å­˜å¤„ç†åæ–‡æ¡£çš„å‰¯æœ¬ä»¥ä¾›éªŒè¯ã€‚

    å‚æ•°ï¼š
    file_pathï¼šè¦å¤„ç†çš„æ–‡æ¡£æ–‡ä»¶çš„ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„ã€‚
    """
    from tools.document_tools import learn_document as learn_document_logic
    return learn_document_logic(file_path)

@mcp.tool()
def ask_rag(query: str) -> str:
    """
    å‘ RAG çŸ¥è¯†åº“æé—®ï¼Œå¹¶æ ¹æ®å­˜å‚¨çš„ä¿¡æ¯è¿”å›ç­”æ¡ˆã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - è¯¢é—®ç‰¹å®šä¸»é¢˜æˆ–æ¦‚å¿µ
    - è¯·æ±‚è§£é‡Šæˆ–å®šä¹‰
    - ä»å¤„ç†è¿‡çš„æ–‡æ¡£ä¸­è·å–ä¿¡æ¯
    - åŸºäºå­¦ä¹ çš„æ–‡æœ¬æˆ–æ–‡æ¡£è·å–ç­”æ¡ˆ
    
    å‚æ•°ï¼š
        query: è¦å‘çŸ¥è¯†åº“æå‡ºçš„é—®é¢˜æˆ–æŸ¥è¯¢ã€‚
    """
    from tools.search_tools import ask_rag as ask_rag_logic
    return ask_rag_logic(query)

@mcp.tool()
def ask_rag_filtered(query: str, file_type: str = None, min_tables: int = None, min_titles: int = None, processing_method: str = None) -> str:
    """
    å‘ RAG çŸ¥è¯†åº“æé—®ï¼Œå¹¶ä½¿ç”¨ç‰¹å®šè¿‡æ»¤å™¨èšç„¦æœç´¢ã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - ä»…æœç´¢ PDF æ–‡æ¡£ï¼šfile_type=".pdf"
    - æŸ¥æ‰¾åŒ…å«è¡¨æ ¼çš„æ–‡æ¡£ï¼šmin_tables=1
    - æŸ¥æ‰¾ç»“æ„è‰¯å¥½çš„æ–‡æ¡£ï¼šmin_titles=5
    - æœç´¢å¢å¼ºå¤„ç†çš„æ–‡æ¡£ï¼šprocessing_method="unstructured_enhanced"
    
    å‚æ•°ï¼š
        query: è¦å‘çŸ¥è¯†åº“æå‡ºçš„é—®é¢˜æˆ–æŸ¥è¯¢ã€‚
        file_type: æŒ‰æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼ˆä¾‹å¦‚ ".pdf", ".docx", ".txt"ï¼‰ã€‚
        min_tables: æ–‡æ¡£å¿…é¡»åŒ…å«çš„æœ€å°è¡¨æ ¼æ•°é‡ã€‚
        min_titles: æ–‡æ¡£å¿…é¡»åŒ…å«çš„æœ€å°æ ‡é¢˜æ•°é‡ã€‚
        processing_method: æŒ‰å¤„ç†æ–¹æ³•è¿‡æ»¤ï¼ˆä¾‹å¦‚ "unstructured_enhanced", "markitdown"ï¼‰ã€‚
    """
    from tools.search_tools import ask_rag_filtered as ask_rag_filtered_logic
    return ask_rag_filtered_logic(query, file_type, min_tables, min_titles, processing_method)

@mcp.tool()
def get_knowledge_base_stats() -> str:
    """
    è·å–æœ‰å…³çŸ¥è¯†åº“çš„ç»¼åˆç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡æ¡£ç±»å‹ã€å¤„ç†æ–¹æ³•å’Œç»“æ„ä¿¡æ¯ã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - æ£€æŸ¥çŸ¥è¯†åº“ä¸­æœ‰å¤šå°‘æ–‡æ¡£
    - äº†è§£æ–‡ä»¶ç±»å‹çš„åˆ†å¸ƒ
    - æŸ¥çœ‹ä½¿ç”¨äº†å“ªäº›å¤„ç†æ–¹æ³•
    - åˆ†æå­˜å‚¨æ–‡æ¡£çš„ç»“æ„å¤æ‚æ€§

    è¿”å›ï¼š
        æœ‰å…³çŸ¥è¯†åº“å†…å®¹çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    from tools.utility_tools import get_knowledge_base_stats as get_knowledge_base_stats_logic
    return get_knowledge_base_stats_logic()

@mcp.tool()
def get_embedding_cache_stats() -> str:
    """
    è·å–æœ‰å…³åµŒå…¥ç¼“å­˜æ€§èƒ½çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡ä»¥æŸ¥çœ‹ç³»ç»Ÿæ˜¯å¦é«˜æ•ˆå·¥ä½œ
    - ç›‘æ§ç¼“å­˜çš„å†…å­˜ä½¿ç”¨æƒ…å†µ
    - äº†è§£åµŒå…¥çš„é‡ç”¨é¢‘ç‡
    - è°ƒè¯•æ€§èƒ½é—®é¢˜

    è¿”å›ï¼š
        æœ‰å…³åµŒå…¥ç¼“å­˜æ€§èƒ½çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    from tools.utility_tools import get_embedding_cache_stats as get_embedding_cache_stats_logic
    return get_embedding_cache_stats_logic()

@mcp.tool()
def clear_embedding_cache_tool() -> str:
    """
    æ¸…é™¤åµŒå…¥ç¼“å­˜ä»¥é‡Šæ”¾å†…å­˜å’Œç£ç›˜ç©ºé—´ã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - åœ¨ç³»ç»Ÿå†…å­˜ä¸è¶³æ—¶é‡Šæ”¾å†…å­˜
    - åœ¨æ›´æ”¹åµŒå…¥æ¨¡å‹åé‡ç½®ç¼“å­˜
    - æ¸…é™¤ä¸å†éœ€è¦çš„æ—§ç¼“å­˜åµŒå…¥
    - æ’æŸ¥ä¸ç¼“å­˜ç›¸å…³çš„é—®é¢˜

    è¿”å›ï¼š
        æœ‰å…³ç¼“å­˜æ¸…ç†æ“ä½œçš„ç¡®è®¤æ¶ˆæ¯ã€‚
    """
    from tools.utility_tools import clear_embedding_cache_tool as clear_embedding_cache_tool_logic
    return clear_embedding_cache_tool_logic()

@mcp.tool()
def optimize_vector_database() -> str:
    """
    ä¼˜åŒ–å‘é‡æ•°æ®åº“ä»¥æé«˜æœç´¢æ€§èƒ½ã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - æœç´¢é€Ÿåº¦å˜æ…¢
    - æ·»åŠ äº†è®¸å¤šæ–°æ–‡æ¡£
    - å¸Œæœ›æé«˜ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½

    è¿”å›ï¼š
        æœ‰å…³ä¼˜åŒ–è¿‡ç¨‹çš„ä¿¡æ¯ã€‚
    """
    from tools.utility_tools import optimize_vector_database as optimize_vector_database_logic
    return optimize_vector_database_logic()

@mcp.tool()
def get_vector_database_stats() -> str:
    """
    è·å–å‘é‡æ•°æ®åº“çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
    - åˆ†ææ–‡æ¡£åˆ†å¸ƒ
    - è¯Šæ–­æ€§èƒ½é—®é¢˜
    - è§„åˆ’ä¼˜åŒ–

    è¿”å›ï¼š
        å‘é‡æ•°æ®åº“çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    from tools.utility_tools import get_vector_database_stats as get_vector_database_stats_logic
    return get_vector_database_stats_logic()

@mcp.tool()
def reindex_vector_database(profile: str = 'auto') -> str:
    """
    ä½¿ç”¨ä¼˜åŒ–é…ç½®é‡æ–°ç´¢å¼•å‘é‡æ•°æ®åº“ã€‚
    ä½¿ç”¨åœºæ™¯ï¼š
    - æ›´æ”¹é…ç½®æ–‡ä»¶
    - æœç´¢é€Ÿåº¦éå¸¸æ…¢
    - å¸Œæœ›é’ˆå¯¹ç‰¹å®šæ•°æ®åº“å¤§å°è¿›è¡Œä¼˜åŒ–
    - å­˜åœ¨æŒç»­çš„æ€§èƒ½é—®é¢˜

    å‚æ•°ï¼š
        profile: é…ç½®æ–‡ä»¶ï¼ˆ'small', 'medium', 'large', 'auto'ï¼‰ã€‚
                 'auto' ä¼šè‡ªåŠ¨æ£€æµ‹æœ€ä½³é…ç½®æ–‡ä»¶

    è¿”å›ï¼š
        æœ‰å…³é‡æ–°ç´¢å¼•è¿‡ç¨‹çš„ä¿¡æ¯ã€‚
    """
    from tools.utility_tools import reindex_vector_database as reindex_vector_database_logic
    return reindex_vector_database_logic(profile)

# --- å°†æ‰€æœ‰å·¥å…·å‡½æ•°æš´éœ²ä¸º mcp çš„æ–¹æ³•ï¼Œæ–¹ä¾¿ç›´æ¥è°ƒç”¨ï¼ˆå…¨å±€ä½œç”¨åŸŸï¼Œæ‰€æœ‰å‡½æ•°å®šä¹‰ä¹‹åï¼‰ ---
mcp.learn_text = learn_text
mcp.learn_document = learn_document
mcp.ask_rag = ask_rag
mcp.ask_rag_filtered = ask_rag_filtered
mcp.get_knowledge_base_stats = get_knowledge_base_stats
mcp.get_embedding_cache_stats = get_embedding_cache_stats
mcp.clear_embedding_cache_tool = clear_embedding_cache_tool
mcp.optimize_vector_database = optimize_vector_database
mcp.get_vector_database_stats = get_vector_database_stats
mcp.reindex_vector_database = reindex_vector_database

# --- å¯åŠ¨ MCP RAG æœåŠ¡å™¨ ---
if __name__ == "__main__":
    log_mcp_server("å¯åŠ¨ MCP RAG æœåŠ¡å™¨...")
    warm_up_rag_system()  # å¯åŠ¨æ—¶é¢„çƒ­ç³»ç»Ÿ
    log_mcp_server("ğŸš€ æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œè¿è¡Œæ¨¡å¼: stdio (å¦‚éœ€ Web æœåŠ¡è¯·è®¾ç½® host/port)")
    # å°†æ‰€æœ‰å·¥å…·å‡½æ•°æš´éœ²ä¸º mcp çš„æ–¹æ³•ï¼Œæ–¹ä¾¿ç›´æ¥è°ƒç”¨
    mcp.learn_text = learn_text
    mcp.learn_document = learn_document
    mcp.ask_rag = ask_rag
    mcp.ask_rag_filtered = ask_rag_filtered
    mcp.get_knowledge_base_stats = get_knowledge_base_stats
    mcp.get_embedding_cache_stats = get_embedding_cache_stats
    mcp.clear_embedding_cache_tool = clear_embedding_cache_tool
    mcp.optimize_vector_database = optimize_vector_database
    mcp.get_vector_database_stats = get_vector_database_stats
    mcp.reindex_vector_database = reindex_vector_database
    # å¦‚éœ€ Web æœåŠ¡å¯æ”¹ä¸º: mcp.run(host="127.0.0.1", port=8000)
    mcp.run(transport='stdio')