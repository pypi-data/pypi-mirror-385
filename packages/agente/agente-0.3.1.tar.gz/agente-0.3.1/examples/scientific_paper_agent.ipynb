{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Paper Agent\n",
    "\n",
    "In this notebook, we will create an agent that given a dataframe will answer user questions about it. This example is based on the [Scientific Paper Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/scientific_paper_agent_langgraph.ipynb) from the [GenAI Agents](https://github.com/NirDiamant/GenAI_Agents) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import io\n",
    "import urllib3\n",
    "# import pdfplumber\n",
    "import time\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, ClassVar\n",
    "\n",
    "from agente.core.base import BaseAgent,BaseTaskAgent\n",
    "from agente.core.decorators import function_tool,agent_tool\n",
    "\n",
    "## Load and set environment variables from .env file\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's define the Core API Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreAPIWrapper(BaseModel):\n",
    "    \"\"\"Simple wrapper around the CORE API.\"\"\"\n",
    "    base_url: ClassVar[str] = \"https://api.core.ac.uk/v3\"\n",
    "    api_key: ClassVar[str] = os.environ[\"CORE_API_KEY\"]\n",
    "\n",
    "    top_k_results: int = Field(description = \"Top k results obtained by running a query on Core\", default = 1)\n",
    "\n",
    "    def _get_search_response(self, query: str) -> dict:\n",
    "        http = urllib3.PoolManager()\n",
    "\n",
    "        # Retry mechanism to handle transient errors\n",
    "        max_retries = 5    \n",
    "        for attempt in range(max_retries):\n",
    "            response = http.request(\n",
    "                'GET',\n",
    "                f\"{self.base_url}/search/outputs\", \n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"}, \n",
    "                fields={\"q\": query, \"limit\": self.top_k_results}\n",
    "            )\n",
    "            if 200 <= response.status < 300:\n",
    "                return response.json()\n",
    "            elif attempt < max_retries - 1:\n",
    "                time.sleep(2 ** (attempt + 2))\n",
    "            else:\n",
    "                raise Exception(f\"Got non 2xx response from CORE API: {response.status} {response.data}\")\n",
    "\n",
    "    def search(self, query: str) -> str:\n",
    "        response = self._get_search_response(query)\n",
    "        results = response.get(\"results\", [])\n",
    "        if not results:\n",
    "            return \"No relevant results were found\"\n",
    "\n",
    "        # Format the results in a string\n",
    "        docs = []\n",
    "        for result in results:\n",
    "            published_date_str = result.get('publishedDate') or result.get('yearPublished', '')\n",
    "            authors_str = ' and '.join([item['name'] for item in result.get('authors', [])])\n",
    "            docs.append((\n",
    "                f\"* ID: {result.get('id', '')},\\n\"\n",
    "                f\"* Title: {result.get('title', '')},\\n\"\n",
    "                f\"* Published Date: {published_date_str},\\n\"\n",
    "                f\"* Authors: {authors_str},\\n\"\n",
    "                f\"* Abstract: {result.get('abstract', '')},\\n\"\n",
    "                f\"* Paper URLs: {result.get('sourceFulltextUrls') or result.get('downloadUrl', '')}\"\n",
    "            ))\n",
    "        return \"\\n-----\\n\".join(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we start by defining the Judge Adgent, because is the last one to be used in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeAgent(BaseTaskAgent):\n",
    "    \"\"\"Agent that judges the quality of the final answer provided by the research agent.\"\"\"\n",
    "\n",
    "    agent_name:str = \"judge_agent\"\n",
    "    system_prompt: str = \"\"\"You are an expert scientific researcher.\n",
    "Your goal is to review the final answer you provided for a specific user query.\n",
    "\n",
    "Look at the conversation history between you and the user. Based on it, you need to decide if the final answer is satisfactory or not.\n",
    "\n",
    "A good final answer should:\n",
    "- Directly answer the user query. For example, it does not answer a question about a different paper or area of research.\n",
    "- Answer extensively the request from the user.\n",
    "- Take into account any feedback given through the conversation.\n",
    "- Provide inline sources to support any claim made in the answer.\n",
    "\n",
    "In case the answer is not good enough, provide clear and concise feedback on what needs to be improved to pass the evaluation.\n",
    "\n",
    "Write your evaluation by calling the `complete_task` function with the evaluation as an argument.\n",
    "\"\"\"\n",
    "    completion_kwargs: dict = {\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"stream\": True,\n",
    "    }\n",
    "    user_query: str = None\n",
    "\n",
    "    @function_tool\n",
    "    def task_completed(self, \n",
    "                        evaluation: Annotated[str, \"The evaluation of the final answer.\"], \n",
    "                        re_do: Annotated[bool, \"Whether to go repeat the research process or not. Default is False.\"] = False) -> str:\n",
    "        \"\"\"Evaluate the final answer and provide feedback.\"\"\"\n",
    "        if re_do:\n",
    "            self.parent_agent.next_tool_map[\"judge_agent\"] = \"planning_agent\"\n",
    "\n",
    "        return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we define the Planning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanningAgent(BaseTaskAgent):\n",
    "    \"\"\"Agent that plans the search for research papers using the CORE API.\"\"\"\n",
    "\n",
    "    agent_name:str = \"planing_agent\"\n",
    "    system_prompt: str = \"\"\"# IDENTITY AND PURPOSE\n",
    "\n",
    "You are an experienced scientific researcher.\n",
    "Your goal is to make a new step by step plan to help the user with their scientific research .\n",
    "\n",
    "Subtasks should not rely on any assumptions or guesses, but only rely on the information provided in the context or look up for any additional information.\n",
    "\n",
    "If any feedback is provided about a previous answer, incorportate it in your new planning.\n",
    "\n",
    "\n",
    "# TOOLS\n",
    "\n",
    "For each subtask, indicate the given tool required to complete the subtask. \n",
    "Tools can be one of the following:\n",
    "\n",
    "- search_papers: Search for research papers using the CORE API.\n",
    "- download_paper: Download a research paper from a given URL.\n",
    "- ask_human_feedback: Ask for human feedback on a given answer.\n",
    "\"\"\"\n",
    "    completion_kwargs: dict = {\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"stream\": True,\n",
    "    }\n",
    "\n",
    "\n",
    "    @function_tool\n",
    "    def task_completed(self, plan: Annotated[str, \"The plan to be executed\"]) -> str:\n",
    "        \"\"\"Complete the task by providing the plan.\"\"\"\n",
    "        return plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the research agent, that will be solely responsible to execute the research plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAgent(BaseTaskAgent):\n",
    "    \"\"\"Agent that do the research for the user.\"\"\"\n",
    "\n",
    "    agent_name:str = \"research_agent\"\n",
    "    system_prompt: str = \"\"\"# IDENTITY AND PURPOSE\n",
    "\n",
    "You are an experienced scientific researcher. \n",
    "Your goal is to help the user with their scientific research. You have access to a set of external tools to complete your tasks.\n",
    "Follow the plan given by the planning agent to successfully complete the task.\n",
    "At the end call the complete_task tool to provide the final answer to the user.\n",
    "\n",
    "Add extensive inline citations to support any claim made in the answer.\n",
    "\n",
    "\n",
    "# EXTERNAL KNOWLEDGE\n",
    "\n",
    "## CORE API\n",
    "\n",
    "The CORE API has a specific query language that allows you to explore a vast papers collection and perform complex queries. See the following table for a list of available operators:\n",
    "\n",
    "| Operator       | Accepted symbols         | Meaning                                                                                      |\n",
    "|---------------|-------------------------|----------------------------------------------------------------------------------------------|\n",
    "| And           | AND, +, space          | Logical binary and.                                                                           |\n",
    "| Or            | OR                     | Logical binary or.                                                                            |\n",
    "| Grouping      | (...)                  | Used to prioritise and group elements of the query.                                           |\n",
    "| Field lookup  | field_name:value       | Used to support lookup of specific fields.                                                    |\n",
    "| Range queries | fieldName(>, <,>=, <=) | For numeric and date fields, it allows to specify a range of valid values to return.         |\n",
    "| Exists queries| _exists_:fieldName     | Allows for complex queries, it returns all the items where the field specified by fieldName is not empty. |\n",
    "\n",
    "Use this table to formulate more complex queries filtering for specific papers, for example publication date/year.\n",
    "Here are the relevant fields of a paper object you can use to filter the results:\n",
    "{\n",
    "  \"authors\": [{\"name\": \"Last Name, First Name\"}],\n",
    "  \"documentType\": \"presentation\" or \"research\" or \"thesis\",\n",
    "  \"publishedDate\": \"2019-08-24T14:15:22Z\",\n",
    "  \"title\": \"Title of the paper\",\n",
    "  \"yearPublished\": \"2019\"\n",
    "}\n",
    "\n",
    "Example queries:\n",
    "- \"machine learning AND yearPublished:2023\"\n",
    "- \"maritime biology AND yearPublished>=2023 AND yearPublished<=2024\"\n",
    "- \"cancer research AND authors:Vaswani, Ashish AND authors:Bello, Irwan\"\n",
    "- \"title:Attention is all you need\"\n",
    "- \"mathematics AND _exists_:abstract\"\n",
    "\"\"\"\n",
    "\n",
    "    completion_kwargs: dict = {\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"stream\": True,\n",
    "        \"tool_choice\": \"required\"\n",
    "    }\n",
    "\n",
    "\n",
    "    @function_tool\n",
    "    def search_papers(self,\n",
    "                        query: Annotated[str, \"The query to search for scientific papers.\"],\n",
    "                        max_papers: Annotated[int, \"The maximum number of papers to return. Default is 1.\"] = 1) -> str:\n",
    "        \"\"\"Search for scientific papers using the CORE API.\n",
    "\n",
    "        Example:\n",
    "        {\"query\": \"Attention is all you need\", \"max_papers\": 1}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return CoreAPIWrapper(top_k_results=max_papers).search(query)\n",
    "        except Exception as e:\n",
    "            return f\"Error performing paper search: {e}\"\n",
    "\n",
    "    @function_tool\n",
    "    def download_paper(self,url: Annotated[str, \"The URL to download the scientific paper\"]) -> str:\n",
    "        \"\"\"Download a specific scientific paper from a given URL.\n",
    "\n",
    "        Example:\n",
    "        {\"url\": \"https://sample.pdf\"}\n",
    "        \"\"\"\n",
    "        try:        \n",
    "            http = urllib3.PoolManager(\n",
    "                cert_reqs='CERT_NONE',\n",
    "            )\n",
    "            \n",
    "            # Mock browser headers to avoid 403 error\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "                'Accept-Language': 'en-US,en;q=0.5',\n",
    "                'Accept-Encoding': 'gzip, deflate, br',\n",
    "                'Connection': 'keep-alive',\n",
    "            }\n",
    "            max_retries = 5\n",
    "            for attempt in range(max_retries):\n",
    "                response = http.request('GET', url, headers=headers)\n",
    "                if 200 <= response.status < 300:\n",
    "                    pdf_file = io.BytesIO(response.data)\n",
    "                    with pdfplumber.open(pdf_file) as pdf:\n",
    "                        text = \"\"\n",
    "                        for page in pdf.pages:\n",
    "                            text += page.extract_text() + \"\\n\"\n",
    "                    return text\n",
    "                elif attempt < max_retries - 1:\n",
    "                    time.sleep(2 ** (attempt + 2))\n",
    "                else:\n",
    "                    raise Exception(f\"Got non 2xx when downloading paper: {response.status_code} {response.text}\")\n",
    "        except Exception as e:\n",
    "            return f\"Error downloading paper: {e}\"\n",
    "\n",
    "\n",
    "    @agent_tool\n",
    "    def ask_human_feedback(self,question: Annotated[str, \"The question to ask for human feedback\"]) -> str:\n",
    "        \"\"\"Ask for human feedback. You should call this tool when encountering unexpected errors. \"\"\"\n",
    "\n",
    "        class HumanFeedback(BaseTaskAgent):\n",
    "\n",
    "            agent_name:str = \"human_feedback\"\n",
    "\n",
    "            @function_tool\n",
    "            def complete_task(self, feedback: str) -> str:\n",
    "                \"\"\"Complete the task by providing the feedback.\n",
    "\n",
    "                Args:\n",
    "                    feedback: The feedback provided by the human.\n",
    "                \"\"\"\n",
    "                return feedback\n",
    "        \n",
    "        human_feedback = HumanFeedback()\n",
    "        human_feedback.add_message(\"assistant\",question)\n",
    "        return human_feedback\n",
    "            \n",
    "\n",
    "    @function_tool\n",
    "    def task_completed(self, final_answer: Annotated[str, \"The final answer to the user query.\"]) -> str:\n",
    "        \"\"\"Complete the task by providing the final answer. \"\"\"\n",
    "        return final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's define the main agent, responsible to orchestrate the other agents. \n",
    "\n",
    "Here, we merge the original, and initial, decision step in the same main agent. It will decice if it replies directly or start the research pipeline, by calling the planning agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainAgent(BaseAgent):\n",
    "\n",
    "    agent_name:str = \"MainAgent\"\n",
    "    system_prompt: str = \"\"\"You are an experienced scientific researcher.\n",
    "Your goal is to help the user with their scientific research.\n",
    "\n",
    "Based on the user query, decide if you need to perform a research or if you can answer the question directly.\n",
    "- You should perform a research if the user query requires any supporting evidence or information. In this case, you should call first the planning agent to create a plan and then the research agent to execute the plan, and finally the judge agent to evaluate the final answer.\n",
    "- You should answer the question directly only for simple conversational questions, like \"how are you?\".\n",
    "\"\"\"    \n",
    "    completion_kwargs: dict = {\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    user_query:str = None\n",
    "\n",
    "    @agent_tool(next_tool=\"research_agent\",manual_call=lambda m:{'plan':m})\n",
    "    def planning_agent(self,user_query: str):\n",
    "        \"\"\"The query to be planned\n",
    "\n",
    "        Args:\n",
    "            user_query: The user query.        \n",
    "        \"\"\"\n",
    "        self.user_query = user_query\n",
    "        planning_agent = PlanningAgent()\n",
    "        planning_agent.add_message(\"user\",user_query)\n",
    "        return planning_agent\n",
    "\n",
    "    @agent_tool(next_tool=\"judge_agent\",manual_call=lambda m:{'final_answer':m})\n",
    "    def research_agent(self,plan: str):\n",
    "        \"\"\"The plan to be executed\n",
    "        \n",
    "        Args:\n",
    "            plan: The plan to be executed        \n",
    "        \"\"\"\n",
    "\n",
    "        research_agent = ResearchAgent()\n",
    "        research_agent.add_message(\"user\",plan)\n",
    "        return research_agent\n",
    "\n",
    "    @agent_tool\n",
    "    def judge_agent(self,final_answer: str):\n",
    "        \"\"\"Judge tool that will evaluate the answer from the research agent. It should be used after the research agent have finished its job.\n",
    "\n",
    "        Args:\n",
    "            final_answer: The final answer to be judged\n",
    "\n",
    "        \"\"\" \n",
    "        judge_agent = JudgeAgent(user_query = self.user_query)\n",
    "        prompt = f\"Initial user question:{self.user_query}\\n\\nThe answer from the research agent:{final_answer}\"\n",
    "        judge_agent.add_message(\"user\",prompt)\n",
    "        return judge_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_agent = MainAgent()\n",
    "main_agent.add_message(\"user\",\"Can you find 5 papers on quantum machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing agent: MainAgent\n",
      "Executing agent: planing_agent\n",
      "Executing tool: task_completed (agent: planing_agent)\n",
      "Executing agent: research_agent\n",
      "Executing tool: search_papers (agent: research_agent)\n",
      "Executing agent: research_agent\n"
     ]
    }
   ],
   "source": [
    "response_iterator = await main_agent.run(max_retries = 10)\n",
    "async for response in response_iterator:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role='system' agent_name='MainAgent' content=[Content(type='text', text='You are an experienced scientific researcher.\\nYour goal is to help the user with their scientific research.\\n\\nBased on the user query, decide if you need to perform a research or if you can answer the question directly.\\n- You should perform a research if the user query requires any supporting evidence or information. In this case, you should call first the planning agent to create a plan and then the research agent to execute the plan, and finally the judge agent to evaluate the final answer.\\n- You should answer the question directly only for simple conversational questions, like \"how are you?\".\\n')] tool_calls=None tool_call_id=None tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 20, 700055)\n",
      "--------------------------------\n",
      "role='user' agent_name='MainAgent' content=[Content(type='text', text='Can you find 5 papers on quantum machine learning?')] tool_calls=None tool_call_id=None tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 20, 700108)\n",
      "--------------------------------\n",
      "role='assistant' agent_name='MainAgent' content=[] tool_calls=[{'index': 0, 'id': 'call_1fBPhOA2mwsZPMXUxqyOenJL', 'function': {'name': 'planning_agent', 'arguments': '{\"user_query\":\"Find 5 papers on quantum machine learning\"}'}, 'type': 'function'}] tool_call_id=None tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 21, 865921)\n",
      "--------------------------------\n",
      "role='tool' agent_name='MainAgent' content=[Content(type='text', text='\"Step 1: Use the search_papers tool to look for recent and relevant papers on \\'quantum machine learning.\\'\\\\nStep 2: From the search results, select five papers that provide diverse perspectives, methodologies, or applications within quantum machine learning.\\\\nStep 3: Present the titles and basic citation information for each of the five papers to the user.\\\\n\\\\n[Tool required: search_papers]\"')] tool_calls=None tool_call_id='call_1fBPhOA2mwsZPMXUxqyOenJL' tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 24, 311336)\n",
      "--------------------------------\n",
      "role='assistant' agent_name='MainAgent' content=[] tool_calls=[{'id': 'manual_8tRdKg2s6hp4CRWu4Pt093jR', 'function': {'name': 'research_agent', 'arguments': '{\"plan\": \"Step 1: Use the search_papers tool to look for recent and relevant papers on \\'quantum machine learning.\\'\\\\nStep 2: From the search results, select five papers that provide diverse perspectives, methodologies, or applications within quantum machine learning.\\\\nStep 3: Present the titles and basic citation information for each of the five papers to the user.\\\\n\\\\n[Tool required: search_papers]\"}'}, 'type': 'function'}] tool_call_id=None tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 24, 314876)\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for m in main_agent.conv_history.messages:\n",
    "    print(m)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role='system' agent_name='research_agent' content=[Content(type='text', text='# IDENTITY AND PURPOSE\\n\\nYou are an experienced scientific researcher. \\nYour goal is to help the user with their scientific research. You have access to a set of external tools to complete your tasks.\\nFollow the plan given by the planning agent to successfully complete the task.\\nAt the end call the complete_task tool to provide the final answer to the user.\\n\\nAdd extensive inline citations to support any claim made in the answer.\\n\\n\\n# EXTERNAL KNOWLEDGE\\n\\n## CORE API\\n\\nThe CORE API has a specific query language that allows you to explore a vast papers collection and perform complex queries. See the following table for a list of available operators:\\n\\n| Operator       | Accepted symbols         | Meaning                                                                                      |\\n|---------------|-------------------------|----------------------------------------------------------------------------------------------|\\n| And           | AND, +, space          | Logical binary and.                                                                           |\\n| Or            | OR                     | Logical binary or.                                                                            |\\n| Grouping      | (...)                  | Used to prioritise and group elements of the query.                                           |\\n| Field lookup  | field_name:value       | Used to support lookup of specific fields.                                                    |\\n| Range queries | fieldName(>, <,>=, <=) | For numeric and date fields, it allows to specify a range of valid values to return.         |\\n| Exists queries| _exists_:fieldName     | Allows for complex queries, it returns all the items where the field specified by fieldName is not empty. |\\n\\nUse this table to formulate more complex queries filtering for specific papers, for example publication date/year.\\nHere are the relevant fields of a paper object you can use to filter the results:\\n{\\n  \"authors\": [{\"name\": \"Last Name, First Name\"}],\\n  \"documentType\": \"presentation\" or \"research\" or \"thesis\",\\n  \"publishedDate\": \"2019-08-24T14:15:22Z\",\\n  \"title\": \"Title of the paper\",\\n  \"yearPublished\": \"2019\"\\n}\\n\\nExample queries:\\n- \"machine learning AND yearPublished:2023\"\\n- \"maritime biology AND yearPublished>=2023 AND yearPublished<=2024\"\\n- \"cancer research AND authors:Vaswani, Ashish AND authors:Bello, Irwan\"\\n- \"title:Attention is all you need\"\\n- \"mathematics AND _exists_:abstract\"\\n')] tool_calls=None tool_call_id=None tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 24, 322266)\n",
      "--------------------------------\n",
      "role='user' agent_name='research_agent' content=[Content(type='text', text=\"Step 1: Use the search_papers tool to look for recent and relevant papers on 'quantum machine learning.'\\nStep 2: From the search results, select five papers that provide diverse perspectives, methodologies, or applications within quantum machine learning.\\nStep 3: Present the titles and basic citation information for each of the five papers to the user.\\n\\n[Tool required: search_papers]\")] tool_calls=None tool_call_id=None tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 24, 322283)\n",
      "--------------------------------\n",
      "role='assistant' agent_name='research_agent' content=[] tool_calls=[{'index': 0, 'id': 'call_YtkYAnS7GnjQsXzu5rCqpCOF', 'function': {'name': 'search_papers', 'arguments': '{\"query\":\"quantum machine learning AND yearPublished>=2022\",\"max_papers\":10}'}, 'type': 'function'}] tool_call_id=None tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 25, 861591)\n",
      "--------------------------------\n",
      "role='tool' agent_name='research_agent' content=[Content(type='text', text='\"* ID: 186289797,\\\\n* Title: PennyLane: Automatic differentiation of hybrid quantum-classical\\\\n  computations,\\\\n* Published Date: 2022-07-29T01:00:00+01:00,\\\\n* Authors: Bergholm, Ville and Izaac, Josh and Schuld, Maria and Gogolin, Christian and Ahmed, Shahnawaz and Ajith, Vishnu and Alam, M. Sohaib and Alonso-Linaje, Guillermo and AkashNarayanan, B. and Asadi, Ali and Arrazola, Juan Miguel and Azad, Utkarsh and Banning, Sam and Blank, Carsten and Bromley, Thomas R and Cordier, Benjamin A. and Ceroni, Jack and Delgado, Alain and Di Matteo, Olivia and Dusko, Amintor and Garg, Tanya and Guala, Diego and Hayes, Anthony and Hill, Ryan and Ijaz, Aroosa and Isacsson, Theodor and Ittah, David and Jahangiri, Soran and Jain, Prateek and Jiang, Edward and Khandelwal, Ankit and Kottmann, Korbinian and Lang, Robert A. and Lee, Christina and Loke, Thomas and Lowe, Angus and McKiernan, Keri and Meyer, Johannes Jakob and Monta\\\\u00f1ez-Barrera, J. A. and Moyard, Romain and Niu, Zeyue and O\\'Riordan, Lee James and Oud, Steven and Panigrahi, Ashish and Park, Chae-Yeun and Polatajko, Daniel and Quesada, Nicol\\\\u00e1s and Roberts, Chase and S\\\\u00e1, Nahum and Schoch, Isidor and Shi, Borun and Shu, Shuli and Sim, Sukin and Singh, Arshpreet and Strandberg, Ingrid and Soni, Jay and Sz\\\\u00e1va, Antal and Thabet, Slimane and Vargas-Hern\\\\u00e1ndez, Rodrigo A. and Vincent, Trevor and Vitucci, Nicola and Weber, Maurice and Wierichs, David and Wiersema, Roeland and Willmann, Moritz and Wong, Vincent and Zhang, Shaoming and Killoran, Nathan,\\\\n* Abstract: PennyLane is a Python 3 software framework for differentiable programming of\\\\nquantum computers. The library provides a unified architecture for near-term\\\\nquantum computing devices, supporting both qubit and continuous-variable\\\\nparadigms. PennyLane\\'s core feature is the ability to compute gradients of\\\\nvariational quantum circuits in a way that is compatible with classical\\\\ntechniques such as backpropagation. PennyLane thus extends the automatic\\\\ndifferentiation algorithms common in optimization and machine learning to\\\\ninclude quantum and hybrid computations. A plugin system makes the framework\\\\ncompatible with any gate-based quantum simulator or hardware. We provide\\\\nplugins for hardware providers including the Xanadu Cloud, Amazon Braket, and\\\\nIBM Quantum, allowing PennyLane optimizations to be run on publicly accessible\\\\nquantum devices. On the classical front, PennyLane interfaces with accelerated\\\\nmachine learning libraries such as TensorFlow, PyTorch, JAX, and Autograd.\\\\nPennyLane can be used for the optimization of variational quantum eigensolvers,\\\\nquantum approximate optimization, quantum machine learning models, and many\\\\nother applications.Comment: Code available at https://github.com/XanaduAI/pennylane/ .\\\\n  Significant contributions to the code (new features, new plugins, etc.) will\\\\n  be recognized by the opportunity to be a co-author on this pape,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/1811.04968\\']\\\\n-----\\\\n* ID: 200814172,\\\\n* Title: Hidden self-energies as origin of cuprate superconductivity revealed by\\\\n  machine learning,\\\\n* Published Date: 2023-02-13T00:00:00+00:00,\\\\n* Authors: Yamaji, Youhei and Yoshida, Teppei and Fujimori, Atsushi and Imada, Masatoshi,\\\\n* Abstract: Experimental data are the source of understanding matter. However, measurable\\\\nquantities are limited and theoretically important quantities are sometimes\\\\nhidden. Nonetheless, recent progress of machine-learning techniques opens\\\\npossibilities of exposing them only from available experimental data. In this\\\\npaper, after establishing the reliability of the method in various careful\\\\nbenchmark tests, the Boltzmann-machine method is applied to the angle-resolved\\\\nphotoemission spectroscopy spectra of cuprate high temperature superconductors,\\\\nBi$_2$Sr$_2$CuO$_{6+\\\\\\\\delta}$ (Bi2201) and Bi$_2$Sr$_2$CaCuO$_{8+\\\\\\\\delta}$\\\\n(Bi2212). We find prominent peak structures both in normal and anomalous\\\\nself-energies, but they cancel in the total self-energy making the structure\\\\napparently invisible, while the peaks make universally dominant contributions\\\\nto superconducting gap, hence evidencing the signal that generates the\\\\nhigh-$T_{\\\\\\\\rm c}$ superconductivity. The relation between superfluid density and\\\\ncritical temperature supports involvement of universal carrier relaxation\\\\nassociated with dissipative strange metals, where enhanced superconductivity is\\\\npromoted by entangled quantum-soup nature of the cuprates. The present\\\\nachievement opens avenues for innovative machine-learning spectroscopy method\\\\nto reveal fundamental properties hidden in direct experimental accesses.Comment: 41 pages, 25 figure,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/1903.08060\\']\\\\n-----\\\\n* ID: 323174114,\\\\n* Title: On compression rate of quantum autoencoders: Control design, numerical\\\\n  and experimental realization,\\\\n* Published Date: 2022-06-27T01:00:00+01:00,\\\\n* Authors: Ma, Hailan and Huang, Chang-Jiang and Chen, Chunlin and Dong, Daoyi and Wang, Yuanlong and Wu, Re-Bing and Xiang, Guo-Yong,\\\\n* Abstract: Quantum autoencoders which aim at compressing quantum information in a\\\\nlow-dimensional latent space lie in the heart of automatic data compression in\\\\nthe field of quantum information. In this paper, we establish an upper bound of\\\\nthe compression rate for a given quantum autoencoder and present a learning\\\\ncontrol approach for training the autoencoder to achieve the maximal\\\\ncompression rate. The upper bound of the compression rate is theoretically\\\\nproven using eigen-decomposition and matrix differentiation, which is\\\\ndetermined by the eigenvalues of the density matrix representation of the input\\\\nstates. Numerical results on 2-qubit and 3-qubit systems are presented to\\\\ndemonstrate how to train the quantum autoencoder to achieve the theoretically\\\\nmaximal compression, and the training performance using different machine\\\\nlearning algorithms is compared. Experimental results of a quantum autoencoder\\\\nusing quantum optical systems are illustrated for compressing two 2-qubit\\\\nstates into two 1-qubit states,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/2005.11149\\']\\\\n-----\\\\n* ID: 83851408,\\\\n* Title: Unified Representation of Molecules and Crystals for Machine Learning,\\\\n* Published Date: 2022-11-24T00:00:00+00:00,\\\\n* Authors: Huo, Haoyan and Rupp, Matthias,\\\\n* Abstract: Accurate simulations of atomistic systems from first principles are limited\\\\nby computational cost. In high-throughput settings, machine learning can reduce\\\\nthese costs significantly by accurately interpolating between reference\\\\ncalculations. For this, kernel learning approaches crucially require a\\\\nrepresentation that accommodates arbitrary atomistic systems. We introduce a\\\\nmany-body tensor representation that is invariant to translations, rotations,\\\\nand nuclear permutations of same elements, unique, differentiable, can\\\\nrepresent molecules and crystals, and is fast to compute. Empirical evidence\\\\nfor competitive energy and force prediction errors is presented for changes in\\\\nmolecular structure, crystal chemistry, and molecular dynamics using kernel\\\\nregression and symmetric gradient-domain machine learning as models.\\\\nApplicability is demonstrated for phase diagrams of Pt-group/transition-metal\\\\nbinary systems.Comment: Final revised version, major updat,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/1704.06439\\']\\\\n-----\\\\n* ID: 186266268,\\\\n* Title: A Grover-search Based Quantum Learning Scheme for Classification,\\\\n* Published Date: 2022-05-29T01:00:00+01:00,\\\\n* Authors: Du, Yuxuan and Hsieh, Min-Hsiu and Liu, Tongliang and Tao, Dacheng,\\\\n* Abstract: The hybrid quantum-classical learning scheme provides a prominent way to\\\\nachieve quantum advantages on near-term quantum devices. A concrete example\\\\ntowards this goal is the quantum neural network (QNN), which has been developed\\\\nto accomplish various supervised learning tasks such as classification and\\\\nregression. However, there are two central issues that remain obscure when QNN\\\\nis exploited to accomplish classification tasks. First, a quantum classifier\\\\nthat can well balance the computational cost such as the number of measurements\\\\nand the learning performance is unexplored. Second, it is unclear whether\\\\nquantum classifiers can be applied to solve certain problems that outperform\\\\ntheir classical counterparts. Here we devise a Grover-search based quantum\\\\nlearning scheme (GBLS) to address the above two issues. Notably, most existing\\\\nQNN-based quantum classifiers can be seamlessly embedded into the proposed\\\\nscheme. The key insight behind our proposal is reformulating the classification\\\\ntasks as the search problem. Numerical simulations exhibit that GBLS can\\\\nachieve comparable performance with other quantum classifiers under various\\\\nnoise settings, while the required number of measurements is dramatically\\\\nreduced. We further demonstrate a potential quantum advantage of GBLS over\\\\nclassical classifiers in the measure of query complexity. Our work provides\\\\nguidance to develop advanced quantum classifiers on near-term quantum devices\\\\nand opens up an avenue to explore potential quantum advantages in various\\\\nclassification tasks.Comment: final versio,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/1809.06056\\']\\\\n-----\\\\n* ID: 93944686,\\\\n* Title: Learning to Detect Entanglement,\\\\n* Published Date: 2024-05-22T01:00:00+01:00,\\\\n* Authors: Wang, Bingjie,\\\\n* Abstract: Classifying states as entangled or separable is a fundamental, but expensive\\\\ntask. This paper presents a method, the forest algorithm, to improve the amount\\\\nof resources needed to detect entanglement. Starting from \\'optimized\\' methods\\\\nfor using geometric criterion to detect entanglement, specific steps are\\\\nreplaced with machine learning models. Tests using numerical simulations\\\\nindicate that the model is able to declare a state as entangled in fewer steps\\\\ncompared to existing methods. This improvement is achieved without affecting\\\\nthe correctness of the original algorithm,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/1709.03617\\']\\\\n-----\\\\n* ID: 186308984,\\\\n* Title: Kymatio: Scattering Transforms in Python,\\\\n* Published Date: 2022-05-31T01:00:00+01:00,\\\\n* Authors: Andreux, Mathieu and Angles, Tom\\\\u00e1s and Exarchakis, Georgios and Leonarduzzi, Roberto and Rochette, Gaspar and Thiry, Louis and Zarka, John and Mallat, St\\\\u00e9phane and and\\\\u00e9n, Joakim and Belilovsky, Eugene and Bruna, Joan and Lostanlen, Vincent and Chaudhary, Muawiz and Hirn, Matthew J. and Oyallon, Edouard and Zhang, Sixin and Cella, Carmine and Eickenberg, Michael,\\\\n* Abstract: The wavelet scattering transform is an invariant signal representation\\\\nsuitable for many signal processing and machine learning applications. We\\\\npresent the Kymatio software package, an easy-to-use, high-performance Python\\\\nimplementation of the scattering transform in 1D, 2D, and 3D that is compatible\\\\nwith modern deep learning frameworks. All transforms may be executed on a GPU\\\\n(in addition to CPU), offering a considerable speed up over CPU\\\\nimplementations. The package also has a small memory footprint, resulting\\\\ninefficient memory usage. The source code, documentation, and examples are\\\\navailable undera BSD license at https://www.kymat.io,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/1812.11214\\']\\\\n-----\\\\n* ID: 186268843,\\\\n* Title: An Efficient Algorithmic Way to Construct Boltzmann Machine\\\\n  Representations for Arbitrary Stabilizer Code,\\\\n* Published Date: 2022-02-23T00:00:00+00:00,\\\\n* Authors: Zhang, Yuan-Hang and Jia, Zhian and Wu, Yu-Chun and Guo, Guang-Can,\\\\n* Abstract: The restricted Boltzmann machine (RBM) has seen great success as a\\\\nvariational quantum state, but its representational power is far less\\\\nunderstood. We analytically give the first proof that RBMs can exactly and\\\\nefficiently represent stabilizer code states, a family of highly entangled\\\\nstates of great importance in the field of quantum error correction. Given the\\\\nstabilizer generators, we present an efficient algorithm to compute the\\\\nstructure of the RBM, as well as the exact values of RBM parameters. This opens\\\\nup a new perspective on the representational power of RBMs, justifying the\\\\nsuccess of RBMs in representing highly entangled states, and is potentially\\\\nuseful in the classical simulation of quantum error-correcting codes,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/1809.08631\\']\\\\n-----\\\\n* ID: 294827880,\\\\n* Title: Representations of molecules and materials for interpolation of quantum-mechanical simulations via machine learning,\\\\n* Published Date: 2022-03-16T00:00:00+00:00,\\\\n* Authors: Langer, M. and Goe\\\\u00dfmann, A. and Rupp, M.,\\\\n* Abstract: Computational study of molecules and materials from first principles is a cornerstone of physics, chemistry and materials science, but limited by the cost of accurate and precise simulations. In settings involving many simulations, machine learning can reduce these costs, sometimes by orders of magnitude, by interpolating between reference simulations. This requires representations that describe any molecule or material and support interpolation. We review, discuss and benchmark state-of-the-art representations and relations between them, including smooth overlap of atomic positions, many-body tensor representation, and symmetry functions. For this, we use a unified mathematical framework based on many-body functions, group averaging and tensor products, and compare energy predictions for organic molecules, binary alloys and Al-Ga-In sesquioxides in numerical experiments controlled for data distribution, regression method and hyper-parameter optimization,\\\\n* Paper URLs: [\\'http://hdl.handle.net/21.11116/0000-0005-FB6F-5\\']\\\\n-----\\\\n* ID: 200805474,\\\\n* Title: Local Function Complexity for Active Learning via Mixture of Gaussian\\\\n  Processes,\\\\n* Published Date: 2023-12-12T00:00:00+00:00,\\\\n* Authors: Panknin, Danny and Chmiela, Stefan and M\\\\u00fcller, Klaus-Robert and Nakajima, Shinichi,\\\\n* Abstract: Inhomogeneities in real-world data, e.g., due to changes in the observation\\\\nnoise level or variations in the structural complexity of the source function,\\\\npose a unique set of challenges for statistical inference. Accounting for them\\\\ncan greatly improve predictive power when physical resources or computation\\\\ntime is limited. In this paper, we draw on recent theoretical results on the\\\\nestimation of local function complexity (LFC), derived from the domain of local\\\\npolynomial smoothing (LPS), to establish a notion of local structural\\\\ncomplexity, which is used to develop a model-agnostic active learning (AL)\\\\nframework. Due to its reliance on pointwise estimates, the LPS model class is\\\\nnot robust and scalable concerning large input space dimensions that typically\\\\ncome along with real-world problems. Here, we derive and estimate the Gaussian\\\\nprocess regression (GPR)-based analog of the LPS-based LFC and use it as a\\\\nsubstitute in the above framework to make it robust and scalable. We assess the\\\\neffectiveness of our LFC estimate in an AL application on a prototypical\\\\nlow-dimensional synthetic dataset, before taking on the challenging real-world\\\\ntask of reconstructing a quantum chemical force field for a small organic\\\\nmolecule and demonstrating state-of-the-art performance with a significantly\\\\nreduced training demand.Comment: 30 pages (+18 pages of references and appendices), 20 figure,\\\\n* Paper URLs: [\\'http://arxiv.org/abs/1902.10664\\']\"')] tool_calls=None tool_call_id='call_YtkYAnS7GnjQsXzu5rCqpCOF' tool_name=None hidden=False id=None usage=None timestamp=datetime.datetime(2025, 9, 27, 9, 24, 29, 239022)\n",
      "--------------------------------\n",
      "role='assistant' agent_name='research_agent' content=[Content(type='text', text='Here are five recent and diverse papers on quantum machine learning, highlighting different perspectives, methodologies, or applications:\\n\\n1. **PennyLane: Automatic differentiation of hybrid quantum-classical computations**  \\n   *Authors:* Bergholm, Ville; Izaac, Josh; Schuld, Maria; et al.  \\n   *Published:* 2022  \\n   *Summary:* Introduces PennyLane, a Python library for differentiable programming of quantum computers, enabling seamless hybrid quantum-classical machine learning models and optimization on various quantum hardware and simulators.  \\n   *URL:* http://arxiv.org/abs/1811.04968\\n\\n2. **Learning to Detect Entanglement**  \\n   *Author:* Wang, Bingjie  \\n   *Published:* 2024  \\n   *Summary:* Proposes a machine learning–based \"forest algorithm\" that improves the efficiency of detecting entanglement in quantum states, requiring fewer computational resources compared to traditional algorithms.  \\n   *URL:* http://arxiv.org/abs/1709.03617\\n\\n3. **On compression rate of quantum autoencoders: Control design, numerical and experimental realization**  \\n   *Authors:* Ma, Hailan; Huang, Chang-Jiang; Chen, Chunlin; et al.  \\n   *Published:* 2022  \\n   *Summary:* Explores quantum autoencoders—a quantum analog of classical data compression—and provides theoretical, numerical, and experimental insights into maximizing compression rates for quantum information.  \\n   *URL:* http://arxiv.org/abs/2005.11149\\n\\n4. **A Grover-search Based Quantum Learning Scheme for Classification**  \\n   *Authors:* Du, Yuxuan; Hsieh, Min-Hsiu; Liu, Tongliang; Tao, Dacheng  \\n   *Published:* 2022  \\n   *Summary:* Presents a novel hybrid quantum-classical learning scheme that leverages Grover\\'s search for efficient quantum classification, reducing resource consumption and potentially outperforming classical classifiers in some scenarios.  \\n   *URL:* http://arxiv.org/abs/1809.06056\\n\\n5. **An Efficient Algorithmic Way to Construct Boltzmann Machine Representations for Arbitrary Stabilizer Code**  \\n   *Authors:* Zhang, Yuan-Hang; Jia, Zhian; Wu, Yu-Chun; Guo, Guang-Can  \\n   *Published:* 2022  \\n   *Summary:* Demonstrates how restricted Boltzmann machines (a type of generative machine learning model) can exactly and efficiently represent stabilizer code states, bridging quantum error correction and machine learning.  \\n   *URL:* http://arxiv.org/abs/1809.08631\\n\\nThese papers exemplify the diversity of current research in quantum machine learning, spanning software frameworks, algorithmic advances, hardware experiments, foundational theory, and application-driven innovations.')] tool_calls=None tool_call_id=None tool_name=None hidden=False id=None usage=Usage(completion_tokens=582, prompt_tokens=4442, total_tokens=5024) timestamp=datetime.datetime(2025, 9, 27, 9, 24, 45, 903414)\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for m in main_agent.child_agents[1].conv_history.messages:\n",
    "    print(m)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new agent\n",
      "Executing agent: MainAgent\n",
      "Executing agent: MainAgent\n",
      "Executing agent: planing_agent\n",
      "Executing tool: task_completed (agent: planing_agent)\n",
      "Executing agent: research_agent\n",
      "Executing tool: search_papers (agent: research_agent)\n",
      "Executing agent: research_agent\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from litellm import ModelResponseStream\n",
    "from agente.models.schemas import StreamResponse\n",
    "\n",
    "\n",
    "def get_new_agent():\n",
    "    \"\"\"Create a fresh agent instance\"\"\"\n",
    "    print(\"Creating a new agent\")\n",
    "    new_agent = MainAgent()\n",
    "    return new_agent\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(type=\"messages\")\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    # Initialize with a function call instead of direct instantiation\n",
    "    main_agent = gr.State(value=None)\n",
    "\n",
    "    def user(user_message, history,agent):\n",
    "        if agent is None:\n",
    "            agent = get_new_agent()\n",
    "        agent.add_message(\"user\", user_message)\n",
    "        history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        return \"\", history, agent\n",
    "\n",
    "    async def bot(history, agent):\n",
    "        if agent is None:\n",
    "            agent = get_new_agent()\n",
    "        if not history:\n",
    "            yield [], agent\n",
    "            return\n",
    "        \n",
    "        history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "        # agent_name = \"\"\n",
    "        # async for chunk in agent.run(max_retries=10):            \n",
    "        #     if chunk.content:\n",
    "        #         if hasattr(chunk, \"is_tool_call\"):\n",
    "        #             if chunk.is_tool_call:\n",
    "        #                 tool_name = chunk.tool_name\n",
    "        #                 temp = f\"Calling the {tool_name} tool...\"\n",
    "        #                 if history[-1][\"content\"].endswith(temp):\n",
    "        #                     pass\n",
    "        #                 else:\n",
    "        #                     history[-1][\"content\"] += f\"\\n\\n{temp}\"\n",
    "        #             else:\n",
    "        #                 history[-1][\"content\"] += chunk.content\n",
    "        #             yield history, agent\n",
    "        #         else:\n",
    "        #             history[-1][\"content\"] += chunk.content\n",
    "        #             yield history, agent\n",
    "\n",
    "        response_generator = await agent.run(stream=True)\n",
    "        async for chunk in response_generator:\n",
    "            #check if chunk is litellm or agente\n",
    "            if isinstance(chunk, ModelResponseStream):\n",
    "                if chunk.choices[0].delta.content:\n",
    "                    history[-1][\"content\"] += chunk.choices[0].delta.content\n",
    "                    yield history, agent\n",
    "            elif isinstance(chunk, StreamResponse):\n",
    "                if chunk.content:\n",
    "                    history[-1][\"content\"] += chunk.content\n",
    "                    yield history, agent\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown chunk type: {type(chunk)}\")\n",
    "\n",
    "\n",
    "    def reset_state():\n",
    "        return None, get_new_agent()\n",
    "\n",
    "    msg.submit(user, [msg, chatbot,main_agent], [msg, chatbot, main_agent]).then(\n",
    "        bot, [chatbot, main_agent], [chatbot, main_agent]\n",
    "    )\n",
    "    clear.click(reset_state, None, [chatbot, main_agent])\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agente",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
