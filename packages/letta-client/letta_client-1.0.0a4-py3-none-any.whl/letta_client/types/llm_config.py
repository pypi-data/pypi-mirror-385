# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic
from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.unchecked_base_model import UncheckedBaseModel
from .llm_config_compatibility_type import LlmConfigCompatibilityType
from .llm_config_model_endpoint_type import LlmConfigModelEndpointType
from .llm_config_reasoning_effort import LlmConfigReasoningEffort
from .llm_config_verbosity import LlmConfigVerbosity
from .provider_category import ProviderCategory


class LlmConfig(UncheckedBaseModel):
    """
    Configuration for Language Model (LLM) connection and generation parameters.
    """

    model: str = pydantic.Field()
    """
    LLM model name. 
    """

    display_name: typing.Optional[str] = pydantic.Field(default=None)
    """
    A human-friendly display name for the model.
    """

    model_endpoint_type: LlmConfigModelEndpointType = pydantic.Field()
    """
    The endpoint type for the model.
    """

    model_endpoint: typing.Optional[str] = pydantic.Field(default=None)
    """
    The endpoint for the model.
    """

    provider_name: typing.Optional[str] = pydantic.Field(default=None)
    """
    The provider name for the model.
    """

    provider_category: typing.Optional[ProviderCategory] = pydantic.Field(default=None)
    """
    The provider category for the model.
    """

    model_wrapper: typing.Optional[str] = pydantic.Field(default=None)
    """
    The wrapper for the model.
    """

    context_window: int = pydantic.Field()
    """
    The context window size for the model.
    """

    put_inner_thoughts_in_kwargs: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Puts 'inner_thoughts' as a kwarg in the function call if this is set to True. This helps with function calling performance and also the generation of inner thoughts.
    """

    handle: typing.Optional[str] = pydantic.Field(default=None)
    """
    The handle for this config, in the format provider/model-name.
    """

    temperature: typing.Optional[float] = pydantic.Field(default=None)
    """
    The temperature to use when generating text with the model. A higher temperature will result in more random text.
    """

    max_tokens: typing.Optional[int] = pydantic.Field(default=None)
    """
    The maximum number of tokens to generate. If not set, the model will use its default value.
    """

    enable_reasoner: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Whether or not the model should use extended thinking if it is a 'reasoning' style model
    """

    reasoning_effort: typing.Optional[LlmConfigReasoningEffort] = pydantic.Field(default=None)
    """
    The reasoning effort to use when generating text reasoning models
    """

    max_reasoning_tokens: typing.Optional[int] = pydantic.Field(default=None)
    """
    Configurable thinking budget for extended thinking. Used for enable_reasoner and also for Google Vertex models like Gemini 2.5 Flash. Minimum value is 1024 when used with enable_reasoner.
    """

    frequency_penalty: typing.Optional[float] = pydantic.Field(default=None)
    """
    Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. From OpenAI: Number between -2.0 and 2.0.
    """

    compatibility_type: typing.Optional[LlmConfigCompatibilityType] = pydantic.Field(default=None)
    """
    The framework compatibility type for the model.
    """

    verbosity: typing.Optional[LlmConfigVerbosity] = pydantic.Field(default=None)
    """
    Soft control for how verbose model output should be, used for GPT-5 models.
    """

    tier: typing.Optional[str] = pydantic.Field(default=None)
    """
    The cost tier for the model (cloud only).
    """

    parallel_tool_calls: typing.Optional[bool] = pydantic.Field(default=None)
    """
    If set to True, enables parallel tool calling. Defaults to False.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
