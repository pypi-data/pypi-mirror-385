# -*- coding: utf-8 -*-
"""
Google Cloud Spanner driver
"""

from hashlib import new
import time
from typing import Any, Dict, List, Optional

from google.cloud import spanner
from google.cloud.spanner_v1 import Client, data_types
from google.oauth2 import service_account
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import Flow
from google.cloud import spanner
import google.oauth2.credentials
import re

from .base import BaseDatabaseDriver
from ..models.project import Project, GraphSchema, GraphSchemaMap, QueryData, QueryResponse, SchemaResponse, GraphSchemaResponse, SampleDataResponse, AuthType, Category, Relationship
from ..common.util import get_default_oauth_config
from ..services.project_service import ProjectService

import json


class SpannerDriver(BaseDatabaseDriver):
    """Google Cloud Spanner driver"""

    def __init__(self, project: Project):
        super().__init__(project)
        self.client: Optional[Client] = None
        self.instance = None
        self.database = None
    
    async def connect(self) -> None:
        """Establish connection to Spanner"""
        try:
            print(f"[INFO] Connecting to Spanner with auth type: {self.config.auth_type}")
            
            # Initialize client based on auth type
            if self.config.auth_type == AuthType.OAUTH2:
                print("[INFO] Using OAuth2 authentication")
                self.client = await self._get_oauth_client()
            elif self.config.auth_type == AuthType.SERVICE_ACCOUNT:
                print("[INFO] Using Service Account authentication")
                self.client = await self._get_service_account_client()
            else:
                raise ValueError(f"Unsupported auth type: {self.config.auth_type}")
            
            print(f"[INFO] Project: {self.config.project_id}")
            print(f"[INFO] Instance: {self.config.instance_id}")
            print(f"[INFO] Database: {self.config.database_id}")
            
            # Get instance and database
            self.instance = self.client.instance(self.config.instance_id)
            self.database = self.instance.database(self.config.database_id)
            
            print("[OK] Spanner connection established")
            
        except Exception as e:
            print(f"[ERROR] Failed to connect to Spanner: {str(e)}")
            raise ConnectionError(f"Failed to connect to Spanner: {str(e)}")

    async def _refresh_oauth_token(self, credentials: google.oauth2.credentials.Credentials) -> google.oauth2.credentials.Credentials:
        """Refresh OAuth token"""
        try:
            print("[INFO] Refreshing OAuth token...")
            request = Request()
            credentials.refresh(request)
            
            # Update the project with new token information
            current_time = time.time()
            project_service = ProjectService()
            await project_service.update_project_token(
                project_id=self.project.id,
                token=credentials.token,
                last_refreshed=current_time,
                expires_in=getattr(credentials, 'expires_in', 3600)
            )
            
            # Update local config
            self.project.database_config.oauth_config.token = credentials.token
            self.project.database_config.oauth_config.last_refreshed = current_time
            self.config.oauth_config = self.project.database_config.oauth_config
            
            print("[OK] OAuth token refreshed successfully")
            return credentials
            
        except Exception as e:
            print(f"[ERROR] Failed to refresh OAuth token: {e}")
            raise e

    def get_token_status(self) -> Dict[str, Any]:
        """Get current token status information"""
        if not self.config.oauth_config:
            return {"status": "no_oauth_config"}
        
        oauth_info = self.config.oauth_config
        current_time = time.time()
        
        status = {
            "has_token": bool(oauth_info.token),
            "has_refresh_token": bool(oauth_info.refresh_token),
            "expires_in": oauth_info.expires_in,
            "last_refreshed": oauth_info.last_refreshed,
            "current_time": current_time
        }
        
        if oauth_info.last_refreshed and oauth_info.expires_in:
            time_since_refresh = current_time - oauth_info.last_refreshed
            time_until_expiry = oauth_info.expires_in - time_since_refresh
            status.update({
                "time_since_refresh": time_since_refresh,
                "time_until_expiry": time_until_expiry,
                "is_expired": time_until_expiry <= 0,
                "expires_soon": time_until_expiry <= 300  # 5 minutes
            })
        
        return status

    async def _get_oauth_client(self) -> Client:
        """Get Spanner client using OAuth2"""
        if not self.config.oauth_config:
            raise ValueError("OAuth config is required for OAuth2 authentication")
        
        if not self.config.oauth_config.client_id or not self.config.oauth_config.client_secret:
            default_oauth = get_default_oauth_config()
            #empty dict check
            if default_oauth == {}:
                raise ValueError("OAuth configuration file not found and client_id/client_secret not provided. Please ensure config/default.google.localhost.oauth.json exists or provide complete OAuth configuration.")
            self.config.oauth_config.client_id = default_oauth.get("client_id")
            self.config.oauth_config.client_secret = default_oauth.get("client_secret")

        oauth_info = self.config.oauth_config
        
        # print(f"[OAuth] Client ID: {oauth_info.client_id[:10]}..." if oauth_info.client_id else "None")
        # print(f"[OAuth] Token available: {'Yes' if oauth_info.token else 'No'}")
        # print(f"[OAuth] Refresh token available: {'Yes' if oauth_info.refresh_token else 'No'}")
        
        # Create credentials with proper scopes for Spanner
        credentials = google.oauth2.credentials.Credentials(
            token=oauth_info.token,
            refresh_token=oauth_info.refresh_token or None,
            token_uri="https://oauth2.googleapis.com/token",
            client_id=oauth_info.client_id,
            client_secret=oauth_info.client_secret,
            scopes=[
                "https://www.googleapis.com/auth/cloudplatformprojects.readonly",
                "https://www.googleapis.com/auth/spanner.admin",
                "https://www.googleapis.com/auth/spanner.data",
                "https://www.googleapis.com/auth/userinfo.profile",
                "https://www.googleapis.com/auth/userinfo.email",
            ]
        )

        # Initialize last_refreshed if not set
        if oauth_info.last_refreshed is None:
            oauth_info.last_refreshed = time.time()
            # Save the initialized timestamp
            project_service = ProjectService()
            await project_service.update_project_token(
                project_id=self.project.id,
                token=oauth_info.token,
                last_refreshed=oauth_info.last_refreshed,
                expires_in=oauth_info.expires_in
            )

        # Check if token needs refresh (expires in 5 minutes or less)
        needs_refresh = False
        if oauth_info.expires_in and oauth_info.last_refreshed:
            time_since_refresh = time.time() - oauth_info.last_refreshed
            expires_soon = time_since_refresh >= (oauth_info.expires_in - 300)  # 5 minutes buffer
            needs_refresh = expires_soon
            
            if needs_refresh:
                print(f"[INFO] Token expires soon (refreshed {time_since_refresh:.0f}s ago, expires in {oauth_info.expires_in}s)")

        if needs_refresh and oauth_info.refresh_token:
            print("[INFO] Refreshing OAuth token...")
            credentials = await self._refresh_oauth_token(credentials)
        elif needs_refresh and not oauth_info.refresh_token:
            print("[WARN] Token expires soon but no refresh token available")

        return spanner.Client(project=self.config.project_id, credentials=credentials)
    
    async def _get_service_account_client(self) -> Client:
        """Get Spanner client using service account"""
        if not self.config.oauth_config:
            raise ValueError("OAuth config with service account data is required for service account authentication")
        
        # Check if we have service account fields in oauth_config
        sa_config = self.config.oauth_config
        if sa_config.type == "service_account" and sa_config.private_key and sa_config.client_email:
            # Create credentials from service account info in oauth_config
            service_account_info = {
                "type": sa_config.type,
                "project_id": sa_config.project_id or self.config.project_id,
                "private_key_id": sa_config.private_key_id,
                "private_key": sa_config.private_key,
                "client_email": sa_config.client_email,
                "client_id": sa_config.client_id,
                "auth_uri": sa_config.auth_uri or "https://accounts.google.com/o/oauth2/auth",
                "token_uri": sa_config.token_uri or "https://oauth2.googleapis.com/token",
                "auth_provider_x509_cert_url": sa_config.auth_provider_x509_cert_url or "https://www.googleapis.com/oauth2/v1/certs",
                "client_x509_cert_url": sa_config.client_x509_cert_url
            }
            credentials = service_account.Credentials.from_service_account_info(
                service_account_info,
                scopes=[
                    "https://www.googleapis.com/auth/cloudplatformprojects.readonly",
                    "https://www.googleapis.com/auth/spanner.admin", 
                    "https://www.googleapis.com/auth/spanner.data"
                ]
            )
        else:
            raise ValueError("Service account information is incomplete in oauth_config")
        
        return spanner.Client(project=self.config.project_id, credentials=credentials)
    
    async def disconnect(self) -> None:
        """Close connection to Spanner"""
        # Spanner client doesn't need explicit disconnection
        self.client = None
        self.instance = None
        self.database = None
    
    async def test_connection(self) -> bool:
        """Test Spanner connection"""
        try:
            if not self.database:
                await self.connect()
            
            # Test database existence first
            if not self.database.exists():
                print(f"Database {self.config.database_id} does not exist")
                return False
            
            # Simple test query using snapshot for read-only operation
            with self.database.snapshot() as snapshot:
                results = snapshot.execute_sql("SELECT 1 as test_value")
                list(results)  # Consume results
            return True
        except Exception as e:
            print(f"Connection test failed: {e}")
            return False
    
    async def execute_query(self, query: str, parameters: Dict[str, Any] = None) -> QueryResponse:
        """Execute a Spanner query"""
        start_time = time.time()
        
        try:
            if not self.database:
                await self.connect()
            
            query = query.strip().rstrip(';')  # Clean up query
            # Check if it's a graph query or SQL query
            # Skip MATCH (n) RETURN n.propName LIMIT 25
            # Skip MATCH (n) RETURN count(*) LIMIT 23
            # Skip MATCH (n) RETURN SAFE_TO_JSON(*) LIMIT 23
            test_query = re.sub(r'SAFE_TO_JSON|TO_JSON', '', query, flags=re.IGNORECASE).strip()
            isGraphQuery = (re.search(r'MATCH', test_query, re.IGNORECASE) and 
                           not re.search(r'RETURN\s*[a-z0-9]+\.', test_query, re.IGNORECASE) and 
                           not re.search(r'RETURN\s*[a-z0-9]+\(.+\)', test_query, re.IGNORECASE))
            if isGraphQuery and self.config.graph_name:
                # MATCH (n)-[r:HasOyster]-(m) RETURN * LIMIT 25, split to three parts: MATCH, RETURN, LIMIT
                
                # Replace keywords with flags and split
                command_with_flags = query
                command_with_flags = re.sub(r'MATCH(\s+[a-z]+=)?', '_flag_', command_with_flags, flags=re.IGNORECASE)
                command_with_flags = re.sub(r'RETURN', '_flag_', command_with_flags, flags=re.IGNORECASE)
                command_with_flags = re.sub(r'LIMIT', '_flag_', command_with_flags, flags=re.IGNORECASE)
                command_parts = [part.strip() for part in command_with_flags.split('_flag_')]
                graph_namespace = command_parts[0] if command_parts[0] else f"GRAPH {self.config.graph_name}"
                limit = command_parts[3] if len(command_parts) > 3 and command_parts[3] else ""
                match_command = command_parts[1] if len(command_parts) > 1 else ""
                
                query = f"""
                {graph_namespace}
                MATCH __p={match_command}
                RETURN SAFE_TO_JSON(__p) as thePath  {f"LIMIT {limit}" if limit else "" }"""

                print(f"[DEBUG] Transformed graph query:\n{query}")
                query = query.strip().rstrip(';')  # Clean up query again

                # Auto append the graph namespace
                if self.config.graph_name and not re.search(r'^GRAPH', query, re.IGNORECASE) and re.search(r'^MATCH', query, re.IGNORECASE):
                    query = f"""
                    GRAPH {self.config.graph_name}
                    {query}
                    """

                 # Property Graph query
                results = self._execute_graph_query(query, parameters)
            else:
                # SQL query
                results = self._execute_sql_query(query, parameters)
            
            execution_time = time.time() - start_time
            
            return QueryResponse(
                success=True,
                data=results,
                execution_time=execution_time
            )
        
        except Exception as e:
            execution_time = time.time() - start_time
            return QueryResponse(
                success=False,
                error=str(e),
                execution_time=execution_time
            )
    
    def _execute_graph_query(self, query: str, parameters: Dict[str, Any] = None) -> QueryData:
        """Execute a Property Graph query"""
        with self.database.snapshot() as snapshot:
            results = snapshot.execute_sql(query, params=parameters or {})
            
            # Parse graph data similar to the Node.js implementation
            graph = {
                "nodes": {},
                "relationships": {}
            }
            
            if not results:
                return QueryData(
                    type="GRAPH",
                    data={
                        "nodes": [],
                        "relationships": []
                    }
                )
            
            for row in results:
                # Get the first value from the row (thePath data)
                the_path_data = row[0] if row and row[0] else row
                
     
                if not the_path_data:
                    continue

                if isinstance(the_path_data, list):
                    the_path_data = the_path_data[0]

                if isinstance(the_path_data, data_types.JsonObject) and hasattr(the_path_data, '_array_value'):
                    the_path_data = the_path_data._array_value

                if isinstance(the_path_data, str):
                    try:
                        the_path_data = json.loads(the_path_data)
                    except json.JSONDecodeError as err:
                        print(f"Invalid parseGraph thePathData: {err}")
                        the_path_data = []                
                        
                if not isinstance(the_path_data, list):
                    the_path_data=[the_path_data]
        
                for node_or_edge in the_path_data:
                    # Support schema-less graph where properties is directly in the nodeOrEdge object
                    # Use the last label as the main label for compatibility with schema-less graph
                    is_dynamic_label = node_or_edge.get("properties", {}).get("label")
                    labels = node_or_edge.get("labels", [])
                    last_label = is_dynamic_label or (labels[-1] if labels else "")

                    properties = node_or_edge.get("properties", {})
                    ## if schema-less, properties has properties field, merge it into properties, then remove properties field
                    if properties and isinstance(properties, dict) and "properties" in properties:
                        merged_properties = properties.get("properties", {})
                        properties.update(merged_properties)
                        del properties["properties"]

                    if node_or_edge.get("kind") == "node":
                        graph["nodes"][node_or_edge.get("identifier")] = {
                            "id": node_or_edge.get("identifier"),
                            "labels": [last_label] if last_label else [],
                            "properties": properties
                        }
                    elif node_or_edge.get("kind") == "edge":
                        graph["relationships"][node_or_edge.get("identifier")] = {
                            "id": node_or_edge.get("identifier"),
                            "type": last_label,
                            "startNodeId": node_or_edge.get("source_node_identifier"),
                            "endNodeId": node_or_edge.get("destination_node_identifier"),
                            "properties": properties
                        }
            
            return QueryData(
                type="GRAPH",
                data={
                    "nodes": list(graph["nodes"].values()),
                    "relationships": list(graph["relationships"].values())
                }
            )

    def _execute_sql_query(self, query: str, parameters: Dict[str, Any] = None) -> QueryData:
        """Execute a SQL query"""
        with self.database.snapshot() as snapshot:
            results = snapshot.execute_sql(query, params=parameters or {})
            rows = []
            for row in results:
                row_dict = {}
                for i, field in enumerate(results.fields):
                    val = row[i]
                    # Convert Array to string
                    if isinstance(val, list):
                        val = ", ".join(str(item) for item in val)
                    row_dict[field.name] = val
                rows.append(row_dict)
            return QueryData(
                type="TABLE",
                data=rows
            )

    def _is_schema_less(self, meta_json) -> bool:
        """Check if the graph schema is schema-less (has dynamic properties)"""
        if not meta_json or (not meta_json.get("nodeTables") and not meta_json.get("edgeTables")):
            return False
        
        node_tables = meta_json.get("nodeTables", [])
        edge_tables = meta_json.get("edgeTables", [])
        
        has_dynamic_node_table = any(
            table.get("dynamicLabelExpr") or table.get("dynamicPropertyExpr") 
            for table in node_tables
        )
        
        has_dynamic_edge_table = any(
            table.get("dynamicLabelExpr") or table.get("dynamicPropertyExpr") 
            for table in edge_tables
        )
        
        return has_dynamic_node_table or has_dynamic_edge_table
    

    def _getSchemaForSchemaLessGraphs(self, definMata:GraphSchemaMap) -> GraphSchema:
        """Get schema for schema-less graphs"""
        try:
            # First query to get labels for nodes and relationships
            meta_query = f"""
            GRAPH {self.config.graph_name}
            MATCH (n) 
            RETURN DISTINCT ARRAY_TO_STRING(LABELS(n),",") AS name,"" as startCategory, "" as endCategory , "category" as type 
            LIMIT 1000
            UNION ALL
            MATCH (n)-[r]->(m)
            RETURN DISTINCT ARRAY_TO_STRING(LABELS(r),",") AS name ,  ARRAY_TO_STRING(LABELS(n),",") as startCategory, ARRAY_TO_STRING(LABELS(m),",") as endCategory ,"relationship" as type
            LIMIT 1000
            """
            
            rows = self._execute_sql_query(meta_query)
            
            meta = {
                "categories": {},
                "relationships": {}
            }
            
            # Process labels
            for row in rows.data:
                names = row["name"].split(",")
                row_type = row["type"]
                names = [name.strip() for name in names if name.strip()]
                defineCategoriesOrRels = definMata.categories if row_type == "category" else definMata.relationships
                ## find the category or relationship from names
                defineCategoryOrRel = next((cat for cat in defineCategoriesOrRels.values() if cat.name in names), None)

                for name in names:
                    if row_type == "category" and name not in meta["categories"]:
                        meta["categories"][name] = {
                            "name": name,
                            "props": [],
                            "keys": defineCategoryOrRel.keys if defineCategoryOrRel else [],
                            "keysTypes": defineCategoryOrRel.keysTypes if defineCategoryOrRel else {},
                            "propsTypes": {}
                        }
                    elif row_type == "relationship" and name not in meta["relationships"]:
                        start_categories = [cat.strip() for cat in row["startCategory"].split(",") if cat.strip()]
                        end_categories = [cat.strip() for cat in row["endCategory"].split(",") if cat.strip()]
                        common_categories = [cat for cat in start_categories if cat in end_categories]
                        
                        start_category = next((cat for cat in start_categories if cat not in common_categories), 
                                            start_categories[0] if start_categories else "")
                        end_category = next((cat for cat in end_categories if cat not in common_categories), 
                                          end_categories[0] if end_categories else "")
                        
                        meta["relationships"][name] = {
                            "name": name,
                            "props": [],
                            "keys": defineCategoryOrRel.keys if defineCategoryOrRel else [],
                            "keysTypes": defineCategoryOrRel.keysTypes if defineCategoryOrRel else {},
                            "propsTypes": {},
                            "startCategory": start_category,
                            "endCategory": end_category
                        }
            
            # Second query to get properties
            categories = list(meta["categories"].values())
            relationships = list(meta["relationships"].values())
            
            prop_queries = []
            
            # Add category property queries
            for category in categories:
                prop_queries.append(f"""
                MATCH (n:`{category["name"]}`) 
                RETURN SAFE_TO_JSON(n) as props, SAFE_TO_JSON(n) as startN, SAFE_TO_JSON(n) as endN 
                LIMIT 1
                """)
            
            # Add relationship property queries
            for relationship in relationships:
                prop_queries.append(f"""
                MATCH (n:`{relationship["startCategory"]}`)-[r:`{relationship["name"]}`]->(m:`{relationship["endCategory"]}`) 
                RETURN SAFE_TO_JSON(r) as props, SAFE_TO_JSON(n) as startN, SAFE_TO_JSON(m) as endN 
                LIMIT 1
                """)
            
            if prop_queries:
                prop_query = f"""
                GRAPH {self.config.graph_name}
                {" UNION ALL ".join(prop_queries)}
                """

            prop_rows = self._execute_sql_query(prop_query)

            # Process property results
            for row in prop_rows.data:
                props_data = row["props"]
                if isinstance(props_data, str):
                    data = json.loads(props_data)
                else:
                    # Handle JsonObject from Spanner
                    data = props_data
                
                if data.get("kind") == "node":
                    # Remove element_definition_name from categories if it exists
                    if data.get("element_definition_name") in meta["categories"]:
                        del meta["categories"][data["element_definition_name"]]
                    
                    # Get the category name (last label that's not element_definition_name)
                    labels = data.get("labels", [])
                    category = next((label for label in reversed(labels) 
                                    if label != data.get("element_definition_name")), None)
                    
                    if category and category in meta["categories"]:
                        properties = data.get("properties", {})
                        ## if schema-less, properties has properties field, merge it into properties, then remove properties field
                        if properties and isinstance(properties, dict) and "properties" in properties:
                            merged_properties = properties.get("properties", {})
                            properties.update(merged_properties)
                            del properties["properties"]

                        props_type_map = {}
                        for key, value in properties.items():
                            props_type_map[key] = type(value).__name__.upper()
                        
                        meta["categories"][category]["props"] = list(properties.keys())
                        meta["categories"][category]["propsTypes"] = props_type_map
                
                elif data.get("kind") == "edge":
                    start_data_raw = row["startN"]
                    end_data_raw = row["endN"]
                    
                    if isinstance(start_data_raw, str):
                        start_data = json.loads(start_data_raw)
                    else:
                        start_data = start_data_raw
                        
                    if isinstance(end_data_raw, str):
                        end_data = json.loads(end_data_raw)
                    else:
                        end_data = end_data_raw
                    
                    # Remove element_definition_name from relationships if it exists
                    if data.get("element_definition_name") in meta["relationships"]:
                        del meta["relationships"][data["element_definition_name"]]
                    
                    # Get relationship and category names
                    relationship_labels = data.get("labels", [])
                    relationship = next((label for label in reversed(relationship_labels) 
                                        if label != data.get("element_definition_name")), None)
                    
                    start_labels = start_data.get("labels", [])
                    start_category = next((label for label in reversed(start_labels) 
                                            if label != start_data.get("element_definition_name")), None)
                    
                    end_labels = end_data.get("labels", [])
                    end_category = next((label for label in reversed(end_labels) 
                                        if label != end_data.get("element_definition_name")), None)
                    
                    if relationship and relationship in meta["relationships"]:
                        properties = data.get("properties", {})
                        if properties and isinstance(properties, dict) and "properties" in properties:
                            merged_properties = properties.get("properties", {})
                            properties.update(merged_properties)
                            del properties["properties"]

                        props_type_map = {}
                        for key, value in properties.items():
                            props_type_map[key] = type(value).__name__.upper()
                        
                        meta["relationships"][relationship]["startCategory"] = start_category or ""
                        meta["relationships"][relationship]["endCategory"] = end_category or ""
                        meta["relationships"][relationship]["props"] = list(properties.keys())
                        meta["relationships"][relationship]["propsTypes"] = props_type_map
            
            return GraphSchema(
                categories=[Category(**cat) for cat in meta["categories"].values()],
                relationships=[Relationship(**rel) for rel in meta["relationships"].values()]
            )

        except Exception as e:
            print(f"Error getting schema for schema-less graphs: {e}")
            return GraphSchema(
                categories=[],
                relationships=[]
            )

    async def get_graph_schema(self) -> GraphSchemaResponse:
        """Get Spanner Property Graph schema"""
        try:
            start_time = time.time()
            if not self.database:
                await self.connect()
            
            # Get Property Graph information
            graph_schema_query = f"""
                SELECT
                PG.PROPERTY_GRAPH_NAME as graphDB, PG.PROPERTY_GRAPH_METADATA_JSON as metaJSON
                FROM
                INFORMATION_SCHEMA.PROPERTY_GRAPHS as PG
                WHERE PG.PROPERTY_GRAPH_NAME = "{self.config.graph_name}"
            """
            schema_results = self._execute_sql_query(graph_schema_query)
            meta = {
                "categories": {},
                "relationships": {}
            }
            if not schema_results or not schema_results.data or len(schema_results.data) == 0:
                return GraphSchemaResponse(
                    success=False,
                    error="No schema results found",
                    execution_time= time.time() - start_time
                )

            meta_json = schema_results.data[0].get("metaJSON")

            if not meta_json:
                return GraphSchemaResponse(
                    success=False,
                    error="No metadata found",
                    execution_time= time.time() - start_time
                )

            # Build property declarations map
            property_declarations_map = {}
            for prop_decl in meta_json.get("propertyDeclarations", []):
                property_declarations_map[prop_decl.get("name")] = prop_decl.get("type")
            
            # Build node table label map
            node_table_label_map = {}
            
            # Process nodes as categories
            for node_table in meta_json.get("nodeTables", []):
                category_name = node_table.get("labelNames", [])[0] if node_table.get("labelNames") else None
                if not category_name:
                    continue
                    
                props_types = {}
                for prop_def in node_table.get("propertyDefinitions", []):
                    prop_name = prop_def.get("propertyDeclarationName")
                    prop_type = (property_declarations_map.get(prop_name) or 
                                property_declarations_map.get(prop_def.get("valueExpressionSql")) or 
                                "string")
                    props_types[prop_name] = prop_type
                keys = node_table.get("keyColumns", [])
                keys_types = {key: props_types.get(key, "string") for key in keys}
                
                table_name = (node_table.get("baseTableName") or 
                            node_table.get("name") or 
                            category_name)
                node_table_label_map[table_name] = category_name
                
                meta["categories"][category_name] = {
                    "name": category_name,
                    "props": list(props_types.keys()),
                    "propsTypes": props_types or {},
                    "keys":  keys,
                    "keysTypes": keys_types
                }
            
            # Process edges as relationships
            for edge_table in meta_json.get("edgeTables", []):
                relationship_name = edge_table.get("labelNames", [])[0] if edge_table.get("labelNames") else None
                if not relationship_name:
                    continue
                    
                props_types = {}
                for prop_def in edge_table.get("propertyDefinitions", []):
                    prop_name = prop_def.get("propertyDeclarationName")
                    prop_type = (property_declarations_map.get(prop_name) or 
                                property_declarations_map.get(prop_def.get("valueExpressionSql")) or 
                                "string")
                    props_types[prop_name] = prop_type
                keys = edge_table.get("keyColumns", [])
                keys_types = {key: props_types.get(key, "string") for key in keys}

                source_node_table = edge_table.get("sourceNodeTable", {}).get("nodeTableName")
                dest_node_table = edge_table.get("destinationNodeTable", {}).get("nodeTableName")
                
                meta["relationships"][relationship_name] = {
                    "name": relationship_name,
                    "propsTypes": props_types or {},
                    "props": list(props_types.keys()),
                    "keys": keys,
                    "keysTypes": keys_types,
                    "startCategory": node_table_label_map.get(source_node_table, source_node_table),
                    "endCategory": node_table_label_map.get(dest_node_table, dest_node_table)
                }
            
            if self._is_schema_less(meta_json):
                # Convert dict to GraphSchemaMap before calling the method
                schema_map = GraphSchemaMap(
                    categories={name: Category(**cat_data) for name, cat_data in meta["categories"].items()},
                    relationships={name: Relationship(**rel_data) for name, rel_data in meta["relationships"].items()}
                )
                meta = self._getSchemaForSchemaLessGraphs(schema_map)
                return GraphSchemaResponse(
                    success=True,
                    data=meta,
                    execution_time= time.time() - start_time
                )

            return GraphSchemaResponse(
                success=True, 
                data=GraphSchema(
                    categories=[Category(**cat) for cat in meta["categories"].values()],
                    relationships=[Relationship(**rel) for rel in meta["relationships"].values()]
                ),
                execution_time= time.time() - start_time
            )
        
        except Exception as e:
            return GraphSchemaResponse(success=False, error=str(e))

    async def get_schema(self) -> SchemaResponse:
        """Get Spanner database schema"""
        try:
            if not self.database:
                await self.connect()
            
            # Get table information
            schema_query = """
                SELECT
                    table_name as tableName,
                    column_name as columnName,
                    spanner_type as spannerType
                FROM
                    INFORMATION_SCHEMA.COLUMNS
                WHERE
                    table_schema NOT IN ('INFORMATION_SCHEMA', 'SPANNER_SYS')
            """
            
            results = self._execute_sql_query(schema_query)

            schema = {}
            for row in results.data:
                table_name = row["tableName"]
                column_name = row["columnName"]
                column_type = row["spannerType"]

                if table_name not in schema:
                    schema[table_name] = {}

                schema[table_name][column_name] = column_type

            return SchemaResponse(success=True, data=schema)

        except Exception as e:
            return SchemaResponse(success=False, error=str(e))
        
    async def get_sample_data(self) -> SampleDataResponse:
        """Get sample data from Spanner database"""
        try:
            limit = 10  # Number of rows to sample from each table/graph
            if not self.database:
                await self.connect()
            
            sample_data = {
            }
            
            # Get list of tables
            tables_query = """
            SELECT
                table_name
            FROM
                INFORMATION_SCHEMA.TABLES
            WHERE
                table_type = 'BASE TABLE'
            """
            
            table_results = self._execute_sql_query(tables_query)

            def get_table_sample(table_name: str):
                """Get sample data for a single table"""
                try:
                    sample_query = f"SELECT * FROM `{table_name}` LIMIT {limit}"
                    sample_rows = self._execute_sql_query(sample_query)
                    return table_name, sample_rows.data
                    
                except Exception as table_error:
                    # Return empty list for tables that can't be queried
                    return table_name, []
                
            # Extract table names
            table_names = [row['table_name'] for row in table_results.data]

            # Execute queries for each table
            for table_name in table_names:
                table_name, sample_rows = get_table_sample(table_name)
                sample_data[table_name] = sample_rows
            
            return SampleDataResponse(success=True, data=sample_data)
        
        except Exception as e:
            return SampleDataResponse(success=False, error=str(e))

    def get_api_info(self, project_name: str) -> Dict[str, Any]:
        """Get API information for Spanner"""
        base_url = f"/api/spanner/{project_name}"
        return {
            "type": "spanner",
            "api_urls": {
                "info": base_url,
                "query": f"{base_url}/query",
                "schema": f"{base_url}/schema",
                "graphSchema": f"{base_url}/graphSchema",
                "sampleData": f"{base_url}/sampleData",
                "tokenStatus": f"{base_url}/token-status",
                "test": f"{base_url}/test"
            },
            "version": "1.0",
            "features": {
                "property_graph": True,
                "sql": True,
                "schema": True,
                "graph_schema": True,
                "sample_data": True,
                "token_management": True,
                "transactions": True
            }
        }