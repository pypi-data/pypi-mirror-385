"""éªŒè¯å¯¼å‡ºæ•°æ®çš„ timestamp å¯¹é½è´¨é‡.

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºå¦‚ä½•ï¼š
1. è¯»å–å¯¼å‡ºçš„ timestamp æ•°æ®
2. éªŒè¯å¯¹é½è´¨é‡
3. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
"""

import json
from pathlib import Path
from typing import cast

import numpy as np


def extract_timestamps(timestamp_array: np.ndarray, metadata: dict, ts_type: str) -> np.ndarray:
    """ä»åˆå¹¶æ•°ç»„ä¸­æå–ç‰¹å®šç±»å‹çš„ timestamp.

    Args:
        timestamp_array: åˆå¹¶çš„ timestamp æ•°ç»„
        metadata: å…ƒæ•°æ®å­—å…¸
        ts_type: timestamp ç±»å‹ï¼ˆå¦‚ "kline_timestamp"ï¼‰

    Returns:
        æå–çš„ timestamp æ•°ç»„
    """
    order = metadata["order"]
    columns = metadata["columns"]

    if ts_type not in order:
        raise ValueError(f"{ts_type} not found in timestamp data")

    # è®¡ç®—èµ·å§‹åˆ—ç´¢å¼•
    start_col = sum(columns[ts] for ts in order[: order.index(ts_type)])
    end_col = start_col + columns[ts_type]

    return timestamp_array[:, start_col:end_col]


def load_timestamps(data_dir: Path, date: str) -> dict[str, np.ndarray]:
    """åŠ è½½åˆå¹¶çš„ timestamp æ–‡ä»¶.

    Args:
        data_dir: æ•°æ®ç›®å½•
        date: æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆYYYYMMDDï¼‰

    Returns:
        timestamp å­—å…¸
    """
    # è¯»å–åˆå¹¶çš„ timestamp æ–‡ä»¶
    timestamp_file = data_dir / "timestamp" / f"{date}.npy"
    meta_file = data_dir / "timestamp" / f"{date}_meta.json"

    if not timestamp_file.exists():
        print(f"âŒ Timestamp æ–‡ä»¶ä¸å­˜åœ¨: {timestamp_file}")
        return {}

    # åŠ è½½æ•°æ®
    timestamp_array = np.load(timestamp_file)
    print(f"âœ… åŠ è½½åˆå¹¶ timestamp: {timestamp_array.shape}")

    # åŠ è½½å…ƒæ•°æ®
    with open(meta_file, encoding="utf-8") as f:
        metadata = json.load(f)

    print(f"â„¹ï¸  Timestamp é¡ºåº: {' -> '.join(metadata['order'])}")
    print(f"â„¹ï¸  æ¯éƒ¨åˆ†åˆ—æ•°: {metadata['columns']}")

    # æå–å„ç±»å‹ timestamp
    timestamps = {}
    for ts_type in metadata["order"]:
        ts_array = extract_timestamps(timestamp_array, metadata, ts_type)
        timestamps[ts_type] = ts_array
        print(f"âœ… æå– {ts_type}: {ts_array.shape}")

    return timestamps


def validate_alignment_quality(timestamps: dict[str, np.ndarray]) -> dict:
    """éªŒè¯å¯¹é½è´¨é‡.

    Args:
        timestamps: timestamp å­—å…¸

    Returns:
        è´¨é‡æŠ¥å‘Š
    """
    if "kline_timestamp" not in timestamps:
        raise ValueError("ç¼ºå°‘ kline_timestampï¼Œæ— æ³•éªŒè¯å¯¹é½è´¨é‡")

    kline_ts = timestamps["kline_timestamp"]
    report = {}

    for ts_type, metrics_ts in timestamps.items():
        if ts_type == "kline_timestamp":
            continue

        # åˆ›å»ºæœ‰æ•ˆæ•°æ®çš„ maskï¼ˆæ’é™¤ 0 å€¼ï¼Œ0 è¡¨ç¤ºæ•°æ®ä¸å­˜åœ¨ï¼‰
        valid_mask = (kline_ts != 0) & (metrics_ts != 0)

        if valid_mask.sum() == 0:
            print(f"âš ï¸  {ts_type}: æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯éªŒè¯")
            continue

        # åªå¯¹æœ‰æ•ˆæ•°æ®è®¡ç®—æ—¶é—´å·®
        valid_kline = kline_ts[valid_mask]
        valid_metrics = metrics_ts[valid_mask]

        # è®¡ç®—æ—¶é—´å·®ï¼ˆæ¯«ç§’ï¼‰
        time_diff_ms = valid_kline - valid_metrics

        # è½¬æ¢ä¸ºåˆ†é’Ÿï¼ˆæ˜ç¡®è½¬æ¢ä¸º floatï¼‰
        time_diff_min = time_diff_ms.astype(float) / 1000.0 / 60.0

        # ç»Ÿè®¡
        report[ts_type] = {
            "mean_min": float(time_diff_min.mean()),
            "median_min": float(np.median(time_diff_min)),
            "max_min": float(time_diff_min.max()),
            "min_min": float(time_diff_min.min()),
            "std_min": float(time_diff_min.std()),
            "within_5min": int((np.abs(time_diff_min) <= 5).sum()),
            "within_30min": int((np.abs(time_diff_min) <= 30).sum()),
            "within_60min": int((np.abs(time_diff_min) <= 60).sum()),
            "total": int(time_diff_min.size),
            "shape": list(time_diff_min.shape),
        }

        # è®¡ç®—æ¯”ä¾‹
        total = cast(int, report[ts_type]["total"])
        within_5min = cast(int, report[ts_type]["within_5min"])
        within_30min = cast(int, report[ts_type]["within_30min"])
        within_60min = cast(int, report[ts_type]["within_60min"])
        report[ts_type]["within_5min_pct"] = within_5min / total * 100
        report[ts_type]["within_30min_pct"] = within_30min / total * 100
        report[ts_type]["within_60min_pct"] = within_60min / total * 100

    return report


def print_report(report: dict):
    """æ‰“å°è´¨é‡æŠ¥å‘Š.

    Args:
        report: è´¨é‡æŠ¥å‘Šå­—å…¸
    """
    print("\n" + "=" * 80)
    print("ğŸ“Š æ—¶é—´å¯¹é½è´¨é‡æŠ¥å‘Š")
    print("=" * 80)

    for ts_type, stats in report.items():
        print(f"\n{ts_type}:")
        print(f"  æ•°æ®ç»´åº¦: {stats['shape']}")
        print(f"  å¹³å‡æ—¶é—´å·®: {stats['mean_min']:.2f} åˆ†é’Ÿ")
        print(f"  ä¸­ä½æ•°æ—¶é—´å·®: {stats['median_min']:.2f} åˆ†é’Ÿ")
        print(f"  æœ€å¤§æ—¶é—´å·®: {stats['max_min']:.2f} åˆ†é’Ÿ")
        print(f"  æœ€å°æ—¶é—´å·®: {stats['min_min']:.2f} åˆ†é’Ÿ")
        print(f"  æ ‡å‡†å·®: {stats['std_min']:.2f} åˆ†é’Ÿ")
        print(f"  åœ¨ 5 åˆ†é’Ÿå†…: {stats['within_5min']}/{stats['total']} ({stats['within_5min_pct']:.1f}%)")
        print(f"  åœ¨ 30 åˆ†é’Ÿå†…: {stats['within_30min']}/{stats['total']} ({stats['within_30min_pct']:.1f}%)")
        print(f"  åœ¨ 60 åˆ†é’Ÿå†…: {stats['within_60min']}/{stats['total']} ({stats['within_60min_pct']:.1f}%)")

        # è´¨é‡è¯„ä¼°
        if stats["within_5min_pct"] >= 95:
            quality = "âœ… ä¼˜ç§€"
        elif stats["within_30min_pct"] >= 95:
            quality = "âœ… è‰¯å¥½"
        elif stats["within_60min_pct"] >= 95:
            quality = "âš ï¸  ä¸€èˆ¬"
        else:
            quality = "âŒ è¾ƒå·®"

        print(f"  è´¨é‡è¯„ä¼°: {quality}")

    print("\n" + "=" * 80)


def check_timestamp_validity(timestamps: dict[str, np.ndarray]) -> dict:
    """æ£€æŸ¥ timestamp çš„æœ‰æ•ˆæ€§.

    Args:
        timestamps: timestamp å­—å…¸

    Returns:
        éªŒè¯ç»“æœ
    """
    checks = {}

    for ts_type, ts_array in timestamps.items():
        checks[ts_type] = {
            "all_positive": bool((ts_array > 0).all()),  # æ‰€æœ‰å€¼éƒ½ä¸ºæ­£
            "no_zero": bool((ts_array != 0).all()),  # æ²¡æœ‰é›¶å€¼
            "reasonable_range": bool(
                (ts_array >= 1600000000000).all() and (ts_array <= 2000000000000).all()
            ),  # 2020-2033å¹´èŒƒå›´
            "monotonic": bool((np.diff(ts_array, axis=1) >= 0).all()) if ts_array.shape[1] > 1 else True,  # å•è°ƒé€’å¢
        }

        checks[ts_type]["valid"] = all(checks[ts_type].values())

    return checks


def print_validity_checks(checks: dict):
    """æ‰“å°æœ‰æ•ˆæ€§æ£€æŸ¥ç»“æœ.

    Args:
        checks: æ£€æŸ¥ç»“æœå­—å…¸
    """
    print("\n" + "=" * 80)
    print("ğŸ” Timestamp æœ‰æ•ˆæ€§æ£€æŸ¥")
    print("=" * 80)

    for ts_type, results in checks.items():
        status = "âœ…" if results["valid"] else "âŒ"
        print(f"\n{status} {ts_type}:")
        print(f"  æ‰€æœ‰å€¼ä¸ºæ­£: {results['all_positive']}")
        print(f"  æ²¡æœ‰é›¶å€¼: {results['no_zero']}")
        print(f"  æ—¶é—´èŒƒå›´åˆç†: {results['reasonable_range']}")
        print(f"  å•è°ƒé€’å¢: {results['monotonic']}")

    print("\n" + "=" * 80)


def save_report_to_json(report: dict, output_file: Path):
    """ä¿å­˜æŠ¥å‘Šä¸º JSON æ–‡ä»¶.

    Args:
        report: æŠ¥å‘Šå­—å…¸
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•°."""
    # é…ç½®
    data_dir = Path("../data/exports/H1B/univ_1_1_1_r0.9_custom_2024-10-01_2024-10-31")
    date = "20241001"

    print(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
    print(f"ğŸ“… æ—¥æœŸ: {date}")
    print()

    try:
        # 1. åŠ è½½ timestamp
        print("ğŸ“¥ åŠ è½½ timestamp æ•°æ®...")
        timestamps = load_timestamps(data_dir, date)

        # 2. æœ‰æ•ˆæ€§æ£€æŸ¥
        print("\nğŸ” æ‰§è¡Œæœ‰æ•ˆæ€§æ£€æŸ¥...")
        validity_checks = check_timestamp_validity(timestamps)
        print_validity_checks(validity_checks)

        # 3. å¯¹é½è´¨é‡éªŒè¯
        if len(timestamps) > 1:
            print("\nğŸ“Š æ‰§è¡Œå¯¹é½è´¨é‡éªŒè¯...")
            report = validate_alignment_quality(timestamps)
            print_report(report)

            # 4. ä¿å­˜æŠ¥å‘Š
            output_file = data_dir / f"alignment_report_{date}.json"
            save_report_to_json(report, output_file)

        print("\nâœ… éªŒè¯å®Œæˆ!")

    except Exception as e:
        print(f"\nâŒ éªŒè¯å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
