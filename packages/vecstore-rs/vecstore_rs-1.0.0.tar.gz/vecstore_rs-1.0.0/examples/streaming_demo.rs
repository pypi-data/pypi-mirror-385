// Streaming/Incremental Indexing Demo
//
// This example demonstrates vecstore's ability to add vectors incrementally
// without rebuilding the entire index. This is crucial for real-time applications!

use std::collections::HashMap;
use std::time::Instant;
use vecstore::{make_record, Metadata, VecStore};

fn main() -> anyhow::Result<()> {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                                                               â•‘");
    println!("â•‘     vecstore Streaming/Incremental Indexing Demo             â•‘");
    println!("â•‘                                                               â•‘");
    println!("â•‘         Add vectors in real-time - No rebuild needed!        â•‘");
    println!("â•‘                                                               â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    let temp_dir = tempfile::tempdir()?;
    let mut store = VecStore::open(temp_dir.path())?;

    // Demo 1: Streaming Insertion (one at a time)
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Demo 1: Streaming Insertion");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Adding vectors one at a time - perfect for real-time systems!\n");

    let start = Instant::now();
    for i in 0..1000 {
        let id = format!("stream_{}", i);
        let vector: Vec<f32> = (0..128).map(|j| ((i + j) as f32) / 1000.0).collect();
        let mut meta = Metadata {
            fields: HashMap::new(),
        };
        meta.fields
            .insert("type".into(), serde_json::json!("streaming"));
        let record = make_record(&id, vector, meta);
        store.upsert(id, record.vector, record.metadata)?;
    }
    let elapsed = start.elapsed();

    println!("âœ… Added 1,000 vectors incrementally");
    println!(
        "   Time: {:.2}ms ({:.2}Î¼s per vector)",
        elapsed.as_millis(),
        elapsed.as_micros() as f64 / 1000.0
    );
    println!("   â€¢ No index rebuild required!");
    println!("   â€¢ Each vector is immediately searchable");
    println!();

    // Verify vectors are searchable immediately
    let query_vec: Vec<f32> = (0..128).map(|i| (i as f32) / 1000.0).collect();
    let results = store.query(vecstore::Query {
        vector: query_vec.clone(),
        k: 5,
        filter: None,
    })?;

    println!("ğŸ” Immediate search works:");
    for (i, result) in results.iter().take(3).enumerate() {
        println!("   {}. {} (score: {:.3})", i + 1, result.id, result.score);
    }
    println!();

    // Demo 2: Batch Insertion (optimized for bulk adds)
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Demo 2: Batch Insertion (Optimized)");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Adding vectors in batches - uses parallel processing!\n");

    let batch_records: Vec<_> = (0..1000)
        .map(|i| {
            let id = format!("batch_{}", i);
            let vector: Vec<f32> = (0..128).map(|j| ((i + j + 1000) as f32) / 1000.0).collect();
            let mut meta = Metadata {
                fields: HashMap::new(),
            };
            meta.fields
                .insert("type".into(), serde_json::json!("batch"));
            make_record(&id, vector, meta)
        })
        .collect();

    let start = Instant::now();
    store.batch_upsert(batch_records)?;
    let elapsed = start.elapsed();

    println!("âœ… Added 1,000 vectors in batch");
    println!(
        "   Time: {:.2}ms ({:.2}Î¼s per vector)",
        elapsed.as_millis(),
        elapsed.as_micros() as f64 / 1000.0
    );
    println!("   â€¢ Uses parallel processing (rayon)");
    println!("   â€¢ Much faster than streaming for bulk inserts");
    println!();

    // Demo 3: Incremental Updates (upsert behavior)
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Demo 3: Incremental Updates");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Updating existing vectors without rebuilding the index\n");

    let start = Instant::now();
    for i in 0..100 {
        let id = format!("stream_{}", i);
        let vector: Vec<f32> = (0..128).map(|j| ((i + j + 5000) as f32) / 1000.0).collect();
        let mut meta = Metadata {
            fields: HashMap::new(),
        };
        meta.fields
            .insert("type".into(), serde_json::json!("updated"));
        let record = make_record(&id, vector, meta);
        store.upsert(id, record.vector, record.metadata)?;
    }
    let elapsed = start.elapsed();

    println!("âœ… Updated 100 existing vectors");
    println!("   Time: {:.2}ms", elapsed.as_millis());
    println!("   â€¢ Old vectors automatically replaced");
    println!("   â€¢ No index rebuild required");
    println!();

    // Demo 4: Deletions and Optimization
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Demo 4: Deletions and Index Optimization");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Removing vectors and optimizing the index\n");

    // Remove some vectors
    let start = Instant::now();
    for i in 0..200 {
        let id = format!("stream_{}", i);
        let _ = store.remove(&id); // Ignore errors if already removed
    }
    let elapsed = start.elapsed();

    println!("âœ… Removed 200 vectors");
    println!("   Time: {:.2}ms", elapsed.as_millis());
    println!("   âš ï¸  Note: HNSW index still contains 'ghost' entries");
    println!();

    // Optimize to clean up ghost entries
    println!("ğŸ”§ Optimizing index to remove ghost entries...");
    let start = Instant::now();
    let removed = store.optimize()?;
    let elapsed = start.elapsed();

    println!("âœ… Optimization complete");
    println!("   Time: {:.2}ms", elapsed.as_millis());
    println!("   Ghost entries removed: {}", removed);
    println!("   â€¢ Index is now compact and efficient");
    println!("   â€¢ Search performance improved");
    println!();

    // Demo 5: Real-time Use Case
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Demo 5: Real-time Use Case Simulation");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("Simulating a real-time document indexing system\n");

    println!("Scenario: Indexing incoming documents as they arrive");
    println!();

    for batch in 0..5 {
        let doc_id = format!("document_{}", batch);
        let vector: Vec<f32> = (0..128).map(|i| ((batch + i) as f32) / 100.0).collect();
        let mut meta = Metadata {
            fields: HashMap::new(),
        };
        meta.fields
            .insert("type".into(), serde_json::json!("document"));
        meta.fields.insert("batch".into(), serde_json::json!(batch));
        let record = make_record(&doc_id, vector, meta);

        let start = Instant::now();
        store.upsert(doc_id.clone(), record.vector, record.metadata)?;
        let elapsed = start.elapsed();

        println!(
            "   ğŸ“„ {} indexed in {:.2}ms - immediately searchable!",
            doc_id,
            elapsed.as_millis() as f64
        );

        // Simulate some processing time
        std::thread::sleep(std::time::Duration::from_millis(10));
    }

    println!();
    println!("âœ… All documents indexed incrementally");
    println!("   â€¢ No downtime for index rebuilds");
    println!("   â€¢ Each document is searchable immediately");
    println!("   â€¢ Perfect for real-time RAG systems");
    println!();

    // Summary
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                  Summary & Best Practices                    â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();
    println!("âœ¨ Key Features:");
    println!("   â€¢ True incremental indexing - no rebuild needed");
    println!("   â€¢ Vectors are immediately searchable after insert");
    println!("   â€¢ Batch insert for optimal bulk loading performance");
    println!("   â€¢ Optimize() to clean up after deletions");
    println!();
    println!("ğŸ¯ When to use each method:");
    println!("   â€¢ upsert() - Real-time, one-at-a-time indexing");
    println!("   â€¢ batch_upsert() - Bulk loading, initial index creation");
    println!("   â€¢ optimize() - Periodically after many deletions");
    println!();
    println!("ğŸ“Š Performance Tips:");
    println!("   â€¢ Use batch_upsert() for initial data loading");
    println!("   â€¢ Use upsert() for real-time incremental updates");
    println!("   â€¢ Run optimize() when >20% of data is deleted");
    println!("   â€¢ Batch size sweet spot: 1,000-10,000 vectors");
    println!();
    println!("ğŸ”¥ Why This Matters:");
    println!("   1. No downtime for index maintenance");
    println!("   2. Real-time RAG applications can update continuously");
    println!("   3. Better than systems requiring full rebuilds");
    println!("   4. Memory efficient with periodic optimization");
    println!();
    println!("ğŸ’¡ Example Use Cases:");
    println!("   â€¢ Real-time document indexing");
    println!("   â€¢ Streaming log analysis");
    println!("   â€¢ Live chatbot knowledge base updates");
    println!("   â€¢ Continuous embedding updates from LLMs");
    println!();

    println!("â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®");
    println!("â”‚  Streaming Indexing: Making Real-time RAG Possible! âœ¨   â”‚");
    println!("â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯");

    Ok(())
}
