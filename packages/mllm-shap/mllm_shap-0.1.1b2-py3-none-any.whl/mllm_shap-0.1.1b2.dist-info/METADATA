Metadata-Version: 2.3
Name: mllm-shap
Version: 0.1.1b2
Summary: Shap implementation for Multi Modal Large Language Models with audio and text on input.
Keywords: shapley-value,llms,mllms,audio,text,xai
Author: Paweł Pozorski, Jakub Muszyński
Author-email: Paweł Pozorski <pozorski.paul@gmail.com>, Jakub Muszyński <muszynski.jakub@gmail.com>
License: MIT License
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python :: 3.12
Classifier: Operating System :: OS Independent
Classifier: License :: OSI Approved :: MIT License
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: Science/Research
Maintainer: Paweł Pozorski, Jakub Muszyński
Maintainer-email: Paweł Pozorski <pozorski.paul@gmail.com>, Jakub Muszyński <muszynski.jakub@gmail.com>
Requires-Python: >=3.12, <3.13
Project-URL: Changelog, https://pawlo77.github.io/MLLM-Shap/
Project-URL: Documentation, https://pawlo77.github.io/MLLM-Shap/
Project-URL: Homepage, https://github.com/Pawlo77/MLLM-Shap.git
Project-URL: Issues, https://github.com/Pawlo77/MLLM-Shap/issues
Project-URL: Repository, https://github.com/Pawlo77/MLLM-Shap.git
Description-Content-Type: text/markdown

# MLLM-Shap

MLLM-SHAP is a Python package designed to **interpret the predictions of large language models (LLMs) using SHAP (SHapley Additive exPlanations) values**. It helps you understand the contribution of input features to model outputs, enabling transparent and explainable AI workflows.

Key features:

- Integration with audio and text models, supporting multi-modal inputs and outputs.
- Flexible aggregation strategies: mean, sum, max, min, etc.
- Multiple similarity metrics (cosine, euclidean, etc.) for embedding analysis.
- Customizable SHAP calculation algorithms: exact, Monte Carlo approximations, and more.
- Examples showcasing common explainability pipelines in examples/ on official GitHub repository.
