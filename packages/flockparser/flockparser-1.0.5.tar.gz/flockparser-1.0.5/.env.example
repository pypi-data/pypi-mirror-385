# FlockParser Environment Configuration
# Copy this file to .env and update with your values

# ====================
# Ollama Configuration
# ====================

# Ollama API endpoint
# - For local installation: http://localhost:11434
# - For Docker host access: http://host.docker.internal:11434
# - For remote nodes: http://NODE_IP:11434
OLLAMA_HOST=http://localhost:11434

# ====================
# API Configuration
# ====================

# API authentication key for flock_ai_api.py
# IMPORTANT: Change this to a strong, random value in production!
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
FLOCKPARSE_API_KEY=change-this-secret-key

# ====================
# Docker Configuration
# ====================

# These are used by docker-compose.yml
# Uncomment and customize if using Docker deployment

# Port mappings (defaults shown)
# API_PORT=8000
# WEBUI_PORT=8501
# OLLAMA_PORT=11434

# ====================
# Advanced Configuration
# ====================

# Model configuration (optional)
# DEFAULT_MODEL=llama3.2
# EMBEDDING_MODEL=nomic-embed-text

# Performance tuning (optional)
# MAX_WORKERS=50
# PDF_TIMEOUT=300
# SEARCH_TIMEOUT=60
# CHAT_TIMEOUT=120

# Database paths (optional, defaults to local directories)
# CHROMA_DB_CLI_PATH=./chroma_db_cli
# CHROMA_DB_API_PATH=./chroma_db
# CONVERTED_FILES_PATH=./converted_files
# KNOWLEDGE_BASE_PATH=./knowledge_base

# ====================
# Security Notes
# ====================

# 1. Never commit .env to version control (already in .gitignore)
# 2. Use strong API keys in production (32+ characters, random)
# 3. Enable HTTPS for remote API access (use nginx/apache reverse proxy)
# 4. Restrict network access to trusted IPs when possible
# 5. Rotate API keys periodically
