# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [1.0.10] - 2025-10-20

### Added
- ğŸ§  **Dynamic Prompt System**: Context-aware system prompts that adapt to active features
  - Prevents hallucinations by only including instructions for enabled features
  - Separate prompt sections for KB, tools, business/personal modes
  - Automatic feature detection (Knowledge Base presence, tools availability)
  - Logging shows active features: "âœ… Knowledge Base | âŒ Tools | ğŸ’¾ Memory: SQL"
- ğŸ”„ **Universal Ollama Model Compatibility**: Full support for ALL Ollama models
  - Thinking-enabled models (Qwen3, DeepSeek, etc.) now work correctly
  - Auto-detection and handling of thinking mode
  - `enable_thinking: false` parameter for direct responses
  - Fallback extraction from thinking process when needed
  - Empty response retry with simpler prompts
- ğŸ“Š **Comprehensive Test Suite**: Pre-publish validation system
  - 34 automated tests covering all major features
  - Tests: imports, CLI, Ollama, JSON/SQL memory, MemAgent, config, multi-user
  - User scenario testing with output analysis
  - Hallucination detection and context verification

### Changed
- âš¡ **LLM Token Limits**: Increased from 150 to 2000 tokens for thinking models
- ğŸ§¹ **Removed Obsolete Module**: Deleted `prompt_templates.py` (replaced by dynamic system)
- ğŸ“ **Context Window**: Increased from 2048 to 4096 tokens for better context
- ğŸ¯ **Response Quality**: Better handling of empty responses with automatic retry

### Fixed
- ğŸ› **Thinking Model Issue**: Qwen3 and similar models now respond correctly
  - Fixed empty responses from thinking-mode models
  - Proper content extraction from model responses
  - System prompt instructions to suppress thinking process
- ğŸ”§ **Stop Sequences**: Removed problematic stop sequences that interfered with models
- âš ï¸ **Empty Response Handling**: Automatic retry with fallback for reliability

### Improved
- ğŸ¨ **Prompt Quality**: Feature-specific instructions prevent confusion
- ğŸš€ **Model Performance**: Works seamlessly with granite4, qwen3, llama3, and all Ollama models
- ğŸ“ˆ **User Experience**: No more irrelevant feature mentions in responses
- ğŸ§ª **Testing Coverage**: Complete validation before releases

### Technical Details
- Created `mem_llm/dynamic_prompt.py` (350+ lines) - modular prompt builder
- Modified `mem_llm/mem_agent.py`:
  - Added `has_knowledge_base` and `has_tools` tracking flags
  - Implemented `_build_dynamic_system_prompt()` method
  - Removed ~70 lines of old static prompt code
  - Added empty response retry logic
- Modified `mem_llm/llm_client.py`:
  - Added thinking mode detection and suppression
  - Increased token limits and context window
  - Improved response extraction logic
  - Added fallback for thinking-enabled models
- Updated `mem_llm/__init__.py` - exported `dynamic_prompt_builder`
- Cleaned `MANIFEST.in` - removed non-existent files
- Created `comprehensive_test.py` - 34 automated tests
- Created `user_test.py` - real-world scenario validation

### Breaking Changes
- None - fully backward compatible

## [1.0.9] - 2025-10-20

### Added
- ğŸ“ **PyPI-Optimized README**: Complete rewrite with practical examples
  - 5 comprehensive usage examples with full code and output
  - Print statements in all examples for better user experience
  - Step-by-step workflows showing complete processes
  - Real-world customer service scenario example
  - Turkish language support demonstration
  - User profile extraction example
- ğŸ“„ **Document Configuration Examples**: Added example demonstrating PDF/DOCX/TXT config generation
- ğŸ§ª **Config Update Testing**: Verification that manual YAML edits work correctly

### Changed
- ğŸ—‘ï¸ **Removed docs folder**: Consolidated documentation into main README
- ğŸªµ **Logging Behavior**: Changed from file+console to console-only logging
  - No more `mem_agent.log` files cluttering workspace
  - Keeps workspace clean with only `.db` and `.yaml` files
- ğŸ“– **Example Format**: All examples now include:
  - Print statements for visibility
  - Expected output blocks
  - Full conversation flows
  - Real usage scenarios

### Fixed
- ğŸ› **Log File Pollution**: Removed FileHandler from logging, only StreamHandler now
- ğŸ“ **README Examples**: Fixed examples that didn't show actual output or complete process

### Improved
- ğŸ¯ **User Experience**: Much clearer examples for new users
- ğŸ“š **Documentation Quality**: Professional PyPI-ready documentation
- ğŸ” **Example Clarity**: Each example shows input, process, and output

### Technical Details
- Modified `mem_llm/mem_agent.py` - removed FileHandler from logging setup
- Rewrote `README.md` with 5 detailed examples
- Created `examples/07_document_config.py` for PDF/DOCX/TXT feature
- Verified config changes work correctly with manual YAML edits

## [1.0.8] - 2025-10-20

### Added
- ğŸ¯ **CLI Tool**: Full-featured command-line interface
  - `mem-llm chat` - Interactive chat sessions
  - `mem-llm check` - System verification
  - `mem-llm stats` - Statistics and analytics
  - `mem-llm export` - Data export (JSON/TXT)
  - `mem-llm clear` - User data deletion
- ğŸ“Š **Feature Comparison Matrix**: Clear comparison between JSON and SQL modes
- ğŸ“¦ **Improved Dependencies**: Proper separation of core, dev, and optional requirements
  - `requirements.txt` - Core dependencies only
  - `requirements-dev.txt` - Development tools
  - `requirements-optional.txt` - Optional features (web, API, etc.)
- ğŸ”§ **Better Error Handling**: Improved startup checks with user-friendly messages
- ğŸ“š **Enhanced Documentation**: CLI usage examples and feature matrices

### Changed
- ğŸŒ **Multi-language Support**: Changed from "Turkish Support" to general multi-language
- ğŸ“– **Documentation**: All content now in English for broader accessibility
- ğŸ¨ **CLI Entry Point**: Added `mem-llm` console script in setup.py

### Fixed
- ğŸ› Missing `click` dependency in requirements
- ğŸ› Improved error messages when Ollama is not running

### Improved
- âš¡ Better user experience with CLI commands
- ğŸ“ Clearer README with usage examples
- ğŸ¯ More intuitive API design

## [1.0.4] - 2025-10-13

### Added
- âœ¨ Config-free knowledge base support - KB now works without config.yaml
- âœ¨ Smart keyword extraction for knowledge base search (Turkish & English stopwords)
- âœ¨ Enhanced KB context injection - KB data injected directly into user message
- âœ¨ Automatic user profile extraction (name, favorite_food, location)
- âœ¨ Turkish language support for profile extraction
- âœ¨ SQL-JSON memory compatibility methods
- ğŸ“š New example: `example_knowledge_base.py`
- ğŸ§ª Comprehensive test suite

### Fixed
- ğŸ› Knowledge base not being used without config.yaml
- ğŸ› LLM ignoring knowledge base information
- ğŸ› User profiles returning empty dictionaries
- ğŸ› Profile updates not working correctly with SQL memory
- ğŸ› Keyword search failing with Turkish queries

### Improved
- âš¡ Better KB-first response priority in system prompts
- âš¡ More accurate answers from knowledge base
- âš¡ Enhanced search algorithm with stopword filtering

## [1.0.3] - 2025-10-12

### Added
- ğŸ“¦ Initial PyPI release
- ğŸ¯ Core memory features (JSON & SQL)
- ğŸ¤– Ollama integration
- ğŸ’¾ Knowledge base system
- ğŸ› ï¸ User tools
- âš™ï¸ Configuration management

### Features
- Memory-enabled AI agent
- JSON and SQL memory backends
- Knowledge base integration
- User profile management
- Conversation history
- Configuration from YAML/documents

## [1.0.2] - 2025-10-11

### Internal
- ğŸ”§ Package structure improvements
- ğŸ“ Documentation updates

## [1.0.1] - 2025-10-10

### Fixed
- ğŸ› Import errors after package rename
- ğŸ“¦ Package directory naming issues

## [1.0.0] - 2025-10-09

### Initial Release
- ğŸ‰ First stable release
- ğŸ¤– Memory-enabled AI assistant
- ğŸ’¾ JSON memory management
- ğŸ”Œ Ollama integration
