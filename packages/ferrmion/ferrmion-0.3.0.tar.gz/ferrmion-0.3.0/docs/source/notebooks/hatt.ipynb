{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9355093a",
   "metadata": {},
   "source": [
    "# Hamiltonian Adaptive Ternary Tree\n",
    "\n",
    "HATT is an algorithm for the construction of Ternary-Tree encodings which are optimised for the Hamiltonian of interest.\n",
    "\n",
    "This notebook shows how to reproduce the results of: \n",
    "Y. Liu et al., \"HATT: Hamiltonian Adaptive Ternary Tree for Optimizing Fermion-to-Qubit Mapping,\" 2025 IEEE International Symposium on High Performance Computer Architecture (HPCA), Las Vegas, NV, USA, 2025, pp. 143-157, doi: 10.1109/HPCA61900.2025.00022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353ac6f",
   "metadata": {},
   "source": [
    "# Preprocess Hamiltonian\n",
    "\n",
    "The first thing we need to do for HATT is to process our fermionic operator into a majorana operator.\n",
    "\n",
    "There's a function to do this in `ferrmion.utils` if you need it, and the details aren't so important. We'll start with the small example given in the original paper.\n",
    "\n",
    "$$H_F = a^{\\dagger}_0a_0 + 2 a^{\\dagger}_1 a^{\\dagger}_2 a_1 a_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d182fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): np.complex128(0.25+0j),\n",
       " (0, 1): np.complex128(0.25j),\n",
       " (1, 0): np.complex128(-0.25j),\n",
       " (1, 1): np.complex128(0.25+0j),\n",
       " (2, 4, 2, 4): np.complex128(0.125+0j),\n",
       " (2, 4, 2, 5): np.complex128(0.125j),\n",
       " (2, 4, 3, 4): np.complex128(0.125j),\n",
       " (2, 4, 3, 5): np.complex128(-0.125+0j),\n",
       " (2, 5, 2, 4): np.complex128(-0.125j),\n",
       " (2, 5, 2, 5): np.complex128(0.125+0j),\n",
       " (2, 5, 3, 4): np.complex128(0.125+0j),\n",
       " (2, 5, 3, 5): np.complex128(0.125j),\n",
       " (3, 4, 2, 4): np.complex128(-0.125j),\n",
       " (3, 4, 2, 5): np.complex128(0.125+0j),\n",
       " (3, 4, 3, 4): np.complex128(0.125+0j),\n",
       " (3, 4, 3, 5): np.complex128(0.125j),\n",
       " (3, 5, 2, 4): np.complex128(-0.125+0j),\n",
       " (3, 5, 2, 5): np.complex128(-0.125j),\n",
       " (3, 5, 3, 4): np.complex128(-0.125j),\n",
       " (3, 5, 3, 5): np.complex128(0.125+0j)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ferrmion.utils import fermionic_to_sparse_majorana\n",
    "import numpy as np\n",
    "\n",
    "n_modes = 3\n",
    "ones = np.zeros((n_modes, n_modes))\n",
    "twos = np.zeros((n_modes, n_modes, n_modes, n_modes))\n",
    "\n",
    "ones[0,0]= 1\n",
    "twos[1,2,1,2] = 2\n",
    "\n",
    "majorana_ham =fermionic_to_sparse_majorana([(ones, \"+-\"), (twos, \"++--\")])\n",
    "majorana_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770ed18",
   "metadata": {},
   "source": [
    "By rerodering the modes using $\\{\\gamma_i,\\gamma_j\\}=2\\delta_{i,j}$ you can simplify this down to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73219c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "majorana_ham = {(0,1):0.5j, (2,3):-0.5j, (4,5):-0.5j, (2,3,4,5):0.5}\n",
    "n_modes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c81ac",
   "metadata": {},
   "source": [
    "# Algorithm 3\n",
    "\n",
    "There are three algorithms presented, each iteratively adding some improvements. We'll jump straight to algorithm 3, which caches some information about the tree as we build it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94340021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from typing import Iterable\n",
    "from ferrmion.encode import TernaryTree\n",
    "from ferrmion.encode.ternary_tree_node import TTNode\n",
    "\n",
    "def _qubit_term_weight(term: Iterable, comb: tuple[int, int, int]) -> int:\n",
    "    \"\"\" Find the single-qubit Pauli-weight of majorana terms.\n",
    "\n",
    "    If any pauli term is found an even number f times, we obtain I, weight = 0.\n",
    "    If we find all three pauli terms, return I (with an imaginary ccoefficient), weight = 0\n",
    "    If we find either one pauli or two then the weight = 1.\n",
    "\n",
    "    Args:\n",
    "        term (Iterable): Indices of term in our majorana-hamiltonian.\n",
    "        comb (tuple[int, int, int]): Combination of indices to weigh (x,y,z).\n",
    "\n",
    "    Returns:\n",
    "        int: Weight of the term.\n",
    "    \"\"\"\n",
    "    term_array = np.array([t for t in term])\n",
    "    odd_parity_paulis = np.array([np.count_nonzero(np.array(term_array-index))%2 for index in comb])\n",
    "    non_commuting = np.sum(odd_parity_paulis) % 3\n",
    "    return int(non_commuting!=0)\n",
    "\n",
    "def _reduce_hamiltonian(majorana_ham: dict[tuple[int,...],float], parent_index:int, selection:tuple[int, int, int]) -> dict[tuple[int,...],float]:\n",
    "    \"\"\"Simplify the Hamiltonian.\n",
    "    \n",
    "    As we increase the qubit number, we iteratively remove majoranas\n",
    "    which act trivially on the remaining qubits.\n",
    "    We replace them with the index of their parent string\n",
    "    as going forward they are identical to the parent string.\n",
    "\n",
    "    Args:\n",
    "        majorana_ham (dict[tuple[int,...],float]): Current Hamiltonian.\n",
    "        parent_index (int): Qubit index of the parent node.\n",
    "        selection (tuple[int, int, int]): Indices of the majoranas to be replaced.\n",
    "    \n",
    "    Returns:\n",
    "        dict[tuple[int,...],float]: Reduced Hamiltonian.\n",
    "    \"\"\"\n",
    "    new_ham = {}\n",
    "    for term, coeff in majorana_ham.items():\n",
    "        new_term = (i if i not in selection else parent_index for i in term)\n",
    "        if len(set(new_term)) != 1:\n",
    "            new_ham[new_term] = coeff\n",
    "    return new_ham\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d223df4",
   "metadata": {},
   "source": [
    "We'll first set up for iteratively building the tree. \n",
    "\n",
    "We need:\n",
    "- a set of leaves and nodes\n",
    "- a way to keep track of which ones have been used already \n",
    "- maps from each node to its furthest child and parent which can be found by taking only z branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2896bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need 2*M +1 leaves and M nodes.\n",
    "nodes = {i:None for i in range(2*n_modes+1)}\n",
    "for i in range(n_modes):\n",
    "    nodes[2*n_modes+1+i] = TTNode(qubit_label=i)\n",
    "\n",
    "# Start with all the leaves unassigned\n",
    "unassigned = {*range(2*n_modes+1)}\n",
    "\n",
    "# We create two maps, of z_ancestors and z_descendants\n",
    "ancestor_map = {i:i for i in nodes}\n",
    "descendant_map = {i:i for i in nodes}\n",
    "\n",
    "# We can also total up the pauli-weight as we go to save effort later\n",
    "total_weight = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afbe4f",
   "metadata": {},
   "source": [
    "The next step is to iteratively update the tree, using a greedy method to explicitly check which combination of possible child nodes gives us the smallest Pauli-weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d108eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_modes):\n",
    "    parent_index = 2*n_modes+1+i\n",
    "    parent = nodes[parent_index]\n",
    "\n",
    "    min = np.inf\n",
    "    selection = None\n",
    "    for comb in permutations(unassigned, 2):\n",
    "        small_y = None\n",
    "        small_x = None\n",
    "        x_index, z_index = comb\n",
    "        small_x = descendant_map[x_index]\n",
    "\n",
    "        # discard this combination\n",
    "        if small_x == 2*n_modes:\n",
    "            continue\n",
    "\n",
    "        if small_x % 2 == 0:\n",
    "            small_y = small_x+1\n",
    "        else:\n",
    "            small_y = small_x-1\n",
    "        # We can't use this index for y a \n",
    "        # it has been used in the combination already\n",
    "        # so we'd be replacing our x or z!\n",
    "        if small_y in comb:\n",
    "            continue\n",
    "        \n",
    "        y_index = ancestor_map[small_y]\n",
    "\n",
    "        if y_index in comb:\n",
    "            continue\n",
    "\n",
    "        if small_x %2 ==0:\n",
    "            comb = np.array([x_index, y_index, z_index], dtype=np.uint)\n",
    "        else:\n",
    "            comb = np.array([y_index, x_index, z_index], dtype=np.uint)\n",
    "        comb = [int(i) for i in comb]\n",
    "        weight = np.sum([_qubit_term_weight(term, comb) for term in majorana_ham.keys()])\n",
    "        if weight < min:\n",
    "            min = weight\n",
    "            selection = comb\n",
    "\n",
    "\n",
    "    total_weight += min\n",
    "    # Now find the Y pair of the x-node\n",
    "    for (i,char) in zip(selection, [\"x\",\"y\",\"z\"]):\n",
    "        if i in unassigned:\n",
    "            unassigned.remove(i)\n",
    "\n",
    "        if isinstance(nodes.get(i, None), TTNode):\n",
    "            parent.add_child(which_child=char, child_node=nodes.get(i))\n",
    "        else:\n",
    "            parent.leaf_majorana_indices[char] = i\n",
    "\n",
    "    z_index = selection[2]\n",
    "    z_desc = descendant_map[z_index]\n",
    "    descendant_map[parent_index] = z_desc\n",
    "    ancestor_map[z_index] = parent_index\n",
    "    ancestor_map[z_desc] = parent_index\n",
    "    \n",
    "    unassigned.add(parent_index)\n",
    "\n",
    "    # See the docstring for this function above\n",
    "    majorana_ham = _reduce_hamiltonian(majorana_ham, parent_index, selection)\n",
    "\n",
    "if len(unassigned) != 1:\n",
    "    raise ValueError(\"Not all nodes assigned by HATT.\")\n",
    "root = nodes[unassigned.pop()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99b09c",
   "metadata": {},
   "source": [
    "Finally, we can build the tree from our root node, which must be the only node without a parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d379765d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'x': 2, 'y': 3, 'z': 4}, 'y': 5, 'z': {'x': 0, 'y': 1, 'z': 6}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = TernaryTree(n_modes=n_modes, root_node=root)\n",
    "tree.enumeration_scheme = tree.default_enumeration_scheme()\n",
    "tree.pauli_weight = total_weight\n",
    "tree.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edc52f",
   "metadata": {},
   "source": [
    "# Inbuilt function\n",
    "\n",
    "`ferrmion` has an inbuilt function which works in just the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e09872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'x': 2, 'y': 3, 'z': 4}, 'y': 5, 'z': {'x': 0, 'y': 1, 'z': 6}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ferrmion.optimize.hatt import hamiltonian_adaptive_ternary_tree\n",
    "majorana_ham = {(0,1):0.5j, (2,3):-0.5j, (4,5):-0.5j, (2,3,4,5):0.5}\n",
    "n_modes = 3\n",
    "hatt=hamiltonian_adaptive_ternary_tree(majorana_ham, n_modes)\n",
    "hatt.as_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ferrmion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
