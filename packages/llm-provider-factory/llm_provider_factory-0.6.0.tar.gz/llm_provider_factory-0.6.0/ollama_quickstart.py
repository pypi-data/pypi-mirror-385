#!/usr/bin/env python3
"""
ðŸš€ Ollama Quick Start - 5 Dakikada BaÅŸla!
"""

import asyncio
from llm_provider import LLMProviderFactory
from llm_provider.utils.config import OllamaConfig
from llm_provider.settings import GenerationRequest


async def quick_start():
    """5 dakikada Ollama kullanmaya baÅŸla!"""
    
    print("ðŸ¦™ OLLAMA QUICK START")
    print("=" * 30)
    
    # âœ… 1. ADIM: Config oluÅŸtur
    config = OllamaConfig(
        base_url="http://localhost:11434",
        model="llama3.1:latest"
    )
    
    # âœ… 2. ADIM: Provider oluÅŸtur  
    factory = LLMProviderFactory()
    provider = factory.create_provider("ollama", config)
    
    # âœ… 3. ADIM: Soru sor
    request = GenerationRequest(
        prompt="Python ile web scraping nasÄ±l yapÄ±lÄ±r?",
        max_tokens=200
    )
    
    # âœ… 4. ADIM: CevabÄ± al
    response = await provider.generate(request)
    print(f"ðŸ¤– Cevap: {response.content}")
    
    print("\nðŸŽ‰ BaÅŸarÄ±lÄ±! ArtÄ±k Ollama kullanÄ±yorsunuz!")


if __name__ == "__main__":
    asyncio.run(quick_start())