"""
End-to-End Integration Tests: Streamlit Dashboard ↔ LSH Daemon ↔ Supabase

NOTE: This test suite requires external services (Supabase, LSH daemon).
Tests are skipped pending service dependency configuration.
"""

import pytest

# Skip all tests in this module - requires external service dependencies
pytestmark = pytest.mark.skip(reason="requires external services (Supabase, LSH daemon)")

import asyncio
import json
import os
import sys
from datetime import datetime, timedelta
from typing import Any, Dict, List

import pandas as pd
import requests

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../../src"))

# Conditionally import external dependencies (only if not skipped)
try:
    from dotenv import load_dotenv
    from supabase import Client, create_client

    HAS_DEPENDENCIES = True
except ImportError:
    # If imports fail, tests are already skipped
    create_client = None
    Client = None
    load_dotenv = lambda: None
    HAS_DEPENDENCIES = False

# Load environment variables if available
if HAS_DEPENDENCIES:
    load_dotenv()


class TestInfrastructureConnectivity:
    """Test basic connectivity to all infrastructure components"""

    @pytest.fixture(scope="class")
    def lsh_url(self):
        """LSH daemon URL from environment"""
        return os.getenv("LSH_API_URL", "https://mcli-lsh-daemon.fly.dev")

    @pytest.fixture(scope="class")
    def lsh_api_key(self):
        """LSH API key from environment"""
        return os.getenv("LSH_API_KEY")

    @pytest.fixture(scope="class")
    def supabase_client(self) -> Client:
        """Supabase client fixture"""
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_KEY")

        if not url or not key:
            pytest.skip("Supabase credentials not configured")

        return create_client(url, key)

    def test_lsh_daemon_health(self, lsh_url):
        """Test LSH daemon is healthy and responding"""
        response = requests.get(f"{lsh_url}/health", timeout=10)

        assert response.status_code == 200, f"LSH health check failed: {response.status_code}"

        data = response.json()
        assert data["status"] == "healthy", "LSH daemon not healthy"
        assert "uptime" in data, "Missing uptime in health response"
        assert "version" in data, "Missing version in health response"

        print(f"✓ LSH Daemon Health: {data['status']}")
        print(f"  Uptime: {data['uptime']:.2f}s")
        print(f"  Version: {data['version']}")

    def test_lsh_daemon_status(self, lsh_url):
        """Test LSH daemon status endpoint"""
        response = requests.get(f"{lsh_url}/api/status", timeout=10)

        assert response.status_code == 200, "LSH status endpoint failed"

        data = response.json()
        assert data["running"] is True, "LSH daemon not running"
        assert "pid" in data, "Missing PID in status"
        assert "memoryUsage" in data, "Missing memory usage"

        print(f"✓ LSH Daemon Status: Running")
        print(f"  PID: {data['pid']}")
        print(f"  Memory: {data['memoryUsage']['heapUsed'] / 1024 / 1024:.2f} MB")

    def test_lsh_daemon_jobs_endpoint(self, lsh_url):
        """Test LSH daemon jobs endpoint is accessible"""
        response = requests.get(f"{lsh_url}/api/jobs", timeout=10)

        assert response.status_code == 200, "LSH jobs endpoint failed"

        data = response.json()
        assert "jobs" in data, "Missing jobs in response"
        assert "total" in data, "Missing total in response"

        print(f"✓ LSH Jobs Endpoint: Accessible")
        print(f"  Total jobs: {data['total']}")

    def test_supabase_connection(self, supabase_client):
        """Test Supabase database connection"""
        try:
            # Try to fetch from politicians table
            response = supabase_client.table("politicians").select("id").limit(1).execute()

            assert response.data is not None, "Supabase query returned None"

            print(f"✓ Supabase Connection: Successful")
            print(f"  Database: Connected")

        except Exception as e:
            pytest.fail(f"Supabase connection failed: {e}")

    def test_supabase_politicians_table(self, supabase_client):
        """Test Supabase politicians table exists and has data"""
        response = supabase_client.table("politicians").select("*").limit(10).execute()

        assert response.data is not None, "Politicians table query failed"
        assert len(response.data) > 0, "Politicians table is empty"

        # Verify required fields
        politician = response.data[0]
        required_fields = ["id", "first_name", "last_name"]
        for field in required_fields:
            assert field in politician, f"Missing field '{field}' in politicians table"

        print(f"✓ Politicians Table: {len(response.data)} records")
        print(f"  Sample: {politician['first_name']} {politician['last_name']}")

    def test_supabase_trading_disclosures_table(self, supabase_client):
        """Test Supabase trading_disclosures table exists and has data"""
        response = supabase_client.table("trading_disclosures").select("*").limit(10).execute()

        assert response.data is not None, "Trading disclosures query failed"

        if len(response.data) > 0:
            disclosure = response.data[0]
            required_fields = ["id", "politician_id", "asset_ticker", "transaction_type"]
            for field in required_fields:
                assert field in disclosure, f"Missing field '{field}' in trading_disclosures"

            print(f"✓ Trading Disclosures Table: {len(response.data)} records")
            print(
                f"  Sample: {disclosure.get('asset_ticker')} - {disclosure.get('transaction_type')}"
            )
        else:
            print(f"⚠ Trading Disclosures Table: Empty (no test data)")


class TestDataFlow:
    """Test data flow between components"""

    @pytest.fixture(scope="class")
    def supabase_client(self) -> Client:
        """Supabase client fixture"""
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_KEY")

        if not url or not key:
            pytest.skip("Supabase credentials not configured")

        return create_client(url, key)

    @pytest.fixture(scope="class")
    def sample_politician(self, supabase_client):
        """Get a sample politician from Supabase"""
        response = supabase_client.table("politicians").select("*").limit(1).execute()

        if not response.data or len(response.data) == 0:
            pytest.skip("No politicians in database")

        return response.data[0]

    def test_fetch_politicians_for_dashboard(self, supabase_client):
        """Test fetching politicians list for dashboard dropdown"""
        response = (
            supabase_client.table("politicians").select("id, first_name, last_name").execute()
        )

        assert response.data is not None, "Failed to fetch politicians"
        assert len(response.data) > 0, "No politicians available"

        # Convert to DataFrame (as dashboard does)
        df = pd.DataFrame(response.data)
        assert "first_name" in df.columns, "Missing first_name column"
        assert "last_name" in df.columns, "Missing last_name column"

        # Create name list (as dashboard does)
        names = [f"{row['first_name']} {row['last_name']}" for _, row in df.iterrows()]

        print(f"✓ Fetched {len(names)} politicians for dashboard")
        print(f"  Sample: {names[0] if names else 'None'}")

    def test_fetch_trading_history_for_politician(self, supabase_client, sample_politician):
        """Test fetching trading history for a specific politician"""
        politician_id = sample_politician["id"]

        response = (
            supabase_client.table("trading_disclosures")
            .select("*")
            .eq("politician_id", politician_id)
            .order("disclosure_date", desc=True)
            .limit(100)
            .execute()
        )

        assert response.data is not None, "Failed to fetch trading history"

        if len(response.data) > 0:
            df = pd.DataFrame(response.data)

            # Verify required columns for dashboard
            required_columns = ["asset_ticker", "transaction_type", "disclosure_date"]
            for col in required_columns:
                assert col in df.columns, f"Missing column '{col}' in trading data"

            print(
                f"✓ Fetched {len(df)} trades for {sample_politician['first_name']} {sample_politician['last_name']}"
            )
            print(f"  Tickers: {df['asset_ticker'].unique()[:5].tolist()}")
        else:
            print(
                f"⚠ No trading history for {sample_politician['first_name']} {sample_politician['last_name']}"
            )

    def test_fetch_recent_disclosures(self, supabase_client):
        """Test fetching recent trading disclosures (last 90 days)"""
        cutoff_date = (datetime.now() - timedelta(days=90)).isoformat()

        response = (
            supabase_client.table("trading_disclosures")
            .select("*")
            .gte("disclosure_date", cutoff_date)
            .order("disclosure_date", desc=True)
            .execute()
        )

        assert response.data is not None, "Failed to fetch recent disclosures"

        if len(response.data) > 0:
            df = pd.DataFrame(response.data)
            print(f"✓ Fetched {len(df)} recent disclosures (last 90 days)")
            print(f"  Date range: {df['disclosure_date'].min()} to {df['disclosure_date'].max()}")
        else:
            print(f"⚠ No recent disclosures (last 90 days)")

    def test_politician_statistics_calculation(self, supabase_client, sample_politician):
        """Test calculating politician trading statistics"""
        politician_id = sample_politician["id"]

        response = (
            supabase_client.table("trading_disclosures")
            .select("*")
            .eq("politician_id", politician_id)
            .execute()
        )

        if not response.data or len(response.data) == 0:
            pytest.skip(
                f"No trades for {sample_politician['first_name']} {sample_politician['last_name']}"
            )

        df = pd.DataFrame(response.data)

        # Calculate statistics (as ML model does)
        total_trades = len(df)
        purchases = len(df[df["transaction_type"].str.contains("purchase", case=False, na=False)])
        sales = total_trades - purchases
        purchase_ratio = purchases / total_trades if total_trades > 0 else 0
        unique_stocks = df["asset_ticker"].nunique() if "asset_ticker" in df.columns else 0

        # Verify calculations
        assert total_trades > 0, "No trades found"
        assert 0 <= purchase_ratio <= 1, f"Invalid purchase ratio: {purchase_ratio}"
        assert unique_stocks >= 0, f"Invalid unique stocks count: {unique_stocks}"

        print(
            f"✓ Calculated statistics for {sample_politician['first_name']} {sample_politician['last_name']}"
        )
        print(f"  Total trades: {total_trades}")
        print(f"  Purchases: {purchases} ({purchase_ratio*100:.1f}%)")
        print(f"  Sales: {sales}")
        print(f"  Unique stocks: {unique_stocks}")


class TestMLPredictionPipeline:
    """Test ML prediction pipeline with real data"""

    @pytest.fixture(scope="class")
    def supabase_client(self) -> Client:
        """Supabase client fixture"""
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_KEY")

        if not url or not key:
            pytest.skip("Supabase credentials not configured")

        return create_client(url, key)

    @pytest.fixture(scope="class")
    def sample_trading_data(self, supabase_client):
        """Get sample trading data for predictions"""
        response = supabase_client.table("trading_disclosures").select("*").limit(100).execute()

        if not response.data or len(response.data) == 0:
            pytest.skip("No trading data available")

        return pd.DataFrame(response.data)

    def test_feature_engineering_from_data(self, sample_trading_data, supabase_client):
        """Test feature engineering pipeline using real Supabase data"""
        # Get a sample disclosure
        if len(sample_trading_data) == 0:
            pytest.skip("No trading data available")

        sample = sample_trading_data.iloc[0]
        politician_id = sample["politician_id"]

        # Fetch politician's historical data
        history_response = (
            supabase_client.table("trading_disclosures")
            .select("*")
            .eq("politician_id", politician_id)
            .execute()
        )

        history_df = pd.DataFrame(history_response.data)

        # Calculate politician statistics
        total_trades = len(history_df)
        purchases = len(
            history_df[
                history_df["transaction_type"].str.contains("purchase", case=False, na=False)
            ]
        )
        purchase_ratio = purchases / total_trades if total_trades > 0 else 0.5
        unique_stocks = (
            history_df["asset_ticker"].nunique() if "asset_ticker" in history_df.columns else 1
        )

        # Engineer features (matching training pipeline)
        features = {
            "politician_trade_count": min(total_trades / 100, 1.0),
            "politician_purchase_ratio": purchase_ratio,
            "politician_diversity": min(unique_stocks / 50, 1.0),
            "transaction_is_purchase": (
                1.0 if "purchase" in str(sample["transaction_type"]).lower() else 0.0
            ),
            "transaction_amount_log": 4.5,  # Placeholder
            "transaction_amount_normalized": 0.5,  # Placeholder
            "market_cap_score": 0.5,
            "sector_risk": 0.5,
            "sentiment_score": 0.5,
            "volatility_score": 0.3,
        }

        # Verify all 10 features present
        assert len(features) == 10, f"Expected 10 features, got {len(features)}"

        # Verify all features in valid range [0, 1] or reasonable log scale
        for key, value in features.items():
            assert value is not None, f"Feature '{key}' is None"
            assert isinstance(value, (int, float)), f"Feature '{key}' is not numeric"

        print(f"✓ Engineered {len(features)} features from Supabase data")
        print(f"  Politician stats: {total_trades} trades, {purchase_ratio*100:.1f}% purchases")
        print(f"  Sample features: {list(features.keys())[:5]}")

    def test_model_loading(self):
        """Test loading trained model from models directory"""
        models_dir = os.path.join(os.path.dirname(__file__), "../../models")

        if not os.path.exists(models_dir):
            pytest.skip("Models directory not found")

        # Look for model files
        import glob

        model_files = glob.glob(os.path.join(models_dir, "*.pt"))
        metadata_files = glob.glob(os.path.join(models_dir, "*.json"))

        if not model_files:
            pytest.skip("No trained models found")

        # Load latest model metadata
        latest_metadata = sorted(metadata_files, reverse=True)[0]

        with open(latest_metadata, "r") as f:
            metadata = json.load(f)

        # Verify metadata structure
        required_keys = ["model_name", "accuracy", "created_at"]
        for key in required_keys:
            assert key in metadata, f"Missing key '{key}' in model metadata"

        # Verify training metrics
        assert "final_metrics" in metadata, "Missing final_metrics in model metadata"
        assert (
            "train_accuracy" in metadata["final_metrics"]
        ), "Missing train_accuracy in final_metrics"

        print(f"✓ Model metadata loaded: {metadata['model_name']}")
        print(f"  Accuracy: {metadata['accuracy']:.4f}")
        print(f"  Epochs: {metadata.get('epochs', 'N/A')}")
        print(f"  Created: {metadata['created_at']}")

    def test_prediction_generation(self, sample_trading_data):
        """Test generating prediction from features"""
        if len(sample_trading_data) == 0:
            pytest.skip("No trading data available")

        # Create sample features
        features = {
            "politician_trade_count": 0.5,
            "politician_purchase_ratio": 0.7,
            "politician_diversity": 0.3,
            "transaction_is_purchase": 1.0,
            "transaction_amount_log": 4.5,
            "transaction_amount_normalized": 0.5,
            "market_cap_score": 0.6,
            "sector_risk": 0.4,
            "sentiment_score": 0.7,
            "volatility_score": 0.3,
        }

        # Simple weighted prediction (matching dashboard logic)
        weights = {
            "politician_trade_count": 0.15,
            "politician_purchase_ratio": 0.10,
            "politician_diversity": 0.08,
            "transaction_is_purchase": 0.12,
            "sentiment_score": 0.20,
            "volatility_score": -0.12,
            "market_cap_score": 0.10,
            "sector_risk": -0.08,
        }

        score = 0.5  # Baseline
        for feature, value in features.items():
            if feature in weights:
                score += weights[feature] * value

        # Clip to [0, 1]
        score = max(0, min(1, score))

        # Generate prediction
        if score >= 0.65:
            recommendation = "BUY"
        elif score <= 0.35:
            recommendation = "SELL"
        else:
            recommendation = "HOLD"

        predicted_return = (score - 0.5) * 0.2  # -10% to +10%
        confidence = min(0.5 + abs(score - 0.5), 0.95)

        # Verify prediction structure
        assert recommendation in [
            "BUY",
            "SELL",
            "HOLD",
        ], f"Invalid recommendation: {recommendation}"
        assert -1.0 <= predicted_return <= 1.0, f"Predicted return out of range: {predicted_return}"
        assert 0.5 <= confidence <= 0.95, f"Confidence out of range: {confidence}"

        print(f"✓ Generated prediction from features")
        print(f"  Recommendation: {recommendation}")
        print(f"  Predicted return: {predicted_return*100:.2f}%")
        print(f"  Confidence: {confidence*100:.1f}%")


class TestLSHIntegration:
    """Test LSH daemon integration with dashboard"""

    @pytest.fixture(scope="class")
    def lsh_url(self):
        """LSH daemon URL"""
        return os.getenv("LSH_API_URL", "https://mcli-lsh-daemon.fly.dev")

    @pytest.fixture(scope="class")
    def lsh_headers(self):
        """LSH API headers"""
        api_key = os.getenv("LSH_API_KEY")
        if api_key:
            return {"x-api-key": api_key}
        return {}

    def test_lsh_api_accessibility(self, lsh_url):
        """Test LSH API is accessible from test environment"""
        response = requests.get(f"{lsh_url}/", timeout=10)

        assert response.status_code == 200, "LSH API not accessible"

        data = response.json()
        assert "service" in data, "Missing service info"
        assert "endpoints" in data, "Missing endpoints list"

        print(f"✓ LSH API accessible: {data['service']}")
        print(f"  Endpoints: {', '.join(data['endpoints'])}")

    def test_lsh_job_listing(self, lsh_url, lsh_headers):
        """Test listing jobs from LSH daemon"""
        response = requests.get(f"{lsh_url}/api/jobs", headers=lsh_headers, timeout=10)

        assert response.status_code == 200, "Failed to list jobs"

        data = response.json()
        assert "jobs" in data, "Missing jobs in response"
        assert "total" in data, "Missing total count"

        print(f"✓ LSH jobs listed successfully")
        print(f"  Total jobs: {data['total']}")


class TestEndToEndWorkflow:
    """Test complete end-to-end workflow"""

    @pytest.fixture(scope="class")
    def supabase_client(self) -> Client:
        """Supabase client fixture"""
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_KEY")

        if not url or not key:
            pytest.skip("Supabase credentials not configured")

        return create_client(url, key)

    @pytest.fixture(scope="class")
    def lsh_url(self):
        """LSH daemon URL"""
        return os.getenv("LSH_API_URL", "https://mcli-lsh-daemon.fly.dev")

    def test_complete_prediction_workflow(self, supabase_client, lsh_url):
        """Test complete prediction workflow: Supabase → Features → Prediction"""

        # Step 1: Fetch politician from Supabase
        print("\n→ Step 1: Fetching politician from Supabase...")
        politicians = supabase_client.table("politicians").select("*").limit(1).execute()

        if not politicians.data or len(politicians.data) == 0:
            pytest.skip("No politicians in database")

        politician = politicians.data[0]
        print(f"  ✓ Fetched: {politician['first_name']} {politician['last_name']}")

        # Step 2: Fetch trading history from Supabase
        print("\n→ Step 2: Fetching trading history from Supabase...")
        trades = (
            supabase_client.table("trading_disclosures")
            .select("*")
            .eq("politician_id", politician["id"])
            .execute()
        )

        trades_df = pd.DataFrame(trades.data)
        print(f"  ✓ Fetched {len(trades_df)} trades")

        # Step 3: Calculate politician statistics
        print("\n→ Step 3: Calculating politician statistics...")
        total_trades = len(trades_df)
        purchases = (
            len(
                trades_df[
                    trades_df["transaction_type"].str.contains("purchase", case=False, na=False)
                ]
            )
            if len(trades_df) > 0
            else 0
        )
        purchase_ratio = purchases / total_trades if total_trades > 0 else 0.5
        unique_stocks = (
            trades_df["asset_ticker"].nunique()
            if "asset_ticker" in trades_df.columns and len(trades_df) > 0
            else 0
        )

        print(f"  ✓ Total trades: {total_trades}")
        print(f"  ✓ Purchase ratio: {purchase_ratio:.2%}")
        print(f"  ✓ Unique stocks: {unique_stocks}")

        # Step 4: Engineer features
        print("\n→ Step 4: Engineering features...")
        features = {
            "politician_trade_count": min(total_trades / 100, 1.0),
            "politician_purchase_ratio": purchase_ratio,
            "politician_diversity": min(unique_stocks / 50, 1.0),
            "transaction_is_purchase": 1.0,
            "transaction_amount_log": 4.7,
            "transaction_amount_normalized": 0.5,
            "market_cap_score": 0.5,
            "sector_risk": 0.5,
            "sentiment_score": 0.5,
            "volatility_score": 0.3,
        }
        print(f"  ✓ Engineered {len(features)} features")

        # Step 5: Generate prediction
        print("\n→ Step 5: Generating prediction...")
        weights = {
            "politician_trade_count": 0.15,
            "sentiment_score": 0.20,
            "volatility_score": -0.12,
        }

        score = 0.5
        for feature, value in features.items():
            if feature in weights:
                score += weights[feature] * value

        score = max(0, min(1, score))

        if score >= 0.65:
            recommendation = "BUY"
        elif score <= 0.35:
            recommendation = "SELL"
        else:
            recommendation = "HOLD"

        predicted_return = (score - 0.5) * 0.2
        confidence = min(0.5 + abs(score - 0.5), 0.95)

        print(f"  ✓ Recommendation: {recommendation}")
        print(f"  ✓ Predicted return: {predicted_return*100:.2f}%")
        print(f"  ✓ Confidence: {confidence*100:.1f}%")

        # Step 6: Verify LSH daemon is accessible
        print("\n→ Step 6: Verifying LSH daemon accessibility...")
        lsh_response = requests.get(f"{lsh_url}/health", timeout=10)
        assert lsh_response.status_code == 200, "LSH daemon not accessible"
        print(f"  ✓ LSH daemon: {lsh_response.json()['status']}")

        # Final verification
        print("\n✅ Complete end-to-end workflow successful!")
        print(f"   Supabase → Features → Prediction → LSH verification")

    def test_dashboard_data_pipeline(self, supabase_client):
        """Test dashboard's complete data pipeline"""

        print("\n→ Testing dashboard data pipeline...")

        # Simulate dashboard loading sequence

        # 1. Load politicians list
        politicians = (
            supabase_client.table("politicians").select("id, first_name, last_name").execute()
        )

        assert politicians.data is not None
        politician_count = len(politicians.data)
        print(f"  ✓ Loaded {politician_count} politicians")

        # 2. Load recent disclosures
        cutoff = (datetime.now() - timedelta(days=90)).isoformat()
        disclosures = (
            supabase_client.table("trading_disclosures")
            .select("*")
            .gte("disclosure_date", cutoff)
            .execute()
        )

        disclosure_count = len(disclosures.data) if disclosures.data else 0
        print(f"  ✓ Loaded {disclosure_count} recent disclosures")

        # 3. Check for models
        models_dir = os.path.join(os.path.dirname(__file__), "../../models")
        has_models = os.path.exists(models_dir)
        print(f"  ✓ Models directory: {'Found' if has_models else 'Not found'}")

        # 4. Verify data structure
        if disclosure_count > 0:
            df = pd.DataFrame(disclosures.data)
            required_cols = ["politician_id", "asset_ticker", "transaction_type", "disclosure_date"]

            for col in required_cols:
                assert col in df.columns, f"Missing required column: {col}"

            print(f"  ✓ Data structure validated")

        print("\n✅ Dashboard data pipeline test successful!")


if __name__ == "__main__":
    # Run tests with verbose output
    pytest.main([__file__, "-v", "-s", "--tb=short"])
