{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Collinear Red Team - Custom Target Model\n",
    "\n",
    "This notebook shows how to test your own custom model with red-team evaluation.\n",
    "\n",
    "Red-teaming tests whether LLMs can be manipulated into violating safety policies through adversarial prompting.\n",
    "\n",
    "**Note:** The attack plan is loaded automatically on the server. You only need to specify which model you want to test!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Install SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install collinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the client and set your API keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collinear.client import Client\n",
    "\n",
    "# Set your API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"\n",
    "os.environ[\"COLLINEAR_API_KEY\"] = \"your-collinear-key-here\"\n",
    "os.environ[\"COLLINEAR_BACKEND_URL\"] = \"https://stage.collinear.ai\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Initialize Client\n",
    "\n",
    "The client needs your default API credentials. These will be used for the attacker and evaluator models (running on Collinear's side):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\n",
    "    assistant_model_url=\"https://api.openai.com/v1\",\n",
    "    assistant_model_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    assistant_model_name=\"gpt-4o-mini\",\n",
    "    collinear_api_key=os.environ[\"COLLINEAR_API_KEY\"],\n",
    ")\n",
    "\n",
    "print(\"✓ Client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Test Your Custom Model\n",
    "\n",
    "Specify the model you want to test using the `target_model` parameter.\n",
    "\n",
    "The target model will use the same API endpoint and credentials from the client initialization above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start evaluation with your custom target model\n",
    "evaluation = client.redteam(\n",
    "    target_model=\"gpt-4o\",  # Replace with your model name\n",
    "    max_turns=10,\n",
    ")\n",
    "\n",
    "print(f\"✓ Started evaluation: {evaluation.id}\")\n",
    "print(f\"  Testing model: gpt-4o\")\n",
    "print(f\"  Attack plan loaded automatically on the server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Alternative: Use a Different API Endpoint for Your Target Model\n",
    "\n",
    "If your target model is hosted at a different endpoint (e.g., Azure OpenAI, a custom deployment, or a different provider), use `ModelConfig`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collinear.redteam import ModelConfig\n",
    "\n",
    "# Define your custom target model configuration\n",
    "my_target = ModelConfig(\n",
    "    provider=\"openai_compat\",\n",
    "    model=\"gpt-4o\",  # Replace with your model name\n",
    "    base_url=\"https://api.openai.com/v1\",  # Replace with your API endpoint\n",
    "    api_key=\"your-api-key-here\",  # Replace with your API key\n",
    "    temperature=0.0,\n",
    "    max_retries=10,\n",
    ")\n",
    "\n",
    "# Start evaluation with custom target configuration\n",
    "evaluation = client.redteam(\n",
    "    target_config=my_target,\n",
    "    max_turns=10,\n",
    ")\n",
    "\n",
    "print(f\"✓ Started evaluation: {evaluation.id}\")\n",
    "print(f\"  Testing custom model configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Poll for Results\n",
    "\n",
    "Wait for the evaluation to complete (may take several minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for completion (up to 10 minutes)\n",
    "result = evaluation.poll(timeout=600.0, interval=5.0)\n",
    "\n",
    "# View summary\n",
    "summary = evaluation.summary()\n",
    "print(f\"\\nStatus: {summary['status']}\")\n",
    "print(f\"Total behaviors tested: {summary['total_behaviors']}\")\n",
    "print(f\"Successful: {summary['successful']}\")\n",
    "print(f\"Failed: {summary['failed']}\")\n",
    "\n",
    "if summary['errors_by_type']:\n",
    "    print(f\"\\nErrors: {summary['errors_by_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## View Full Results\n",
    "\n",
    "The result contains all attack transcripts, judge scores, and evaluation details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
