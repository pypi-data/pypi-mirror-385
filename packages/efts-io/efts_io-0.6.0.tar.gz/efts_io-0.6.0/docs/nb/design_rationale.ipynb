{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Design rationale\n",
    "\n",
    "The [netCDF STF 2.0 compliant format](https://github.com/csiro-hydroinformatics/efts/blob/107c553045a37e6ef36b2eababf6a299e7883d50/docs/netcdf_for_water_forecasting.md) is such that a file loaded from Python via `xarray` is not the most convenient data model for users.\n",
    "\n",
    "This notebook illustrates interactively the behaviors, and informs the design choices made to reconcile the `xarray` view with the on-disk representation.\n",
    "\n",
    "## Loading an existing reference netCDF file\n",
    "\n",
    "A file was created using (probably) a Matlab implementation of STF data handling and I/O. Let's load it via `xarray` as well as the `netCDF4` package, as we are not sure which will be most adequate for `efts-io` for saving/loading operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "`xarray.open_dataset` has arguments to turn on/off the decoding of climate and forecast (SF) and related conventions. \n",
    "\n",
    "* `decode_times=False` is a must, otherwise the statement fails. Decoding would work for the `time` dimension, but decoding `lead_time` fails.  \n",
    "* `decode_cf` seems to influence at least how the station_name variable appears, notably whether it ends up of dimensions `(station, strLen)` if True, or `(station,)` if False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import efts_io.helpers as hlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = hlp.derived_rainfall_tas()\n",
    "\n",
    "rain_xr = xr.open_dataset(fn, decode_times=False, decode_cf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_nc = nc.Dataset(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### xarray read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "If we use `decode_cf=True`, we seem to get a one dimensional array of array of bytes, rather than a matrix of bytes (type 'S1'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rain_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode = xr.open_dataset(fn, decode_times=False, decode_cf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode.station_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode.station_name.values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### netCDF4 read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Modulo the value of `decode_cf` for `xarray.open_dataset`, the shape of the data in memory appears consistent between `xarray` and `netCDF4`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Requirements\n",
    "\n",
    "### Desired in-memory representation\n",
    "\n",
    "See [this discussion](https://github.com/csiro-hydroinformatics/efts-io/issues/2) for background.\n",
    "\n",
    "We assume that an \"intuitive\" data representation in an xarray dataset would have the following characteristics:\n",
    "\n",
    "* The `time` coordinate has values with python representations `np.datetime64` or similar\n",
    "* A `station_id` coordinate has values as strings rather than bytes, so that slicing can be done with statements such as `data.sel(station_id=\"407113A\")`. The STF representation is such that `station` is a dimension/coordinate, not `station_id`\n",
    "* In the example case loaded, the variable datatypes is 32-bits `np.float32` rather than 64 bits `np.float`. The latter is probably more convenient in most use cases we can anticipate. However we may want to consider keeping a 32 bits representation: ensemble forecasting and modelling methods can be RAM-hungry even with 2024 typical machine setups.\n",
    "* coordinate data is in type `int32`. Memory footprint is not a consideration, we may want to change is to 64 bits, or not, based on other factors.\n",
    "* There should be a coordinate named \"realisation\" (or U.S. \"realization\"??) rather than \"ens_member\" \n",
    "\n",
    "### STF 2.0 compliance\n",
    "\n",
    "It is imperative to be able to export the in-memory xarray representation to a `netCDF` file that complies with documented conventions and is readable by existing toolsets in `Matlab`, `C++` or even `Fortran`. A key question is whether we can use `xarray.to_netcdf` or whether we need to use the lower level package `netCDF4` to achieve that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "This notebook will illustrate the various steps taken to bridge the gap between the on-disk and in-memory representations.\n",
    "\n",
    "### Reading from disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### time\n",
    "\n",
    "For background in issue https://jira.csiro.au/browse/WIRADA-635. We cannot have xarray automagically decoding this axis, so we need to do the work manually, but using as much as possible work already done. Not sure how I had figured out about `CFDatetimeCoder`, but:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xarray.coding import times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "decod = times.CFDatetimeCoder(use_cftime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "decod.decode?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "We need to pass a \"Variable\", not a `DataArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rain_cfdecode.coords['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_DIMNAME=\"time\"\n",
    "var = xr.as_variable(rain_cfdecode.coords[TIME_DIMNAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zone = var.attrs[\"time_standard\"]\n",
    "time_coords = decod.decode(var, name=TIME_DIMNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time_coords.values[0]\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Date/time, calendar and time zone handling are a topic of underappreciated complexity, to put it mildly. Let's look at what we get here.\n",
    "\n",
    "Unfamiliar with this type of time stamp. It seems not to have time zone from the decoding operation, but can have it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp.tzinfo is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Should our new `time` axis hold time zone info with each time stamp, or still rely on the coordinate attribute `time_standard`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efts_io.wrapper import cftimes_to_pdtstamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time_values = cftimes_to_pdtstamps(\n",
    "    time_coords.values,\n",
    "    time_zone,\n",
    ")\n",
    "new_time_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "This may be a suitable time axis. Depending on usage needs we may want to revisit though. In particular, users may create \"naive\" date time stamps from strings: how would `ds.sel()` then behave if time stamps have time zones??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Timestamp('2000-11-15 23:00:00+0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp('2000-11-15 23:00:00+0000') == new_time_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp('2000-11-15 23:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp('2000-11-15 23:00:00') == new_time_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "As expected, the naive date time is not equal to the one with a time zone. Using time zone in the time stamps may be a fraught choice in practice. In particular there may be logical but unintuitive if we use a time `slice` to subset data\n",
    "\n",
    "See also [github issue 3](https://github.com/csiro-hydroinformatics/efts-io/issues/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time_values = cftimes_to_pdtstamps(\n",
    "    time_coords.values,\n",
    "    None,\n",
    ")\n",
    "new_time_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### station_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = rain_cfdecode.station_id.values\n",
    "station_ids.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "STF conventions are such that the station ID can only be an integer. We want a `str` in the in memory model. This is easy going one direction; when we consider going the other way (writing to STF 2.0) this will be trickier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids_str = [str(x) for x in station_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode.station_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rain_cfdecode.station_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rain_cfdecode.station)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "A key thing here is that we will promote \"station_id\" which is a variable, to a coordinate, so we cannot just assign dimensions; we will need to reconstruct a new xarray."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "#### station_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode.station_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = b'18594010'\n",
    "str(x, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Using helper functions already included in the package at the time of writing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efts_io.wrapper import byte_stations_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_name_str = byte_stations_to_str(rain_cfdecode.station_name.values)\n",
    "station_name_str[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### creating a new dataset\n",
    "\n",
    "The package already includes a function to create high level `xarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efts_io import wrapper as w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode.ens_member.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "issue_times = new_time_values\n",
    "station_ids = station_ids_str\n",
    "lead_times = rain_cfdecode.lead_time.values\n",
    "lead_time_tstep = \"days\"\n",
    "ensemble_size = len(rain_cfdecode.ens_member.values)\n",
    "station_names= station_name_str\n",
    "nc_attributes = None\n",
    "latitudes = rain_cfdecode.lat.values\n",
    "longitudes = rain_cfdecode.lon.values\n",
    "areas = rain_cfdecode.area.values\n",
    "\n",
    "d = w.xr_efts(\n",
    "    issue_times,\n",
    "    station_ids,\n",
    "    lead_times,\n",
    "    lead_time_tstep,\n",
    "    ensemble_size,\n",
    "    station_names,\n",
    "    latitudes,\n",
    "    longitudes,\n",
    "    areas,\n",
    "    nc_attributes,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.station_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "d.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sel(station_id=\"28286670\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(d.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(rain_cfdecode.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_cfdecode.rain_obs.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = rain_cfdecode.rain_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "Assigning the data variable straight is not possible due to the differing names for the coordinate(s) for the station ids: we'd end up with 5 dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tmp = d.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tmp.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.assign_coords(d_tmp.station.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tmp['rain_obs'] = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "There is a [DataArray.rename](https://docs.xarray.dev/en/latest/generated/xarray.DataArray.rename.html) method to rename coordinates, but since we also have a change of values for the `station` and `station_id` coordinates, we need to do more work anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we manipulate the 4D dataset: do not assume a certain order in the dimensions:\n",
    "coordinates_mapping = {\n",
    "    \"time\": \"time\",\n",
    "    \"station\": \"station_id\",\n",
    "    \"ens_member\": \"ens_member\",\n",
    "    \"lead_time\": \"lead_time\",\n",
    "}\n",
    "list(coordinates_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_obs = rain_cfdecode.rain_obs\n",
    "rain_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.station_id.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### time axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = \"hours since 2010-08-01 13:00:00 +0000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cftime.time2index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EFTS-IO",
   "language": "python",
   "name": "efts_io"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
