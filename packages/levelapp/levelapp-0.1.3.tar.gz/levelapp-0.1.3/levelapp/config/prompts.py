EVAL_PROMPT_TEMPLATE = """
You are an impartial evaluator for a conversational system.
Compare the AGENT's reply to the EXPECTED reply for the SAME user message.

Consider only:
1) Semantic Coverage — does the AGENT cover the key points in EXPECTED?
2) Faithfulness — no contradictions or invented details relative to EXPECTED.
3) Appropriateness — tone/format suitable for the user message.
Ignore minor wording/punctuation differences. Do NOT reward verbosity.

Scale (integer):
0 = Poor (misses key points or contradicts)
1 = Moderate (captures some ideas, noticeable gaps)
2 = Good (mostly matches, minor omissions/differences)
3 = Excellent (semantically equivalent; no meaningful differences)

USER_MESSAGE:
\"\"\"{user_input}\"\"\"

EXPECTED (reference reply):
\"\"\"{reference_text}\"\"\"

AGENT (model reply):
\"\"\"{generated_text}\"\"\"

Return ONLY a single JSON object on one line with exactly these keys:
- "score": <0|1|2|3>,
- "label": "<Poor|Moderate|Good|Excellent>",
- "justification": "<1-2 concise sentences>",
- "evidence":
    - "covered_points": ["<short phrase>", "..."],   // <=3 items
    - "missing_or_wrong": ["<short phrase>", "..."]  // <=3 items
    
Do NOT include any additional text, explanations, or formatting (e.g., "JSON object:", ```json or ```, or markdown).
"""


SUMMARIZATION_PROMPT_TEMPLATE = """
You are reviewing evaluation justifications from LLM judges about replies generated by a virtual assistant.
Interpret the context from the verdicts: (e.g., real-estate leasing, medical appointment scheduling, etc.).

Each justification contains the judge's assessment of how well the assistant's response matched the expected reply.
Your task is to **identify and summarize only the negative points**, such as:
- Errors or inaccuracies
- Misunderstandings or misinterpretations
- Missing or incomplete information
- Failure to meet expectations or requirements

**Instructions:**
- Return up to {max_bullets} concise bullet points.
- Start each point with "- " and focus on clarity and relevance.
- Avoid redundancy and prioritize actionable feedback.

---
- Judge: {judge}
- Verdicts: {verdicts}
"""
