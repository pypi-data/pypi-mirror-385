{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b8fbe6a2",
      "metadata": {
        "id": "b8fbe6a2"
      },
      "source": [
        "# **Honegumi RAG Assistant: A Google Colab Tutorial**\n",
        "**Agentic Code Generation for Bayesian Optimization**\n",
        "\n",
        "### **Purpose of This Tutorial**\n",
        "This tutorial demonstrates how to use [**Honegumi RAG Assistant**](https://github.com/hasan-sayeed/honegumi_rag_assistant), an intelligent agentic AI system that automatically generates high-quality, executable Python code for Bayesian optimization experiments. With just a natural language problem description, Honegumi RAG Assistant can:\n",
        "\n",
        "- Interpret your optimization problem and extract parameters automatically\n",
        "- Generate deterministic code skeletons using [Honegumi](https://honegumi.readthedocs.io)\n",
        "- Retrieve relevant [Ax Platform](https://ax.dev/) documentation to enhance code generation\n",
        "- Produce complete, ready-to-run Python code tailored to your specific requirements\n",
        "- Optionally review and refine the generated code\n",
        "\n",
        "By following this tutorial, you'll learn how to set up Honegumi RAG Assistant in Google Colab, describe your optimization problem, build a vector store for documentation retrieval, and execute the agentic pipeline to generate production-ready Bayesian optimization code.\n",
        "\n",
        "> This automation offers a powerful **starting point for optimization engineers and researchers**â€”helping them **move faster**, explore ideas more effectively, and focus on science rather than boilerplate code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3da99556",
      "metadata": {
        "id": "3da99556"
      },
      "source": [
        "## **Step 1. Install Required Packages**\n",
        "\n",
        "Installs the `honegumi-rag-assistant` package. Output is suppressed for a cleaner notebook experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "746e530e",
      "metadata": {
        "id": "746e530e"
      },
      "outputs": [],
      "source": [
        "!pip install honegumi-rag-assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77f9b12e",
      "metadata": {
        "id": "77f9b12e"
      },
      "source": [
        "## **Step 2. Mount Google Drive**\n",
        "Allows the notebook to save the vector store and generated code to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef75f66e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef75f66e",
        "outputId": "2da76bc5-d0f0-40a9-f2b0-821437d8056c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e4034da",
      "metadata": {
        "id": "6e4034da"
      },
      "source": [
        "## **Step 3. Set Your API Keys**\n",
        "Honegumi RAG Assistant requires two API keys:\n",
        "\n",
        "- `OPENAI_API_KEY` â€“ for accessing GPT models (e.g., GPT-5, GPT-4o)\n",
        "- `LANGCHAIN_API_KEY` â€“ for logging execution traces to LangSmith (optional but recommended)\n",
        "\n",
        "Choose one of the following methods:\n",
        "\n",
        "### **Option A: Set Environment Variables Directly**\n",
        "Replace the placeholders with your actual keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ad8e3a",
      "metadata": {
        "id": "38ad8e3a"
      },
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY=sk-...\n",
        "%env LANGCHAIN_API_KEY=lsv2_..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "486c88e0",
      "metadata": {
        "id": "486c88e0"
      },
      "source": [
        "### **Option B: Use the Colab Secrets Sidebar**\n",
        "1. In the left Secrets tab (ðŸ”‘), add two secrets with exact names:\n",
        "   - `OPENAI_API_KEY`\n",
        "   - `LANGCHAIN_API_KEY`\n",
        "\n",
        "2. Then run the following to inject them into your environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17b550d4",
      "metadata": {
        "id": "17b550d4"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# List whatever secrets you've added in the UI\n",
        "for key in (\"OPENAI_API_KEY\", \"LANGCHAIN_API_KEY\"):\n",
        "    val = userdata.get(key)  # Grabs the secret by name\n",
        "    if val is not None:\n",
        "        os.environ[key] = val  # Inject into the process env"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36effd28",
      "metadata": {
        "id": "36effd28"
      },
      "source": [
        "This makes your API keys available to Honegumi RAG Assistant without hardcoding them into the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c36f8a44",
      "metadata": {
        "id": "c36f8a44"
      },
      "source": [
        "## **Step 4. Build Vector Store (One-Time Setup)**\n",
        "\n",
        "The vector store contains embeddings of Ax Platform documentation, enabling the assistant to retrieve relevant context when generating code.\n",
        "\n",
        "**Note:** This defaults to Ax v0.4.3 (matching the honegumi dependency). This ensures documentation matches the API version used in generated code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "429bff4a",
      "metadata": {
        "id": "429bff4a"
      },
      "outputs": [],
      "source": [
        "# Set the path where the vector store will be saved\n",
        "VECTORSTORE_PATH = \"/content/drive/MyDrive/honegumi_data/ax_docs_vectorstore\"\n",
        "\n",
        "# Build the vector store using the installed package\n",
        "from honegumi_rag_assistant.build_vector_store import main\n",
        "import sys\n",
        "\n",
        "# Pass arguments to the build script\n",
        "sys.argv = ['build_vector_store.py', '--output', VECTORSTORE_PATH]\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ec79750",
      "metadata": {},
      "source": [
        "## **Step 5. Set Vector Store Path**\n",
        "\n",
        "Configure environment variables and reload settings to ensure the assistant can find the vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f96053e",
      "metadata": {
        "id": "7f96053e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['AX_DOCS_VECTORSTORE_PATH'] = \"/content/drive/MyDrive/honegumi_data/ax_docs_vectorstore\"\n",
        "os.environ['OUTPUT_DIR'] = \"/content/drive/MyDrive/honegumi_data/honegumi_outputs\"\n",
        "\n",
        "# IMPORTANT: Reload settings if package was already imported\n",
        "# This ensures the settings pick up the new environment variables\n",
        "try:\n",
        "    from honegumi_rag_assistant.app_config import settings\n",
        "    settings.reload_from_env()\n",
        "    print(f\"âœ“ Vector store path set to: {settings.retrieval_vectorstore_path}\")\n",
        "except ImportError:\n",
        "    # Package not yet imported, settings will load correctly on first import\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f41796a8",
      "metadata": {
        "id": "f41796a8"
      },
      "source": [
        "## **Step 6. Run Honegumi RAG Assistant**\n",
        "\n",
        "Now you can describe your optimization problem and let the assistant generate code! (You can find an example run in the hidden output)\n",
        "\n",
        "Use the Python API directly within the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7364986",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d7364986",
        "outputId": "01fa62f0-8e72-4d2c-c732-51c954bffb9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing problem and selecting optimization parameters...\n",
            "Generating code skeleton using Honegumi...\n",
            "Planning retrieval strategy...\n",
            "Skeleton is sufficient, skipping retrieval\n",
            "\n",
            "================================================================================\n",
            "GENERATED CODE\n",
            "================================================================================\n",
            "# Generated by Honegumi (https://arxiv.org/abs/2502.06815)\n",
            "# %pip install ax-platform==0.4.3 matplotlib\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "\n",
            "obj1_name = \"branin\"\n",
            "\n",
            "\n",
            "def branin(x1, x2):\n",
            "    y = float(\n",
            "        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n",
            "        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n",
            "        + 10\n",
            "    )\n",
            "\n",
            "    return y\n",
            "\n",
            "\n",
            "ax_client = AxClient()\n",
            "\n",
            "ax_client.create_experiment(\n",
            "    parameters=[\n",
            "        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [-5.0, 10.0]},\n",
            "        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, 10.0]},\n",
            "    ],\n",
            "    objectives={\n",
            "        obj1_name: ObjectiveProperties(minimize=True),\n",
            "    },\n",
            ")\n",
            "\n",
            "\n",
            "for i in range(19):\n",
            "\n",
            "    parameterization, trial_index = ax_client.get_next_trial()\n",
            "\n",
            "    # extract parameters\n",
            "    x1 = parameterization[\"x1\"]\n",
            "    x2 = parameterization[\"x2\"]\n",
            "\n",
            "    results = branin(x1, x2)\n",
            "    ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n",
            "\n",
            "best_parameters, metrics = ax_client.get_best_parameters()\n",
            "\n",
            "\n",
            "# Plot results\n",
            "objectives = ax_client.objective_names\n",
            "df = ax_client.get_trials_data_frame()\n",
            "\n",
            "fig, ax = plt.subplots(figsize=(6, 4), dpi=150)\n",
            "ax.scatter(df.index, df[objectives], ec=\"k\", fc=\"none\", label=\"Observed\")\n",
            "ax.plot(\n",
            "    df.index,\n",
            "    np.minimum.accumulate(df[objectives]),\n",
            "    color=\"#0033FF\",\n",
            "    lw=2,\n",
            "    label=\"Best to Trial\",\n",
            ")\n",
            "ax.set_xlabel(\"Trial Number\")\n",
            "ax.set_ylabel(objectives[0])\n",
            "\n",
            "ax.legend()\n",
            "plt.show()\n",
            "\n",
            "# Generated by adapting a Honegumi skeleton for chemical reaction optimization\n",
            "# %pip install ax-platform==0.4.3 matplotlib\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
            "\n",
            "\n",
            "# Metric name for the objective\n",
            "yield_metric_name = \"yield_percent\"\n",
            "\n",
            "# Reproducible randomness for simulated measurements\n",
            "_rng = np.random.default_rng(20251020)\n",
            "\n",
            "\n",
            "def evaluate_chemical_reaction(temperature_celsius: float, pressure_bar: float) -> float:\n",
            "    \"\"\"\n",
            "    Simulate the yield (%) of a chemical reaction as a function of temperature (Â°C) and pressure (bar).\n",
            "\n",
            "    In production, replace this with actual experimental/simulation logic that:\n",
            "      - Runs the reaction under the specified conditions\n",
            "      - Measures product yield as a percentage (0-100)\n",
            "      - Returns the measured yield as a float\n",
            "\n",
            "    The model below is a smooth synthetic surface with a maximum near an optimum (T*, P*) and mild noise,\n",
            "    intended to mimic realistic experimental response behavior.\n",
            "\n",
            "    Args:\n",
            "        temperature_celsius: Reaction temperature in degrees Celsius (50 to 200).\n",
            "        pressure_bar: Reaction pressure in bar (1 to 10).\n",
            "\n",
            "    Returns:\n",
            "        float: Reaction yield percentage (0 to 100).\n",
            "    \"\"\"\n",
            "    # Optimum and shape parameters for a plausible response surface\n",
            "    T_opt = 135.0\n",
            "    P_opt = 6.5\n",
            "    sigma_T = 22.0\n",
            "    sigma_P = 1.4\n",
            "\n",
            "    # 2D Gaussian peak around (T_opt, P_opt)\n",
            "    t_term = ((temperature_celsius - T_opt) / sigma_T) ** 2\n",
            "    p_term = ((pressure_bar - P_opt) / sigma_P) ** 2\n",
            "    base_peak = 92.0 * np.exp(-0.5 * (t_term + p_term))\n",
            "\n",
            "    # Mild asymmetry and interaction to avoid a perfectly symmetric surface\n",
            "    asymmetry_t = 6.0 * np.exp(-((temperature_celsius - 150.0) / 28.0) ** 2)\n",
            "    interaction = 4.0 * np.exp(-((temperature_celsius - 160.0) / 35.0) ** 2) * (\n",
            "        1.0 - np.exp(-((pressure_bar - 8.0) / 1.1) ** 2)\n",
            "    )\n",
            "\n",
            "    # Combine contributions and add small measurement noise\n",
            "    noise = _rng.normal(loc=0.0, scale=0.6)\n",
            "    yield_value = base_peak + asymmetry_t + interaction + noise\n",
            "\n",
            "    # Clamp to valid percentage range\n",
            "    return float(np.clip(yield_value, 0.0, 100.0))\n",
            "\n",
            "\n",
            "# Initialize Ax client with default Bayesian optimization model (GP + EI)\n",
            "ax_client = AxClient()\n",
            "\n",
            "# Define the experiment: two continuous parameters and a single objective to maximize\n",
            "ax_client.create_experiment(\n",
            "    parameters=[\n",
            "        {\n",
            "            \"name\": \"temperature_celsius\",\n",
            "            \"type\": \"range\",\n",
            "            \"bounds\": [50.0, 200.0],\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"pressure_bar\",\n",
            "            \"type\": \"range\",\n",
            "            \"bounds\": [1.0, 10.0],\n",
            "        },\n",
            "    ],\n",
            "    objectives={\n",
            "        yield_metric_name: ObjectiveProperties(minimize=False),\n",
            "    },\n",
            ")\n",
            "\n",
            "# Optimization loop: request trials from Ax, evaluate, and report results back\n",
            "num_trials = 25\n",
            "for _ in range(num_trials):\n",
            "    parameterization, trial_index = ax_client.get_next_trial()\n",
            "\n",
            "    temperature_celsius = float(parameterization[\"temperature_celsius\"])\n",
            "    pressure_bar = float(parameterization[\"pressure_bar\"])\n",
            "\n",
            "    try:\n",
            "        measured_yield = evaluate_chemical_reaction(\n",
            "            temperature_celsius=temperature_celsius,\n",
            "            pressure_bar=pressure_bar,\n",
            "        )\n",
            "        # For a single-objective experiment, a float is a valid shorthand for raw_data\n",
            "        ax_client.complete_trial(trial_index=trial_index, raw_data=measured_yield)\n",
            "    except Exception:\n",
            "        # If something goes wrong during evaluation, mark the trial as failed\n",
            "        ax_client.log_trial_failure(trial_index=trial_index)\n",
            "\n",
            "# Retrieve the best found parameters and their corresponding objective value estimate\n",
            "best_parameters, best_values = ax_client.get_best_parameters()\n",
            "best_yield_mean = None\n",
            "if isinstance(best_values, dict) and yield_metric_name in best_values:\n",
            "    metric_info = best_values[yield_metric_name]\n",
            "    # metric_info typically includes \"mean\" and \"sem\"\n",
            "    best_yield_mean = metric_info.get(\"mean\", None)\n",
            "\n",
            "print(\"Best parameters found:\")\n",
            "print(best_parameters)\n",
            "print(f\"Estimated best yield (%) (model-based): {best_yield_mean}\")\n",
            "\n",
            "# Plot observed yields over trials with best-so-far curve\n",
            "df = ax_client.get_trials_data_frame()\n",
            "\n",
            "# Extract the yield series robustly\n",
            "if yield_metric_name in df.columns:\n",
            "    yield_series = df[yield_metric_name].astype(float).reset_index(drop=True)\n",
            "else:\n",
            "    # Fallback: handle potential DataFrame shape variations\n",
            "    yield_series = df[[yield_metric_name]].iloc[:, 0].astype(float).reset_index(drop=True)\n",
            "\n",
            "x = np.arange(len(yield_series))\n",
            "best_so_far = np.maximum.accumulate(yield_series.values)\n",
            "\n",
            "fig, ax = plt.subplots(figsize=(6, 4), dpi=150)\n",
            "ax.scatter(x, yield_series, ec=\"k\", fc=\"none\", label=\"Observed yield\")\n",
            "ax.plot(x, best_so_far, color=\"#0033FF\", lw=2, label=\"Best to trial\")\n",
            "ax.set_xlabel(\"Trial number\")\n",
            "ax.set_ylabel(\"Yield (%)\")\n",
            "ax.set_title(\"Chemical Reaction Optimization: Yield vs. Trial\")\n",
            "ax.legend()\n",
            "plt.tight_layout()\n",
            "plt.show()\n"
          ]
        }
      ],
      "source": [
        "from honegumi_rag_assistant.orchestrator import run_from_text\n",
        "\n",
        "# Describe your optimization problem\n",
        "problem = \"\"\"\n",
        "Optimize temperature (50-200Â°C) and pressure (1-10 bar) for maximum yield\n",
        "in a chemical reaction.\n",
        "\"\"\"\n",
        "\n",
        "# Generate code (streaming enabled by default)\n",
        "code = run_from_text(\n",
        "    problem,\n",
        "    output_dir=\"/content/drive/MyDrive/honegumi_data/honegumi_outputs\",  # Set to None to skip saving\n",
        "    debug=False,  # Set to True for detailed logging\n",
        "    enable_review=False  # Set to True for code review (slower but more accurate)\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERATED CODE\")\n",
        "print(\"=\"*80)\n",
        "print(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b6d61b",
      "metadata": {
        "id": "68b6d61b"
      },
      "source": [
        "## **Step 7. View Generated Code**\n",
        "\n",
        "If you specified `--output-dir`, navigate to your Google Drive folder to find:\n",
        "- `honegumi_generated_<hash>.py` - The complete Python script for your optimization problem\n",
        "\n",
        "You can also trace the assistant's reasoning in your [LangSmith dashboard](https://smith.langchain.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b12988",
      "metadata": {
        "id": "31b12988"
      },
      "source": [
        "## **Example Problems to Try**\n",
        "\n",
        "Here are some example optimization problems you can try:\n",
        "\n",
        "### **1. Chemical Process Optimization**\n",
        "```\n",
        "Optimize temperature (100-300Â°C), pressure (1-5 bar), and catalyst concentration (0.1-1.0 M)\n",
        "to maximize conversion rate in a catalytic reaction.\n",
        "```\n",
        "\n",
        "### **2. Materials Design**\n",
        "```\n",
        "Optimize composition of a polymer blend: Component A (0-100%), Component B (0-100%),\n",
        "and curing temperature (80-150Â°C) to maximize tensile strength while minimizing cost.\n",
        "```\n",
        "\n",
        "### **3. Machine Learning Hyperparameters**\n",
        "```\n",
        "Optimize neural network hyperparameters: learning rate (1e-5 to 1e-1),\n",
        "batch size (16 to 256), and dropout rate (0.1 to 0.5) to maximize validation accuracy.\n",
        "```\n",
        "\n",
        "### **4. Pharmaceutical Formulation**\n",
        "```\n",
        "Optimize drug formulation: API concentration (5-20 mg/mL), pH (4-8),\n",
        "and excipient ratio (0.5-2.0) to maximize bioavailability and minimize side effects.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
